{
    "collab_server" : "",
    "contents" : "list.of.packages <- c(\"caret\",\"caretEnsemble\",\"mlr\",\"MLmetrics\")\n#list.of.packages <- c(\"caretEnsemble\",\"logicFS\",\" RWeka\",\"ordinalNet\",\"xgboost\",\"mlr\",\"caret\",\"MLmetrics\",\"bartMachine\",\"spikeslab\",\"party\",\"rqPen\",\"monomvn\",\"foba\",\"logicFS\",\"rPython\",\"qrnn\",\"randomGLM\",\"msaenet\",\"Rborist\",\"relaxo\",\"ordinalNet\",\"rrf\",\"frbs\",\"extraTrees\",\"ipred\",\"elasticnet\",\"bst\",\"brnn\",\"Boruta\",\"arm\",\"elmNN\",\"evtree\",\"extraTrees\",\"deepnet\",\"kknn\",\"KRLS\",\"RSNNS\",\"partDSA\",\"plsRglm\",\"quantregForest\",\"ranger\",\"inTrees\")\nnew.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages, dep = TRUE)\n\n#install.packages(\"mlr\", dependencies = c(\"Depends\", \"Suggests\"))\n#install.packages(\"caret\", dependencies = c(\"Depends\", \"Suggests\"))\n#install.packages(\"SuperLearner\", dependencies = c(\"Depends\", \"Suggests\"))\n#install.packages(\"rattle\", dependencies = c(\"Depends\", \"Suggests\"))\n\n# Load libraries\n#library(mlbench)\nlibrary(caret)\n#library(caretEnsemble)\nlibrary(MLmetrics)\n\n\nbefore.last.alg<-as.matrix(read.csv(\"beforelast algorithm.csv\", sep = \",\",fill=TRUE, header = FALSE,quote=\"\",dec=\".\"))\nlast.alg<-as.matrix(read.csv(\"last algorithm tried.csv\", sep = \",\",fill=TRUE, header = FALSE,quote=\"\",dec=\".\"))\nif(last.alg==before.last.alg){print(\"algorithm may be broken\")}\nwrite.table(last.alg,file = \"beforelast algorithm.csv\",  quote = F, row.names = F,col.names = F)\n\n\n#make sure not to redo a test\ncheck.redundant<-function(df=df.previous.calcs,norming=\"asis\",trans.y=1,withextra=\"missing\",missingdata=\"leaveempty\",datasource=\"mean\" ,column.to.predict=200,allmodel=\"ctree\")\n{\n  for(intern in 1:length(df[,1])){\n    if((any(df[intern,] == norming, na.rm=T))&&\n       (any(df[intern,] == withextra, na.rm=T))&&\n       (any(df[intern,] == missingdata, na.rm=T))&&\n       (any(df[intern,] == datasource, na.rm=T))&&\n       (any(df[intern,] == column.to.predict, na.rm=T))&&\n       (any(df[intern,] == allmodel, na.rm=T))&&\n       (  (df[intern,9] == trans.y)))\n    {return(TRUE)}\n  }\n  return(FALSE)\n}\n\n\n\n\n\nallmodels <- c(\"avNNet\", \"bagEarth\", \"bagEarthGCV\",\n               \"bayesglm\", \"bdk\", \"blackboost\", \"Boruta\", \"brnn\", \"BstLm\" ,\n               \"bstTree\", \"cforest\", \"ctree\", \"ctree2\", \"cubist\", \"DENFIS\",\n               \"dnn\", \"earth\", \"elm\", \"enet\",   \"evtree\",\n               \"extraTrees\",  \"gamLoess\",  \"gaussprLinear\", \"gaussprPoly\", \"gaussprRadial\",\n               \"gcvEarth\",\"glm\", \"glmboost\",  \"icr\", \"kernelpls\",\n               \"kknn\", \"knn\",  \"krlsRadial\", \"lars\" , \"lasso\",\n               \"leapBackward\", \"leapForward\", \"leapSeq\", \"lm\", \"M5\", \"M5Rules\",\n               \"mlpWeightDecay\", \"neuralnet\" , \"partDSA\",\n               \"pcaNNet\", \"pcr\", \"penalized\", \"pls\", \"plsRglm\", \"ppr\",\n               \"qrf\" , \"ranger\",  \"rf\")\nallmodels <- c(\"rlm\", \"rpart\", \"rpart2\",\n               \"RRF\", \"RRFglobal\",  \"simpls\",\n               \"svmLinear\", \"svmPoly\", \"svmRadial\", \"svmRadialCost\",\n               \"widekernelpls\",  \"xgbLinear\",\n               \"xgbTree\")\nallmodels <- c(\"avNNet\",\"BstLm\",\"bstTree\",\"cforest\",\"ctree\",\"ctree2\",\n               \"cubist\",\"earth\",\"enet\",\"evtree\",\"glmboost\",\n               \"icr\",\"kernelpls\",\"kknn\",\"lasso\",\"pcaNNet\",\n               \"pcr\",\"pls\",\"qrf\",\"ranger\",\"rf\"\n)\n#allmodels <- c(\"ranger\")#\"BstLm\",\"enet\",\"lasso\",\n#allmodels <- c(\"rf\")\"rqlasso\",, \"xyf\" \"rvmPoly\", \"rvmRadial\",    \"spls\", \"superpc\" ,   \"treebag\",  \"svmLinear2\",  \"SBC\",\n#allmodels <- c(\"bartMachine\", \"xgbLinear\", \"pcaNNet\",\"svmLinear\",\"glmnet\",\"cforest\",\"cubist\",\"rf\",\"ranger\")\"glmnet\",\n#wow rfRules is really slow \"rfRules\",\"WM\", takes 50min\n# brak everythig \"rbfDDA\",\"ridge\",\"rqnc\",\n# use \"rf\" to test all\nallmodels <- unique(modelLookup()[modelLookup()$forReg,c(1)])\n\n#library(doParallel); cl <- makeCluster(detectCores()); registerDoParallel(cl)\n\n\nadaptControl <- trainControl(method = \"adaptive_cv\",\n                             number = 5, repeats = 2,\n                             adaptive = list(min = 2, alpha = 0.05,\n                                             method = \"gls\", complete = FALSE),\n                             search = \"random\")\nsimpleControl <- trainControl(method = \"cv\",\n                              number = 8,\n                              search = \"random\")\n\n\nseed.const=222\nseed.var=seed.const\ncolumn.to.predict=8\n\nprint(date());\n\nif(!exists(\"gen.count\")){gen.count=17}\ngens.names<-as.matrix(read.table(\"gens names.csv\", sep = \",\",header = FALSE,row.names=1,fill=TRUE, quote=\"\",dec=\".\"))\nfor(gend.data in 1:gen.count){\n  data.source<-as.matrix(read.csv(paste(gens.names[gend.data],\".csv\", sep = \"\"), sep = \",\",fill=TRUE, header = FALSE,quote=\"\",dec=\".\"))\n  datasource<-gens.names[gend.data]\n  missingdatas=c(\"ignore\")\n  for(missingdata in missingdatas){\n    withextras=c(\"none\")\n    for(withextra in withextras){\n      ################data wrestling###############\n\n      dependant.selection=complete.cases(data.source[,column.to.predict])\n      df.previous.calcs=as.data.frame(read.csv(file=\"gen test out.csv\", header = FALSE, sep = \",\", quote = \"\",\n                                               dec = \".\", fill = TRUE, comment.char = \"\"))\n      unimportant.computations<-vector(mode = \"logical\",length=length(df.previous.calcs[,1])  )\n      for(intern in 1:length(df.previous.calcs[,1])){\n        if((any(df.previous.calcs[intern,] == withextra, na.rm=T))&&\n           (any(df.previous.calcs[intern,] == missingdata, na.rm=T))&&\n           (any(df.previous.calcs[intern,] == datasource, na.rm=T))&&\n           (any(df.previous.calcs[intern,] == column.to.predict, na.rm=T)))\n        {unimportant.computations[intern]<-T}}\n\n      df.previous.calcs<-df.previous.calcs[unimportant.computations,]\n\n\n\n      data.source=data.frame( data.source[,column.to.predict],data.source[,1:2], data.source[,4:(column.to.predict-1)], data.source[,(column.to.predict+1):length( data.source[1,])])\n\n\n      normings=c(\"range01\",\"centernscale\",\"YeoJohnson\",\"expoTrans\",\"quantile\",\"asis\")#\n      for(norming in normings) {\n        for(trans.y in 1:2) {\n          df.toprocess=data.source\n          y.untransformed<-df.toprocess[,1]\n\n          if(norming==\"centernscale\"){\n            preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c(\"center\", \"scale\"))\n            df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}\n          if(norming==\"range01\"){\n            preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c(\"range\"))\n            df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}\n          if(norming==\"expoTrans\"){\n            preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c(\"expoTrans\"))\n            df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}\n          if(norming==\"YeoJohnson\"){\n            preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c(\"YeoJohnson\"))#\"center\", \"scale\",\n            df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}\n\n          if((norming==\"asis\")&&(trans.y==2)){next}\n\n\n          ################preprocess###########\n          df.toprocess=data.frame(df.toprocess[dependant.selection,])\n          y.untransformed=y.untransformed[dependant.selection]\n          if(norming==\"quantile\"){\n            for(Clol in trans.y:length(data.source[1,])){\n              df.toprocess[,Clol]<- (rank(df.toprocess[,Clol],na.last = \"keep\",ties.method = \"average\")-1) }\n            preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c(\"range\"))\n            df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}\n\n\n          loess.model<-loess(y.untransformed~ df.toprocess[,1],span = 0.21, degree = 1)\n\n\n          #df.toprocess = data.frame(df.toprocess,)\n          #nzv <- nearZeroVar(df.toprocess[,1:10])#, saveMetrics= TRUE\n          #nzv[nzv$nzv,][1:10,]\n          #df.toprocess = (df.toprocess[, -nzv])\n\n          tuneLength=16\n          tuneLength2=10\n          seed.var=seed.var+1\n          set.seed(seed.var)\n          inTrain <- createDataPartition(y = df.toprocess[,1],\n                                         p = .75,\n                                         list = FALSE)\n          training <- df.toprocess[ inTrain,]\n          testing  <- df.toprocess[-inTrain,]\n\n\n          ######for all models########\n          for(allmodel in allmodels){#just before all models define d.f and reduce it\n            write.table(allmodel,file = \"last algorithm tried.csv\",  quote = F, row.names = F,col.names = F)\n            bad.models=c(\"brnn\",\"gamLoess\",\"ANFIS\",\"FIR.DM\",\"FS.HGD\",\"nodeHarvest\",\"mlpWeightDecayML\",\"monmlp\",\"mlp\",\"mlpWeightDecay\",\"mlpSGD\",\"rbf\",\"rbfDDA\",\"rfRules\",\"GFS.FR.MOGUL\",\"mlpML\",\"HYFIS\",\"GFS.THRIFT\" ,\"GFS.LT.RS\")\n            if(allmodel %in% bad.models) {next()} #gamLoess crashes. the capitals are slow and terrible\n            library(caret) #mlp...s creat some bizzare problem that breaks caret::train ##nodeHarvest is SLOW ##\"rbf\"crash R \"rbfDDA\" crash train and really bad #rfRules is REALLY slow.##\"pythonKnnReg\",pythonKnnReg can not install\n\n            list.of.packages <-getModelInfo(allmodel)[[1]]$library\n            new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]\n            if(length(new.packages)) install.packages(new.packages, dep = TRUE)\n            if(length(list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])])){\n              write.table(paste(\"Fail\",\"Fail\",\"Fail\",\"Fail\",\"PackageFail\",date(),allmodel,column.to.predict,trans.y,datasource,missingdata,withextra,norming,round(proc.time()[3]-when[3]),  sep = \",\"),\n                          file = \"gen test out.csv\", append =TRUE, quote = F, sep = \",\",\n                          eol = \"\\n\", na = \"NA\", dec = \".\", row.names = F,\n                          col.names = F, qmethod = \"double\")\n              next()}\n            when<-proc.time()\n\n            if(length(df.previous.calcs[,1])>0){\n              if(check.redundant(df=df.previous.calcs,norming=norming,trans.y=trans.y,withextra=withextra,missingdata=missingdata,datasource=datasource ,column.to.predict=column.to.predict,allmodel=allmodel)){next}}\n            not.failed=0\n            set.seed(seed.const)\n            try({trainedmodel <- train(x=data.frame(training[,2:length(training[1,])]),\n                                       y = df.toprocess[inTrain,1],\n                                       method = allmodel,\n                                       trControl = adaptControl,\n                                       tuneLength = tuneLength)\n            #SVMS crash cause mean needs na.rm to = T #\n            predicted.outcomes<-predict(trainedmodel, newdata=(testing))\n            p <- data.frame(predicted.outcomes,testing)\n            #Rsqd =(1-sum((p[,2]-p[,1])^2, na.rm = T)/sum((p[,2]-mean(p[,2]))^2, na.rm = T))\n            Rsqd=1-RMSE(p[,1],p[,2])/RMSE(p[,2],mean(p[,2], na.rm = T))\n            #mean.improvement=1-mean(abs(p[,2]-p[,1]), na.rm = T)/mean(abs(p[,2]-median(p[,2])), na.rm = T)\n            mean.improvement=1-MAE(p[,1],p[,2])/MAE(p[,2],mean(p[,2], na.rm = T))\n            p<- data.frame(predict(loess.model,predicted.outcomes),y.untransformed[-inTrain])\n            #RMSE=(sqrt(mean((p[,1]-p[,2])^2, na.rm = T)))\n            RMSE=RMSE(p[,1],p[,2])\n            #RMSE.mean=(sqrt(mean((p[,2]-mean(p[,2]))^2, na.rm = T)))\n            RMSE.mean=RMSE(p[,2],mean(p[,2], na.rm = T))\n            #mae=mean(abs(p[,2]-p[,1]), na.rm = T)\n            mae=MAE(p[,1],p[,2])\n\n            wut=print(trainedmodel,selectCol=TRUE)\n            overRMSE=as.numeric(wut[wut[,length(wut[1,])]==\"*\",length(wut[1,])-3])\n            replace.overRMSE=1\n            try({if(is.numeric(overRMSE)){replace.overRMSE=0}})\n            if(replace.overRMSE==1){overRMSE=-1}\n            if(length(overRMSE)<1){overRMSE=-1}\n\n            #print(c(Rsqd,RMSE,overRMSE,date(),allmodel,column.to.predict,datasource,missingdata,withextra,norming,adaptControl$search,seed.const,adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,adaptControl$adaptive$min,trainedmodel$bestTune))\n            write.table(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),round(overRMSE,digits = 3),round(RMSE,digits = 3),round(mae,digits = 3),date(),allmodel,column.to.predict,trans.y,datasource,missingdata,withextra,norming,RMSE.mean,adaptControl$search,seed.const,round(proc.time()[3]-when[3]),adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,adaptControl$adaptive$min,trainedmodel$bestTune),\n                        file = \"gen test out.csv\", append =TRUE, quote = F, sep = \",\",\n                        eol = \"\\n\", na = \"NA\", dec = \".\", row.names = F,\n                        col.names = F, qmethod = \"double\")\n            print(date())\n            not.failed=1\n            })\n\n            if(not.failed==0) {\n              try({trainedmodel <- train(x=data.frame(training[,2:length(training[1,])]),\n                                         y =  df.toprocess[inTrain,1],\n                                         method = allmodel,\n                                         trControl = simpleControl,\n                                         tuneLength = tuneLength2)\n\n              predicted.outcomes<-predict(trainedmodel, newdata=(testing))\n              p <- data.frame(predicted.outcomes,testing)\n              #Rsqd =(1-sum((p[,2]-p[,1])^2, na.rm = T)/sum((p[,2]-mean(p[,2]))^2, na.rm = T))\n              Rsqd=1-RMSE(p[,1],p[,2])/RMSE(p[,2],mean(p[,2], na.rm = T))\n              #mean.improvement=1-mean(abs(p[,2]-p[,1]), na.rm = T)/mean(abs(p[,2]-median(p[,2])), na.rm = T)\n              mean.improvement=1-MAE(p[,1],p[,2])/MAE(p[,2],mean(p[,2], na.rm = T))\n              p<- data.frame(predict(loess.model,predicted.outcomes),y.untransformed[-inTrain])\n              #RMSE=(sqrt(mean((p[,1]-p[,2])^2, na.rm = T)))\n              RMSE=RMSE(p[,1],p[,2])\n              #RMSE.mean=(sqrt(mean((p[,2]-mean(p[,2]))^2, na.rm = T)))\n              RMSE.mean=RMSE(p[,2],mean(p[,2], na.rm = T))\n              #mae=mean(abs(p[,2]-p[,1]), na.rm = T)\n              mae=MAE(p[,1],p[,2])\n\n              wut=print(trainedmodel,selectCol=TRUE)\n              overRMSE=as.numeric(wut[wut[,length(wut[1,])]==\"*\",length(wut[1,])-3])\n              replace.overRMSE=1\n              try({if(is.numeric(overRMSE)){replace.overRMSE=0}})\n              if(replace.overRMSE==1){overRMSE=-1}\n              if(length(overRMSE)<1){overRMSE=-1}\n\n              #print(c(Rsqd,RMSE,overRMSE,date(),allmodel,column.to.predict,datasource,missingdata,withextra,norming,adaptControl$search,seed.const,adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,adaptControl$adaptive$min,trainedmodel$bestTune))\n              write.table(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),round(overRMSE,digits = 3),round(RMSE,digits = 3),round(mae,digits = 3),date(),allmodel,column.to.predict,trans.y,datasource,missingdata,withextra,norming,RMSE.mean,simpleControl$search,seed.const,round(proc.time()[3]-when[3]),simpleControl$method,tuneLength2,simpleControl$number,\"no rep\",\"no min\",trainedmodel$bestTune),\n                          file = \"gen test out.csv\", append =TRUE, quote = F, sep = \",\",\n                          eol = \"\\n\", na = \"NA\", dec = \".\", row.names = F,\n                          col.names = F, qmethod = \"double\")\n              print(date())\n              not.failed=1\n              })\n\n            }\n            if(not.failed==0) {\n              print(c(\"failed\",\"failed\",date(),datasource,missingdata,withextra,norming,allmodel))\n              write.table(paste(\"Fail\",\"Fail\",\"Fail\",\"Fail\",\"Fail\",date(),allmodel,column.to.predict,trans.y,datasource,missingdata,withextra,norming,round(proc.time()[3]-when[3]),  sep = \",\"),\n                          file = \"gen test out.csv\", append =TRUE, quote = F, sep = \",\",\n                          eol = \"\\n\", na = \"NA\", dec = \".\", row.names = F,\n                          col.names = F, qmethod = \"double\")\n              write.table(paste(\"Fail\",date(),allmodel,  sep = \", \"),\n                          file = \"backup.csv\", append =TRUE, quote = F, sep = \",\",\n                          eol = \"\\n\", na = \"NA\", dec = \".\", row.names = F,\n                          col.names = F, qmethod = \"double\")\n            }\n            if(not.failed==1) {\n              write.table(paste(\"Succ\",date(),allmodel,  sep = \", \"),\n                          file = \"backup.csv\", append =TRUE, quote = F, sep = \",\",\n                          eol = \"\\n\", na = \"NA\", dec = \".\", row.names = F,\n                          col.names = F, qmethod = \"double\")}\n          }}}}}}\n#stopCluster(cl)\n",
    "created" : 1501666333655.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "429994267",
    "id" : "4F4A6F16",
    "lastKnownWriteTime" : 1501672227,
    "last_content_update" : -2147483648,
    "path" : "C:/Users/Dm/Desktop/generated data test/Model tester on Generated data .R",
    "project_path" : "Model tester on Generated data .R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}