ttdz<-data.frame(exp.res.noF,orderedlevels)
ttdd<-ttdz[expiramentresults[,1]!="Fail",]
p <- ggplot(as.data.frame(ttdd), aes(x=melt(ttdd)[,1],y=melt(ttdd)[,3]))
p  +geom_boxplot(width=0.4) + stat_summary(fun.y = "mean", colour = "red", size = 1, geom = "point")+
theme(axis.text.x=element_text(size=7, angle=270,hjust=0.95,vjust=0.2))+scale_x_discrete(position = "top")+
xlab(paste("task in",exp.name)) + ylab("detectability MAE, boxplot and mean red dot") + coord_flip()
ggsave(paste(exp.name,"PowerTaskMean.png", sep = ""),plot = last_plot(),scale = 3)
#some algos are better at some category of tasks and missing them could affect statistic metric index
########difference between %MAE & %RMSE by task####
exp.res.noF<-expiramentresults[,1]
exp.res.noF<-as.numeric(levels(exp.res.noF))[exp.res.noF]
exp.res.noF[is.na(exp.res.noF)]<-0
exp.res.noF2<-expiramentresults[,2]
exp.res.noF2<-as.numeric(levels(exp.res.noF2))[exp.res.noF2]
exp.res.noF2[is.na(exp.res.noF2)]<-0
Results.Defactor<-data.frame(exp.res.noF,exp.res.noF2,expiramentresults[,3:length(expiramentresults[1,])])
exp.res.noFZ<-exp.res.noF;exp.res.noFZ2<-exp.res.noF2
for(countr in 1:length(exp.res.noFZ))
{if(exp.res.noFZ[countr]<0) exp.res.noFZ[countr]<-0
if(exp.res.noFZ2[countr]<0) exp.res.noFZ2[countr]<-0 }
res.diff<-round((exp.res.noFZ-exp.res.noFZ2),digits = 3)
rel.res.diff<-(round((exp.res.noFZ-exp.res.noFZ2)/(exp.res.noFZ+exp.res.noFZ2),digits = 3))
rel.res.diff[is.na(rel.res.diff)]<-0
diff.df<-data.frame()
countr=0
for(algo in unique(Results.Defactor[,10]))
{
countr=countr+1
only.algo<-as.logical((Results.Defactor[,10]==algo)*(expiramentresults[,1]!="Fail"))
only.algo[is.na(only.algo)]<-F
if(sum(only.algo, na.rm=T)<1) {
countr=countr-1
next()}
diff.df[countr,1]<-algo
diff.df[countr,2]<-sum(only.algo, na.rm=T)
fivenumber<-round(fivenum(res.diff[only.algo],na.rm = T),digits = 3)
diff.df[countr,3]<-(fivenumber[1]);diff.df[countr,4]<-(fivenumber[2])
diff.df[countr,5]<-(fivenumber[3]);diff.df[countr,6]<-(fivenumber[4]);diff.df[countr,7]<-(fivenumber[5])
diff.df[countr,8]<-round(mean(res.diff[only.algo],na.rm = T),digits = 3)
fivenumber<-round(fivenum(rel.res.diff[only.algo],na.rm = T),digits = 3)
diff.df[countr,9]<-(fivenumber[1]);diff.df[countr,10]<-(fivenumber[2])
diff.df[countr,11]<-(fivenumber[3]);diff.df[countr,12]<-(fivenumber[4]);diff.df[countr,13]<-(fivenumber[5])
diff.df[countr,14]<-round(mean(rel.res.diff[only.algo],na.rm = T),digits = 3)
}
iti <- order(diff.df[,5],diff.df[,11])
diff.df<-rbind(diff.df)[iti,]
write.table(diff.df,
file = paste(exp.name,"DiffTask.csv", sep = ""), append =F, quote = F, sep = ",",
eol = "\n", na = "", dec = ".", row.names = F,
col.names = F, qmethod = "double")
#diff.df<-data.frame(diff.df, row.names = 1:length(diff.df[,1]))
not.interesting<-(diff.df[,6]<10)+ is.na(diff.df[,6])
I.diff.df<-diff.df#[!not.interesting,]
z<-ggplot(I.diff.df, aes(y = I.diff.df[,4], x = reorder(I.diff.df[,1], I.diff.df[,8]))) + geom_point()+ coord_flip()
z+ geom_point(colour="red",aes(I.diff.df[,1] ,I.diff.df[,8]),na.rm = TRUE)+
geom_point(colour="blue",aes(I.diff.df[,1] ,I.diff.df[,6]))+
geom_point(colour="green",aes(I.diff.df[,1] ,(I.diff.df[,7])))+
ylab(paste("%MAE - %RMSE, Bk L.Quartile, R mean, Bu U.Quart, G max")) + xlab("")
ggsave(paste(exp.name,"DiffTask.png", sep = ""),plot = last_plot(),scale = 3)
#########acceptable minimum ######
acceptablePloss<-.05
lowestFindScore<-.01
acceptAlgo.df<-data.frame()
acceptAlgo.df[1,1]<-NA
acceptAlgo.df[,c(1:400)]<-NA
acceptAlgo.Rdf<-data.frame()
acceptAlgo.Rdf[1,1]<-NA
acceptAlgo.Rdf[,c(1:400)]<-NA
countr=0
for(algo in unique(expiramentresults[,10]))
{
countr=countr+1
only.algo<-as.logical((expiramentresults[,10]==algo)*(expiramentresults[,1]!="Fail"))
only.algo[is.na(only.algo)]<-F
if(sum(only.algo, na.rm=T)<1) {
countr=countr-1
next()}
taskSeek=(power.df[,1]==algo)
if(power.df[taskSeek,5]<lowestFindScore) {countr=countr-1 ; next()}
minAccept<-power.df[taskSeek,5]*(1-acceptablePloss)
acceptAlgo.df[countr,1]<-algo
acceptAlgo<-as.logical((exp.res.noF>minAccept)*only.algo)
acceptAlgo.df[countr,2]<-sum(acceptAlgo)
acceptAlgo.df[countr,3]<-power.df[taskSeek,5]
acceptAlgo.df[countr,4:(sum(acceptAlgo)+3)]<-as.character(expiramentresults[acceptAlgo,7])
acceptAlgo.Rdf[countr,4:(sum(acceptAlgo)+3)]<-as.numeric(as.character(expiramentresults[acceptAlgo,1]))
}
for(countr in 1:length(acceptAlgo.df[,3]))
{
iti <- order(as.numeric(acceptAlgo.Rdf[countr,4:(acceptAlgo.df[countr,2]+3)]), decreasing = T)
acceptAlgo.df[countr,4:(acceptAlgo.df[countr,2]+3)]<-(acceptAlgo.df[countr,4:(acceptAlgo.df[countr,2]+3)])[iti]
}
iti <- order(acceptAlgo.df[,3],acceptAlgo.df[,2])
#acceptAlgo.df<-rbind(acceptAlgo.df)[iti,]
gene.expect[,3]<-1#,gene.expect[length(acceptAlgo.df[,1]),3]
out<-data.frame(acceptAlgo.df[,1:2],acceptAlgo.df[,3:length(acceptAlgo.df[1,])])
write.table(out,
file = paste(exp.name,acceptablePloss,"MinNecessary.csv", sep = ""), append =F, quote = F, sep = ",",
eol = "\n", na = "", dec = ".", row.names = F,
col.names = F, qmethod = "double")
######power to detect#####
exp.res.noF<-expiramentresults[,1]
exp.res.noF<-as.numeric(levels(exp.res.noF))[exp.res.noF]
exp.res.noF[is.na(exp.res.noF)]<-0
exp.res.noF[exp.res.noF<0]<-0
algPower.df<-data.frame()
countr=0
for(algo in unique(expiramentresults[,7]))
{
countr=countr+1
only.algo<-as.logical((expiramentresults[,7]==algo)*(expiramentresults[,1]!="Fail"))
only.algo[is.na(only.algo)]<-F
if(sum(only.algo, na.rm=T)<1) {
countr=countr-1
next()}
algPower.df[countr,1]<-algo
algPower.df[countr,2]<-round(mean(exp.res.noF[only.algo],na.rm = T),digits = 3)
}
algo.max<-vector()
for(countr in 1:length(exp.res.noF)){
for(task in 1:length(power.df[,1])){
if(power.df[task,1]==expiramentresults[countr,10]){
algo.max[countr]<-power.df[task,5]}}}
algo.max[algo.max<.2]<-.2
exp.res.noF<-exp.res.noF/algo.max
#exp.res.noF<-exp.res.noF+1-algo.max
#algPower.df<-data.frame()
countr=0
for(algo in unique(expiramentresults[,7]))
{
countr=countr+1
only.algo<-as.logical((expiramentresults[,7]==algo)*(expiramentresults[,1]!="Fail"))
only.algo[is.na(only.algo)]<-F
if(sum(only.algo, na.rm=T)<1) {
countr=countr-1
next()}
#algPower.df[countr,1]<-algo
algPower.df[countr,3]<-min(exp.res.noF[only.algo],na.rm = T)
algPower.df[countr,4]<-median(exp.res.noF[only.algo],na.rm = T)
#algPower.df[countr,4]<-round(mean(exp.res.noF[only.algo],na.rm = T),digits = 3)
algPower.df[countr,5]<-max(exp.res.noF[only.algo],na.rm = T)
algPower.df[countr,6]<-sum(only.algo, na.rm=T)
algPower.df[countr,7]<-round(quantile(exp.res.noF[only.algo], probs = c(.7), na.rm =T),digits = 3)
algPower.df[countr,8]<-round(quantile(exp.res.noF[only.algo], probs = c(.8), na.rm =T),digits = 3)
algPower.df[countr,9]<-round(quantile(exp.res.noF[only.algo], probs = c(.9), na.rm =T),digits = 3)
}
iti <- order(algPower.df[,4],algPower.df[,8])
algPower.df<-rbind(algPower.df)[iti,]
write.table(algPower.df,
file = paste(exp.name,"Power.csv", sep = ""), append =F, quote = F, sep = ",",
eol = "\n", na = "", dec = ".", row.names = F,
col.names = F, qmethod = "double")
#algPower.df<-data.frame(algPower.df, row.names = 1:length(algPower.df[,1]))
not.interesting<-(algPower.df[,6]<20)+(algPower.df[,4]<.2)+ is.na(algPower.df[,6])
I.power.df<-algPower.df[!not.interesting,]
z<-ggplot(I.power.df, aes(y = I.power.df[,2], x = reorder(I.power.df[,1], I.power.df[,2]))) +
geom_point()+#+##+coord_flip()
theme(axis.text.x=element_text(size=7, angle=270,hjust=0.95,vjust=0.2))+scale_x_discrete(position = "top")
z+ geom_point(colour="red",aes(I.power.df[,1] ,I.power.df[,8]),na.rm = TRUE)+
geom_point(colour="blue",aes(I.power.df[,1] ,I.power.df[,5]))+
xlab("") + ylab("%MAE, ord. by mean, G Succ.Attempts, Bk mean, Bu P R Max 90 80 quant of max for task") +
geom_point(colour="purple",aes(I.power.df[,1] ,I.power.df[,9]))+
geom_point(colour="green",aes(I.power.df[,1] ,(I.power.df[,6]/max(I.power.df[,6])-.45)))
ggsave(paste(exp.name,"Power.png", sep = ""),plot = last_plot(),scale = 3)
#some tasks are harder and thus improvement in them should count for more
#that affects the black mean but not red-blue bc 1-0 is % of max score on that task
#some algos are better at some category of tasks and these tasks are overepresented
#that affects the black mean but less red-blue bc as only method's best 20% matter
z<-ggplot(I.power.df, aes(y = I.power.df[,2], x = reorder(I.power.df[,1], I.power.df[,8]))) +
geom_point()+#+##+coord_flip()
theme(axis.text.x=element_text(size=7, angle=270,hjust=0.95,vjust=0.2))+scale_x_discrete(position = "top")
z+ geom_point(colour="red",aes(I.power.df[,1] ,I.power.df[,8]),na.rm = TRUE)+
geom_point(colour="blue",aes(I.power.df[,1] ,I.power.df[,5]))+
xlab("") + ylab("%MAE, ord. by 80%, G Succ.Attempts, Bk mean, Bu P R Max 90 80 quant of max for task") +
geom_point(colour="purple",aes(I.power.df[,1] ,I.power.df[,9]))+
geom_point(colour="green",aes(I.power.df[,1] ,(I.power.df[,6]/max(I.power.df[,6])-.45)))
ggsave(paste(exp.name,"PowerReorder.png", sep = ""),plot = last_plot(),scale = 3)
z<-ggplot(I.power.df, aes(y = I.power.df[,2], x = reorder(I.power.df[,1], I.power.df[,9]))) +
geom_point()+#+##+coord_flip()
theme(axis.text.x=element_text(size=7, angle=270,hjust=0.95,vjust=0.2))+scale_x_discrete(position = "top")
z+ geom_point(colour="red",aes(I.power.df[,1] ,I.power.df[,8]),na.rm = TRUE)+
geom_point(colour="blue",aes(I.power.df[,1] ,I.power.df[,5]))+
xlab("") + ylab("%MAE, ord. by 90%, G Succ.Attempts, Bk mean, Bu P R Max 90 80 quant of max for task") +
geom_point(colour="purple",aes(I.power.df[,1] ,I.power.df[,9]))+
geom_point(colour="green",aes(I.power.df[,1] ,(I.power.df[,6]/max(I.power.df[,6])-.45)))
ggsave(paste(exp.name,"PowerReorder2.png", sep = ""),plot = last_plot(),scale = 3)
################end#######
setwd(file.path(mainDir))
}
setwd("C:/Users/Dm/Desktop/generated data test")
debugSource('C:/Users/Dm/Desktop/generated data test/expirament analysis selected.R')
setwd("C:/Users/Dm/Desktop/generated data test")
debugSource('C:/Users/Dm/Desktop/generated data test/expirament analysis selected.R')
View(expiramentresultsmain)
setwd("C:/Users/Dm/Desktop/generated data test")
debugSource('C:/Users/Dm/Desktop/generated data test/expirament analysis selected.R')
z<-ggplot(I.fails.df, aes(y = I.fails.df[,4], x = reorder(I.fails.df[,1], I.fails.df[,5]))) + geom_point()+ coord_flip()
z+ geom_point(colour="red",aes(I.fails.df[,1] ,I.fails.df[,3]),na.rm = TRUE)+
geom_point(colour="blue",aes(I.fails.df[,1] ,I.fails.df[,2]))+
geom_point(colour="green",aes(I.fails.df[,1] ,(I.fails.df[,5]*.5*max(I.fails.df[,2]))))+
ylab(paste("Failures, R %fail/NA, Bu Attempts, Bk NA, G Fails")) + xlab("")
I.fails.df
fails.df
unique(expiramentresults[,7])
expiramentresults[,7]
expiramentresultsmain<-read.csv("gen test out random hunt.csv", sep = ",",fill=TRUE, header = F,quote="",dec=".")
setwd("C:/Users/Dm/Desktop/generated data test")
expiramentresultsmain<-read.csv("gen test out random hunt.csv", sep = ",",fill=TRUE, header = F,quote="",dec=".")
summary(expiramentresultsmain[,1])
max(expiramentresultsmain[,1])
max(expiramentresultsmain[,1]levels())
workwith<-expiramentresultsmain[,1]
as.numeric(levels(workwith))[workwith]
summary(as.numeric(levels(workwith))[workwith])
workwith<-expiramentresultsmain[,2]
summary(as.numeric(levels(workwith))[workwith])
Rows=1000
simScores<-matrix(data = 0, nrow = Rows, ncol = 12, byrow = FALSE,dimnames = NULL);
simScores[,11]<-1;###!!!!!!! this may be necessary for many algorithms
#vector of strings to keep names of each project, increase maximum
gens.names=vector(length = 100)
max.out=vector(length = 100)
max.out.sq=vector(length = 100)
max.out.sq[]<-NA
varimport=matrix(data=0, nrow = 100, ncol = 1000)
#single scalar to keep count
gen.count=0
###use 7:  basic sum, interactive latent, random, last bm, last poly, 2nd poly, last ifs
######basic sum C1 + C2 ########
simScores<-matrix(data = 0, nrow = Rows, ncol = 3, byrow = FALSE,dimnames = NULL);
gen.count=gen.count+1
gens.names[gen.count]="basic sum C1 + C2"
max.out[gen.count]=1
varim=c(1,1)
varimport[gen.count,1:length(varim)]=varim
for(Row in 1:Rows){
simScores[Row,1:3]=rnorm(3, mean = 0, sd = 1)
}
for(Row in 1:Rows){
simScores[Row,1]=simScores[Row,2]+simScores[Row,3]
}
write.table(round(simScores,digits  = 3),
file = paste(gens.names[gen.count],".csv",sep=""), append =F, quote = F, sep = ",",
eol = "\n", na = "", dec = ".", row.names = F,
col.names = F, qmethod = "double")
simScores<-matrix(data = 0, nrow = Rows, ncol = 12, byrow = FALSE,dimnames = NULL);
simScores[,11]<-1
######basic latent features######
gen.count=gen.count+1
gens.names[gen.count]="basic latent features"
max.out[gen.count]=1
varim=c(1,1,1,1,1,1,1,1,1)
varimport[gen.count,1:length(varim)]=varim
simPubs<-matrix(data = 0, nrow = 10, ncol = 3, byrow = FALSE,dimnames = NULL)
simGames<-matrix(data = 0, nrow = Rows, ncol = 3, byrow = FALSE,dimnames = NULL)
#simScores<-matrix(data = 0, nrow = Rows, ncol = 11, byrow = FALSE,dimnames = NULL)
for(Col in 1:10)
{simPubs[Col,1:3]=rnorm(3, mean = 0, sd = 1)}
for(Row in 1:Rows)
{simGames[Row,1:3]=rnorm(3, mean = 0, sd = 1)}
for(Col in 1:10){
for(Row in 1:Rows){
simScores[Row,Col]=sum(simPubs[Col,1]*simGames[Row,1],simPubs[Col,2]*simGames[Row,2],simPubs[Col,3]*simGames[Row,3])
}}
write.table(round(simScores,digits  = 3),
file = paste(gens.names[gen.count],".csv", sep = ""), append =F, quote = F, sep = ",",
eol = "\n", na = "", dec = ".", row.names = F,
col.names = F, qmethod = "double")
######bas interactive latent features######
gen.count=gen.count+1
gens.names[gen.count]="bas interactive latent features"
max.out[gen.count]=1
varim=c(1,1,1,1,1,1,1,1,1)
varimport[gen.count,1:length(varim)]=varim
simPubs<-matrix(data = 0, nrow = 10, ncol = 3, byrow = FALSE,dimnames = NULL)
simGames<-matrix(data = 0, nrow = Rows, ncol = 3, byrow = FALSE,dimnames = NULL)
#simScores<-matrix(data = 0, nrow = Rows, ncol = 11, byrow = FALSE,dimnames = NULL)
for(Col in 1:10)
{simPubs[Col,1:3]=runif(3, min = 0, max = 2)}
for(Row in 1:Rows)
{simGames[Row,1:3]=runif(3, min = 0, max = 2)}
for(Col in 1:10){
for(Row in 1:Rows){
simScores[Row,Col]=(simPubs[Col,1]*simGames[Row,1])+(simGames[Row,2]^simPubs[Col,2])*(simPubs[Col,3]^simGames[Row,3])
}}
write.table(round(simScores,digits  = 3),
file = paste(gens.names[gen.count],".csv", sep = ""), append =F, quote = F, sep = ",",
eol = "\n", na = "", dec = ".", row.names = F,
col.names = F, qmethod = "double")
######just random#########
gen.count=gen.count+1
gens.names[gen.count]="just random"
max.out[gen.count]=0
varim=c(0,0,0,0,0,0,0,0,0,0)
varimport[gen.count,1:length(varim)]=varim
for(Row in 1:Rows){
simScores[Row,1:10]=rnorm(10, mean = 0, sd = 1)
}
write.table(round(simScores,digits  = 3),
file = paste(gens.names[gen.count],".csv",sep=""), append =F, quote = F, sep = ",",
eol = "\n", na = "", dec = ".", row.names = F,
col.names = F, qmethod = "double")
#
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
?ParConfig
debugSource('C:/Users/Dm/Desktop/generated data test/MLR part.R')
debugSource('C:/Users/Dm/Desktop/generated data test/MLR part.R')
mod
mod<-hyperopt(regr.task, learner = allmodel, hyper.control =hyper.control.rand)
?hyperopt()
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
install.packages("devtools")
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
install.packages("CCTpack")
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/MLR part.R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
previous.fails<-as.matrix(read.csv("test after which reset.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
previous.fails
previous.fails<-(read.csv("test after which reset.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
previous.fails
previous.fails<-previous.fails[previous.fails[,6]==which.computer,]
which.computer<-Sys.info()[['nodename']]
previous.fails<-previous.fails[previous.fails[,6]==which.computer,]
previous.fails
previous.fails<-(read.csv("test after which reset.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
previous.fails
previous.fails[,6]==which.computer
which.computer
previous.fails[1,6]
previous.fails[2,6]
previous.fails<-(read.csv("test after which reset.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
previous.fails<-previous.fails[previous.fails[,6]==which.computer,]
previous.fails
l<-length(previous.fails[,2]
if(previous.fails[,2])
#######not to redo a test function#####
check.redundant<-function(df=df.previous.calcs,norming="asis",trans.y=1,withextra="missing",missingdata="leaveempty",datasource="mean" ,column.to.predict=200,allmodel="ctree")
{
for(intern in 1:length(df[,1])){
if((any(df[intern,] == norming, na.rm=T))&&
(any(df[intern,] == withextra, na.rm=T))&&
(any(df[intern,] == missingdata, na.rm=T))&&
(any(df[intern,] == datasource, na.rm=T))&&
(any(df[intern,] == column.to.predict, na.rm=T))&&
(any(df[intern,] == allmodel, na.rm=T))&&
(  (df[intern,9] == trans.y)))
{return(TRUE)}
}
return(FALSE)
}
#####caret init#####
best.ranged <- c("avNNet", "nnet", "pcaNNet", "glm.nb")
best.asis <- c("svmLinear3", "relaxo", "superpc", "xgbTree")
best.cns <- c("gam", "bam", "svmLinear2", "msaenet", "BstLm", "gbm")
cv6hp5 <- c( "BstLm", "qrnn")#earth
cv3hp32 <- c("Rborist", "pcaNNet", "SBC")
cv7x5hp32 <- c("gbm", "krlsPoly", "kknn", "xgbLinear","RRF", "cubist", "rlm" )
cv6hp5.avoid <- c("pcaNNet")
cv3hp32.avoid <- c("glm.nb", "gamboost", "ctree2","glmboost", "leapSeq","ctree","svmLinear2")
cv7x5hp32.avoid <- c("SBC","bagearthgcv","gcvearth","lmStepAIC","glmStepAIC","bridge","lm","glm","bayesglm","blassoAveraged","treebag","rpart1SE")
allmodels <- c("avNNet", "bagEarth", "bagEarthGCV",
"bayesglm", "bdk", "blackboost", "Boruta", "brnn", "BstLm" ,
"bstTree", "cforest", "ctree", "ctree2", "cubist", "DENFIS",
"dnn", "earth", "elm", "enet",   "evtree",
"extraTrees",  "gamLoess",  "gaussprLinear", "gaussprPoly", "gaussprRadial",
"gcvEarth","glm", "glmboost",  "icr", "kernelpls",
"kknn", "knn",  "krlsRadial", "lars" , "lasso",
"leapBackward", "leapForward", "leapSeq", "lm", "M5", "M5Rules",
"mlpWeightDecay", "neuralnet" , "partDSA",
"pcaNNet", "pcr", "penalized", "pls", "plsRglm", "ppr",
"qrf" , "ranger",  "rf")
allmodels <- c("rlm", "rpart", "rpart2",
"RRF", "RRFglobal",  "simpls",
"svmLinear", "svmPoly", "svmRadial", "svmRadialCost",
"widekernelpls",  "xgbLinear",
"xgbTree")
allmodels <- c("avNNet","BstLm","bstTree","cforest","ctree","ctree2",
"cubist","earth","enet","evtree","glmboost",
"icr","kernelpls","kknn","lasso","pcaNNet",
"pcr","pls","qrf","ranger","rf")
allmodels <- c("kknn", "cubist", "avNNet", "xgbLinear", "RRF", "pcaNNet","earth","nnet","gbm","enet","lasso","BstLm",
"foba", "leapBackward", "gcvEarth", "SBC","glm.nb","gamboost","ctree2","relaxo",
"bartMachine","extraTrees","bam","gam","randomGLM")
#allmodels <- c("bam")
#allmodels <- c("rf")"rqlasso",, "xyf" "rvmPoly", "rvmRadial",    "spls", "superpc" ,   "treebag",  "svmLinear2",  "SBC",
#allmodels <- c("bartMachine", "xgbLinear", "pcaNNet","svmLinear","glmnet","cforest","cubist","rf","ranger")"glmnet",
#wow rfRules is really slow "rfRules","WM", takes 50min
# brak everythig "rbfDDA","ridge","rqnc",
# use "rf" to test all
library(caret)
previous.fails<-(read.csv("test after which reset.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
previous.fails<-previous.fails[previous.fails[,6]==which.computer,]
l<-length(previous.fails[,2]
if(previous.fails[,2])
#######not to redo a test function#####
check.redundant<-function(df=df.previous.calcs,norming="asis",trans.y=1,withextra="missing",missingdata="leaveempty",datasource="mean" ,column.to.predict=200,allmodel="ctree")
{
for(intern in 1:length(df[,1])){
if((any(df[intern,] == norming, na.rm=T))&&
(any(df[intern,] == withextra, na.rm=T))&&
(any(df[intern,] == missingdata, na.rm=T))&&
(any(df[intern,] == datasource, na.rm=T))&&
(any(df[intern,] == column.to.predict, na.rm=T))&&
(any(df[intern,] == allmodel, na.rm=T))&&
(  (df[intern,9] == trans.y)))
{return(TRUE)}
}
return(FALSE)
}
#####caret init#####
best.ranged <- c("avNNet", "nnet", "pcaNNet", "glm.nb")
best.asis <- c("svmLinear3", "relaxo", "superpc", "xgbTree")
best.cns <- c("gam", "bam", "svmLinear2", "msaenet", "BstLm", "gbm")
cv6hp5 <- c( "BstLm", "qrnn")#earth
cv3hp32 <- c("Rborist", "pcaNNet", "SBC")
cv7x5hp32 <- c("gbm", "krlsPoly", "kknn", "xgbLinear","RRF", "cubist", "rlm" )
cv6hp5.avoid <- c("pcaNNet")
cv3hp32.avoid <- c("glm.nb", "gamboost", "ctree2","glmboost", "leapSeq","ctree","svmLinear2")
cv7x5hp32.avoid <- c("SBC","bagearthgcv","gcvearth","lmStepAIC","glmStepAIC","bridge","lm","glm","bayesglm","blassoAveraged","treebag","rpart1SE")
allmodels <- c("avNNet", "bagEarth", "bagEarthGCV",
"bayesglm", "bdk", "blackboost", "Boruta", "brnn", "BstLm" ,
"bstTree", "cforest", "ctree", "ctree2", "cubist", "DENFIS",
"dnn", "earth", "elm", "enet",   "evtree",
"extraTrees",  "gamLoess",  "gaussprLinear", "gaussprPoly", "gaussprRadial",
"gcvEarth","glm", "glmboost",  "icr", "kernelpls",
"kknn", "knn",  "krlsRadial", "lars" , "lasso",
"leapBackward", "leapForward", "leapSeq", "lm", "M5", "M5Rules",
"mlpWeightDecay", "neuralnet" , "partDSA",
"pcaNNet", "pcr", "penalized", "pls", "plsRglm", "ppr",
"qrf" , "ranger",  "rf")
allmodels <- c("rlm", "rpart", "rpart2",
"RRF", "RRFglobal",  "simpls",
"svmLinear", "svmPoly", "svmRadial", "svmRadialCost",
"widekernelpls",  "xgbLinear",
"xgbTree")
allmodels <- c("avNNet","BstLm","bstTree","cforest","ctree","ctree2",
"cubist","earth","enet","evtree","glmboost",
"icr","kernelpls","kknn","lasso","pcaNNet",
"pcr","pls","qrf","ranger","rf")
allmodels <- c("kknn", "cubist", "avNNet", "xgbLinear", "RRF", "pcaNNet","earth","nnet","gbm","enet","lasso","BstLm",
"foba", "leapBackward", "gcvEarth", "SBC","glm.nb","gamboost","ctree2","relaxo",
"bartMachine","extraTrees","bam","gam","randomGLM")
#allmodels <- c("bam")
#allmodels <- c("rf")"rqlasso",, "xyf" "rvmPoly", "rvmRadial",    "spls", "superpc" ,   "treebag",  "svmLinear2",  "SBC",
#allmodels <- c("bartMachine", "xgbLinear", "pcaNNet","svmLinear","glmnet","cforest","cubist","rf","ranger")"glmnet",
#wow rfRules is really slow "rfRules","WM", takes 50min
# brak everythig "rbfDDA","ridge","rqnc",
# use "rf" to test all
library(caret)
ll<-length(previous.fails[,2])
if(previous.fails[ll,2]==previous.fails[ll-1,2])
vgj
previous.fails[ll,2]==previous.fails[ll-1,2]
previous.fails<-(read.csv("test after which reset.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
previous.fails<-previous.fails[previous.fails[,6]==which.computer,]
previous.fails
ll<-length(previous.fails[,2])
for(lt in 2:ll){
if(previous.fails[lt,2]==previous.fails[lt-1,2]){
bad.models=union(bad.models,c(previous.fails[lt,2]))}}
bad.models=c("spaccceeee")
for(lt in 2:ll){
if(previous.fails[lt,2]==previous.fails[lt-1,2]){
bad.models=union(bad.models,c(previous.fails[lt,2]))}}
bad.models
previous.fails[lt,2]
previous.fails[lt,2]factor()
as.numeric(paste(previous.fails[lt,2])
)
paste(previous.fails[lt,2])
bad.models=union(bad.models,paste(previous.fails[lt,2]))}}
bad.models=union(bad.models,paste(previous.fails[lt,2]))}
for(lt in 2:ll){
if(previous.fails[lt,2]==previous.fails[lt-1,2]){
bad.models=union(bad.models,c(paste(previous.fails[lt,2])))}}
bad.models
bad.models=c("spaccceeee")
previous.fails<-(read.csv("test after which reset.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
previous.fails<-previous.fails[previous.fails[,6]==which.computer,]
ll<-length(previous.fails[,2])
for(lt in 2:ll){
if(previous.fails[lt,2]==previous.fails[lt-1,2]){
bad.models=union(bad.models,c(paste(previous.fails[lt,2])))}}
bad.models
bad.models[2]
allmodels <- unique(modelLookup()[modelLookup()$forReg,c(1)])
library(caret)
allmodels <- unique(modelLookup()[modelLookup()$forReg,c(1)])
bad.models[2]==allmodels
allmodels
if(which.computer=="ALTA")
source("MLR part.R")
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
