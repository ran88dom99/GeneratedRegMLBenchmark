View(mlrallmodels)
debugSource('C:/Users/Dm/Desktop/generated data test/MLR part.R')
setwd("C:/Users/Dm/Desktop/generated data test")
debugSource('C:/Users/Dm/Desktop/generated data test/MLR part.R')
debugSource('C:/Users/Dm/Desktop/generated data test/MLR part.R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
debugSource('C:/Users/Dm/Desktop/generated data test/MLR part.R')
mod$y
write.table(mod$y,
file = "hyperopt.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
mod$learner
mod$y
mod$control
mod$opt.path
source('C:/Users/Dm/Desktop/generated data test/MLR part.R')
source('C:/Users/Dm/Desktop/generated data test/MLR part.R')
write.table(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,adaptControl$search,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min,mod$x),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
mod$x
source('C:/Users/Dm/Desktop/generated data test/MLR part.R')
write.table(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,NoHyper,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min,c(1,2)),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
write.table(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,NoHyper,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,NoHyper,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min)
str(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,NoHyper,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min))
write.csv(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,NoHyper,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
write.table(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,NoHyper,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
write.csv2(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,NoHyper,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
write.table(paste(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,NoHyper,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min, sep = ","),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
source('C:/Users/Dm/Desktop/generated data test/MLR part.R')
View(mlrallmodels)
mlrallmodels<-"regr.bartMachine"
for(allmodel in mlrallmodels[[1]]){#just before all models define d.f and reduce it
write.table(allmodel,file = "last algorithm tried.csv",  quote = F, row.names = F,col.names = F)
bad.models=c("regr.GPfit","neuralnet","partDSA","blackboost","bstSm","bstTree","penalized","brnn","gamLoess","ANFIS","FIR.DM","FS.HGD","nodeHarvest","mlpWeightDecayML","monmlp","mlp","mlpWeightDecay","mlpSGD","rbf","rbfDDA","rfRules","GFS.FR.MOGUL","mlpML","HYFIS","GFS.THRIFT" ,"GFS.LT.RS")
#too slow neuralnet# dnfis useless and just stops on huge datasets
if(allmodel %in% bad.models) {next()} #gamLoess crashes. the capitals are slow and terrible
library(caret) #mlp...s creat some bizzare problem that breaks caret::train ##nodeHarvest is SLOW ##"rbf"crash R "rbfDDA" crash train and really bad #rfRules is REALLY slow.##"pythonKnnReg",pythonKnnReg can not install
#penalized slow then fails
slow.models=c("leapSeq","glmStepAIC","ppr","qrnn")#leapSeq
if(allmodel %in% slow.models && datasource=="needles in haystack"){next()}#too slow for many columns
if(allmodel %in% slow.models && datasource=="needles hay noise"){next()}#too slow for many columns
slow.models=c("qrnn")
if(allmodel %in% slow.models){next()}#too slow for much cv
noNA.models=c("kknn")#leapSeq
if(allmodel %in% noNA.models && datasource=="sparsity NA"){next()}#too slow for many columns
seed.var=seed.var+1
error.pack=0
try({list.of.packages <-getLearnerPackages(allmodel)
error.pack=1})
if(error.pack==0){next()}
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, dep = TRUE)
if(length(list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])])){
write.table(paste("Fail","Fail","Fail","Fail","PackageFail",date(),allmodel,column.to.predict,trans.y,datasource,missingdata,withextra,norming,round(proc.time()[3]-when[3]),  sep = ","),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
next()}
when<-proc.time()
if(length(df.previous.calcs[,1])>0){
if(check.redundant(df=df.previous.calcs,norming=norming,trans.y=trans.y,withextra=withextra,missingdata=missingdata,datasource=datasource ,column.to.predict=column.to.predict,allmodel=allmodel)){next}}
not.failed=0
set.seed(seed.var)
try({mod<-hyperopt(regr.task, learner = allmodel, hyper.control =hyper.control.rand)
lrn = setHyperPars(makeLearner(allmodel), par.vals = mod$x)
m = train(lrn, regr.task)
#keep rmse but train new model on mod$x's parameters
predicted.outcomes<-predict(m, newdata=(testing))
p <- data.frame(predicted.outcomes$data[,2],testing[,1])
#Rsqd =(1-sum((p[,2]-p[,1])^2, na.rm = T)/sum((p[,2]-mean(p[,2]))^2, na.rm = T))
Rsqd=1-RMSE(p[,1],p[,2])/RMSE(p[,2],mean(p[,2], na.rm = T))
#mean.improvement=1-mean(abs(p[,2]-p[,1]), na.rm = T)/mean(abs(p[,2]-median(p[,2])), na.rm = T)
mean.improvement=1-MAE(p[,1],p[,2])/MAE(p[,2],mean(p[,2], na.rm = T))
p<- data.frame(predict(loess.model,predicted.outcomes$data[,2]),y.untransformed[-inTrain])
#RMSE=(sqrt(mean((p[,1]-p[,2])^2, na.rm = T)))
RMSE=RMSE(p[,1],p[,2])
#RMSE.mean=(sqrt(mean((p[,2]-mean(p[,2]))^2, na.rm = T)))
RMSE.mean=RMSE(p[,2],mean(p[,2], na.rm = T))
#MMAAEE=mean(abs(p[,2]-p[,1]), na.rm = T)
MMAAEE=MAE(p[,1],p[,2])
overRMSE=-1
overRMSE<-mod$y
#if(replace.overRMSE==1){overRMSE=-1}
if(length(overRMSE)<1){overRMSE=-1}
#print(c(Rsqd,RMSE,overRMSE,date(),allmodel,column.to.predict,datasource,missingdata,withextra,norming,adaptControl$search,seed.const,adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,adaptControl$adaptive$min,trainedmodel$bestTune))
write.table(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,adaptControl$search,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min,mod$x),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
print(date())
not.failed=1
})
#if hyperopt failed just use no hypering
try({if(not.failed==0) {
mod<-  train(allmodel, regr.task)
predicted.outcomes<-predict(mod, newdata=(testing))
p <- data.frame(predicted.outcomes$data[,2],testing[,1])
#Rsqd =(1-sum((p[,2]-p[,1])^2, na.rm = T)/sum((p[,2]-mean(p[,2]))^2, na.rm = T))
Rsqd=1-RMSE(p[,1],p[,2])/RMSE(p[,2],mean(p[,2], na.rm = T))
#mean.improvement=1-mean(abs(p[,2]-p[,1]), na.rm = T)/mean(abs(p[,2]-median(p[,2])), na.rm = T)
mean.improvement=1-MAE(p[,1],p[,2])/MAE(p[,2],mean(p[,2], na.rm = T))
p<- data.frame(predict(loess.model,predicted.outcomes$data[,2]),y.untransformed[-inTrain])
#RMSE=(sqrt(mean((p[,1]-p[,2])^2, na.rm = T)))
RMSE=RMSE(p[,1],p[,2])
#RMSE.mean=(sqrt(mean((p[,2]-mean(p[,2]))^2, na.rm = T)))
RMSE.mean=RMSE(p[,2],mean(p[,2], na.rm = T))
#MMAAEE=mean(abs(p[,2]-p[,1]), na.rm = T)
MMAAEE=MAE(p[,1],p[,2])
overRMSE=-1
#if(replace.overRMSE==1){overRMSE=-1}
if(length(overRMSE)<1){overRMSE=-1}
NoAp<-"NoAp"
NoHyper<-"nohyperparam"
#print(c(Rsqd,RMSE,overRMSE,date(),allmodel,column.to.predict,datasource,missingdata,withextra,norming,adaptControl$search,seed.const,adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,adaptControl$adaptive$min,trainedmodel$bestTune))
write.table(paste(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,NoHyper,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min, sep = ","),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
print(date())
not.failed=1
}})
if(not.failed==0) {
print(c("failed","failed",date(),datasource,missingdata,withextra,norming,allmodel))
write.table(paste("Fail","Fail","Fail","Fail","Fail",date(),allmodel,column.to.predict,trans.y,datasource,missingdata,withextra,norming,round(proc.time()[3]-when[3]),  sep = ","),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
write.table(paste("Fail",date(),allmodel,  sep = ", "),
file = "backup.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
}
if(not.failed==1) {
write.table(paste("Succ",date(),allmodel,  sep = ", "),
file = "backup.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")}
}
mlrallmodels<-"regr.bartMachine"
write.table(allmodel,file = "last algorithm tried.csv",  quote = F, row.names = F,col.names = F)
bad.models=c("regr.GPfit","neuralnet","partDSA","blackboost","bstSm","bstTree","penalized","brnn","gamLoess","ANFIS","FIR.DM","FS.HGD","nodeHarvest","mlpWeightDecayML","monmlp","mlp","mlpWeightDecay","mlpSGD","rbf","rbfDDA","rfRules","GFS.FR.MOGUL","mlpML","HYFIS","GFS.THRIFT" ,"GFS.LT.RS")
if(allmodel %in% bad.models) {next()} #gamLoess crashes. the capitals are slow and terrible
library(caret) #mlp...s creat some bizzare problem that breaks caret::train ##nodeHarvest is SLOW ##"rbf"crash R "rbfDDA" crash train and really bad #rfRules is REALLY slow.##"pythonKnnReg",pythonKnnReg can not install
slow.models=c("leapSeq","glmStepAIC","ppr","qrnn")#leapSeq
if(allmodel %in% slow.models && datasource=="needles in haystack"){next()}#too slow for many columns
if(allmodel %in% slow.models && datasource=="needles hay noise"){next()}#too slow for many columns
slow.models=c("qrnn")
if(allmodel %in% slow.models){next()}#too slow for much cv
noNA.models=c("kknn")#leapSeq
if(allmodel %in% noNA.models && datasource=="sparsity NA"){next()}#too slow for many columns
seed.var=seed.var+1
error.pack=0
list.of.packages <-getLearnerPackages(allmodel)
source('C:/Users/Dm/Desktop/generated data test/MLR part.R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/MLR part.R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source("MLR part.R")
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
loadedNamespaces
loadedNamespaces()
source('C:/Users/Dm/Desktop/generated data test/run comparison.R')
p <- ggplot(melt(ttdd), aes(x=melt(ttdd)[,1],y=melt(ttdd)[,2]))
p + geom_violin() + geom_boxplot(width=0.05)+ stat_summary(fun.y = "mean", colour = "red", size = 1, geom = "point")+
xlab(paste("fail runs of",exp.name)) + ylab("diff")
p <- ggplot(melt(ttdd), aes(x=(melt(ttdd)[,2]),y=melt((ttdd))[,3]))
p  + geom_boxplot(width=0.4)+ stat_summary(fun.y = "mean", colour = "red", size = 1, geom = "point")+
theme(axis.text.x=element_text(size=7, angle=270,hjust=0.95,vjust=0.2))+scale_x_discrete(position = "top")+
xlab(paste("fail learners in",exp.name)) + ylab("diff")
setwd("C:/Users/Dm/Desktop/generated data test")
source('C:/Users/Dm/Desktop/generated data test/run comparison.R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
trainedmodel <- train(x=data.frame(training[,2:length(training[1,])]),
y = df.toprocess[inTrain,1],
method = allmodel,
trControl = adaptControl,
tuneLength = tuneLength)
allmodels
warnings
warnings()
BstLm
allmodels <- c("BstLm")#"","enet","lasso",
adaptControl <- trainControl(method = "adaptive_cv",
number = 7, repeats = 5,
adaptive = list(min = 4, alpha = 0.05,
method = "gls", complete = FALSE),
search = "random")
adaptControl <-trainControl(method = "cv", number = 3,
search = "random")
simpleControl <- trainControl(method = "cv",
number = 3,
search = "random")
tuneLength=32
tuneLength2=32
seed.const=222+round(runif(1,min=0,max=100))
seed.var=seed.const
column.to.predict=1
print(date());
if(!exists("gen.count")){gen.count=40}
gens.names<-as.matrix(read.table("gens names.csv", sep = ",",header = FALSE,row.names=1,fill=TRUE, quote="",dec="."))
for(gend.data in 3:3){
data.source<-as.matrix(read.csv(paste(gens.names[gend.data],".csv", sep = ""), sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
datasource<-gens.names[gend.data]
missingdatas=c("ignore")
for(missingdata in missingdatas){
withextras=c("none")
for(withextra in withextras){
################data wrestling###############
dependant.selection=complete.cases(data.source[,column.to.predict])
df.previous.calcs=as.data.frame(read.csv(file="gen test out.csv", header = FALSE, sep = ",", quote = "",
dec = ".", fill = TRUE, comment.char = ""))
unimportant.computations<-vector(mode = "logical",length=length(df.previous.calcs[,1])  )
for(intern in 1:length(df.previous.calcs[,1])){
if((any(df.previous.calcs[intern,] == withextra, na.rm=T))&&
(any(df.previous.calcs[intern,] == missingdata, na.rm=T))&&
(any(df.previous.calcs[intern,] == datasource, na.rm=T))&&
(any(df.previous.calcs[intern,] == column.to.predict, na.rm=T)))
{unimportant.computations[intern]<-T}}
df.previous.calcs<-df.previous.calcs[unimportant.computations,]
#data.source=data.frame( data.source[,column.to.predict],data.source[,1:2], data.source[,4:(column.to.predict-1)], data.source[,(column.to.predict+1):length( data.source[1,])])
normings=c("range01","asis")#,"expoTrans","quantile","centernscale","YeoJohnson"
for(norming in normings) {
for(trans.y in 1:1) {
df.toprocess=data.source
y.untransformed<-df.toprocess[,1]
if(norming=="centernscale"){
preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("center", "scale"))
df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
if(norming=="range01"){
preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("range"))
df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
if(norming=="expoTrans"){
preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("expoTrans"))
df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
if(norming=="YeoJohnson"){
preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("YeoJohnson"))#"center", "scale",
df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
if((norming=="asis")&&(trans.y==2)){next}
################preprocess###########
df.toprocess=data.frame(df.toprocess[dependant.selection,])
y.untransformed=y.untransformed[dependant.selection]
if(norming=="quantile"){
for(Clol in trans.y:length(data.source[1,])){
df.toprocess[,Clol]<- (rank(df.toprocess[,Clol],na.last = "keep",ties.method = "average")-1) }
preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("range"))
df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
loess.model<-loess(y.untransformed~ df.toprocess[,1],span = 0.21, degree = 1)
#df.toprocess = data.frame(df.toprocess,)
nzv <- nearZeroVar(df.toprocess[,])#, saveMetrics= TRUE
#nzv[nzv$nzv,][1:10,]
if(length(nzv)>1){
df.toprocess = (df.toprocess[, -nzv])}
set.seed(seed.var)
inTrain <- createDataPartition(y = df.toprocess[,1],
p = .75,
list = FALSE)
training <- df.toprocess[ inTrain,]
testing  <- df.toprocess[-inTrain,]
write.table(df.toprocess,file = "sanity check 1.csv",  quote = F, row.names = F,col.names = F)
###########for all models#################
for(allmodel in allmodels){#just before all models define d.f and reduce it
write.table(allmodel,file = "last algorithm tried.csv",  quote = F, row.names = F,col.names = F)
bad.models=c("DENFIS","neuralnet","partDSA","blackboost","bstSm","bstTree","penalized","brnn","gamLoess","ANFIS","FIR.DM","FS.HGD","nodeHarvest","mlpWeightDecayML","monmlp","mlp","mlpWeightDecay","mlpSGD","rbf","rbfDDA","rfRules","GFS.FR.MOGUL","mlpML","HYFIS","GFS.THRIFT" ,"GFS.LT.RS")
#too slow neuralnet# dnfis useless and just stops on huge datasets
if(allmodel %in% bad.models) {next()} #gamLoess crashes. the capitals are slow and terrible
library(caret) #mlp...s creat some bizzare problem that breaks train ##nodeHarvest is SLOW ##"rbf"crash R "rbfDDA" crash train and really bad #rfRules is REALLY slow.##"pythonKnnReg",pythonKnnReg can not install
#penalized slow then fails
slow.models=c("leapSeq","glmStepAIC","ppr","qrnn")#,"cubist","plsRglm","WM","gamboost")#cubist, plsRglm,WM,gamboost  only sometimes
if(allmodel %in% slow.models && datasource=="needles in haystack"){next()}#too slow for many columns
if(allmodel %in% slow.models && datasource=="needles hay noise"){next()}#too slow for many columns
slow.models=c("qrnn")
#if(allmodel %in% slow.models){next()}#too slow for much cv
noNA.models=c("kknn")#leapSeq
if(allmodel %in% noNA.models && datasource=="sparsity NA"){next()}#too slow for many columns
seed.var=seed.var+1
if(length(df.previous.calcs[,1])>0){
if(check.redundant(df=df.previous.calcs,norming=norming,trans.y=trans.y,withextra=withextra,missingdata=missingdata,datasource=datasource ,column.to.predict=column.to.predict,allmodel=allmodel)){next}}
list.of.packages <-getModelInfo(allmodel)[[1]]$library
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, dep = TRUE)
if(length(list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])])){
write.table(paste("Fail","Fail","Fail","Fail","PackageFail",date(),allmodel,column.to.predict,trans.y,datasource,missingdata,withextra,norming,round(proc.time()[3]-when[3]),  sep = ","),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
next()}
when<-proc.time()
not.failed=0
set.seed(seed.var)
try({trainedmodel <- train(x=data.frame(training[,2:length(training[1,])]),
y = df.toprocess[inTrain,1],
method = allmodel,
trControl = adaptControl,
tuneLength = tuneLength)
predicted.outcomes<-predict(trainedmodel, newdata=(testing))
p <- data.frame(predicted.outcomes,testing)
#Rsqd =(1-sum((p[,2]-p[,1])^2, na.rm = T)/sum((p[,2]-mean(p[,2]))^2, na.rm = T))
Rsqd=1-RMSE(p[,1],p[,2])/RMSE(p[,2],mean(p[,2], na.rm = T))
#mean.improvement=1-mean(abs(p[,2]-p[,1]), na.rm = T)/mean(abs(p[,2]-median(p[,2])), na.rm = T)
mean.improvement=1-MAE(p[,1],p[,2])/MAE(p[,2],mean(p[,2], na.rm = T))
p<- data.frame(predict(loess.model,predicted.outcomes),y.untransformed[-inTrain])
#RMSE=(sqrt(mean((p[,1]-p[,2])^2, na.rm = T)))
RMSE=RMSE(p[,1],p[,2])
#RMSE.mean=(sqrt(mean((p[,2]-mean(p[,2]))^2, na.rm = T)))
RMSE.mean=RMSE(p[,2],mean(p[,2], na.rm = T))
#MMAAEE=mean(abs(p[,2]-p[,1]), na.rm = T)
MMAAEE=MAE(p[,1],p[,2])
wut=print(trainedmodel,selectCol=TRUE)
overRMSE=-1
try({overRMSE=as.numeric(wut[wut[,length(wut[1,])]=="*","RMSE"])})#length(wut[1,])-3]
replace.overRMSE=1
try({if(is.numeric(overRMSE)){replace.overRMSE=0}})
if(replace.overRMSE==1){overRMSE=-1}
if(length(overRMSE)<1){overRMSE=-1}
#print(c(Rsqd,RMSE,overRMSE,date(),allmodel,column.to.predict,datasource,missingdata,withextra,norming,adaptControl$search,seed.const,adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,adaptControl$adaptive$min,trainedmodel$bestTune))
write.table(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),
round(overRMSE,digits = 3),round(RMSE,digits = 3),round(MMAAEE,digits = 3),
date(),allmodel,column.to.predict,trans.y,datasource,missingdata,
withextra,norming,RMSE.mean,adaptControl$search,seed.var,round(proc.time()[3]-when[3]),
adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,
adaptControl$adaptive$min,trainedmodel$bestTune),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
print(date())
not.failed=1
})
if(not.failed==0) {
try({trainedmodel <- train(x=data.frame(training[,2:length(training[1,])]),
y =  df.toprocess[inTrain,1],
method = allmodel,
trControl = simpleControl,
tuneLength = tuneLength2)
predicted.outcomes<-predict(trainedmodel, newdata=(testing))
p <- data.frame(predicted.outcomes,testing)
#Rsqd =(1-sum((p[,2]-p[,1])^2, na.rm = T)/sum((p[,2]-mean(p[,2]))^2, na.rm = T))
Rsqd=1-RMSE(p[,1],p[,2])/RMSE(p[,2],mean(p[,2], na.rm = T))
#mean.improvement=1-mean(abs(p[,2]-p[,1]), na.rm = T)/mean(abs(p[,2]-median(p[,2])), na.rm = T)
mean.improvement=1-MAE(p[,1],p[,2])/MAE(p[,2],mean(p[,2], na.rm = T))
p<- data.frame(predict(loess.model,predicted.outcomes),y.untransformed[-inTrain])
#RMSE=(sqrt(mean((p[,1]-p[,2])^2, na.rm = T)))
RMSE=RMSE(p[,1],p[,2])
#RMSE.mean=(sqrt(mean((p[,2]-mean(p[,2]))^2, na.rm = T)))
RMSE.mean=RMSE(p[,2],mean(p[,2], na.rm = T))
#MMAAEE=mean(abs(p[,2]-p[,1]), na.rm = T)
MMAAEE=MAE(p[,1],p[,2])
print(confusionMatrix(p[,1],p[,2]))
overRMSE=-1
wut=print(trainedmodel,selectCol=TRUE)
try({overRMSE=as.numeric(wut[wut[,length(wut[1,])]=="*","RMSE"])})#length(wut[1,])-
replace.overRMSE=1
try({if(is.numeric(overRMSE)){replace.overRMSE=0}})
if(replace.overRMSE==1){overRMSE=-1}
if(length(overRMSE)<1){overRMSE=-1}
#print(c(Rsqd,RMSE,overRMSE,date(),allmodel,column.to.predict,datasource,missingdata,withextra,norming,adaptControl$search,seed.const,adaptControl$method,tuneLength,adaptControl$number,adaptControl$repeats,adaptControl$adaptive$min,trainedmodel$bestTune))
write.table(c(round(mean.improvement,digits = 3),round(Rsqd,digits = 3),round(overRMSE,digits = 3),
round(RMSE,digits = 3),round(MMAAEE,digits = 3),date(),allmodel,column.to.predict,
trans.y,datasource,missingdata,withextra,norming,RMSE.mean,simpleControl$search,
seed.var,round(proc.time()[3]-when[3]),simpleControl$method,tuneLength2,
simpleControl$number,"no rep","no min",trainedmodel$bestTune),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
print(date())
not.failed=1
})
}
if(not.failed==0) {
print(c("failed","failed",date(),datasource,missingdata,withextra,norming,allmodel))
write.table(paste("Fail","Fail","Fail","Fail","Fail",date(),allmodel,column.to.predict,trans.y,datasource,missingdata,withextra,norming,round(proc.time()[3]-when[3]),  sep = ","),
file = "gen test out.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
write.table(paste("Fail",date(),allmodel,  sep = ", "),
file = "backup.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")
}
if(not.failed==1) {
write.table(paste("Succ",date(),allmodel,  sep = ", "),
file = "backup.csv", append =TRUE, quote = F, sep = ",",
eol = "\n", na = "NA", dec = ".", row.names = F,
col.names = F, qmethod = "double")}
}
#source("MLR part.R")
}}}}
}
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
pkgs = names(sessionInfo()$otherPkgs)
pkgs
pkgs = paste('package:', pkgs, sep = "")
pkgs
lapply(pkg, detach, character.only = TRUE, unload = TRUE)
lapply(pkgs, detach, character.only = TRUE, unload = TRUE)
pkgs = names(sessionInfo()$otherPkgs)
pkgs = paste('package:', pkgs, sep = "")
pkgs
pkgs = names(sessionInfo()$otherPkgs)
pkgs
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
pkgs = names(sessionInfo()$otherPkgs)
pkgs = paste('package:', pkgs, sep = "")
lapply(pkgs, detach, character.only = TRUE, unload = TRUE)
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/MLR part.R')
pkgs = names(sessionInfo()$otherPkgs)
pkgs
if(pkgs!="NULL")
.
if(pkgs!="NULL"){print(data())}
if(length(pkgs)>0){print(data())}
source('C:/Users/Dm/Desktop/generated data test/MLR part.R')
if(length(pkgs)>0){
print(data())
pkgs = paste('package:', pkgs, sep = "")
lapply(pkgs, detach, character.only = TRUE, unload = TRUE)
}
mlrallmodels<-listLearners("regr")
library(mlr)
library(mlbench)
library(mlrHyperopt)
library(MLmetrics)
library(ParamHelpers)
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
source('C:/Users/Dm/Desktop/generated data test/Model Tester Quick .R')
