---
title: "Results analysis"
---
load packages read files comboine files
[1] "pq9TargRank"    "gainin30"       "spearman2"      "pearson2"      
  [5] "pMAE"           "pRMSE"          "ocvRMSE"        "RMSEutrans"    
  [9] "MAEutrans"      "date"           "algomodel"      "trgCol"        
 [13] "transTarg"      "task"           "missing"        "append"        
 [17] "transform"      "pc"             "expirament"     "fold"          
 [21] "maxfold"        "seed"           "seedit"         "foldseed"      
 [25] "RMSEmean"       "RMSEmeantrain"  "hpGen"          "time"          
 [29] "validmethod"    "tuneLength"     "cvcount"        "ignrepeats"    
 [33] "adaptivemin"    "bestTuneparams" "btp1"           "btp2"          
 [37] "btp3"           "btp4"           "btp5"           "btp6"          
 [41] "btp7"           "btp8"           "btp9"           "btp10"         
 [45] "btp11"
```{r}
col_typed <- "dddddddddccddccccccdddddddcdcddc??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????"

try({setwd(mainDir)})
mainDir<-getwd()
subDir<-"QSlinks_simple"
#dir.create(file.path(mainDir, subDir))
  require(readr)


resultDir<-"ACEREBOUT"
#setwd(resultDir)
setwd(file.path(mainDir, resultDir))
QSlink3ACE <- read_csv("outQSlink3ACEREBOUTwindowsx64.csv",col_types = col_typed)
#summary(QSlink3ACE[,1:30])
 spec(QSlink3ACE)
 problems(QSlink3ACE)
 setwd(file.path(mainDir))


 
 resultDir<-"HOPPER"
#setwd(resultDir)
setwd(file.path(mainDir, resultDir))
QSlink3HOP <- read_csv("outQSlink3HOPPERwindowsx64.csv",col_types = col_typed)
#summary(QSlink3ACE[,1:30])
 spec(QSlink3HOP)
 problems(QSlink3HOP)
 setwd(file.path(mainDir))
 
 names(QSlink3HOP)
 
  resultDir<-"LAPTOPBBQ"
#setwd(resultDir)
setwd(file.path(mainDir, resultDir))
QSlink3BBQ <- read_csv("outQSlink3LAPTOPBBQwindowsx64.csv",col_types = col_typed)
#summary(QSlink3ACE[,1:30])
 spec(QSlink3BBQ)
 problems(QSlink3BBQ)
 setwd(file.path(mainDir))

  
require(data.table)
DF<-as.data.table(QSlink3ACE)
DF1<-as.data.table(QSlink3HOP)
DF2<-as.data.table(QSlink3BBQ)

DF<-rbindlist(list(DF,DF1,DF2),fill = T)
rm(DF1,DF2,QSlink3BBQ,QSlink3HOP)
```
remove useless columns, convert time, check for unused columns, seed changes?
```{r}

DF$date<-as.numeric(as.POSIXct(DF$date,format = "%a %b %d %H:%M:%S %Y"))
#str(DF)
summary(DF$pq9TargRank)

#what is seedit? and seed bcause foldseed is always the same
summary(DF[,.(seed,seedit,foldseed)])#need foldseed now
unique(DF$seed);unique(DF$seedit);unique(DF$foldseed)
unique(DF$trgCol);unique(DF$missing);unique(DF$append)
unique(DF$hpGen);unique(DF$tuneLength);unique(DF$ignrepeats)
usless<-c("trgCol","missing","append")
names(DF<-DF[,1:45,with=F])
names(DF<-DF[,-(usless),with=F])

```

Which models were somehow missed? Just checking just incase errors or 
machines did not run fast enough
Also if some hype hype parameters were way overblown
```{r}
DF[,keyMiss:=paste0(task,transform,transTarg,expirament,fold)]
luMiss<-length(unique(DF$keyMiss))
DF[,unmissed:=length(unique(keyMiss)),by=algomodel]
DF[unmissed<luMiss][order(unmissed)]
max(DF$unmissed)-luMiss
plot(DF$unmissed[order(DF$unmissed)])
```



for netcoinnetwork grap write out features
these will be used later on to separate data and for more detailed views
outliers too
```{r}
getwd()
DF$imperfect <- DF$algomodel=="perfect"
DF$totFail <- is.na(DF$hpGen) & is.na(DF$RMSEutrans) & is.na(DF$spearman2) & is.na(DF$pq9TargRank)
DF$totFail <- DF$totFail |  DF$algomodel=="ignore"
DF[,noPear:=is.na(spearman2) & !totFail]
DF[,noUtrans:=is.na(RMSEutrans) & !totFail]


if(F){
DF$btp4[is.na(DF$btp4)]<-"NA"
DF$btp4[DF$btp4=="NA"]<-"4.4"
DF$btp5[is.na(DF$btp5)]<-"NA"
DF$btp3[is.na(DF$btp3)]<-"NA"
}
DF$btp3<-(DF$btp3=="3")
summary(DF$btp3)

```


plot the netcoin graphs
first focusing onperfection then droping it
"seed" btw is just a function of R version change
```{r}
require(netCoin)
#,"seedit"
set <- c("transTarg","task","transform","fold","imperfect","seed","btp3")

essCoin <- surCoin(data = DF, variables = set, lwidth ="Haberman", lweight="Haberman", color="variable", lcolor="Haberman", ltext="Haberman", linkFilter="Haberman", repulsion=90)
essCoin
plot(essCoin)

set <- c("algomodel", "transTarg", "task", "transform", "fold", "pc", "totFail", "noPear", "noUtrans")


```
perfect/ideal results at section start
check for oddness, remove
```{r}

names(DF)
DF[,keyRedun:=paste0(transTarg,task,transform,pc,expirament,fold)]
Perf<-DF[(imperfect)]
DF<-DF[!(imperfect)]
summary(Perf[,1:20])

if(F){ #transtarg1 causes utrans to get numbers other than 0
halfver<-median(unique(Perf$RMSEutrans))
P1<-Perf[RMSEutrans>=halfver,]
P2<-Perf[RMSEutrans<=halfver,]
summary(P1[,1:30])
summary(P2[,1:30])
}

Perf[,.N,by=fold]
if(F){ #fold changes max possible but rarely!?
for(i in unique(Perf$fold)){
print(summary(Perf[Perf$fold==i,c(1:30),with=FALSE]))
} }

#check for redundancy against possible combinatorial explosion
Explosion<-1
for(i in which(names(Perf) %in% c("transTarg","task","transform","pc","expirament","fold"))){
  Explosion<-Explosion * dim(unique(Perf[,(i),with=F]))[1]
  print(Explosion)
}
length(unique(Perf$keyRedun))
length(Perf$keyRedun)/length(unique(Perf$keyRedun))
Perf[,.N,by=keyRedun]
```
infinte checked and converted to NA
```{r}
DF[,infin:=0]
for(i in 1:45){
DF$infin <- is.infinite(DF[,i,with=F][[1]]) + DF$infin
}

(infinDF<-DF[(infin>0)])

for(i in names(DF)[1:45]){#i<-2 
  nafound<-as.vector(is.infinite(DF[,i,with=F][[1]]))
  summary(nafound)
  na.replace<-NA
  DF[(nafound),(i):=na.replace]
  
  #DF[(nafound)]
}

DF[(infin>0)]#not getting everything?
infinDF
```


Percent success
```{r}
#install.packages("VIM")
require(VIM)
mice_plot <- aggr(DF[,1:20], col=c('navyblue','yellow'),
numbers=TRUE, sortVars=TRUE,
labels=names(DF[,1:20]), cex.axis=.7,
gap=3, ylab=c("Missing data","Pattern"))
mice_plot <- aggr(DF[,21:40], col=c('navyblue','yellow'),
numbers=TRUE, sortVars=TRUE,
labels=names(DF[,21:40]), cex.axis=.7,
gap=3, ylab=c("Missing data","Pattern"))
```
```{r}
require(naniar)
gg_miss_upset(DF[,1:25],nsets = 15,nintersects=20)
```


Full fails checked and removed
mlr fail state not updated algo "ignore" also a fail
```{r}
sum(DF$totFail)
dim(DF)[1]
DF[(totFail),][1:30,]

TF<-DF[(totFail),]
DF<-DF[!(totFail)]

```
```{r}
require(naniar)
gg_miss_upset(DF[,1:35],nsets = 15,nintersects=20)
require(VIM)
mice_plot <- aggr(DF[,1:35], col=c('navyblue','yellow'),
numbers=TRUE, sortVars=TRUE,
labels=names(DF[,1:35]), cex.axis=.7,
gap=3, ylab=c("Missing data","Pattern"))

```


Which models were often failed or missed again

```{r}
DF[,keyMiss:=paste0(task,transform,transTarg,expirament,fold)]
luMiss<-length(unique(DF$keyMiss))
DF[,unmissed:=length(unique(keyMiss)),by=algomodel]
DF[unmissed<luMiss][order(unmissed)]
max(DF$unmissed)-luMiss
plot(DF$unmissed[order(DF$unmissed)])
```

Checks of variation inside redundant runs
If summary 0s and 1s then no NA variance
redonePQ9TF does range of 90th percentile rank by more than .02?

```{r}
DF[,keyOnerun:=paste0(expirament,task,pc,fold,transTarg,transform,algomodel,seed)]
DF[,redonee:=.N,by=keyOnerun]
DF[,redoneNA:=(sum(noPear) + sum(noUtrans))/redonee,by=keyOnerun]
summary(DF$redoneNA)
DF[,redonePQ9:=max(pq9TargRank,na.rm = T)-min(pq9TargRank,na.rm = T),by=keyOnerun]
DF[,redonePQ9TF:=redonePQ9>.02]
(specimen<-DF[(redonePQ9TF)][order(keyOnerun)][1:100])
(exems<-unique(specimen$keyOnerun))
DF[keyOnerun=="QSlink3QSlinks03_95ACEREBOUT21centernscaleSL.bartMachine403"]
```

outliers moved to some more reasonable state
may be column specific
lots of NAS not dealt with; let NA algo deal with them
```{r}

for(i in names(DF)[1:9]){#i<-2
  bxs <- boxplot.stats(DF[,i,with=F][[1]],coef=3)
  print(bxs$stats)
  nafound <- as.vector(DF[,i,with=F]<bxs$stats[[1]])
  print(summary(nafound))
  #DF[(is.na(nafound))];
  #print(DF[(nafound)])
  DF[(nafound),(i):=bxs$stats[[1]]]
  nafound <- as.vector(DF[,i,with=F]>bxs$stats[[5]])
  print(summary(nafound))
  DF[(nafound),(i):=bxs$stats[[5]]]
}
 
```

net coicidence with everything to be removed, removed
```{r}
#DF$noPear
#DF$noUtrans
# 1 2345 67 8 910
# #get rid of this part when redoing
binnerr<-function(x){
  if(x==1) return(1)
  if(x>=2 & x<=5) return(3)
  if(x>=6 & x<=10) return(8)
}
DF[,rowNum:=seq_len(.N)]
length(unique(DF$rowNum))==dim(DF)[1]
DF[,redoneeb:=binnerr(redonee),by=rowNum]
summary(DF$redoneeb)

set <- c("algomodel", "transTarg", "task", "transform", "fold", "pc",  "noPear", "noUtrans","redonePQ9TF","redoneeb")
essCoin <- surCoin(data = DF, variables = set, lwidth ="Haberman", lweight="Haberman", color="variable", lcolor="Haberman", ltext="Haberman", linkFilter="Haberman", repulsion=90)
essCoin
plot(essCoin)
```
fold now depends on seed so fold becomes paste of fold and seed
```{r}
DF[,keyOnerun:=paste0(expirament,task,pc,fold,transTarg,transform,algomodel,seed)]
dim(DF)
uDF<-unique(DF,by = c("pq9TargRank","pearson2","pRMSE","keyOnerun"))
dim(uDF)
uDF[order(-spearman2)][order(-pRMSE)][order(-pq9TargRank)][order(-gainin30)]
```
missing values in metric will be made 80%tile
only the better score really matter so 
to prevent crashing later score its set to 80%
```{r}
for(i in names(uDF)[1:9]){#i<-2
  print(na.replace<-quantile(uDF[,i,with=F],.8,na.rm=T))
  nafound<-as.vector(is.na(uDF[,i,with=F]))
  summary(nafound)
  uDF[(nafound),(i):=na.replace]
  #uDF[(nafound)]
}
summary(uDF[,1:9,with=F]) 
```
Getting into selecting metrics here; lets see their correlations and distributions
```{r}
uDF[,topmetrics:=(gainin30>quantile(gainin30,.801))+(pq9TargRank>quantile(pq9TargRank,.801))+(spearman2>quantile(spearman2,.801))+(pearson2>quantile(pearson2,.801))+(pMAE>quantile(pMAE,.801))+(pRMSE>quantile(pRMSE,.801))]
iDF<-uDF[(topmetrics>0)][order(-topmetrics)]
summary(iDF$topmetrics)
for(i in names(iDF)[1:9]){#i<-2
  yy<-as.vector(iDF[,i,with=F][[1]])
  print(summary(yy))
  yy<-as.integer(yy*10000)
  print(summary(yy))
  #gg<-ecdf(yy);summary(gg)
  #unique(yy);dim(iDF[,i,with=F]);unique(iDF[,i,with=F]);iDF[,i,with=F]
  plot.ecdf(yy, verticals = TRUE, do.points = FALSE)
  title(i, adj = 1)
}

```
```{r}
require(ggplot2)
for(i in names(iDF)[1:9]){
print(ggplot(iDF, aes(x=get(i))) + geom_histogram(aes(y=..density..), stat="bin", position="stack", alpha=0.5, bins=16) + geom_path(aes(y=..density..), stat="bin", position="identity", linetype="dashed", bins=16, pad=TRUE) + geom_density(aes(y=..density..), stat="density", position="identity", alpha=0.5) + theme_grey() + theme(text=element_text(family="sans", face="plain", color="#000000", size=15, hjust=0.5, vjust=0.5)) + xlab(i) + ylab("density"))
}



```


two medianings because fold is very special compared to just hyperparameer jiggling. 
```{r}
uDF[order(-spearman2)][order(-pRMSE)][order(-pq9TargRank)][order(-gainin30)]
uDF[,keyOneRecipe:=paste0(expirament,task,transTarg,transform,algomodel,fold)]

uDF[,gainin30:=median(gainin30,na.rm = T),by=keyOneRecipe]
uDF[,pq9TargRank:=median(pq9TargRank,na.rm = T),by=keyOneRecipe]
uDF[,spearman2:=median(spearman2,na.rm = T),by=keyOneRecipe]
uDF[,pearson2:=median(pearson2,na.rm = T),by=keyOneRecipe]
uDF[,pMAE:=median(pMAE,na.rm = T),by=keyOneRecipe]
uDF[,pRMSE:=median(pRMSE,na.rm = T),by=keyOneRecipe]
uDF[,ocvRMSE:=median(ocvRMSE,na.rm = T),by=keyOneRecipe]
uDF[,RMSEutrans:=median(RMSEutrans,na.rm = T),by=keyOneRecipe]
uDF[,MAEutrans:=median(MAEutrans,na.rm = T),by=keyOneRecipe] 

uDF[,hyperUnqs:=.N,by=keyOneRecipe]
uDF <- unique(uDF,by = c("pq9TargRank", "pearson2", "pRMSE", "keyOneRecipe"))
dim(uDF)

```
```{r}

uDF[,redonePQ9:=max(pq9TargRank,na.rm = T)-min(pq9TargRank,na.rm = T),by=keyOnerun]
uDF[,redonePQ9TF:=redonePQ9>.02]
(specimen<-uDF[(redonePQ9TF)][order(keyOnerun)][1:100])
(exems<-unique(specimen$keyOnerun))

```

```{r}
uDF[order(-spearman2)][order(-pRMSE)][order(-pq9TargRank)][order(-gainin30)]
uDF[,keyOneRecipe:=paste0(expirament,task,transTarg,transform,algomodel)]

uDF[,gainin30:=mean(gainin30,na.rm = T),by=keyOneRecipe]
uDF[,pq9TargRank:=mean(pq9TargRank,na.rm = T),by=keyOneRecipe]
uDF[,spearman2:=mean(spearman2,na.rm = T),by=keyOneRecipe]
uDF[,pearson2:=mean(pearson2,na.rm = T),by=keyOneRecipe]
uDF[,pMAE:=mean(pMAE,na.rm = T),by=keyOneRecipe]
uDF[,pRMSE:=mean(pRMSE,na.rm = T),by=keyOneRecipe]
uDF[,ocvRMSE:=mean(ocvRMSE,na.rm = T),by=keyOneRecipe]
uDF[,RMSEutrans:=mean(RMSEutrans,na.rm = T),by=keyOneRecipe]
uDF[,MAEutrans:=mean(MAEutrans,na.rm = T),by=keyOneRecipe] 

uDF[,foldCount:=.N,by=keyOneRecipe]
uDF <- unique(uDF,by = c("pq9TargRank", "pearson2", "pRMSE", "keyOneRecipe"))
dim(uDF)
```


actualy randomtime base dseeds cut last 5 digits off

best algo is just first 3 scores in 95% and number of oflds too
else just use median

maybe all this is too much work and I should just take tops?
```{r}
#summary(uDF[,.(gainin30,pq9TargRank,spearman2,pearson2,pMAE,pRMSE)])
uDF[,topmetrics:=(gainin30>quantile(gainin30,.95))+(pq9TargRank>quantile(pq9TargRank,.96))+(spearman2>quantile(spearman2,.96))+(pearson2>quantile(pearson2,.95))+(pMAE>quantile(pMAE,.99))+(pRMSE>quantile(pRMSE,.99))]
summary(uDF[(topmetrics>1)][(foldCount>2)][,.(gainin30,pq9TargRank,spearman2,pearson2,pMAE,pRMSE)])
uDF[(topmetrics>1)][(foldCount>2)][order(-gainin30)]
uDF[(topmetrics>1)][(foldCount>2)][order(-pq9TargRank)]
uDF[(topmetrics>1)][(foldCount>2)][order(-spearman2)]
uDF[(topmetrics>1)][(foldCount>2)][order(-pearson2)]
uDF[(topmetrics>1)][(foldCount>2)][order(-pq9TargRank)][order(-topmetrics)]
```
QSlink3QSlinks14_55Int2range01SL.ranger	#### winner ####
QSlink3QSlinks14_55Int1range01SL.ranger	
QSlink3QSlinks115_602expoTransSL.ranger	
QSlink3QSlinks14_55Int1centernscaleSL.extraTrees	
QSlink3QSlinks14_55Int2range01regr.h2o.randomForest	
QSlink3QSlinks14_55Int2centernscaleSL.extraTrees	
QSlink3QSlinks14_55Int2range01SL.extraTrees	
QSlink3QSlinks14_55Int1range01SL.extraTrees	
QSlink3QSlinks03_951range01regr.randomForest	
QSlink3QSlinks14_55Int2expoTransSL.ranger

QSlink3QSlinks03_951centernscaleregr.h2o.randomForest	0.384000 p2
QSlink3QSlinks03_952expoTransregr.evtree	
QSlink3QSlinks14_55Int2range01SL.ranger	0.374125
QSlink3QSlinks14_55Int1range01SL.ranger	
QSlink3QSlinks14_55Int2quantileSL.ranger	
QSlink3QSlinks14_55Int2expoTransSL.ranger	
QSlink3QSlinks14_55Int2asisSL.ranger	
QSlink3QSlinks14_55Int2YeoJohnsonSL.ranger	
QSlink3QSlinks14_55Int2asisSL.randomForest	
QSlink3QSlinks14_55Int2YeoJohnsonSL.randomForest
 
 QSlink3QSlinks14_55Int2expoTransSL.ranger 0.66875	pq9
QSlink3QSlinks14_55Int2asisSL.ranger	
QSlink3QSlinks14_55Int2range01SL.ranger	
QSlink3QSlinks14_55Int2YeoJohnsonSL.ranger	0.66750
QSlink3QSlinks115_602YeoJohnsonRborist	
QSlink3QSlinks14_55Int1range01SL.ranger	
QSlink3QSlinks14_55Int2centernscaleSL.ranger	
QSlink3QSlinks14_55Int1centernscaleSL.ranger	
QSlink3QSlinks115_602asisregr.ranger	
QSlink3QSlinks115_602YeoJohnsonregr.ranger

QSlink3QSlinks115_602centernscaleregr.randomForest	0.798750 gain30
QSlink3QSlinks14_55Int2centernscaleregr.cvglmnet	
QSlink3QSlinks115_602expoTransSL.randomForest	
QSlink3QSlinks14_55Int2range01SL.extraTrees	
QSlink3QSlinks14_55Int2centernscaleSL.extraTrees	
QSlink3QSlinks14_55Int2range01SL.ranger	         0.775750
QSlink3QSlinks03_952asisregr.ranger	
QSlink3QSlinks03_952YeoJohnsonregr.ranger	
QSlink3QSlinks115_602quantileRborist	
QSlink3QSlinks115_602quantileranger
 
 #spearman only odd because it does not value gulfs between ratings
QSlink3QSlinks03_952centernscaleregr.randomForest	0.400250
QSlink3QSlinks03_952expoTransregr.randomForest	
QSlink3QSlinks14_55Int2range01SL.extraTrees	
QSlink3QSlinks14_55Int2allSL.randomForest	
QSlink3QSlinks14_55Int2range01regr.h2o.randomForest	
QSlink3QSlinks14_55Int1centernscaleSL.extraTrees	
QSlink3QSlinks14_55Int1range01SL.extraTrees	
QSlink3QSlinks03_952asisregr.ranger	
QSlink3QSlinks03_952YeoJohnsonregr.ranger	
QSlink3QSlinks03_952asisSL.randomForest
QSlink3QSlinks03_952YeoJohnsonSL.randomForest	
QSlink3QSlinks14_55Int2asisSL.extraTrees	
QSlink3QSlinks14_55Int2YeoJohnsonSL.extraTrees	
QSlink3QSlinks03_951range01SL.randomForest	
QSlink3QSlinks03_951range01regr.randomForest	
QSlink3QSlinks03_952asisregr.randomForest	
QSlink3QSlinks03_952YeoJohnsonregr.randomForest	
QSlink3QSlinks03_952expoTransSL.randomForest	
QSlink3QSlinks14_55Int2centernscaleSL.extraTrees	
QSlink3QSlinks03_952quantileregr.randomForest
QSlink3QSlinks03_952range01SL.randomForest	
QSlink3QSlinks03_952centernscaleSL.randomForest	
QSlink3QSlinks03_951centernscaleregr.h2o.randomForest	
QSlink3QSlinks03_952centernscaleregr.ranger	
QSlink3QSlinks03_952quantileSL.randomForest	
QSlink3QSlinks03_951centernscaleSL.randomForest	
QSlink3QSlinks14_55Int2asisSL.randomForest	
QSlink3QSlinks14_55Int2YeoJohnsonSL.randomForest	
QSlink3QSlinks14_55Int1centernscaleSL.randomForest	
QSlink3QSlinks14_55Int2allSL.ranger
QSlink3QSlinks14_55Int1range01SL.ranger	  0.386250
QSlink3QSlinks14_55Int1centernscaleSL.ranger	
QSlink3QSlinks14_55Int2range01SL.ranger	0.386125
QSlink3QSlinks14_55Int2centernscaleSL.ranger	
QSlink3QSlinks14_55Int2centernscaleSL.randomForest	
QSlink3QSlinks14_55Int2quantileSL.ranger	
QSlink3QSlinks14_55Int2expoTransSL.ranger	
QSlink3QSlinks14_55Int2asisSL.ranger	
QSlink3QSlinks14_55Int2YeoJohnsonSL.ranger	
QSlink3QSlinks14_55Int2expoTransSL.randomForest
maybe all this is too much work and I should just take tops?
```{r}
summary(uDF[,.(gainin30,pq9TargRank,spearman2,pearson2,pMAE,pRMSE)])
uDF[,topmetrics:=(gainin30>quantile(gainin30,.92))+(pq9TargRank>quantile(pq9TargRank,.99))+(spearman2>quantile(spearman2,.99))+(pearson2>quantile(pearson2,.99))+(pMAE>quantile(pMAE,.99))+(pRMSE>quantile(pRMSE,.99))]
uDF[(topmetrics>5)]
```


Here user must make a combined metric by 
multipying metrics by set score then suming result
eh no!? not doing this 
```{r}

```