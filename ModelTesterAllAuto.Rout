
R version 3.4.3 (2017-11-30) -- "Kite-Eating Tree"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> options(repos=structure(c(CRAN="https://rweb.crmda.ku.edu/cran/")))
> ## capture messages and errors to a file.https://rweb.crmda.ku.edu/cran/
> #zz <- file("all.Rout", open="wt")https://cran.cnr.berkeley.edu
> #sink(zz, type="message") edit for rebaseless
> #chek for R package updates
> #try(log("a")) ## test --no-edit
> #devtools::install_github("berndbischl/ParamHelpers") # version >= 1.11 needed.
> #devtools::install_github("jakob-r/mlrHyperopt", dependencies = TRUE)
> task.subject<-"14th20hp3cv"
> pc.mlr<-c("ACE")#"ALTA","HOPPER"
> which.computer<-Sys.info()[['nodename']]
> out.file<-paste("out",task.subject,which.computer,.Platform$OS.type,.Platform$r_arch,".csv",sep="")
> importance.file<-paste("importance",task.subject,which.computer,.Platform$OS.type,.Platform$r_arch,sep="")
> 
> base.folder<-getwd()
> cpout.folder<-paste(base.folder,"/",which.computer,sep = "")
> setwd(cpout.folder)
> 
> if(length(which(list.files() == out.file))<1) write.table( "0.01,0.01,100,100,100,Wed Aug 02 16:37:25 2017,dummy,8,1,basic latent features,ignore,none,asis,1.12784979099243,random,333,53,adaptive_cv,16,5,2,2,19,0.0107744822639878,FALSE,,,,,,,,,," ,file =,out.file,  quote = F, sep = ",", row.names = F,col.names = F)
> if(length(which(list.files() == paste(importance.file,".csv",sep="")))<1) write.table( ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,," ,file = paste(importance.file,".csv",sep=""),  quote = F, sep = ",", row.names = F,col.names = F)
> if(length(which(list.files() == paste(importance.file,"mlr.csv",sep="")))<1) write.table( ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,," ,file = paste(importance.file,"mlr.csv",sep=""),  quote = F, sep = ",", row.names = F,col.names = F)
> 
> cv.iters=3
> tuneLength=20
> tuneLength2=8
> normings=c("YeoJohnson","ICA", "centernscale","expoTrans","range01","asis","quantile")#,"centernscale"
> 
> gensTTesto<-c(56,53,4,12,13,14,15,20,45,54,55, 44,3,1,52)#,  51,c(4)#c(1:40)#c(5,10,11,13,14,15,16,17,18,19,20,21,24,28,38,39,40)
> gensTTest<-vector()
> write.table( t(gensTTesto),file = "initial tasks to test.csv",  quote = F, sep = ",", row.names = F,col.names = F)
> try({
+   gensTTest<-t(read.csv("tasks to test.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   gensTTest<-as.vector(gensTTest)
+ })
> if(!exists("gensTTest")) gensTTest<-c(gensTTesto)#reversion[length(reversion):1]
> gensTTesto<-c(gensTTesto[length(gensTTesto):1])
> if(length(gensTTest)<1) gensTTest<-c(gensTTesto)#reversion[length(reversion):1]
> 
> 
> ########packages install check######
> 
> #list.of.packages <- c("caret","caretEnsemble","mlr","MLmetrics","tgp")
> #list.of.packages <- c("gower","dimRed","DEoptimR","caretEnsemble","logicFS"," RWeka","ordinalNet","xgboost","mlr","caret","MLmetrics","bartMachine","spikeslab","party","rqPen","monomvn","foba","logicFS","rPython","qrnn","randomGLM","msaenet","Rborist","relaxo","ordinalNet","rrf","frbs","extraTrees","ipred","elasticnet","bst","brnn","Boruta","arm","elmNN","evtree","extraTrees","deepnet","kknn","KRLS","RSNNS","partDSA","plsRglm","quantregForest","ranger","inTrees")
> #new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
> #if(length(new.packages)) install.packages(new.packages, dep = TRUE)
> 
> 
> #install.packages("mlr", dependencies = c("Depends", "Suggests"))
> #install.packages("caret", dependencies = c("Depends", "Suggests"))
> #install.packages("caret",repos = "http://cran.r-project.org",dependencies = c("Depends", "Imports", "Suggests"))
> #install.packages("SuperLearner", dependencies = c("Depends", "Suggests"))
> #install.packages("rattle", dependencies = c("Depends", "Suggests"))
> 
> # Load libraries
> #library(mlbench)
> 
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
> #library(caretEnsemble)
> library(MLmetrics)

Attaching package: 'MLmetrics'

The following objects are masked from 'package:caret':

    MAE, RMSE

The following object is masked from 'package:base':

    Recall

> 
> ########error no repeat#########
> 
> 
> try({
+   before.last.alg<-as.matrix(read.csv("beforelast algorithm.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   last.alg<-as.matrix(read.csv("last algorithm tried.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   #write.table(paste(date(), last.alg,.Platform$OS.type,.Platform$r_arch,which.computer,sep=" "),file = "algos after which reset.csv",  quote = F, row.names = F,col.names = F,append = T)
+   if(last.alg==before.last.alg){print("algorithm may be broken")}
+   write.table(last.alg,file = "beforelast algorithm.csv",  quote = F, row.names = F,col.names = F)
+ })
> try({
+   before.last.tsk<-as.matrix(read.csv("beforelast task.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   last.tsk<-as.matrix(read.csv("last task tried.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   write.table(paste(date(),last.alg, last.tsk,cv.iters,tuneLength,.Platform$OS.type,.Platform$r_arch,which.computer,sep=","),file = "test after which reset.csv",  quote = F, row.names = F,col.names = F,append = T)
+   if(last.tsk==before.last.tsk){print("task may be broken")}
+   write.table(last.tsk,file = "beforelast task.csv",  quote = F, row.names = F,col.names = F)
+ })
[1] "task may be broken"
> bad.models=c("spaccceeee")
> previous.fails<-(read.csv("test after which reset.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
> previous.fails<-previous.fails[previous.fails[,8]==which.computer,]
> lgf<-length(previous.fails[,2])
> for(lt in 2:lgf)  {
+   if(previous.fails[lt,2]==previous.fails[lt-1,2])  {
+     bad.models=union(bad.models,c(paste(previous.fails[lt,2])))  }}
> 
> #######not to redo a test function#####
> check.redundant<-function(df=df.previous.calcs,norming="asis",trans.y=1,withextra="missing",missingdata="leaveempty",datasource="mean" ,column.to.predict=200,allmodel="ctree")
+ {
+   for(intern in 1:length(df[,1])){
+     if((any(df[intern,] == norming, na.rm=T))&&
+        (any(df[intern,] == withextra, na.rm=T))&&
+        (any(df[intern,] == missingdata, na.rm=T))&&
+        (any(df[intern,] == datasource, na.rm=T))&&
+        (any(df[intern,] == column.to.predict, na.rm=T))&&
+        (any(df[intern,] == allmodel, na.rm=T))&&
+        (  (df[intern,9] == trans.y)))
+     {return(TRUE)}
+   }
+   return(FALSE)
+ }
> #####caret init#####
> best.ranged <- c("avNNet", "nnet", "pcaNNet", "glm.nb")
> best.asis <- c("svmLinear3", "relaxo", "superpc", "xgbTree")
> best.cns <- c("gam", "bam", "svmLinear2", "msaenet", "BstLm", "gbm") 
> 
> cv6hp5 <- c( "BstLm", "qrnn")#earth
> cv3hp32 <- c("Rborist", "pcaNNet", "SBC")
> cv7x5hp32 <- c("gbm", "krlsPoly", "kknn", "xgbLinear","RRF", "cubist", "rlm" )
> cv6hp5.avoid <- c("pcaNNet")
> cv3hp32.avoid <- c("glm.nb", "gamboost", "ctree2","glmboost", "leapSeq","ctree","svmLinear2")
> cv7x5hp32.avoid <- c("SBC","bagearthgcv","gcvearth","lmStepAIC","glmStepAIC","bridge","lm","glm","bayesglm","blassoAveraged","treebag","rpart1SE")
> 
> allmodels <- c("avNNet", "bagEarth", "bagEarthGCV",
+                "bayesglm", "bdk", "blackboost", "Boruta", "brnn", "BstLm" ,
+                "bstTree", "cforest", "ctree", "ctree2", "cubist", "DENFIS",
+                "dnn", "earth", "elm", "enet",   "evtree",
+                "extraTrees",  "gamLoess",  "gaussprLinear", "gaussprPoly", "gaussprRadial",
+                "gcvEarth","glm", "glmboost",  "icr", "kernelpls",
+                "kknn", "knn",  "krlsRadial", "lars" , "lasso",
+                "leapBackward", "leapForward", "leapSeq", "lm", "M5", "M5Rules",
+                "mlpWeightDecay", "neuralnet" , "partDSA",
+                "pcaNNet", "pcr", "penalized", "pls", "plsRglm", "ppr",
+                "qrf" , "ranger",  "rf")
> allmodels <- c("rlm", "rpart", "rpart2",
+                "RRF", "RRFglobal",  "simpls",
+                "svmLinear", "svmPoly", "svmRadial", "svmRadialCost",
+                "widekernelpls",  "xgbLinear",
+                "xgbTree")
> allmodels <- c("avNNet","BstLm","bstTree","cforest","ctree","ctree2",
+                "cubist","earth","enet","evtree","glmboost",
+                "icr","kernelpls","kknn","lasso","pcaNNet",
+                "pcr","pls","qrf","ranger","rf")
> 
> allmodels <- c("kknn", "cubist", "avNNet", "xgbLinear", "RRF", "pcaNNet","earth","nnet","gbm","enet","lasso","BstLm",
+                "foba", "leapBackward", "gcvEarth", "SBC","glm.nb","gamboost","ctree2","relaxo", 
+                "bartMachine","extraTrees","bam","gam","randomGLM")
> #allmodels <- c("bam")
> #allmodels <- c("rf")"rqlasso",, "xyf" "rvmPoly", "rvmRadial",    "spls", "superpc" ,   "treebag",  "svmLinear2",  "SBC",
> #allmodels <- c("bartMachine", "xgbLinear", "pcaNNet","svmLinear","glmnet","cforest","cubist","rf","ranger")"glmnet",
> #wow rfRules is really slow "rfRules","WM", takes 50min
> # brak everythig "rbfDDA","ridge","rqnc",
> # use "rf" to test all
> library(caret)
> allmodels <- unique(modelLookup()[modelLookup()$forReg,c(1)])
> #allmodels <-c("avNNet", "nnet", "pcaNNet",  "glm.nb", "gam" ,
> #              "bam","msaenet", "svmLinear2","svmLinear3",
> #              "relaxo",  "superpc", "xgbTree", "BstLm")
> #allmodels<- c("svmLinear","svmPoly","svmRadial")
> #library(doParallel); cl <- makeCluster(detectCores()); registerDoParallel(cl)
> #allmodels<-c("bartMachine","extraTrees")#,"randomGLM"
> 
> 
> adaptControl <- trainControl(method = "adaptive_cv",
+                              number = 7, repeats = 5,
+                              adaptive = list(min = 4, alpha = 0.05,
+                                              method = "gls", complete = FALSE),
+                              search = "random")
> adaptControl <-trainControl(method = "cv", number = cv.iters,  search = "random")
> simpleControl <- trainControl(method = "cv",
+                               number = cv.iters,
+                               search = "random")
> 
> 
> #########MLR init######
> #R.utils::gcDLLs()
> #list.of.packages <- c("ParamHelpers","devtools","mlrMBO","RJSONIO","plot3D","plotly")
> #install.packages("mlrMBO", dependencies = c("Depends", "Suggests"))
> list.of.packages <- c("caretEnsemble","logicFS"," RWeka","ordinalNet","xgboost","mlr","caret","MLmetrics","bartMachine","spikeslab","party","rqPen","monomvn","foba","logicFS","rPython","qrnn","randomGLM","msaenet","Rborist","relaxo","ordinalNet","rrf","frbs","extraTrees","ipred","elasticnet","bst","brnn","Boruta","arm","elmNN","evtree","extraTrees","deepnet","kknn","KRLS","RSNNS","partDSA","plsRglm","quantregForest","ranger","inTrees")
> new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
> if(length(new.packages)) install.packages(new.packages, dep = TRUE)
Warning message:
packages 'logicFS', ' RWeka', 'rPython', 'rrf' are not available (for R version 3.4.3) 
> 
> #devtools::install_github("berndbischl/ParamHelpers") # version >= 1.11 needed.
> #devtools::install_github("jakob-r/mlrHyperopt", dependencies = TRUE)
> 
> tuneLengthMLR<-tuneLength
> mlr.iters<-cv.iters
> #######data read process start#####
> seed.var =222+round(runif(1,min=0,max=100))
> column.to.predict=1
> print(date());
[1] "Sat Mar 03 12:28:46 2018"
> 
> setwd(base.folder)
> if(!exists("gen.count")){gen.count=56}
> gens.names<-as.matrix(read.table("gens names.csv", sep = ",",header = FALSE,row.names=1,fill=TRUE, quote="",dec="."))
> count.toy.data.passed<-1
> for(gend.data in gensTTest){
+   count.toy.data.passed<-count.toy.data.passed+1
+   setwd(base.folder)
+   data.source<-as.matrix(read.csv(paste("Generats/",gens.names[gend.data],".csv", sep = ""), sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   datasource<-gens.names[gend.data,1]
+   setwd(cpout.folder)
+   missingdatas=c("ignore")
+   for(missingdata in missingdatas){
+     withextras=c("none")
+     for(withextra in withextras){
+       ################data wrestling###############
+       
+       dependant.selection=complete.cases(data.source[,column.to.predict])
+       df.previous.calcs=as.data.frame(read.csv(file=out.file, header = FALSE, sep = ",", quote = "",
+                                                dec = ".", fill = TRUE, comment.char = ""))
+       unimportant.computations<-vector(mode = "logical",length=length(df.previous.calcs[,1])  )
+       for(intern in 1:length(df.previous.calcs[,1])){
+         if((any(df.previous.calcs[intern,] == withextra, na.rm=T))&&
+            (any(df.previous.calcs[intern,] == missingdata, na.rm=T))&&
+            (any(df.previous.calcs[intern,] == datasource, na.rm=T))&&
+            (any(df.previous.calcs[intern,] == column.to.predict, na.rm=T)))
+         {unimportant.computations[intern]<-T}}
+       
+       df.previous.calcs<-df.previous.calcs[unimportant.computations,]
+       
+       #data.source=data.frame( data.source[,column.to.predict],data.source[,1:2], data.source[,4:(column.to.predict-1)], data.source[,(column.to.predict+1):length( data.source[1,])])
+       
+         for(norming in normings) {
+         for(trans.y in 1:2) {
+           df.toprocess=data.source
+           y.untransformed<-df.toprocess[,1]
+           
+           if(norming=="centernscale"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("center", "scale"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           if(norming=="range01"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("range"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           if(norming=="expoTrans"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("expoTrans"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           if(norming=="YeoJohnson"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("YeoJohnson"))#"center", "scale",
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           
+           if((norming=="asis")&&(trans.y==2)){next}
+           
+           
+           ################preprocess###########
+           df.toprocess=data.frame(df.toprocess[dependant.selection,])
+           y.untransformed=y.untransformed[dependant.selection]
+           if(norming=="quantile"){
+             for(Clol in trans.y:length(data.source[1,])){
+               df.toprocess[,Clol]<- (rank(df.toprocess[,Clol],na.last = "keep",ties.method = "average")-1) }
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("range"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           
+           loess.model<-loess(y.untransformed~ df.toprocess[,1],span = 0.21, degree = 1)
+   
+           #df.toprocess = data.frame(df.toprocess,)
+           nzv <- nearZeroVar(df.toprocess[,])#, saveMetrics= TRUE
+           #nzv[nzv$nzv,][1:10,]
+           if(length(nzv)>1){
+             df.toprocess = (df.toprocess[, -nzv])}
+           df.toprocess = signif(df.toprocess,digits = 3)
+           
+           seed.var =222+round(runif(1,min=0,max=100))
+           set.seed(seed.var)
+           inTrain <- createDataPartition(y = df.toprocess[,1],
+                                          p = .75,
+                                          list = FALSE)
+           training <- df.toprocess[ inTrain,]
+           testing  <- df.toprocess[-inTrain,]
+           write.table(df.toprocess,file = "sanity check 1.csv",  quote = F, row.names = F,col.names = F)
+           
+           ###########for all models#################
+           setwd(base.folder)
+           if(max(which.computer==pc.mlr)>0)
+             source("MLR part.R")
+           else
+             source("Caret part.R")
+           
+          setwd(cpout.folder)
+           if(norming == normings[length(normings)]){
+             if(count.toy.data.passed>length(gensTTest)){gensTTest<-c(gensTTesto)}
+             write.table( t(gensTTest[count.toy.data.passed:length(gensTTest)]),file = "tasks to test.csv",  quote = F, sep = ",", row.names = F,col.names = F)
+             
+             }
+           
+         }
+       }
+     }
+   }
+   
+ }
Warning in preProcess.default(df.toprocess[, trans.y:length(df.toprocess[1,  :
  These variables have zero variances: V11, V12
Warning in preProcess.default(df.toprocess[, trans.y:length(df.toprocess[1,  :
  These variables have zero variances: V11, V12
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: There were 25 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9     NA's   :9    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 14:04:12 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "gbm_h2o"                 
Loading required package: earth
Loading required package: plotmo
Loading required package: plotrix
Loading required package: TeachingDemos
Multivariate Adaptive Regression Splines 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results:

  RMSE      Rsquared    MAE     
  1.016713  0.00334726  0.803747

Tuning parameter 'degree' was held constant at a value of 1
[1] "Sat Mar 03 14:04:29 2018"
Generalized Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results:

  RMSE      Rsquared      MAE      
  1.017875  0.0007807964  0.8068751

[1] "Sat Mar 03 14:04:44 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3     NA's   :3    
Error : Stopping
In addition: Warning messages:
1: model fit failed for Fold1: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
2: model fit failed for Fold1: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
3: model fit failed for Fold1: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
4: model fit failed for Fold2: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
5: model fit failed for Fold2: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
6: model fit failed for Fold2: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
7: model fit failed for Fold3: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
8: model fit failed for Fold3: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
9: model fit failed for Fold3: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
10: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3     NA's   :3    
Error : Stopping
In addition: Warning messages:
1: model fit failed for Fold1: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
2: model fit failed for Fold1: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
3: model fit failed for Fold1: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
4: model fit failed for Fold2: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
5: model fit failed for Fold2: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
6: model fit failed for Fold2: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
7: model fit failed for Fold3: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
8: model fit failed for Fold3: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
9: model fit failed for Fold3: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
10: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3     NA's   :3    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 14:05:02 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "glm.nb"                  
Boosted Generalized Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  mstop  prune  RMSE      Rsquared      MAE        Selected
    54   yes    1.006412  0.0016668930  0.7970152  *       
    84   no     1.012989  0.0004870994  0.8033530          
   143   no     1.015490  0.0006046650  0.8053470          
   169   yes    1.006412  0.0016668930  0.7970152          
   230   no     1.016987  0.0007108272  0.8063046          
   275   no     1.017320  0.0007398780  0.8064881          
   328   yes    1.006412  0.0016668930  0.7970152          
   380   yes    1.006412  0.0016668930  0.7970152          
   481   yes    1.006412  0.0016668930  0.7970152          
   666   yes    1.006412  0.0016668930  0.7970152          
   709   yes    1.006412  0.0016668930  0.7970152          
   770   yes    1.006412  0.0016668930  0.7970152          
   831   no     1.017873  0.0007807103  0.8068741          
   843   yes    1.006412  0.0016668930  0.7970152          
   854   no     1.017874  0.0007807208  0.8068743          
   938   no     1.017874  0.0007807675  0.8068748          
   945   no     1.017874  0.0007807697  0.8068748          
   976   yes    1.006412  0.0016668930  0.7970152          
   979   no     1.017875  0.0007807785  0.8068749          
  1000   yes    1.006412  0.0016668930  0.7970152          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mstop = 54 and prune = yes.
[1] "Sat Mar 03 14:05:29 2018"
glmnet 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  alpha       lambda       RMSE      Rsquared      MAE        Selected
  0.05386214  0.004425574  1.017650  0.0007726526  0.8066824          
  0.08332438  0.116638285  1.011944  0.0005568229  0.8019892          
  0.14246355  0.243784057  1.004539  0.0020555489  0.7949830          
  0.16836802  0.049370855  1.013469  0.0005487024  0.8034848          
  0.22973081  0.141973221  1.005339  0.0017006757  0.7958312          
  0.27461318  6.281452828  1.004158           NaN  0.7937431          
  0.32791187  0.002492543  1.017452  0.0007502592  0.8065581          
  0.37936144  0.003802498  1.017151  0.0007266121  0.8063489          
  0.48058947  0.005176971  1.016669  0.0006899746  0.8060380          
  0.66516863  0.035666567  1.008659  0.0008104238  0.7989236          
  0.70841213  0.003973544  1.016560  0.0006793006  0.8059762          
  0.76940689  0.002538663  1.016968  0.0007066959  0.8062484          
  0.83084481  2.014897028  1.004158           NaN  0.7937431          
  0.84279334  0.006269737  1.015476  0.0006017138  0.8052498          
  0.85388090  7.730220309  1.004158           NaN  0.7937431  *       
  0.93769504  0.236892420  1.004158           NaN  0.7937431          
  0.94464396  3.644758807  1.004158           NaN  0.7937431          
  0.97571783  0.014405463  1.012166  0.0005574410  0.8023834          
  0.97846688  2.505168631  1.004158           NaN  0.7937431          
  0.99923424  0.003233049  1.016401  0.0006659555  0.8058786          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were alpha = 0.8538809 and lambda = 7.73022.
[1] "Sat Mar 03 14:05:46 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: There were 25 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9     NA's   :9    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 14:08:29 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "glmnet_h2o"              
Start:  AIC=1465.75
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V9    1   519.57 1463.8
- V2    1   519.60 1463.8
- V8    1   519.66 1463.8
- V10   1   519.99 1464.2
- V5    1   520.02 1464.2
- V6    1   520.16 1464.3
- V7    1   520.95 1465.1
<none>      519.57 1465.8
- V3    1   524.54 1468.5
- V4    1   526.77 1470.7

Step:  AIC=1463.76
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V10

       Df Deviance    AIC
- V2    1   519.60 1461.8
- V8    1   519.66 1461.8
- V10   1   519.99 1462.2
- V5    1   520.02 1462.2
- V6    1   520.16 1462.3
- V7    1   520.95 1463.1
<none>      519.57 1463.8
- V3    1   524.59 1466.6
- V4    1   526.78 1468.7

Step:  AIC=1461.79
.outcome ~ V3 + V4 + V5 + V6 + V7 + V8 + V10

       Df Deviance    AIC
- V8    1   519.69 1459.9
- V10   1   520.02 1460.2
- V5    1   520.05 1460.2
- V6    1   520.18 1460.3
- V7    1   521.02 1461.2
<none>      519.60 1461.8
- V3    1   524.63 1464.6
- V4    1   526.85 1466.8

Step:  AIC=1459.87
.outcome ~ V3 + V4 + V5 + V6 + V7 + V10

       Df Deviance    AIC
- V10   1   520.13 1458.3
- V5    1   520.16 1458.3
- V6    1   520.27 1458.4
- V7    1   521.10 1459.2
<none>      519.69 1459.9
- V3    1   524.72 1462.7
- V4    1   526.85 1464.8

Step:  AIC=1458.3
.outcome ~ V3 + V4 + V5 + V6 + V7

       Df Deviance    AIC
- V5    1   520.59 1456.8
- V6    1   520.73 1456.9
- V7    1   521.42 1457.5
<none>      520.13 1458.3
- V3    1   525.06 1461.0
- V4    1   527.77 1463.6

Step:  AIC=1456.75
.outcome ~ V3 + V4 + V6 + V7

       Df Deviance    AIC
- V6    1   521.13 1455.3
- V7    1   521.92 1456.0
<none>      520.59 1456.8
- V3    1   525.35 1459.3
- V4    1   528.29 1462.1

Step:  AIC=1455.27
.outcome ~ V3 + V4 + V7

       Df Deviance    AIC
- V7    1   522.53 1454.6
<none>      521.13 1455.3
- V3    1   525.76 1457.7
- V4    1   529.16 1461.0

Step:  AIC=1454.62
.outcome ~ V3 + V4

       Df Deviance    AIC
<none>      522.53 1454.6
- V3    1   527.18 1457.1
- V4    1   530.27 1460.0
Start:  AIC=1417.92
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V2    1   475.80 1415.9
- V6    1   475.82 1415.9
- V3    1   475.82 1416.0
- V9    1   475.85 1416.0
- V7    1   475.99 1416.1
- V5    1   476.75 1416.9
- V8    1   477.57 1417.8
<none>      475.80 1417.9
- V10   1   477.71 1417.9
- V4    1   480.92 1421.3

Step:  AIC=1415.92
.outcome ~ V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V6    1   475.82 1413.9
- V3    1   475.82 1414.0
- V9    1   475.86 1414.0
- V7    1   475.99 1414.1
- V5    1   476.76 1414.9
- V8    1   477.57 1415.8
<none>      475.80 1415.9
- V10   1   477.71 1415.9
- V4    1   480.92 1419.3

Step:  AIC=1413.94
.outcome ~ V3 + V4 + V5 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V3    1   475.85 1412.0
- V9    1   475.87 1412.0
- V7    1   476.03 1412.2
- V5    1   476.79 1413.0
- V8    1   477.59 1413.8
- V10   1   477.71 1413.9
<none>      475.82 1413.9
- V4    1   481.00 1417.4

Step:  AIC=1411.97
.outcome ~ V4 + V5 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V9    1   475.90 1410.0
- V7    1   476.04 1410.2
- V5    1   476.81 1411.0
- V8    1   477.62 1411.8
<none>      475.85 1412.0
- V10   1   477.77 1412.0
- V4    1   481.00 1415.4

Step:  AIC=1410.03
.outcome ~ V4 + V5 + V7 + V8 + V10

       Df Deviance    AIC
- V7    1   476.11 1408.2
- V5    1   476.88 1409.1
- V8    1   477.67 1409.9
<none>      475.90 1410.0
- V10   1   477.81 1410.0
- V4    1   481.02 1413.4

Step:  AIC=1408.24
.outcome ~ V4 + V5 + V8 + V10

       Df Deviance    AIC
- V5    1   477.10 1407.3
- V8    1   477.84 1408.1
<none>      476.11 1408.2
- V10   1   478.04 1408.3
- V4    1   481.10 1411.5

Step:  AIC=1407.29
.outcome ~ V4 + V8 + V10

       Df Deviance    AIC
- V8    1   478.89 1407.2
- V10   1   479.01 1407.3
<none>      477.10 1407.3
- V4    1   482.05 1410.5

Step:  AIC=1407.16
.outcome ~ V4 + V10

       Df Deviance    AIC
- V10   1   480.37 1406.7
<none>      478.89 1407.2
- V4    1   483.59 1410.1

Step:  AIC=1406.71
.outcome ~ V4

       Df Deviance    AIC
<none>      480.37 1406.7
- V4    1   485.15 1409.7
Start:  AIC=1427.07
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V10   1   486.34 1425.1
- V9    1   486.34 1425.1
- V8    1   486.52 1425.3
- V7    1   486.63 1425.4
- V3    1   486.66 1425.4
- V6    1   487.83 1426.6
<none>      486.32 1427.1
- V5    1   488.62 1427.4
- V2    1   489.04 1427.9
- V4    1   492.66 1431.5

Step:  AIC=1425.08
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9

       Df Deviance    AIC
- V9    1   486.35 1423.1
- V8    1   486.54 1423.3
- V7    1   486.64 1423.4
- V3    1   486.68 1423.4
- V6    1   487.84 1424.6
<none>      486.34 1425.1
- V5    1   488.64 1425.5
- V2    1   489.04 1425.9
- V4    1   492.70 1429.6

Step:  AIC=1423.1
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8

       Df Deviance    AIC
- V8    1   486.56 1421.3
- V7    1   486.66 1421.4
- V3    1   486.68 1421.4
- V6    1   487.87 1422.7
<none>      486.35 1423.1
- V5    1   488.65 1423.5
- V2    1   489.06 1423.9
- V4    1   492.73 1427.6

Step:  AIC=1421.31
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7

       Df Deviance    AIC
- V7    1   486.86 1419.6
- V3    1   486.88 1419.6
- V6    1   488.05 1420.8
<none>      486.56 1421.3
- V5    1   488.74 1421.5
- V2    1   489.28 1422.1
- V4    1   492.79 1425.7

Step:  AIC=1419.62
.outcome ~ V2 + V3 + V4 + V5 + V6

       Df Deviance    AIC
- V3    1   487.19 1418.0
- V6    1   488.30 1419.1
<none>      486.86 1419.6
- V5    1   489.00 1419.8
- V2    1   489.58 1420.4
- V4    1   493.09 1424.0

Step:  AIC=1417.96
.outcome ~ V2 + V4 + V5 + V6

       Df Deviance    AIC
- V6    1   488.58 1417.4
<none>      487.19 1418.0
- V5    1   489.43 1418.3
- V2    1   489.82 1418.7
- V4    1   493.54 1422.4

Step:  AIC=1417.39
.outcome ~ V2 + V4 + V5

       Df Deviance    AIC
<none>      488.58 1417.4
- V5    1   490.65 1417.5
- V2    1   491.10 1418.0
- V4    1   494.97 1421.9
Start:  AIC=2151.35
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V5    1   747.28 2149.3
- V9    1   747.28 2149.3
- V6    1   747.31 2149.4
- V10   1   747.34 2149.4
- V2    1   747.69 2149.8
- V8    1   747.86 2149.9
- V7    1   748.07 2150.2
- V3    1   748.71 2150.8
<none>      747.28 2151.3
- V4    1   756.95 2159.0

Step:  AIC=2149.35
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V9    1   747.28 2147.3
- V6    1   747.31 2147.4
- V10   1   747.34 2147.4
- V2    1   747.69 2147.8
- V8    1   747.86 2147.9
- V7    1   748.07 2148.2
- V3    1   748.71 2148.8
<none>      747.28 2149.3
- V4    1   756.96 2157.0

Step:  AIC=2147.35
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V10

       Df Deviance    AIC
- V6    1   747.31 2145.4
- V10   1   747.34 2145.4
- V2    1   747.70 2145.8
- V8    1   747.86 2145.9
- V7    1   748.08 2146.2
- V3    1   748.73 2146.8
<none>      747.28 2147.3
- V4    1   756.96 2155.0

Step:  AIC=2145.38
.outcome ~ V2 + V3 + V4 + V7 + V8 + V10

       Df Deviance    AIC
- V10   1   747.37 2143.4
- V2    1   747.72 2143.8
- V8    1   747.89 2144.0
- V7    1   748.09 2144.2
- V3    1   748.76 2144.8
<none>      747.31 2145.4
- V4    1   756.96 2153.0

Step:  AIC=2143.44
.outcome ~ V2 + V3 + V4 + V7 + V8

       Df Deviance    AIC
- V2    1   747.79 2141.9
- V8    1   747.93 2142.0
- V7    1   748.18 2142.2
- V3    1   748.84 2142.9
<none>      747.37 2143.4
- V4    1   756.97 2151.0

Step:  AIC=2141.86
.outcome ~ V3 + V4 + V7 + V8

       Df Deviance    AIC
- V8    1   748.34 2140.4
- V7    1   748.57 2140.7
- V3    1   749.19 2141.3
<none>      747.79 2141.9
- V4    1   757.32 2149.4

Step:  AIC=2140.41
.outcome ~ V3 + V4 + V7

       Df Deviance    AIC
- V7    1   749.11 2139.2
- V3    1   749.73 2139.8
<none>      748.34 2140.4
- V4    1   757.60 2147.7

Step:  AIC=2139.19
.outcome ~ V3 + V4

       Df Deviance    AIC
- V3    1   750.48 2138.6
<none>      749.11 2139.2
- V4    1   758.17 2146.2

Step:  AIC=2138.57
.outcome ~ V4

       Df Deviance    AIC
<none>      750.48 2138.6
- V4    1   759.52 2145.6
Generalized Linear Model with Stepwise Feature Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.008304  0.005498488  0.8009077

[1] "Sat Mar 03 14:08:44 2018"
Independent Component Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  n.comp  RMSE      Rsquared      MAE        Selected
  1       1.004660  0.0004896514  0.7945990  *       
  2       1.004705  0.0041178703  0.7947034          
  3       1.006352  0.0019550179  0.7961472          
  4       1.006642  0.0014099675  0.7958844          
  5       1.006999  0.0012602975  0.7971201          
  6       1.011825  0.0013454853  0.8004747          
  7       1.012090  0.0018348008  0.8015935          
  8       1.017193  0.0028980374  0.8078195          
  9       1.017875  0.0007807964  0.8068751          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was n.comp = 1.
[1] "Sat Mar 03 14:09:06 2018"
Partial Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  ncomp  RMSE      Rsquared      MAE        Selected
  1      1.017287  0.0007897085  0.8071035  *       
  2      1.017856  0.0007915537  0.8068571          
  3      1.017870  0.0007830641  0.8068774          
  4      1.017876  0.0007814497  0.8068768          
  5      1.017875  0.0007808109  0.8068752          
  6      1.017875  0.0007807970  0.8068751          
  7      1.017875  0.0007807964  0.8068751          
  8      1.017875  0.0007807964  0.8068751          
  9      1.017875  0.0007807964  0.8068751          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 1.
[1] "Sat Mar 03 14:09:22 2018"
Error in MSEP(object) : could not find function "MSEP"
k-Nearest Neighbors 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  kmax  distance   kernel        RMSE      Rsquared     MAE        Selected
   14   0.5030954  gaussian      1.051142  0.004656401  0.8373190          
   21   1.5923338  gaussian      1.032698  0.006633215  0.8196328          
   36   1.8377713  biweight      1.042891  0.005043730  0.8288361          
   43   1.3061085  inv           1.019102  0.005290082  0.8082940          
   58   1.6577748  inv           1.011010  0.003209618  0.8017104          
   69   2.9194842  triangular    1.015367  0.002396136  0.8055750          
   82   0.3119617  inv           1.015946  0.004560782  0.8050703          
   95   0.4525761  epanechnikov  1.018346  0.005126032  0.8070017          
  121   0.5553055  rectangular   1.016605  0.005254424  0.8073598          
  167   1.1978576  cos           1.008726  0.002674145  0.7997344          
  178   0.4672251  epanechnikov  1.010077  0.001799613  0.7997869          
  193   0.3180656  biweight      1.014613  0.004493910  0.8037770          
  208   2.5409322  cos           1.005267  0.002694016  0.7968085  *       
  211   0.6190663  inv           1.005569  0.000533489  0.7968806          
  214   2.9885791  biweight      1.008231  0.002181227  0.7994157          
  235   1.8282240  triweight     1.011180  0.003966803  0.8020357          
  237   2.7382669  triweight     1.010422  0.003003912  0.8015811          
  244   0.8960215  epanechnikov  1.013909  0.005771140  0.8061126          
  245   2.6134402  biweight      1.007007  0.002538746  0.7983219          
  250   0.3985641  biweight      1.010991  0.002749493  0.8007243          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were kmax = 208, distance = 2.540932
 and kernel = cos.
[1] "Sat Mar 03 14:17:17 2018"
k-Nearest Neighbors 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  k    RMSE      Rsquared      MAE        Selected
   14  1.034815  0.0038531776  0.8213999          
   21  1.029638  0.0063312157  0.8173889          
   36  1.016086  0.0010950601  0.8037583          
   43  1.012353  0.0006306940  0.8019069          
   58  1.014045  0.0006630524  0.8050732          
   69  1.012089  0.0022934158  0.8031029          
   82  1.010342  0.0040590683  0.8005839          
   95  1.009586  0.0017069357  0.8011654          
  121  1.006020  0.0021274438  0.7984309          
  167  1.001523  0.0075513032  0.7935231  *       
  178  1.001626  0.0062124298  0.7937445          
  193  1.003022  0.0041428678  0.7951520          
  208  1.002801  0.0066700438  0.7947045          
  211  1.003106  0.0056089461  0.7952273          
  214  1.003291  0.0050868376  0.7951371          
  235  1.003164  0.0042861317  0.7950013          
  237  1.003096  0.0054649105  0.7949395          
  244  1.002791  0.0056619657  0.7946344          
  245  1.002547  0.0060621437  0.7945004          
  250  1.003247  0.0040372484  0.7946555          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was k = 167.
[1] "Sat Mar 03 14:17:37 2018"
Polynomial Kernel Regularized Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  lambda        degree  RMSE          Rsquared     MAE           Selected
  1.859134e-05  1       89560.097519  0.011447514  7.359552e+04          
  2.609888e-05  2       37033.851172  0.021379263  2.940484e+04          
  5.156057e-05  2       18745.743274  0.021379263  1.488410e+04          
  6.947685e-05  2       13911.694648  0.021379263  1.104587e+04          
  1.408167e-04  2        6863.806176  0.021379264  5.449851e+03          
  2.360836e-04  3        1033.361013  0.006311892  8.144910e+02          
  4.360732e-04  1        3818.204957  0.011447508  3.137590e+03          
  7.885100e-04  1        2111.571646  0.011447502  1.735173e+03          
  2.528991e-03  1         658.322095  0.011447476  5.409731e+02          
  2.117596e-02  2          45.620687  0.021379440  3.621600e+01          
  3.483860e-02  1          47.743788  0.011446984  3.923641e+01          
  7.031281e-02  1          23.643372  0.011446444  1.943098e+01          
  1.426343e-01  3           1.989447  0.006586806  1.585731e+00          
  1.636691e-01  1          10.168146  0.011445021  8.359581e+00          
  1.859536e-01  3           1.659138  0.006671214  1.330298e+00          
  4.880622e-01  2           2.190533  0.021382665  1.743333e+00          
  5.287128e-01  3           1.110266  0.007350003  8.832087e-01          
  7.561173e-01  1           2.390507  0.011435948  1.952816e+00          
  7.804308e-01  3           1.055440  0.007858198  8.377863e-01  *       
  9.912226e-01  1           1.934461  0.011432327  1.571396e+00          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 0.7804308 and degree = 3.
[1] "Sat Mar 03 14:20:34 2018"

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.137314046 -0.082364870 -0.179568723 -0.074673913 -0.048667449 -0.096458922 
          V8           V9          V10 
 0.023656506 -0.006647465 -0.003166386 

 Quartiles of Marginal Effects:
 
             V2          V3         V4         V5          V6          V7
25% -0.29049379 -0.53798007 -0.6493523 -0.4960392 -0.52806181 -0.54211045
50%  0.06698457 -0.04995591 -0.1592683 -0.1341663 -0.08793827 -0.03178229
75%  0.54937284  0.37138853  0.3651325  0.2954794  0.39378730  0.38227461
             V8          V9          V10
25% -0.46693800 -0.49267235 -0.523241489
50%  0.01709884 -0.03604149 -0.006129924
75%  0.51163105  0.45501913  0.538366568

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
 0.01748304 -0.07463857 -0.13116080 -0.03978897 -0.03328108 -0.04249138 
         V8          V9         V10 
-0.05541858  0.01307416  0.03216530 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.07693177 -0.20313873 -0.20219025 -0.17562638 -0.13585876 -0.12844932
50%  0.01705333 -0.07326131 -0.13473337 -0.04699444 -0.03807870 -0.03378967
75%  0.12503617  0.06219322 -0.06235669  0.10080012  0.07597224  0.04925016
             V8         V9         V10
25% -0.20672734 -0.1055963 -0.09278876
50% -0.05787423  0.0115570  0.02965082
75%  0.10752731  0.1265560  0.15395126

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.006265590 -0.065078441 -0.078952035 -0.019246355 -0.024766654 -0.034169819 
          V8           V9          V10 
-0.007155116  0.002438195  0.020942046 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% 0.005665737 -0.06599779 -0.07954701 -0.01995947 -0.02551569 -0.03467587
50% 0.006203851 -0.06517082 -0.07913441 -0.01918205 -0.02488814 -0.03425350
75% 0.006803221 -0.06436490 -0.07841545 -0.01844339 -0.02411097 -0.03373448
              V8          V9        V10
25% -0.007999776 0.001929268 0.02030554
50% -0.007119595 0.002435710 0.02099003
75% -0.006383683 0.002938398 0.02163116

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.006757799 -0.077870017 -0.093243102 -0.022971900 -0.028795526 -0.041016786 
          V8           V9          V10 
-0.009185811  0.001178542  0.024216028 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% 0.006571295 -0.07812308 -0.09340511 -0.02319364 -0.02901184 -0.04116435
50% 0.006745415 -0.07788750 -0.09328402 -0.02296702 -0.02883498 -0.04102896
75% 0.006929831 -0.07766280 -0.09312239 -0.02271149 -0.02857614 -0.04088129
              V8          V9        V10
25% -0.009431686 0.001028081 0.02401883
50% -0.009179509 0.001179695 0.02422004
75% -0.008938939 0.001328377 0.02442988

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.006922006 -0.078953511 -0.094659063 -0.023447618 -0.029192076 -0.041634320 
          V8           V9          V10 
-0.009486098  0.001096172  0.024472932 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% 0.006426696 -0.07962624 -0.09508614 -0.02405077 -0.02977194 -0.04203644
50% 0.006887576 -0.07900419 -0.09476222 -0.02343364 -0.02930660 -0.04166372
75% 0.007387165 -0.07838571 -0.09433997 -0.02274840 -0.02860342 -0.04127514
              V8           V9        V10
25% -0.010143718 0.0006902618 0.02393874
50% -0.009469214 0.0011035975 0.02448373
75% -0.008843011 0.0014935005 0.02504550

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 1.859713e-02  2.756977e-03 -2.727457e-02 -1.638307e-02 -8.802915e-03 
           V7            V8            V9           V10 
 5.172092e-03  8.278944e-03  1.895767e-05 -2.501410e-03 

 Quartiles of Marginal Effects:
 
              V2            V3           V4           V5            V6
25% -0.041595077 -0.0630637639 -0.079913314 -0.091233028 -0.0713129749
50%  0.004236884  0.0009973975 -0.006901202 -0.005082366  0.0005576189
75%  0.080219707  0.0721360444  0.045966713  0.051025262  0.0603108121
              V7            V8           V9         V10
25% -0.074785151 -0.0786021818 -0.080830694 -0.05741651
50% -0.001915676 -0.0005347708 -0.002745683  0.00445641
75%  0.052881732  0.0731624349  0.060254412  0.07073039

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.013429020 -0.086564152 -0.124336887 -0.035434547 -0.034537326 -0.048374834 
          V8           V9          V10 
-0.033582066  0.005842092  0.029764688 

 Quartiles of Marginal Effects:
 
             V2          V3         V4          V5          V6           V7
25% -0.03875971 -0.15100653 -0.1610608 -0.10338636 -0.09084503 -0.091357414
50%  0.01218142 -0.08931796 -0.1280707 -0.03517583 -0.04310449 -0.043971488
75%  0.06888197 -0.01708166 -0.0907099  0.03993342  0.02982020 -0.004377776
             V8           V9         V10
25% -0.11125492 -0.043964587 -0.03458915
50% -0.03500716  0.007647735  0.02899517
75%  0.04932689  0.063579400  0.09345338

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.026809272 -0.003124130 -0.053179986 -0.036496506 -0.018749107 -0.011862705 
          V8           V9          V10 
-0.007645619 -0.003077499 -0.001255036 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5           V6          V7
25% -0.06083068 -0.108568413 -0.15456244 -0.15193342 -0.113006141 -0.11287010
50%  0.01604123 -0.003375341 -0.02817088 -0.02279211 -0.001881117 -0.01016675
75%  0.12739154  0.094073336  0.05537153  0.06735318  0.081220436  0.07387773
              V8          V9          V10
25% -0.127721808 -0.10679539 -0.097231421
50% -0.007458621 -0.00223719  0.002370512
75%  0.102582717  0.10327935  0.108504937

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0094363512 -0.0958520341 -0.1201946639 -0.0316832329 -0.0350737525 
           V7            V8            V9           V10 
-0.0516105169 -0.0204018106  0.0009227938  0.0294157397 

 Quartiles of Marginal Effects:
 
              V2          V3         V4           V5           V6          V7
25% -0.010380981 -0.12143929 -0.1345307 -0.058550938 -0.060001115 -0.06837658
50%  0.008876329 -0.09636874 -0.1209860 -0.032242147 -0.038525189 -0.05080155
75%  0.030856962 -0.06852210 -0.1077218 -0.001638822 -0.008189538 -0.03497879
             V8           V9         V10
25% -0.04998027 -0.017588298 0.005558426
50% -0.01934743  0.001612967 0.029412681
75%  0.01037256  0.022134592 0.053974316

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0091391802 -0.0963153281 -0.1193838327 -0.0312992248 -0.0350705557 
           V7            V8            V9           V10 
-0.0517281548 -0.0188521445  0.0004077718  0.0292557936 

 Quartiles of Marginal Effects:
 
              V2          V3         V4           V5          V6          V7
25% -0.007145437 -0.11701271 -0.1309565 -0.053261113 -0.05544092 -0.06536987
50%  0.008872945 -0.09651488 -0.1200416 -0.031217276 -0.03774861 -0.05128356
75%  0.026603849 -0.07421220 -0.1089920 -0.007206524 -0.01303394 -0.03804179
              V8            V9        V10
25% -0.042837976 -0.0143073685 0.01023729
50% -0.018311255  0.0007187744 0.02924978
75%  0.005989478  0.0175004812 0.04900683

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0074742271 -0.0916226584 -0.1090387526 -0.0274988825 -0.0330707189 
           V7            V8            V9           V10 
-0.0485105095 -0.0119868717 -0.0006030299  0.0274240527 

 Quartiles of Marginal Effects:
 
             V2          V3         V4          V5          V6          V7
25% 0.006566306 -0.09269409 -0.1096552 -0.02862900 -0.03413055 -0.04923140
50% 0.007459242 -0.09167894 -0.1091186 -0.02743253 -0.03323158 -0.04850432
75% 0.008362839 -0.09055942 -0.1085103 -0.02628133 -0.03193373 -0.04786165
             V8            V9        V10
25% -0.01313482 -0.0013446154 0.02646162
50% -0.01196369 -0.0006118942 0.02745169
75% -0.01079095  0.0001893456 0.02845443

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0313440008 -0.0151400002 -0.0747943582 -0.0498092649 -0.0258226352 
           V7            V8            V9           V10 
-0.0243896783 -0.0160730780 -0.0013148290  0.0001059944 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.07549813 -0.12656444 -0.18568130 -0.18579300 -0.13327144 -0.12424632
50%  0.02804661 -0.02515911 -0.05596006 -0.03148613 -0.01077478 -0.02296344
75%  0.14072875  0.09927710  0.05425971  0.08322676  0.09280169  0.06933234
             V8           V9         V10
25% -0.15125218 -0.113041682 -0.11693158
50% -0.01462094  0.004390415 -0.00108143
75%  0.11651466  0.107977865  0.12233977

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.068312640 -0.081203812 -0.140187447 -0.055345527 -0.032786564 -0.019095163 
          V8           V9          V10 
-0.045964168  0.005953398  0.019120107 

 Quartiles of Marginal Effects:
 
             V2         V3         V4          V5          V6         V7
25% -0.19128612 -0.3444604 -0.4011320 -0.37198886 -0.31702720 -0.2737685
50%  0.04266434 -0.0582532 -0.1094381 -0.07713915 -0.05868114 -0.0274403
75%  0.29616381  0.1909389  0.1372603  0.22409185  0.24671400  0.2230148
             V8           V9          V10
25% -0.35846288 -0.292663672 -0.250331817
50% -0.03169277  0.006355477  0.003874983
75%  0.26769826  0.289547297  0.269748236

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
 0.19238944 -0.01651014 -0.20260110 -0.08708428 -0.08687155 -0.10863132 
         V8          V9         V10 
 0.05591520 -0.04081203  0.01551183 

 Quartiles of Marginal Effects:
 
            V2          V3         V4          V5         V6          V7
25% -0.4592150 -0.84565434 -0.9054552 -0.70463823 -0.8123878 -0.75362514
50%  0.1404474  0.05507326 -0.1700466 -0.06179541 -0.1071848 -0.07010062
75%  0.8171928  0.70532541  0.5588690  0.62130256  0.5672311  0.66215633
             V8          V9        V10
25% -0.65971477 -0.76588160 -0.6595327
50%  0.04855019 -0.04243167  0.0186183
75%  0.73116502  0.69059883  0.7156152

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0474558046 -0.0143789754 -0.1071641314 -0.0712676288 -0.0359082535 
           V7            V8            V9           V10 
-0.0398286683 -0.0241427319  0.0007014884 -0.0008432159 

 Quartiles of Marginal Effects:
 
             V2         V3          V4          V5          V6          V7
25% -0.16398281 -0.2350868 -0.33255654 -0.30037264 -0.27307001 -0.23741553
50%  0.04856047 -0.0528545 -0.07420191 -0.05906068 -0.01209859 -0.03439609
75%  0.26228598  0.2237236  0.13460245  0.16315849  0.20511248  0.17959148
            V8           V9          V10
25% -0.2942404 -0.233179919 -0.224978513
50% -0.0204013 -0.002951294  0.002578814
75%  0.2239615  0.228903848  0.234824680

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.019820374 -0.075406757 -0.122217769 -0.040044164 -0.034556635 -0.045027895 
          V8           V9          V10 
-0.034590575  0.006921575  0.026530407 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5          V6           V7
25% -0.05079141 -0.152259635 -0.16621259 -0.12311339 -0.09995979 -0.099137220
50%  0.01600187 -0.079979207 -0.12392819 -0.04752145 -0.04051865 -0.041961298
75%  0.08785352  0.005323568 -0.08078599  0.04906439  0.02939961  0.007928128
             V8           V9         V10
25% -0.12274243 -0.054257433 -0.03932954
50% -0.02698875  0.007389498  0.03142018
75%  0.05505713  0.073624984  0.09585653

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.002635210 -0.024365069 -0.030255811 -0.006672827 -0.009915284 -0.012508992 
          V8           V9          V10 
-0.001724418  0.002624708  0.008746453 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5           V6          V7
25% 0.002612014 -0.02441229 -0.03030057 -0.006699893 -0.009950418 -0.01253915
50% 0.002633609 -0.02437426 -0.03026860 -0.006672101 -0.009921461 -0.01251733
75% 0.002657165 -0.02433205 -0.03022074 -0.006640613 -0.009889037 -0.01248732
              V8          V9         V10
25% -0.001759638 0.002604105 0.008721590
50% -0.001722507 0.002626738 0.008752272
75% -0.001692005 0.002648175 0.008778583

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.009886188 -0.094778638 -0.120756205 -0.032110681 -0.035000520 -0.051237361 
          V8           V9          V10 
-0.022178476  0.001615108  0.029479788 

 Quartiles of Marginal Effects:
 
              V2          V3         V4           V5           V6          V7
25% -0.014312949 -0.12577412 -0.1380928 -0.064927292 -0.064781271 -0.07204287
50%  0.009100098 -0.09586524 -0.1217291 -0.032797216 -0.039138174 -0.04993749
75%  0.036299255 -0.06142523 -0.1052759  0.004672247 -0.002810835 -0.03048153
             V8           V9          V10
25% -0.05898880 -0.021545208 -0.000111535
50% -0.02083488  0.002086959  0.029281350
75%  0.01661498  0.027879659  0.059562522

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.106690009 -0.085922720 -0.167434354 -0.065111424 -0.048810190 -0.072212636 
          V8           V9          V10 
-0.007229673  0.005637144  0.002227175 

 Quartiles of Marginal Effects:
 
             V2          V3         V4         V5          V6         V7
25% -0.27035194 -0.45780707 -0.5917364 -0.4440612 -0.45771087 -0.4267246
50%  0.07356608 -0.07975287 -0.1369053 -0.1209169 -0.07509304 -0.0217213
75%  0.45903006  0.26093211  0.2569485  0.2656848  0.33525156  0.3179008
             V8          V9         V10
25% -0.42830719 -0.41824711 -0.43305368
50%  0.01059209 -0.02334604 -0.02252502
75%  0.41241634  0.35463615  0.47454874

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0103276602  0.0016063854 -0.0129718974 -0.0076835996 -0.0036593202 
           V7            V8            V9           V10 
 0.0041056722  0.0070788493  0.0004294069 -0.0014460481 

 Quartiles of Marginal Effects:
 
              V2            V3           V4           V5            V6
25% -0.021125491 -0.0349148103 -0.038568599 -0.045585826 -0.0337545831
50%  0.002167143  0.0003919568 -0.001792331 -0.001585253  0.0001618181
75%  0.044117922  0.0406916556  0.024677316  0.023597484  0.0302653675
             V7            V8            V9           V10
25% -0.03735335 -4.030986e-02 -0.0419332714 -0.0280731985
50% -0.00071944 -8.982644e-05 -0.0009229557  0.0008672209
75%  0.02783373  3.543262e-02  0.0316232249  0.0365071361

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.01766821 -0.02176875 -0.13661225 -0.19571856  0.13801741  0.02214861 
         V8          V9         V10 
 0.01819121 -0.09296848 -0.18126609 

 Quartiles of Marginal Effects:
 
            V2          V3         V4         V5          V6          V7
25% -0.5290852 -0.45774760 -0.5826378 -0.6570982 -0.40385795 -0.30436314
50% -0.0101415  0.02855026 -0.1197346 -0.2477326  0.05159949  0.01872269
75%  0.4389727  0.44589825  0.3688122  0.2162242  0.61817354  0.36255235
             V8          V9        V10
25% -0.39147912 -0.45451287 -0.6970692
50%  0.07282054 -0.05895925 -0.1584542
75%  0.41672637  0.29693747  0.3276835

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.011476498  0.007137445 -0.116012463 -0.072878113  0.001118056 -0.012864138 
          V8           V9          V10 
-0.066883976  0.011653738 -0.056377963 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5           V6          V7
25% -0.09428412 -0.15092210 -0.18699338 -0.144998778 -0.133314273 -0.08833727
50% -0.01747335  0.02331304 -0.11772618 -0.072653413  0.001869624 -0.01292462
75%  0.06395007  0.14882620 -0.04774377 -0.006328338  0.135756788  0.06945614
             V8          V9         V10
25% -0.16877207 -0.10741419 -0.17638245
50% -0.06361062  0.01037666 -0.05282245
75%  0.03823937  0.12076269  0.06211997

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.001138610 -0.004061401 -0.069017150 -0.029917392 -0.004709065 -0.011190940 
          V8           V9          V10 
-0.037403749  0.006516648 -0.040602145 

 Quartiles of Marginal Effects:
 
               V2           V3          V4          V5           V6          V7
25% -0.0017219312 -0.004849227 -0.06962027 -0.03053164 -0.005385890 -0.01172774
50% -0.0011851591 -0.004064351 -0.06915234 -0.02995778 -0.004733365 -0.01117917
75% -0.0005591452 -0.003285857 -0.06858085 -0.02944152 -0.004033971 -0.01068409
             V8          V9         V10
25% -0.03786670 0.005827864 -0.04124730
50% -0.03747542 0.006528531 -0.04068039
75% -0.03701367 0.007172204 -0.04003619

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.001517254 -0.005253438 -0.082186202 -0.034595196 -0.005632158 -0.013829690 
          V8           V9          V10 
-0.045746837  0.007930132 -0.048559023 

 Quartiles of Marginal Effects:
 
              V2           V3          V4          V5           V6          V7
25% -0.001698894 -0.005519897 -0.08235056 -0.03477121 -0.005845249 -0.01399413
50% -0.001539071 -0.005247672 -0.08221389 -0.03460119 -0.005642655 -0.01383305
75% -0.001329087 -0.005003500 -0.08205939 -0.03444929 -0.005415151 -0.01367523
             V8          V9         V10
25% -0.04588600 0.007725230 -0.04874800
50% -0.04575859 0.007929164 -0.04857258
75% -0.04563201 0.008131354 -0.04837278

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.001497450 -0.005228731 -0.083439632 -0.035382151 -0.005656017 -0.014108041 
          V8           V9          V10 
-0.046470222  0.008167120 -0.049425946 

 Quartiles of Marginal Effects:
 
               V2           V3          V4          V5           V6          V7
25% -0.0019932965 -0.005940040 -0.08387636 -0.03585398 -0.006230982 -0.01455398
50% -0.0015534656 -0.005209333 -0.08351843 -0.03540150 -0.005691571 -0.01411946
75% -0.0009906624 -0.004555188 -0.08309227 -0.03498151 -0.005077716 -0.01369239
             V8          V9         V10
25% -0.04684767 0.007614610 -0.04992923
50% -0.04650280 0.008153064 -0.04946914
75% -0.04615710 0.008705345 -0.04891781

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.013048533  0.010902180 -0.027116672 -0.031904166  0.009986295 -0.005524237 
          V8           V9          V10 
 0.011425662  0.012940059 -0.036281104 

 Quartiles of Marginal Effects:
 
              V2           V3          V4          V5           V6
25% -0.050114557 -0.053478180 -0.11124188 -0.08621130 -0.074376942
50%  0.003277507  0.004418027 -0.01174810 -0.01121929  0.003097751
75%  0.067509718  0.070592024  0.03789736  0.04352301  0.087153326
               V7           V8           V9          V10
25% -7.085682e-02 -0.053837529 -0.053801218 -0.107000749
50%  7.792766e-05  0.003875729  0.002779086 -0.008417737
75%  6.100421e-02  0.088333390  0.076465103  0.041276846

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.006355912  0.001100411 -0.109489050 -0.059737403 -0.004557361 -0.016718972 
          V8           V9          V10 
-0.062218844  0.013931506 -0.061524778 

 Quartiles of Marginal Effects:
 
              V2          V3         V4          V5           V6          V7
25% -0.050210157 -0.08118113 -0.1481270 -0.09934107 -0.071315706 -0.06010359
50% -0.009793773  0.01062549 -0.1108978 -0.06408913 -0.002540257 -0.01623209
75%  0.039422879  0.07875621 -0.0690236 -0.01908373  0.061632496  0.02848801
             V8          V9          V10
25% -0.10740829 -0.04931833 -0.120179767
50% -0.06136474  0.01148472 -0.059766954
75% -0.01421937  0.07159352 -0.003517624

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.016671345  0.017064090 -0.041870410 -0.072275974  0.010654487 -0.012125099 
          V8           V9          V10 
 0.004635886  0.009390325 -0.056896297 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5           V6           V7
25% -0.08124749 -0.08470503 -0.15846476 -0.16304278 -0.098750263 -0.094277130
50%  0.00512071  0.01400434 -0.03057840 -0.03808810  0.006925654 -0.006626175
75%  0.11368183  0.11100853  0.06960569  0.04930425  0.130878276  0.081695096
              V8           V9         V10
25% -0.091106397 -0.085479439 -0.17720996
50%  0.008316583  0.004478829 -0.02626598
75%  0.106983301  0.103919984  0.05792892

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.004104774 -0.003977665 -0.106663741 -0.048136763 -0.006925221 -0.018193816 
          V8           V9          V10 
-0.061368326  0.012447401 -0.063217576 

 Quartiles of Marginal Effects:
 
              V2           V3          V4          V5           V6
25% -0.023005496 -0.036766328 -0.12215692 -0.06504852 -0.032208599
50% -0.006333096 -0.001023059 -0.10711999 -0.04949500 -0.006629163
75%  0.016279104  0.025961792 -0.08920827 -0.03008143  0.019694066
               V7          V8          V9         V10
25% -0.0360658246 -0.07690846 -0.01235841 -0.08532693
50% -0.0177224160 -0.06094783  0.01062422 -0.06470110
75% -0.0006349637 -0.04597087  0.03467839 -0.04134426

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.003592492 -0.004458865 -0.105957342 -0.047264993 -0.006929036 -0.018320643 
          V8           V9          V10 
-0.060889642  0.012211472 -0.063128485 

 Quartiles of Marginal Effects:
 
              V2           V3          V4          V5           V6           V7
25% -0.019362416 -0.030450301 -0.11831633 -0.06113229 -0.026852492 -0.032789958
50% -0.005196068 -0.002164509 -0.10624813 -0.04861952 -0.007106756 -0.017934785
75%  0.012956159  0.019758844 -0.09214466 -0.03243429  0.014485708 -0.003987186
             V8           V9         V10
25% -0.07330630 -0.007944351 -0.08069751
50% -0.06048126  0.010948603 -0.06398306
75% -0.04864407  0.030444366 -0.04569881

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.001811822 -0.006196021 -0.096721723 -0.040620998 -0.006449691 -0.016977896 
          V8           V9          V10 
-0.055074954  0.009900658 -0.057790667 

 Quartiles of Marginal Effects:
 
               V2           V3          V4          V5           V6          V7
25% -0.0027089730 -0.007534208 -0.09744315 -0.04140943 -0.007509643 -0.01774373
50% -0.0018962695 -0.006120291 -0.09682571 -0.04069176 -0.006479218 -0.01699850
75% -0.0008697277 -0.004937121 -0.09603965 -0.03984596 -0.005421844 -0.01623115
             V8          V9         V10
25% -0.05574075 0.008904294 -0.05874939
50% -0.05508829 0.009837957 -0.05781873
75% -0.05447447 0.010897128 -0.05687872

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
 0.01562929  0.01851269 -0.05502115 -0.09614106  0.01229343 -0.01895748 
         V8          V9         V10 
-0.00237221  0.01003883 -0.06939611 

 Quartiles of Marginal Effects:
 
              V2          V3          V4          V5           V6          V7
25% -0.098434664 -0.10675940 -0.18880592 -0.21303748 -0.130673819 -0.11535062
50%  0.008441242  0.01907447 -0.04059278 -0.06780606  0.007210168 -0.01410396
75%  0.130500106  0.11942467  0.07042759  0.03475562  0.146264515  0.09024569
              V8          V9         V10
25% -0.113638835 -0.08737343 -0.20651443
50%  0.005516306  0.01037026 -0.04871838
75%  0.107676876  0.12426128  0.06428811

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.008280259  0.029025418 -0.136878987 -0.150717521  0.049737086  0.001594421 
          V8           V9          V10 
-0.015878693 -0.004059929 -0.056517486 

 Quartiles of Marginal Effects:
 
              V2          V3          V4           V5          V6           V7
25% -0.184366285 -0.29001805 -0.35267540 -0.354509097 -0.23702910 -0.209403222
50%  0.002271069  0.06096754 -0.13202949 -0.191997495  0.02040477 -0.004423062
75%  0.213600556  0.31021348  0.06879101  0.003852555  0.32235512  0.193475175
             V8          V9         V10
25% -0.26345864 -0.22092819 -0.37279740
50% -0.02062131  0.02286666 -0.07938365
75%  0.22228233  0.23784378  0.21377231

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.090572417 -0.001934715 -0.164753805 -0.247376512  0.201184166  0.031044605 
          V8           V9          V10 
 0.021331197 -0.110099043 -0.341052786 

 Quartiles of Marginal Effects:
 
             V2         V3         V4         V5         V6          V7
25% -0.79774608 -0.6640057 -0.8256188 -0.9291300 -0.6042372 -0.48132946
50% -0.02825928 -0.0231345 -0.1439156 -0.3406245  0.1308884  0.05688612
75%  0.63170756  0.6764449  0.4820223  0.4390530  0.8822764  0.64854726
             V8          V9        V10
25% -0.54015230 -0.65027302 -1.1503585
50%  0.03438444 -0.08406841 -0.3289902
75%  0.61372604  0.43291303  0.4124974

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.006805178  0.012905175 -0.071368655 -0.131441214  0.029099724 -0.023633782 
          V8           V9          V10 
 0.017511469 -0.001345893 -0.112490259 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5          V6          V7
25% -0.19180490 -0.226232051 -0.29505041 -0.33682042 -0.22579110 -0.21148661
50% -0.01097257  0.007167406 -0.05937911 -0.09689872  0.00554352 -0.01528031
75%  0.22544413  0.229594420  0.15909722  0.09552584  0.28743069  0.16644867
             V8           V9        V10
25% -0.20050925 -0.189831961 -0.3633898
50%  0.02254678  0.003014938 -0.1026031
75%  0.23687337  0.199841348  0.1348490

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
-6.267648e-04  6.341603e-03 -1.054940e-01 -7.735373e-02  3.470054e-05 
           V7            V8            V9           V10 
-1.888092e-02 -5.417403e-02  1.720316e-02 -6.229505e-02 

 Quartiles of Marginal Effects:
 
               V2           V3          V4          V5           V6          V7
25% -0.0525275188 -0.083893927 -0.15000732 -0.12725686 -0.077141615 -0.07002398
50%  0.0007622295  0.007479293 -0.11008514 -0.08613547 -0.003007469 -0.01890282
75%  0.0480200062  0.095250078 -0.06726549 -0.02864555  0.084229488  0.03050597
              V8          V9          V10
25% -0.106040268 -0.05777118 -0.132367774
50% -0.053414619  0.01696780 -0.060933155
75%  0.001411919  0.08751474  0.005196083

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.000494555 -0.001470971 -0.025833546 -0.011140741 -0.001973652 -0.003589341 
          V8           V9          V10 
-0.013033057  0.001958373 -0.014651607 

 Quartiles of Marginal Effects:
 
               V2           V3          V4          V5           V6
25% -0.0005176953 -0.001497688 -0.02587210 -0.01116950 -0.002000939
50% -0.0004962517 -0.001473531 -0.02584084 -0.01114508 -0.001974754
75% -0.0004703453 -0.001444932 -0.02580749 -0.01111921 -0.001946599
              V7          V8          V9         V10
25% -0.003613142 -0.01305988 0.001932374 -0.01468298
50% -0.003589329 -0.01303853 0.001960786 -0.01465623
75% -0.003566107 -0.01301306 0.001984731 -0.01462914

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.004568838 -0.003303113 -0.107074300 -0.049370932 -0.006782964 -0.017974849 
          V8           V9          V10 
-0.061574193  0.012708330 -0.063082308 

 Quartiles of Marginal Effects:
 
              V2            V3          V4          V5           V6
25% -0.027028537 -0.0432635563 -0.12592598 -0.06978135 -0.038053104
50% -0.006936096  0.0007640186 -0.10785940 -0.05088683 -0.006310376
75%  0.020046802  0.0330776149 -0.08630208 -0.02751417  0.024799293
              V7          V8          V9         V10
25% -0.039849799 -0.08143230 -0.01765401 -0.09029004
50% -0.017358220 -0.06100203  0.01028833 -0.06459640
75%  0.003115331 -0.04187344  0.03952695 -0.03603988

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.005017543 -0.012508378 -0.138717801 -0.175775712  0.102676855  0.012714910 
          V8           V9          V10 
 0.006213419 -0.057191764 -0.128768341 

 Quartiles of Marginal Effects:
 
            V2          V3          V4         V5          V6          V7
25% -0.4197186 -0.39263050 -0.49524778 -0.5117601 -0.36517963 -0.27950411
50% -0.0178146  0.02127347 -0.09513703 -0.2134438  0.07114825  0.02000657
75%  0.3649126  0.40877647  0.26196394  0.1287484  0.49930314  0.30173240
             V8         V9        V10
25% -0.31876809 -0.3727534 -0.5983702
50%  0.04853281 -0.0184623 -0.1293696
75%  0.33749238  0.2797902  0.2907931

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.007732354  0.005764136 -0.015260970 -0.016596712  0.006186664 -0.003950100 
          V8           V9          V10 
 0.006552451  0.009254694 -0.021268620 

 Quartiles of Marginal Effects:
 
               V2           V3           V4           V5            V6
25% -0.0231449913 -0.025391931 -0.051629502 -0.045735573 -0.0327024487
50%  0.0001397794  0.002053432 -0.004374215 -0.003251601  0.0006146092
75%  0.0358626699  0.042120408  0.017091292  0.023460426  0.0427925282
               V7           V8          V9          V10
25% -0.0367881197 -0.028382415 -0.03276935 -0.056635652
50% -0.0003024069  0.001533214  0.00131184 -0.004040193
75%  0.0287231628  0.050067440  0.04717176  0.020986461

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
 0.01010724 -0.04322071 -0.15459416  0.03584850  0.02127866 -0.06428391 
         V8          V9         V10 
 0.03290764 -0.01265958  0.11452401 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.48061336 -0.49029312 -0.61444104 -0.47619418 -0.41998576 -0.58584327
50%  0.02749589 -0.00944486 -0.09405434 -0.05456042  0.06545926 -0.03985748
75%  0.46034717  0.41618075  0.41561960  0.42693395  0.44479952  0.43266748
             V8           V9         V10
25% -0.46356641 -0.475352616 -0.42471536
50% -0.02681656  0.007059533  0.09076356
75%  0.43915874  0.463703399  0.63438803

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.065896027 -0.017785443 -0.110457407  0.044853718  0.033742125 -0.007886184 
          V8           V9          V10 
-0.033803698  0.013053043  0.016542706 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6           V7
25% -0.16618475 -0.13812937 -0.20727914 -0.06736423 -0.07698962 -0.108536380
50% -0.06529321 -0.02311848 -0.11838613  0.03934273  0.03216421 -0.006715395
75%  0.04091257  0.10479997 -0.02214793  0.15856235  0.13705021  0.087881454
             V8          V9         V10
25% -0.13781358 -0.12424833 -0.10632091
50% -0.03676102  0.03024612  0.01574832
75%  0.06322205  0.14808649  0.13686092

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.046905734 -0.017728515 -0.075219623  0.042113367  0.037373115 -0.015454808 
          V8           V9          V10 
-0.009970088 -0.003534130  0.003459498 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5         V6          V7
25% -0.04761151 -0.01848891 -0.07613565 0.04145031 0.03679365 -0.01613180
50% -0.04694080 -0.01772417 -0.07536628 0.04221919 0.03747081 -0.01553411
75% -0.04623154 -0.01697056 -0.07451454 0.04277838 0.03809327 -0.01479452
              V8           V9         V10
25% -0.010503329 -0.004207187 0.002742710
50% -0.010003057 -0.003496480 0.003469155
75% -0.009452921 -0.002820070 0.004165054

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.056509766 -0.020898585 -0.089512739  0.051510187  0.045330290 -0.018489434 
          V8           V9          V10 
-0.012978782 -0.004723888  0.004255873 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5         V6          V7
25% -0.05672435 -0.02112879 -0.08977190 0.05130829 0.04514558 -0.01870006
50% -0.05650268 -0.02090080 -0.08953695 0.05154029 0.04534224 -0.01851085
75% -0.05631543 -0.02066004 -0.08930006 0.05170458 0.04555150 -0.01827509
             V8           V9         V10
25% -0.01314376 -0.004936300 0.004026889
50% -0.01298529 -0.004712122 0.004262007
75% -0.01282569 -0.004494279 0.004487915

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.057271186 -0.021161123 -0.090939557  0.052108503  0.045927745 -0.018815296 
          V8           V9          V10 
-0.013411179 -0.004689874  0.004393894 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5         V6          V7
25% -0.05785148 -0.02177708 -0.09162663 0.05156076 0.04543218 -0.01937425
50% -0.05724791 -0.02116141 -0.09100525 0.05217872 0.04596047 -0.01887476
75% -0.05674026 -0.02052604 -0.09036593 0.05263358 0.04652035 -0.01823927
             V8           V9         V10
25% -0.01385625 -0.005257993 0.003769466
50% -0.01343093 -0.004658573 0.004415062
75% -0.01301100 -0.004070422 0.005020676

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.003173885  0.006074056 -0.022819866 -0.026867093  0.004967891 -0.007098445 
          V8           V9          V10 
-0.001212479  0.007721169 -0.018991999 

 Quartiles of Marginal Effects:
 
               V2           V3           V4           V5           V6
25% -0.0728612996 -0.069342039 -0.084664692 -0.097797172 -0.070777974
50%  0.0006057773 -0.001495033 -0.006328523 -0.008067083 -0.003571426
75%  0.0706482102  0.072435020  0.057932344  0.044411125  0.085432889
              V7           V8           V9          V10
25% -0.067735575 -0.076131856 -0.063571260 -0.066986781
50% -0.002298402 -0.001506821  0.001701908 -0.002052195
75%  0.064669422  0.052174697  0.086749857  0.061846528

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.067951400 -0.018342892 -0.111947440  0.052983248  0.043316431 -0.015570943 
          V8           V9          V10 
-0.028202236  0.003140027  0.013826083 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5          V6          V7
25% -0.11843650 -0.08885478 -0.16833859 -0.005815644 -0.01385629 -0.07191276
50% -0.06641244 -0.01866764 -0.11354420  0.052290745  0.04091357 -0.01754948
75% -0.01275453  0.05140352 -0.05935625  0.109617294  0.10211810  0.04000165
             V8          V9         V10
25% -0.08019018 -0.06619228 -0.05593152
50% -0.02677738  0.01062268  0.01774603
75%  0.02169943  0.07559064  0.08096606

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.002501044 -0.002556262 -0.042212218 -0.042002454  0.009507883 -0.020853786 
          V8           V9          V10 
-0.022164850  0.003798119 -0.018870824 

 Quartiles of Marginal Effects:
 
              V2         V3         V4          V5           V6           V7
25% -0.098726070 -0.1036881 -0.1444799 -0.13681180 -0.087959012 -0.115341628
50% -0.003642952 -0.0052265 -0.0239823 -0.02368332  0.003009757 -0.007349403
75%  0.104248320  0.0913826  0.0594777  0.08120929  0.108720866  0.084415248
              V8           V9          V10
25% -0.112514679 -0.103103394 -0.104942869
50% -0.007518168  0.005647041 -0.009482671
75%  0.066396635  0.110337640  0.085564339

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.071846969 -0.022069051 -0.113375583  0.063004364  0.053030020 -0.020104514 
          V8           V9          V10 
-0.023013762 -0.003167301  0.010073453 

 Quartiles of Marginal Effects:
 
             V2           V3          V4         V5         V6           V7
25% -0.09447193 -0.051090651 -0.13701876 0.03937310 0.02817940 -0.043445890
50% -0.07115347 -0.022657414 -0.11346536 0.06245211 0.05133621 -0.021818061
75% -0.04988746  0.006197834 -0.08952875 0.08413449 0.07642957  0.002463275
              V8            V9         V10
25% -0.042267860 -0.0287448175 -0.01872128
50% -0.022750288 -0.0005486732  0.01086396
75% -0.004352505  0.0236308207  0.03735571

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.071708967 -0.022701254 -0.113323041  0.063464028  0.053949309 -0.020879743 
          V8           V9          V10 
-0.022285256 -0.003752727  0.009294694 

 Quartiles of Marginal Effects:
 
             V2            V3          V4         V5         V6           V7
25% -0.09001853 -0.0460870859 -0.13296013 0.04429504 0.03419027 -0.039785929
50% -0.07076137 -0.0230405468 -0.11349607 0.06286714 0.05253960 -0.022300164
75% -0.05381995  0.0005069831 -0.09386305 0.08030452 0.07298740 -0.002146793
              V8           V9          V10
25% -0.037434393 -0.024250740 -0.013739140
50% -0.021986876 -0.001670713  0.009873113
75% -0.007116778  0.017930239  0.031457951

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.066740136 -0.024176985 -0.105496809  0.061274864  0.053786558 -0.021976745 
          V8           V9          V10 
-0.017180889 -0.005659529  0.005424906 

 Quartiles of Marginal Effects:
 
             V2          V3         V4         V5         V6          V7
25% -0.06775901 -0.02537646 -0.1066832 0.06023576 0.05280796 -0.02298245
50% -0.06668987 -0.02416534 -0.1055824 0.06130476 0.05381962 -0.02208505
75% -0.06576546 -0.02297890 -0.1044389 0.06217793 0.05489619 -0.02096118
             V8           V9         V10
25% -0.01798704 -0.006710006 0.004221086
50% -0.01716037 -0.005583053 0.005435895
75% -0.01640524 -0.004544621 0.006560842

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.009740976 -0.009634501 -0.061349940 -0.041016902  0.012599074 -0.029419626 
          V8           V9          V10 
-0.031528228  0.005378074 -0.013204867 

 Quartiles of Marginal Effects:
 
              V2           V3          V4          V5           V6          V7
25% -0.121249028 -0.120593730 -0.18256475 -0.15632984 -0.093457285 -0.13559768
50% -0.003764432 -0.007817823 -0.05040225 -0.02414188  0.004613309 -0.01149121
75%  0.117251085  0.104069209  0.04617866  0.08256378  0.119845529  0.08476823
             V8           V9          V10
25% -0.14833104 -0.128148696 -0.134020675
50% -0.01768276  0.003155787  0.002038051
75%  0.08783776  0.130562246  0.097606890

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.055101088 -0.002560535 -0.155295583  0.028665061  0.079297033 -0.023062361 
          V8           V9          V10 
 0.013072636 -0.002087394  0.006485617 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5          V6          V7
25% -0.29442087 -0.227444677 -0.35336969 -0.25760289 -0.15625039 -0.22910825
50% -0.05713098 -0.008558599 -0.14620014 -0.03222899  0.06445123 -0.03322593
75%  0.21670699  0.199316487  0.05864981  0.25889465  0.30131593  0.15987211
             V8          V9         V10
25% -0.27540383 -0.24502198 -0.27369783
50% -0.03804166  0.02953127 -0.01071041
75%  0.23510822  0.25866335  0.28193679

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.109637470 -0.123924996 -0.155794429 -0.063688807 -0.031430411 -0.031299094 
          V8           V9          V10 
 0.002250877 -0.041266911  0.091683898 

 Quartiles of Marginal Effects:
 
            V2          V3          V4         V5         V6          V7
25% -0.6904109 -0.88923722 -0.80737111 -0.7530980 -0.7198645 -0.74193386
50%  0.0267154 -0.07304349 -0.05528986 -0.1432072  0.0223013 -0.03427627
75%  0.8554252  0.67890113  0.65783637  0.6027739  0.6998492  0.75011431
             V8          V9         V10
25% -0.70949181 -0.67635371 -0.66136600
50% -0.01351306 -0.03574688  0.01260734
75%  0.58088146  0.61141845  0.86300823

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.005708686 -0.018198424 -0.076470180 -0.066558989  0.009252877 -0.034724157 
          V8           V9          V10 
-0.017968940 -0.004797873 -0.018431403 

 Quartiles of Marginal Effects:
 
             V2          V3         V4          V5          V6          V7
25% -0.20938014 -0.22937937 -0.3065288 -0.28915764 -0.20271455 -0.24676174
50% -0.01644954 -0.01863076 -0.0607412 -0.06073388  0.01225426 -0.01295069
75%  0.23313075  0.20044707  0.1609049  0.17994227  0.24371808  0.18933334
             V8          V9        V10
25% -0.23653067 -0.24419715 -0.2763280
50% -0.01062771 -0.00401748  0.0120810
75%  0.18731685  0.24482423  0.2137559

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.055691365 -0.017158049 -0.111034361  0.033867821  0.037329325 -0.021414134 
          V8           V9          V10 
-0.029554295  0.006370679  0.010320516 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.11857791 -0.09810782 -0.17487721 -0.02682395 -0.02178659 -0.08993429
50% -0.05310028 -0.02128017 -0.12026944  0.03379324  0.03602090 -0.02230163
75%  0.01064304  0.05678856 -0.05418887  0.09703032  0.10325752  0.04652021
             V8          V9         V10
25% -0.09458174 -0.07216462 -0.06972869
50% -0.02472245  0.01073250  0.02044041
75%  0.03491060  0.08693751  0.08856699

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.017322908 -0.006863303 -0.027951189  0.015336577  0.013541600 -0.005492082 
          V8           V9          V10 
-0.002224880 -0.001207707  0.001067498 

 Quartiles of Marginal Effects:
 
             V2           V3          V4         V5         V6           V7
25% -0.01735862 -0.006896181 -0.02800432 0.01530966 0.01351811 -0.005520179
50% -0.01732874 -0.006863692 -0.02796225 0.01534461 0.01354903 -0.005495062
75% -0.01729235 -0.006831575 -0.02791673 0.01537179 0.01357515 -0.005466538
              V8           V9         V10
25% -0.002247515 -0.001232750 0.001037804
50% -0.002226842 -0.001207144 0.001069622
75% -0.002203235 -0.001176945 0.001097561

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.07153130 -0.02134852 -0.11309895  0.06188823  0.05164555 -0.01925849 
         V8          V9         V10 
-0.02378496 -0.00234913  0.01084419 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5         V6           V7
25% -0.09862733 -0.05677848 -0.14191836 0.03336114 0.02155251 -0.046938886
50% -0.07044054 -0.02195188 -0.11306324 0.06141233 0.04973107 -0.020963678
75% -0.04478796  0.01278610 -0.08441993 0.08787138 0.07992871  0.007432473
              V8            V9         V10
25% -0.047830851 -0.0345440606 -0.02395649
50% -0.023230083  0.0007292643  0.01204061
75% -0.001016542  0.0305467069  0.04449612

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.02154640 -0.01954772 -0.15847348  0.04086077  0.04280612 -0.05899911 
         V8          V9         V10 
 0.03038871 -0.01653237  0.07667732 

 Quartiles of Marginal Effects:
 
              V2           V3         V4          V5          V6          V7
25% -0.416666020 -0.396195269 -0.5218856 -0.40257781 -0.28264806 -0.46555953
50%  0.007862102 -0.007435688 -0.1188780 -0.03962773  0.05085807 -0.04750603
75%  0.355426314  0.318852869  0.2506239  0.37451679  0.38844450  0.33958326
            V8            V9         V10
25% -0.4011791 -0.3623285398 -0.38212607
50% -0.0155070  0.0003503372  0.05839848
75%  0.3959506  0.3692292039  0.50374318

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0026475976  0.0047947986 -0.0120041108 -0.0137443844  0.0040879095 
           V7            V8            V9           V10 
-0.0024682595 -0.0003910058  0.0058654405 -0.0117804293 

 Quartiles of Marginal Effects:
 
              V2            V3            V4           V5           V6
25% -0.033295797 -0.0359316597 -0.0411539071 -0.048654278 -0.035739066
50%  0.000336422 -0.0004196634 -0.0007157174 -0.001881322 -0.001426044
75%  0.036345074  0.0372550944  0.0328166690  0.024911296  0.048890110
               V7            V8            V9          V10
25% -0.0350869482 -0.0421707499 -0.0359426072 -0.037504138
50% -0.0006504826 -0.0004093382  0.0009808835 -0.001301234
75%  0.0328702816  0.0280582018  0.0461472117  0.034595251

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
-0.0067244669 -0.0143513682 -0.0376932231 -0.0007950609  0.0006868876 
           V7            V8            V9           V10 
-0.0095335432 -0.0073680889  0.0015739864 -0.0021932498 

 Quartiles of Marginal Effects:
 
              V2          V3          V4            V5           V6
25% -0.006757022 -0.01439800 -0.03774660 -0.0008280727 0.0006504364
50% -0.006729848 -0.01435895 -0.03770621 -0.0007951741 0.0006865953
75% -0.006696152 -0.01431565 -0.03765105 -0.0007589196 0.0007242520
              V7           V8          V9          V10
25% -0.009566682 -0.007403061 0.001549092 -0.002231413
50% -0.009536178 -0.007371464 0.001576180 -0.002194735
75% -0.009506158 -0.007338736 0.001600596 -0.002157146
Radial Basis Function Kernel Regularized Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  lambda        sigma        RMSE      Rsquared      MAE        Selected
  1.859134e-05  2134.057462  1.052170  0.0041325449  0.8362076          
  2.609888e-05    75.316167  1.813163  0.0064900370  1.3480950          
  5.156057e-05    35.451797  2.336538  0.0107588882  1.7170138          
  6.947685e-05   181.351861  1.300554  0.0012379152  1.0146281          
  1.408167e-04    61.607505  1.585830  0.0040877696  1.2016275          
  2.360836e-04     1.280426  1.041417  0.0055851363  0.8264198          
  4.360732e-04  3837.524030  1.016909  0.0009774297  0.8068108          
  7.885100e-04  2492.098499  1.017194  0.0011166545  0.8073459          
  2.528991e-03  1817.994749  1.016704  0.0008782524  0.8063525          
  2.117596e-02   252.846279  1.022812  0.0022686642  0.8129539          
  3.483860e-02  2382.501871  1.015692  0.0007825199  0.8048260          
  7.031281e-02  3766.279201  1.012683  0.0008157126  0.8019236          
  1.426343e-01     4.093459  1.141250  0.0041846648  0.9113818          
  1.636691e-01  1494.783387  1.012879  0.0008024904  0.8021252          
  1.859536e-01     1.035685  1.022309  0.0057679628  0.8114129          
  4.880622e-01    36.506317  1.023770  0.0022291974  0.8139638          
  5.287128e-01     2.233456  1.045909  0.0027951054  0.8297336          
  7.561173e-01   638.711388  1.010203  0.0008069632  0.7996264          
  7.804308e-01     3.276521  1.050294  0.0022514719  0.8329552          
  9.912226e-01  2941.583867  1.005218  0.0009168157  0.7949786  *       

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 0.9912226 and sigma
 = 2941.584.
[1] "Sat Mar 03 14:30:57 2018"
Least Angle Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  fraction    RMSE      Rsquared      MAE        Selected
  0.05386214  1.002241  0.0119015148  0.7925486          
  0.08332438  1.001450  0.0115604523  0.7920971          
  0.14246355  1.000966  0.0091701907  0.7922177  *       
  0.16836802  1.001224  0.0076928089  0.7925270          
  0.22973081  1.002044  0.0052782209  0.7933511          
  0.27461318  1.002862  0.0038626620  0.7940801          
  0.32791187  1.003903  0.0026799047  0.7949658          
  0.37936144  1.004960  0.0019194017  0.7958604          
  0.48058947  1.007395  0.0010515709  0.7978446          
  0.66516863  1.011469  0.0005205938  0.8018143          
  0.70841213  1.012370  0.0005101093  0.8027404          
  0.76940689  1.013582  0.0005124133  0.8038693          
  0.83084481  1.014733  0.0005417163  0.8048029          
  0.84279334  1.014954  0.0005556137  0.8049638          
  0.85388090  1.015161  0.0005687077  0.8051190          
  0.93769504  1.016742  0.0006859245  0.8061423          
  0.94464396  1.016874  0.0006971812  0.8062221          
  0.97571783  1.017434  0.0007450707  0.8065707          
  0.97846688  1.017484  0.0007491269  0.8066051          
  0.99923424  1.017861  0.0007796735  0.8068653          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was fraction = 0.1424635.
[1] "Sat Mar 03 14:31:13 2018"
Least Angle Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  step  RMSE      Rsquared      MAE        Selected
  1     1.004158           NaN  0.7937431          
  2     1.000766  0.0119015148  0.7919104  *       
  3     1.001684  0.0083087720  0.7924491          
  4     1.003236  0.0048814218  0.7937680          
  5     1.008218  0.0006488441  0.7987048          
  6     1.009363  0.0004627169  0.8003041          
  7     1.012735  0.0004642206  0.8034144          
  8     1.014773  0.0005339032  0.8048172          
  9     1.016483  0.0006893054  0.8060065          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was step = 2.
[1] "Sat Mar 03 14:31:28 2018"
The lasso 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  fraction    RMSE      Rsquared      MAE        Selected
  0.05386214  1.002241  0.0119015148  0.7925486          
  0.08332438  1.001450  0.0115604523  0.7920971          
  0.14246355  1.000966  0.0091701907  0.7922177  *       
  0.16836802  1.001224  0.0076928089  0.7925270          
  0.22973081  1.002044  0.0052782209  0.7933511          
  0.27461318  1.002862  0.0038626620  0.7940801          
  0.32791187  1.003903  0.0026799047  0.7949658          
  0.37936144  1.004960  0.0019194017  0.7958604          
  0.48058947  1.007395  0.0010515709  0.7978446          
  0.66516863  1.011469  0.0005205938  0.8018143          
  0.70841213  1.012370  0.0005101093  0.8027404          
  0.76940689  1.013582  0.0005124133  0.8038693          
  0.83084481  1.014733  0.0005417163  0.8048029          
  0.84279334  1.014954  0.0005556137  0.8049638          
  0.85388090  1.015161  0.0005687077  0.8051190          
  0.93769504  1.016742  0.0006859245  0.8061423          
  0.94464396  1.016874  0.0006971812  0.8062221          
  0.97571783  1.017434  0.0007450707  0.8065707          
  0.97846688  1.017484  0.0007491269  0.8066051          
  0.99923424  1.017861  0.0007796735  0.8068653          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was fraction = 0.1424635.
[1] "Sat Mar 03 14:31:44 2018"
Linear Regression with Backwards Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  nvmax  RMSE      Rsquared      MAE        Selected
  2      1.006907  0.0029554955  0.7985755  *       
  3      1.012394  0.0007683833  0.8036125          
  4      1.017242  0.0006043822  0.8071688          
  5      1.017289  0.0005356541  0.8078322          
  6      1.018072  0.0007498778  0.8082600          
  7      1.017435  0.0006876283  0.8069410          
  8      1.017817  0.0007545244  0.8069111          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was nvmax = 2.
[1] "Sat Mar 03 14:31:59 2018"
Linear Regression with Forward Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  nvmax  RMSE      Rsquared      MAE        Selected
  2      1.006907  0.0029554955  0.7985755  *       
  3      1.012394  0.0007683833  0.8036125          
  4      1.017242  0.0006043822  0.8071688          
  5      1.017289  0.0005356541  0.8078322          
  6      1.018072  0.0007498778  0.8082600          
  7      1.017435  0.0006876283  0.8069410          
  8      1.017817  0.0007545244  0.8069111          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was nvmax = 2.
[1] "Sat Mar 03 14:32:14 2018"
Linear Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results:

  RMSE      Rsquared      MAE      
  1.017875  0.0007807964  0.8068751

Tuning parameter 'intercept' was held constant at a value of TRUE
[1] "Sat Mar 03 14:32:29 2018"
Start:  AIC=36.3
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS    AIC
- V9    1    0.0024 519.57 34.304
- V2    1    0.0324 519.60 34.334
- V8    1    0.0858 519.66 34.385
- V10   1    0.4199 519.99 34.709
- V5    1    0.4509 520.02 34.739
- V6    1    0.5912 520.16 34.874
- V7    1    1.3786 520.95 35.635
<none>              519.57 36.302
- V3    1    4.9735 524.54 39.094
- V4    1    7.2033 526.77 41.228

Step:  AIC=34.3
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V10

       Df Sum of Sq    RSS    AIC
- V2    1    0.0331 519.60 32.336
- V8    1    0.0869 519.66 32.389
- V10   1    0.4210 519.99 32.712
- V5    1    0.4523 520.02 32.742
- V6    1    0.5921 520.16 32.877
- V7    1    1.3772 520.95 33.636
<none>              519.57 34.304
- V3    1    5.0161 524.59 37.137
- V4    1    7.2121 526.78 39.239

Step:  AIC=32.34
.outcome ~ V3 + V4 + V5 + V6 + V7 + V8 + V10

       Df Sum of Sq    RSS    AIC
- V8    1    0.0887 519.69 30.422
- V10   1    0.4181 520.02 30.741
- V5    1    0.4437 520.05 30.766
- V6    1    0.5778 520.18 30.895
- V7    1    1.4117 521.02 31.701
<none>              519.60 32.336
- V3    1    5.0212 524.63 35.174
- V4    1    7.2447 526.85 37.301

Step:  AIC=30.42
.outcome ~ V3 + V4 + V5 + V6 + V7 + V10

       Df Sum of Sq    RSS    AIC
- V10   1    0.4387 520.13 28.847
- V5    1    0.4635 520.16 28.871
- V6    1    0.5750 520.27 28.979
- V7    1    1.4074 521.10 29.783
<none>              519.69 30.422
- V3    1    5.0226 524.72 33.260
- V4    1    7.1584 526.85 35.304

Step:  AIC=28.85
.outcome ~ V3 + V4 + V5 + V6 + V7

       Df Sum of Sq    RSS    AIC
- V5    1    0.4621 520.59 27.294
- V6    1    0.5933 520.73 27.420
- V7    1    1.2923 521.42 28.095
<none>              520.13 28.847
- V3    1    4.9253 525.06 31.587
- V4    1    7.6417 527.77 34.183

Step:  AIC=27.29
.outcome ~ V3 + V4 + V6 + V7

       Df Sum of Sq    RSS    AIC
- V6    1    0.5388 521.13 25.814
- V7    1    1.3208 521.92 26.568
<none>              520.59 27.294
- V3    1    4.7563 525.35 29.868
- V4    1    7.6944 528.29 32.674

Step:  AIC=25.81
.outcome ~ V3 + V4 + V7

       Df Sum of Sq    RSS    AIC
- V7    1    1.4006 522.53 25.164
<none>              521.13 25.814
- V3    1    4.6224 525.76 28.256
- V4    1    8.0242 529.16 31.500

Step:  AIC=25.16
.outcome ~ V3 + V4

       Df Sum of Sq    RSS    AIC
<none>              522.53 25.164
- V3    1    4.6498 527.18 27.620
- V4    1    7.7350 530.27 30.555
Start:  AIC=-5.86
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V2    1    0.0019 475.80 -7.8561
- V6    1    0.0211 475.82 -7.8359
- V3    1    0.0259 475.82 -7.8308
- V9    1    0.0553 475.85 -7.7999
- V7    1    0.1936 475.99 -7.6542
- V5    1    0.9547 476.75 -6.8538
- V8    1    1.7748 477.57 -5.9927
<none>              475.80 -5.8581
- V10   1    1.9156 477.71 -5.8450
- V4    1    5.1227 480.92 -2.4928

Step:  AIC=-7.86
.outcome ~ V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V6    1    0.0216 475.82 -9.8334
- V3    1    0.0252 475.82 -9.8296
- V9    1    0.0556 475.86 -9.7975
- V7    1    0.1946 475.99 -9.6512
- V5    1    0.9572 476.76 -8.8493
- V8    1    1.7732 477.57 -7.9924
<none>              475.80 -7.8561
- V10   1    1.9148 477.71 -7.8439
- V4    1    5.1229 480.92 -4.4907

Step:  AIC=-9.83
.outcome ~ V3 + V4 + V5 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS      AIC
- V3    1    0.0248 475.85 -11.8072
- V9    1    0.0534 475.87 -11.7771
- V7    1    0.2054 476.03 -11.6171
- V5    1    0.9678 476.79 -10.8154
- V8    1    1.7671 477.59  -9.9762
- V10   1    1.8933 477.71  -9.8439
<none>              475.82  -9.8334
- V4    1    5.1779 481.00  -6.4109

Step:  AIC=-11.81
.outcome ~ V4 + V5 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS      AIC
- V9    1    0.0556 475.90 -13.7486
- V7    1    0.1983 476.04 -13.5984
- V5    1    0.9654 476.81 -12.7919
- V8    1    1.7734 477.62 -11.9435
<none>              475.85 -11.8072
- V10   1    1.9203 477.77 -11.7895
- V4    1    5.1569 481.00  -8.4069

Step:  AIC=-13.75
.outcome ~ V4 + V5 + V7 + V8 + V10

       Df Sum of Sq    RSS     AIC
- V7    1    0.2048 476.11 -15.533
- V5    1    0.9806 476.88 -14.717
- V8    1    1.7662 477.67 -13.893
<none>              475.90 -13.749
- V10   1    1.9087 477.81 -13.743
- V4    1    5.1199 481.02 -10.387

Step:  AIC=-15.53
.outcome ~ V4 + V5 + V8 + V10

       Df Sum of Sq    RSS     AIC
- V5    1    0.9915 477.10 -16.491
- V8    1    1.7337 477.84 -15.712
<none>              476.11 -15.533
- V10   1    1.9376 478.04 -15.498
- V4    1    4.9955 481.10 -12.304

Step:  AIC=-16.49
.outcome ~ V4 + V8 + V10

       Df Sum of Sq    RSS     AIC
- V8    1    1.7890 478.89 -16.616
- V10   1    1.9077 479.01 -16.492
<none>              477.10 -16.491
- V4    1    4.9476 482.05 -13.322

Step:  AIC=-16.62
.outcome ~ V4 + V10

       Df Sum of Sq    RSS     AIC
- V10   1    1.4876 480.37 -17.062
<none>              478.89 -16.616
- V4    1    4.7076 483.59 -13.715

Step:  AIC=-17.06
.outcome ~ V4

       Df Sum of Sq    RSS     AIC
<none>              480.37 -17.062
- V4    1    4.7757 485.15 -14.106
Start:  AIC=6.13
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V10   1    0.0168 486.34  4.1453
- V9    1    0.0198 486.34  4.1485
- V8    1    0.1997 486.52  4.3333
- V7    1    0.3066 486.63  4.4432
- V3    1    0.3396 486.66  4.4771
- V6    1    1.5159 487.83  5.6842
<none>              486.32  6.1281
- V5    1    2.3054 488.62  6.4928
- V2    1    2.7200 489.04  6.9168
- V4    1    6.3393 492.66 10.6036

Step:  AIC=4.15
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9

       Df Sum of Sq    RSS    AIC
- V9    1    0.0181 486.35 2.1639
- V8    1    0.2002 486.54 2.3511
- V7    1    0.3052 486.64 2.4590
- V3    1    0.3402 486.68 2.4950
- V6    1    1.5052 487.84 3.6904
<none>              486.34 4.1453
- V5    1    2.3031 488.64 4.5075
- V2    1    2.7076 489.04 4.9213
- V4    1    6.3643 492.70 8.6459

Step:  AIC=2.16
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8

       Df Sum of Sq    RSS    AIC
- V8    1    0.2027 486.56 0.3723
- V7    1    0.3041 486.66 0.4765
- V3    1    0.3308 486.68 0.5039
- V6    1    1.5118 487.87 1.7157
<none>              486.35 2.1639
- V5    1    2.2919 488.65 2.5146
- V2    1    2.7072 489.06 2.9394
- V4    1    6.3733 492.73 6.6735

Step:  AIC=0.37
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7

       Df Sum of Sq    RSS     AIC
- V7    1    0.3022 486.86 -1.3173
- V3    1    0.3222 486.88 -1.2968
- V6    1    1.4937 488.05 -0.0951
<none>              486.56  0.3723
- V5    1    2.1833 488.74  0.6109
- V2    1    2.7231 489.28  1.1629
- V4    1    6.2369 492.79  4.7408

Step:  AIC=-1.32
.outcome ~ V2 + V3 + V4 + V5 + V6

       Df Sum of Sq    RSS      AIC
- V3    1    0.3306 487.19 -2.97784
- V6    1    1.4448 488.30 -1.83566
<none>              486.86 -1.31727
- V5    1    2.1460 489.00 -1.11820
- V2    1    2.7247 489.58 -0.52687
- V4    1    6.2272 493.09  3.03748

Step:  AIC=-2.98
.outcome ~ V2 + V4 + V5 + V6

       Df Sum of Sq    RSS     AIC
- V6    1    1.3906 488.58 -3.5528
<none>              487.19 -2.9778
- V5    1    2.2430 489.43 -2.6812
- V2    1    2.6295 489.82 -2.2864
- V4    1    6.3502 493.54  1.4972

Step:  AIC=-3.55
.outcome ~ V2 + V4 + V5

       Df Sum of Sq    RSS     AIC
<none>              488.58 -3.5528
- V5    1    2.0690 490.65 -3.4398
- V2    1    2.5219 491.10 -2.9785
- V4    1    6.3858 494.97  0.9400
Start:  AIC=15.26
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS    AIC
- V5    1    0.0001 747.28 13.263
- V9    1    0.0033 747.28 13.266
- V6    1    0.0273 747.31 13.290
- V10   1    0.0620 747.34 13.325
- V2    1    0.4158 747.69 13.681
- V8    1    0.5797 747.86 13.846
- V7    1    0.7958 748.07 14.063
- V3    1    1.4319 748.71 14.703
<none>              747.28 15.263
- V4    1    9.6725 756.95 22.934

Step:  AIC=13.26
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS    AIC
- V9    1    0.0033 747.28 11.267
- V6    1    0.0274 747.31 11.291
- V10   1    0.0620 747.34 11.325
- V2    1    0.4161 747.69 11.682
- V8    1    0.5821 747.86 11.849
- V7    1    0.7963 748.07 12.064
- V3    1    1.4333 748.71 12.704
<none>              747.28 13.263
- V4    1    9.6781 756.96 20.940

Step:  AIC=11.27
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V10

       Df Sum of Sq    RSS     AIC
- V6    1    0.0275 747.31  9.2941
- V10   1    0.0614 747.34  9.3282
- V2    1    0.4178 747.70  9.6868
- V8    1    0.5802 747.86  9.8501
- V7    1    0.7985 748.08 10.0696
- V3    1    1.4518 748.73 10.7260
<none>              747.28 11.2665
- V4    1    9.6786 756.96 18.9436

Step:  AIC=9.29
.outcome ~ V2 + V3 + V4 + V7 + V8 + V10

       Df Sum of Sq    RSS     AIC
- V10   1    0.0661 747.37  7.3606
- V2    1    0.4094 747.72  7.7060
- V8    1    0.5807 747.89  7.8782
- V7    1    0.7850 748.09  8.0837
- V3    1    1.4535 748.76  8.7553
<none>              747.31  9.2941
- V4    1    9.6532 756.96 16.9457

Step:  AIC=7.36
.outcome ~ V2 + V3 + V4 + V7 + V8

       Df Sum of Sq    RSS     AIC
- V2    1    0.4106 747.79  5.7737
- V8    1    0.5596 747.93  5.9235
- V7    1    0.8026 748.18  6.1677
- V3    1    1.4695 748.84  6.8377
<none>              747.37  7.3606
- V4    1    9.5989 756.97 14.9575

Step:  AIC=5.77
.outcome ~ V3 + V4 + V7 + V8

       Df Sum of Sq    RSS     AIC
- V8    1    0.5515 748.34  4.3282
- V7    1    0.7877 748.57  4.5655
- V3    1    1.4064 749.19  5.1867
<none>              747.79  5.7737
- V4    1    9.5298 757.32 13.2966

Step:  AIC=4.33
.outcome ~ V3 + V4 + V7

       Df Sum of Sq    RSS     AIC
- V7    1    0.7706 749.11  3.1021
- V3    1    1.3975 749.73  3.7312
<none>              748.34  4.3282
- V4    1    9.2606 757.60 11.5770

Step:  AIC=3.1
.outcome ~ V3 + V4

       Df Sum of Sq    RSS     AIC
- V3    1    1.3760 750.48  2.4821
<none>              749.11  3.1021
- V4    1    9.0583 758.17 10.1409

Step:  AIC=2.48
.outcome ~ V4

       Df Sum of Sq    RSS    AIC
<none>              750.48 2.4821
- V4    1    9.0348 759.52 9.4811
Linear Regression with Stepwise Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.008304  0.005498488  0.8009077

[1] "Sat Mar 03 14:32:44 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: There were 25 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9     NA's   :9    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 14:33:23 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "logreg"                  
Error : package RWeka is required
Error : package RWeka is required
Error : package RWeka is required
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 14:33:38 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "M5"                      
Error : package RWeka is required
Error : package RWeka is required
Error : package RWeka is required
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 14:33:53 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "M5Rules"                 
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 14:34:09 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "mlpKerasDecay"           
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 14:34:24 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "mlpKerasDropout"         
Multi-Step Adaptive MCP-Net 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  alphas      nsteps  scale      RMSE      Rsquared     MAE        Selected
  0.09847592   3      3.9352157  1.008222  0.005498302  0.8008236  *       
  0.12499194   6      3.9643744  1.008241  0.005498329  0.8008433          
  0.17821719   7      1.7277752  1.008289  0.005498531  0.8008915          
  0.20153122   5      3.4997439  1.008275  0.005498446  0.8008784          
  0.25675773   6      3.2762789  1.008285  0.005498472  0.8008882          
  0.29715186  10      0.7781832  1.010356  0.005986341  0.8016770          
  0.34512069   2      3.4959381  1.008289  0.005498447  0.8008927          
  0.39142529   3      1.2138427  1.008300  0.005498500  0.8009032          
  0.48253052   3      0.3116205  1.010360  0.005986647  0.8016810          
  0.64865177   5      3.0440529  1.008300  0.005498487  0.8009044          
  0.68757092   3      1.2753583  1.008302  0.005498491  0.8009064          
  0.74246620   2      1.8163637  1.008302  0.005498486  0.8009063          
  0.79776033   9      2.8226189  1.008302  0.005498488  0.8009063          
  0.80851400   3      3.1583913  1.008302  0.005498487  0.8009062          
  0.81849281  10      2.1103828  1.008303  0.005498490  0.8009068          
  0.89392554   7      2.5622563  1.008303  0.005498488  0.8009071          
  0.90017957  10      2.2381637  1.008303  0.005498489  0.8009072          
  0.92814605   4      1.4582482  1.008303  0.005498488  0.8009075          
  0.93062019   9      1.9079892  1.008303  0.005498488  0.8009074          
  0.94931082   3      1.7823372  1.008303  0.005498488  0.8009075          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were alphas = 0.09847592, nsteps = 3
 and scale = 3.935216.
[1] "Sat Mar 03 14:34:52 2018"
# weights:  23
initial  value 618.627598 
iter  10 value 530.143070
iter  20 value 516.550301
iter  30 value 510.231946
iter  40 value 509.319995
iter  50 value 508.362693
iter  60 value 506.218542
iter  70 value 504.239872
iter  80 value 504.032204
iter  90 value 503.992300
final  value 503.992147 
converged
# weights:  23
initial  value 567.482414 
iter  10 value 535.549190
iter  20 value 535.442384
iter  30 value 523.035209
iter  40 value 506.132999
iter  50 value 505.546953
iter  60 value 505.298580
iter  70 value 505.011408
iter  80 value 504.178298
iter  90 value 502.247662
iter 100 value 501.378590
final  value 501.378590 
stopped after 100 iterations
# weights:  221
initial  value 746.118243 
iter  10 value 538.308945
iter  20 value 535.563544
iter  30 value 535.498308
iter  40 value 522.470000
iter  50 value 496.157757
iter  60 value 493.445979
iter  70 value 491.615676
iter  80 value 489.689082
iter  90 value 487.460135
iter 100 value 483.721306
final  value 483.721306 
stopped after 100 iterations
# weights:  177
initial  value 618.373295 
iter  10 value 535.626681
iter  20 value 534.946733
iter  30 value 514.350516
iter  40 value 485.737382
iter  50 value 475.716698
iter  60 value 470.016638
iter  70 value 466.555253
iter  80 value 464.980034
iter  90 value 464.152420
iter 100 value 463.892118
final  value 463.892118 
stopped after 100 iterations
# weights:  188
initial  value 586.950919 
iter  10 value 535.733900
iter  20 value 535.396525
iter  30 value 513.203689
iter  40 value 491.946302
iter  50 value 482.522048
iter  60 value 476.515749
iter  70 value 473.808793
iter  80 value 472.269958
iter  90 value 471.114308
iter 100 value 469.624459
final  value 469.624459 
stopped after 100 iterations
# weights:  67
initial  value 731.217196 
iter  10 value 548.411628
iter  20 value 548.121722
final  value 548.121171 
converged
# weights:  155
initial  value 626.029959 
iter  10 value 535.781684
iter  20 value 510.459118
iter  30 value 482.013720
iter  40 value 472.649512
iter  50 value 465.061772
iter  60 value 458.921948
iter  70 value 449.798872
iter  80 value 437.538595
iter  90 value 433.766264
iter 100 value 429.622072
final  value 429.622072 
stopped after 100 iterations
# weights:  210
initial  value 782.924274 
iter  10 value 538.230024
iter  20 value 538.064906
final  value 538.064727 
converged
# weights:  78
initial  value 554.459413 
iter  10 value 535.537881
final  value 535.533589 
converged
# weights:  111
initial  value 558.001954 
iter  10 value 535.558148
iter  20 value 523.771571
iter  30 value 495.835306
iter  40 value 484.777985
iter  50 value 482.044723
iter  60 value 476.035425
iter  70 value 474.587050
iter  80 value 472.976572
iter  90 value 471.927757
iter 100 value 470.660212
final  value 470.660212 
stopped after 100 iterations
# weights:  166
initial  value 747.738269 
iter  10 value 535.876716
iter  20 value 535.535484
iter  30 value 535.533038
iter  40 value 535.532763
iter  50 value 535.532412
iter  60 value 535.531939
iter  70 value 535.531254
iter  80 value 535.530154
iter  90 value 535.528070
iter 100 value 535.522627
final  value 535.522627 
stopped after 100 iterations
# weights:  221
initial  value 822.236955 
iter  10 value 536.830496
iter  20 value 536.052518
iter  30 value 536.047190
final  value 536.047145 
converged
# weights:  45
initial  value 701.016067 
iter  10 value 519.234906
iter  20 value 498.236816
iter  30 value 489.892448
iter  40 value 483.984531
iter  50 value 480.756347
iter  60 value 480.188720
iter  70 value 479.389164
iter  80 value 479.028450
iter  90 value 478.072322
iter 100 value 477.641725
final  value 477.641725 
stopped after 100 iterations
# weights:  34
initial  value 636.937535 
iter  10 value 521.799641
iter  20 value 503.651630
iter  30 value 493.055929
iter  40 value 490.050389
iter  50 value 488.876250
iter  60 value 488.813463
iter  70 value 488.812888
iter  70 value 488.812886
final  value 488.812886 
converged
# weights:  188
initial  value 696.372073 
iter  10 value 535.669456
iter  20 value 534.660175
iter  30 value 534.592193
final  value 534.590848 
converged
# weights:  210
initial  value 638.965080 
iter  10 value 532.912583
iter  20 value 503.731016
iter  30 value 478.998145
iter  40 value 455.459779
iter  50 value 438.919172
iter  60 value 433.678016
iter  70 value 427.343367
iter  80 value 420.431431
iter  90 value 416.139164
iter 100 value 413.785356
final  value 413.785356 
stopped after 100 iterations
# weights:  221
initial  value 849.950689 
iter  10 value 535.732768
iter  20 value 535.533826
iter  30 value 535.531638
iter  40 value 535.531217
iter  50 value 535.530619
iter  60 value 535.529680
iter  70 value 535.527960
iter  80 value 535.523781
iter  90 value 535.501807
iter 100 value 522.122892
final  value 522.122892 
stopped after 100 iterations
# weights:  89
initial  value 570.119855 
iter  10 value 535.565282
iter  20 value 535.531933
iter  30 value 535.530709
iter  40 value 535.528323
iter  50 value 535.521421
iter  60 value 535.437360
iter  70 value 515.396904
iter  80 value 489.474179
iter  90 value 488.687792
iter 100 value 486.837555
final  value 486.837555 
stopped after 100 iterations
# weights:  56
initial  value 683.539681 
iter  10 value 535.873857
iter  20 value 504.814893
iter  30 value 496.131366
iter  40 value 492.136549
iter  50 value 488.608318
iter  60 value 485.246828
iter  70 value 484.040956
iter  80 value 483.822178
iter  90 value 483.735959
final  value 483.734908 
converged
# weights:  199
initial  value 1017.535047 
iter  10 value 545.768746
iter  20 value 544.628486
final  value 544.622325 
converged
# weights:  23
initial  value 523.149479 
iter  10 value 483.983598
iter  20 value 454.376840
iter  30 value 451.378472
iter  40 value 450.626213
iter  50 value 450.563810
final  value 450.563565 
converged
# weights:  23
initial  value 537.574471 
iter  10 value 486.429468
iter  20 value 486.394837
iter  30 value 486.393259
iter  40 value 486.390616
iter  50 value 486.385417
iter  60 value 486.372254
iter  70 value 486.319055
iter  80 value 481.216341
iter  90 value 455.977748
iter 100 value 447.264330
final  value 447.264330 
stopped after 100 iterations
# weights:  221
initial  value 625.865013 
iter  10 value 488.905875
iter  20 value 486.420888
iter  30 value 486.398844
iter  40 value 486.395593
iter  50 value 486.386172
iter  60 value 486.097332
iter  70 value 469.215146
iter  80 value 434.691940
iter  90 value 424.414238
iter 100 value 421.958937
final  value 421.958937 
stopped after 100 iterations
# weights:  177
initial  value 729.816065 
iter  10 value 486.559861
iter  20 value 486.393815
iter  30 value 486.386611
iter  40 value 486.379363
iter  50 value 486.294438
iter  60 value 471.020939
iter  70 value 441.224588
iter  80 value 432.442575
iter  90 value 430.339274
iter 100 value 429.438941
final  value 429.438941 
stopped after 100 iterations
# weights:  188
initial  value 501.842719 
iter  10 value 486.441220
iter  20 value 486.396842
iter  30 value 486.396768
iter  40 value 486.396690
iter  50 value 486.396608
iter  60 value 486.396521
iter  70 value 486.396429
iter  80 value 486.396329
iter  90 value 486.396221
iter 100 value 486.396102
final  value 486.396102 
stopped after 100 iterations
# weights:  67
initial  value 606.810375 
iter  10 value 498.597276
iter  20 value 497.704193
final  value 497.703918 
converged
# weights:  155
initial  value 527.758680 
iter  10 value 485.033329
iter  20 value 439.450821
iter  30 value 423.985687
iter  40 value 407.017264
iter  50 value 400.696191
iter  60 value 387.896190
iter  70 value 384.350022
iter  80 value 383.369022
iter  90 value 382.081842
iter 100 value 381.158639
final  value 381.158639 
stopped after 100 iterations
# weights:  210
initial  value 740.268620 
iter  10 value 488.453950
iter  20 value 488.267942
final  value 488.267887 
converged
# weights:  78
initial  value 611.552651 
iter  10 value 486.471661
iter  20 value 486.393562
iter  30 value 486.393456
iter  40 value 486.393336
iter  50 value 486.393197
iter  60 value 486.393032
iter  70 value 486.392833
iter  80 value 486.392585
iter  90 value 486.392265
iter 100 value 486.391834
final  value 486.391834 
stopped after 100 iterations
# weights:  111
initial  value 536.605946 
iter  10 value 486.502989
iter  20 value 486.395016
iter  30 value 486.394652
iter  40 value 486.394170
iter  50 value 486.393496
iter  60 value 486.392474
iter  70 value 486.390733
iter  80 value 486.387095
iter  90 value 486.375266
iter 100 value 486.042030
final  value 486.042030 
stopped after 100 iterations
# weights:  166
initial  value 569.356779 
iter  10 value 486.584807
iter  20 value 486.382215
iter  30 value 486.320765
iter  40 value 472.760015
iter  50 value 445.308026
iter  60 value 435.849457
iter  70 value 433.688053
iter  80 value 432.236491
iter  90 value 430.707588
iter 100 value 430.140461
final  value 430.140461 
stopped after 100 iterations
# weights:  221
initial  value 615.021988 
iter  10 value 487.155127
iter  20 value 486.568442
final  value 486.564631 
converged
# weights:  45
initial  value 659.644194 
iter  10 value 487.249234
iter  20 value 476.931462
iter  30 value 447.019142
iter  40 value 438.105099
iter  50 value 433.391708
iter  60 value 429.992272
iter  70 value 428.357047
iter  80 value 428.220080
iter  90 value 428.192999
iter 100 value 428.189673
final  value 428.189673 
stopped after 100 iterations
# weights:  34
initial  value 678.734066 
iter  10 value 481.455503
iter  20 value 466.922227
iter  30 value 457.111730
iter  40 value 455.429660
iter  50 value 454.645930
iter  60 value 453.973024
iter  70 value 453.278260
iter  80 value 453.262592
final  value 453.262490 
converged
# weights:  188
initial  value 846.698949 
iter  10 value 487.186737
iter  20 value 485.828986
iter  30 value 485.820389
final  value 485.820377 
converged
# weights:  210
initial  value 535.773949 
iter  10 value 487.555634
iter  20 value 469.832567
iter  30 value 443.028402
iter  40 value 424.957879
iter  50 value 408.103864
iter  60 value 389.671655
iter  70 value 382.075979
iter  80 value 378.206879
iter  90 value 374.886068
iter 100 value 372.383071
final  value 372.383071 
stopped after 100 iterations
# weights:  221
initial  value 681.103410 
iter  10 value 486.628473
iter  20 value 486.394631
final  value 486.393476 
converged
# weights:  89
initial  value 626.014163 
iter  10 value 486.592005
iter  20 value 486.394262
iter  30 value 486.394088
iter  40 value 486.393874
iter  50 value 486.393607
iter  60 value 486.393261
iter  70 value 486.392792
iter  80 value 486.392119
iter  90 value 486.391065
iter 100 value 486.389177
final  value 486.389177 
stopped after 100 iterations
# weights:  56
initial  value 564.880322 
iter  10 value 485.230239
iter  20 value 454.484308
iter  30 value 445.637073
iter  40 value 443.013256
iter  50 value 439.677155
iter  60 value 437.047000
iter  70 value 434.685677
iter  80 value 433.865670
iter  90 value 433.541149
iter 100 value 433.288444
final  value 433.288444 
stopped after 100 iterations
# weights:  199
initial  value 913.932071 
iter  10 value 495.483069
iter  20 value 494.235098
final  value 494.234852 
converged
# weights:  23
initial  value 572.357938 
iter  10 value 486.340766
iter  20 value 476.525663
iter  30 value 474.184050
iter  40 value 472.237290
iter  50 value 472.170880
iter  60 value 472.169524
final  value 472.169421 
converged
# weights:  23
initial  value 651.794781 
iter  10 value 499.627951
iter  20 value 499.525435
iter  30 value 499.524826
iter  40 value 499.523986
iter  50 value 499.522728
iter  60 value 499.520633
iter  70 value 499.516633
iter  80 value 499.507629
iter  90 value 499.483197
iter 100 value 499.375175
final  value 499.375175 
stopped after 100 iterations
# weights:  221
initial  value 690.739602 
iter  10 value 501.845176
iter  20 value 499.546910
iter  30 value 499.523730
iter  40 value 499.511232
iter  50 value 494.615431
iter  60 value 468.402554
iter  70 value 445.000901
iter  80 value 435.934260
iter  90 value 434.370469
iter 100 value 432.600687
final  value 432.600687 
stopped after 100 iterations
# weights:  177
initial  value 549.002042 
iter  10 value 499.565863
iter  20 value 499.518380
iter  30 value 499.516806
iter  40 value 499.513080
iter  50 value 499.495175
iter  60 value 489.873433
iter  70 value 459.462743
iter  80 value 450.343909
iter  90 value 449.861380
iter 100 value 448.349612
final  value 448.349612 
stopped after 100 iterations
# weights:  188
initial  value 631.048819 
iter  10 value 500.083396
iter  20 value 499.526563
iter  30 value 499.522386
iter  40 value 499.521756
iter  50 value 499.520759
iter  60 value 499.518902
iter  70 value 499.514169
iter  80 value 499.483166
iter  90 value 486.482045
iter 100 value 460.969633
final  value 460.969633 
stopped after 100 iterations
# weights:  67
initial  value 727.085019 
iter  10 value 513.107835
iter  20 value 512.939780
final  value 512.939595 
converged
# weights:  155
initial  value 719.435010 
iter  10 value 497.832125
iter  20 value 460.190678
iter  30 value 430.275376
iter  40 value 418.877073
iter  50 value 413.917402
iter  60 value 411.223587
iter  70 value 408.132425
iter  80 value 401.579647
iter  90 value 398.251827
iter 100 value 394.459527
final  value 394.459527 
stopped after 100 iterations
# weights:  210
initial  value 926.895312 
iter  10 value 503.389963
iter  20 value 502.629518
final  value 502.628801 
converged
# weights:  78
initial  value 724.535270 
iter  10 value 499.615996
iter  20 value 499.011763
iter  30 value 473.369360
iter  40 value 455.734456
iter  50 value 455.403744
iter  60 value 455.367264
iter  70 value 455.290271
iter  80 value 454.815283
iter  90 value 454.412280
iter 100 value 454.128405
final  value 454.128405 
stopped after 100 iterations
# weights:  111
initial  value 604.991787 
iter  10 value 499.779563
iter  20 value 499.523857
iter  30 value 499.523565
iter  40 value 499.523194
iter  50 value 499.522692
iter  60 value 499.521955
iter  70 value 499.520731
iter  80 value 499.518233
iter  90 value 499.510359
iter 100 value 499.352006
final  value 499.352006 
stopped after 100 iterations
# weights:  166
initial  value 738.953052 
iter  10 value 499.834357
iter  20 value 499.523697
iter  30 value 499.519881
iter  40 value 499.518575
iter  50 value 499.515920
iter  60 value 499.507368
iter  70 value 499.249950
iter  80 value 477.618470
iter  90 value 451.842352
iter 100 value 447.266292
final  value 447.266292 
stopped after 100 iterations
# weights:  221
initial  value 586.398892 
iter  10 value 501.434431
iter  20 value 500.678208
final  value 500.676758 
converged
# weights:  45
initial  value 574.085529 
iter  10 value 471.861402
iter  20 value 447.390634
iter  30 value 441.578206
iter  40 value 439.451465
iter  50 value 438.268266
iter  60 value 437.932163
iter  70 value 437.911301
iter  80 value 437.909459
final  value 437.909251 
converged
# weights:  34
initial  value 616.949578 
iter  10 value 497.108896
iter  20 value 482.828223
iter  30 value 477.343464
iter  40 value 472.852461
iter  50 value 469.169261
iter  60 value 466.031900
iter  70 value 465.153251
iter  80 value 465.073627
iter  90 value 465.072321
final  value 465.072200 
converged
# weights:  188
initial  value 573.899354 
iter  10 value 499.962677
iter  20 value 499.646309
iter  30 value 499.601507
final  value 499.600569 
converged
# weights:  210
initial  value 783.669254 
iter  10 value 499.803551
iter  20 value 470.871876
iter  30 value 445.173766
iter  40 value 425.707956
iter  50 value 418.531797
iter  60 value 406.872101
iter  70 value 400.398432
iter  80 value 394.573121
iter  90 value 391.112956
iter 100 value 388.298204
final  value 388.298204 
stopped after 100 iterations
# weights:  221
initial  value 693.947884 
iter  10 value 499.834233
iter  20 value 499.523726
iter  30 value 499.520524
iter  40 value 499.520272
iter  50 value 499.519937
iter  60 value 499.519465
iter  70 value 499.518739
iter  80 value 499.517468
iter  90 value 499.514686
iter 100 value 499.504492
final  value 499.504492 
stopped after 100 iterations
# weights:  89
initial  value 614.564181 
iter  10 value 499.664052
final  value 499.523978 
converged
# weights:  56
initial  value 580.514900 
iter  10 value 485.231336
iter  20 value 464.659138
iter  30 value 456.677570
iter  40 value 451.291859
iter  50 value 446.065328
iter  60 value 441.314705
iter  70 value 438.974850
iter  80 value 437.658666
iter  90 value 435.431207
iter 100 value 435.335907
final  value 435.335907 
stopped after 100 iterations
# weights:  199
initial  value 1006.886521 
iter  10 value 510.366136
iter  20 value 509.236480
final  value 509.236246 
converged
# weights:  221
initial  value 951.841339 
iter  10 value 761.773632
iter  20 value 760.750999
final  value 760.749318 
converged
Neural Network 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  size  decay         RMSE      Rsquared      MAE        Selected
   2    1.014357e-04  1.019924  0.0019955529  0.8095973          
   2    1.529916e-02  1.044442  0.0051632548  0.8250895          
   3    4.737428e-02  1.028035  0.0068671469  0.8102429          
   4    4.094652e-03  1.036703  0.0027788731  0.8248158          
   5    2.067995e-02  1.055203  0.0010859721  0.8320224          
   6    6.901896e+00  1.008295  0.0007739884  0.7930693          
   7    4.206524e-05  1.006907  0.0037275741  0.8017368          
   8    8.038078e-05  1.015174  0.0015010346  0.8006069          
  10    1.290063e-04  1.018733  0.0014368687  0.8010992          
  14    2.487225e-03  1.051043  0.0089546939  0.8233888          
  15    8.599043e-05  1.026954  0.0054090492  0.8127680          
  16    4.326445e-05  1.038573  0.0022767025  0.8274155          
  17    1.730345e-04  1.021497  0.0025702598  0.8042012          
  17    1.207437e+00  1.006092  0.0005812593  0.7932495          
  18    9.487641e+00  1.006703  0.0008159043  0.7925004          
  19    4.533650e-02  1.068578  0.0016201661  0.8474767          
  19    2.995945e+00  1.004987  0.0006533154  0.7925619          
  20    6.267988e-05  1.006526  0.0029298065  0.7951931          
  20    6.195024e-04  1.032639  0.0045759411  0.8159512          
  20    1.686089e+00  1.004799  0.0005260023  0.7927093  *       

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 20 and decay = 1.686089.
[1] "Sat Mar 03 14:36:00 2018"
Non-Negative Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results:

  RMSE      Rsquared   MAE      
  1.011857  0.0120764  0.8015278

[1] "Sat Mar 03 14:36:15 2018"
Non-Informative Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results:

  RMSE      Rsquared  MAE      
  1.004158  NaN       0.7937431

[1] "Sat Mar 03 14:36:30 2018"
Parallel Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  mtry  RMSE      Rsquared     MAE        Selected
  1     1.024288  0.002418442  0.8111905  *       
  2     1.030307  0.002892273  0.8188139          
  3     1.031213  0.001309860  0.8180274          
  4     1.035649  0.001042984  0.8233888          
  5     1.037077  0.001229477  0.8223431          
  6     1.038737  0.001135143  0.8253244          
  7     1.036941  0.001461244  0.8243174          
  8     1.038451  0.001371265  0.8242930          
  9     1.038826  0.001029091  0.8260430          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 1.
[1] "Sat Mar 03 14:38:07 2018"
Error in varImp[, "%IncMSE"] : subscript out of bounds
In addition: Warning messages:
1: package 'mxnet' is not available (for R version 3.4.3) 
2: package 'mxnet' is not available (for R version 3.4.3) 
3: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
4: executing %dopar% sequentially: no parallel backend registered 
# weights:  23
initial  value 619.418213 
iter  10 value 517.115832
iter  20 value 510.220901
iter  30 value 508.526954
iter  40 value 508.342509
final  value 508.342206 
converged
# weights:  23
initial  value 566.270208 
iter  10 value 535.549465
iter  20 value 535.441720
iter  30 value 522.341017
iter  40 value 507.468030
iter  50 value 505.202372
iter  60 value 502.963542
iter  70 value 502.414637
iter  80 value 502.065405
iter  90 value 500.869526
iter 100 value 500.657925
final  value 500.657925 
stopped after 100 iterations
# weights:  221
initial  value 744.718543 
iter  10 value 538.338535
iter  20 value 535.563885
iter  30 value 522.006160
iter  40 value 484.840183
iter  50 value 475.175677
iter  60 value 472.970061
iter  70 value 469.463105
iter  80 value 467.804763
iter  90 value 466.525560
iter 100 value 465.410207
final  value 465.410207 
stopped after 100 iterations
# weights:  177
initial  value 625.783746 
iter  10 value 535.626600
iter  20 value 535.397360
iter  30 value 515.213096
iter  40 value 494.854347
iter  50 value 491.751773
iter  60 value 485.426740
iter  70 value 482.387098
iter  80 value 479.797148
iter  90 value 478.216835
iter 100 value 477.419637
final  value 477.419637 
stopped after 100 iterations
# weights:  188
initial  value 588.105483 
iter  10 value 535.724432
iter  20 value 534.803457
iter  30 value 511.891001
iter  40 value 492.782801
iter  50 value 492.047463
iter  60 value 488.703681
iter  70 value 488.080151
iter  80 value 485.228774
iter  90 value 484.567524
iter 100 value 484.441911
final  value 484.441911 
stopped after 100 iterations
# weights:  67
initial  value 729.989054 
iter  10 value 548.478330
iter  20 value 548.161157
final  value 548.161027 
converged
# weights:  155
initial  value 634.161390 
iter  10 value 536.200575
iter  20 value 535.966062
iter  30 value 501.469575
iter  40 value 479.819231
iter  50 value 473.880912
iter  60 value 471.638951
iter  70 value 466.883018
iter  80 value 464.231910
iter  90 value 462.721430
iter 100 value 458.615986
final  value 458.615986 
stopped after 100 iterations
# weights:  210
initial  value 773.937257 
iter  10 value 538.274998
iter  20 value 538.091586
final  value 538.091494 
converged
# weights:  78
initial  value 554.798541 
iter  10 value 535.537467
final  value 535.533558 
converged
# weights:  111
initial  value 559.219637 
iter  10 value 535.559005
iter  20 value 535.492293
iter  30 value 525.231282
iter  40 value 485.566543
iter  50 value 477.282297
iter  60 value 475.402754
iter  70 value 472.195924
iter  80 value 471.637042
iter  90 value 471.181003
iter 100 value 470.760173
final  value 470.760173 
stopped after 100 iterations
# weights:  166
initial  value 741.384742 
iter  10 value 535.871652
iter  20 value 535.535430
iter  30 value 535.533198
iter  40 value 535.532972
iter  50 value 535.532694
iter  60 value 535.532335
iter  70 value 535.531846
iter  80 value 535.531129
iter  90 value 535.529955
iter 100 value 535.527660
final  value 535.527660 
stopped after 100 iterations
# weights:  221
initial  value 809.862478 
iter  10 value 538.747838
iter  20 value 536.091697
iter  30 value 536.085066
iter  30 value 536.085061
iter  30 value 536.085061
final  value 536.085061 
converged
# weights:  45
initial  value 703.415083 
iter  10 value 520.941600
iter  20 value 491.914153
iter  30 value 478.864304
iter  40 value 471.290698
iter  50 value 468.816705
iter  60 value 467.867498
iter  70 value 467.281791
iter  80 value 467.159787
iter  90 value 466.963765
iter 100 value 466.248777
final  value 466.248777 
stopped after 100 iterations
# weights:  34
initial  value 638.848107 
iter  10 value 524.533625
iter  20 value 506.349082
iter  30 value 500.080385
iter  40 value 499.569578
iter  50 value 499.560130
iter  50 value 499.560126
iter  50 value 499.560126
final  value 499.560126 
converged
# weights:  188
initial  value 692.389190 
iter  10 value 535.879679
iter  20 value 534.726204
iter  30 value 534.705281
final  value 534.699649 
converged
# weights:  210
initial  value 635.109322 
iter  10 value 533.999043
iter  20 value 503.392891
iter  30 value 483.330123
iter  40 value 464.399024
iter  50 value 454.160264
iter  60 value 443.309694
iter  70 value 433.767698
iter  80 value 429.324788
iter  90 value 427.442452
iter 100 value 426.096462
final  value 426.096462 
stopped after 100 iterations
# weights:  221
initial  value 843.203678 
iter  10 value 535.746543
iter  20 value 535.534003
final  value 535.532958 
converged
# weights:  89
initial  value 570.091487 
iter  10 value 535.564695
iter  20 value 535.531976
iter  30 value 535.530751
iter  40 value 535.528344
iter  50 value 535.521334
iter  60 value 535.434706
iter  70 value 509.867028
iter  80 value 500.336971
iter  90 value 499.494686
iter 100 value 495.364787
final  value 495.364787 
stopped after 100 iterations
# weights:  56
initial  value 677.561453 
iter  10 value 507.966863
iter  20 value 485.013249
iter  30 value 477.792510
iter  40 value 476.078219
iter  50 value 474.467122
iter  60 value 473.166389
iter  70 value 469.910584
iter  80 value 469.393967
iter  90 value 468.433065
iter 100 value 467.551381
final  value 467.551381 
stopped after 100 iterations
# weights:  199
initial  value 1012.027516 
iter  10 value 546.200372
iter  20 value 544.645585
final  value 544.638196 
converged
# weights:  23
initial  value 523.243627 
iter  10 value 469.291801
iter  20 value 456.741812
iter  30 value 445.827037
iter  40 value 443.412163
iter  50 value 443.176413
iter  60 value 443.172201
iter  70 value 443.171851
final  value 443.171758 
converged
# weights:  23
initial  value 538.561780 
iter  10 value 486.430049
iter  20 value 477.701376
iter  30 value 452.702042
iter  40 value 447.424136
iter  50 value 447.037849
iter  60 value 447.031167
iter  70 value 447.028604
iter  80 value 447.023005
iter  90 value 446.083408
iter 100 value 445.903319
final  value 445.903319 
stopped after 100 iterations
# weights:  221
initial  value 613.338776 
iter  10 value 488.862392
iter  20 value 486.420387
iter  30 value 486.397931
iter  40 value 486.393507
iter  50 value 486.375145
iter  60 value 481.615418
iter  70 value 443.190391
iter  80 value 433.847887
iter  90 value 431.828401
iter 100 value 429.154246
final  value 429.154246 
stopped after 100 iterations
# weights:  177
initial  value 723.301649 
iter  10 value 486.561444
iter  20 value 486.393837
iter  30 value 486.389679
iter  40 value 486.388027
iter  50 value 486.384280
iter  60 value 486.369109
iter  70 value 481.109781
iter  80 value 455.314254
iter  90 value 445.702891
iter 100 value 444.134167
final  value 444.134167 
stopped after 100 iterations
# weights:  188
initial  value 502.131894 
iter  10 value 486.446023
iter  20 value 476.106400
iter  30 value 442.305049
iter  40 value 434.511393
iter  50 value 429.746597
iter  60 value 428.192866
iter  70 value 427.360854
iter  80 value 426.323640
iter  90 value 425.483169
iter 100 value 423.640773
final  value 423.640773 
stopped after 100 iterations
# weights:  67
initial  value 598.166342 
iter  10 value 498.750625
iter  20 value 497.708198
final  value 497.706484 
converged
# weights:  155
initial  value 523.521739 
iter  10 value 486.494373
iter  20 value 478.832083
iter  30 value 430.088971
iter  40 value 413.399636
iter  50 value 407.596561
iter  60 value 404.017974
iter  70 value 402.225698
iter  80 value 400.668963
iter  90 value 397.198125
iter 100 value 389.032030
final  value 389.032030 
stopped after 100 iterations
# weights:  210
initial  value 731.451609 
iter  10 value 488.641514
iter  20 value 488.257851
final  value 488.257526 
converged
# weights:  78
initial  value 621.613725 
iter  10 value 486.476592
iter  20 value 486.393713
iter  30 value 486.393634
iter  40 value 486.393545
iter  50 value 486.393443
iter  60 value 486.393325
iter  70 value 486.393184
iter  80 value 486.393014
iter  90 value 486.392803
iter 100 value 486.392533
final  value 486.392533 
stopped after 100 iterations
# weights:  111
initial  value 537.950796 
iter  10 value 486.507715
iter  20 value 486.395689
iter  30 value 486.395481
iter  40 value 486.395228
iter  50 value 486.394909
iter  60 value 486.394495
iter  70 value 486.393927
iter  80 value 486.393096
iter  90 value 486.391749
iter 100 value 486.389182
final  value 486.389182 
stopped after 100 iterations
# weights:  166
initial  value 579.030309 
iter  10 value 486.591988
iter  20 value 486.388325
iter  30 value 486.382547
iter  40 value 486.342142
iter  50 value 472.661422
iter  60 value 442.861624
iter  70 value 438.712534
iter  80 value 437.592894
iter  90 value 436.820426
iter 100 value 433.651048
final  value 433.651048 
stopped after 100 iterations
# weights:  221
initial  value 617.392272 
iter  10 value 487.176277
iter  20 value 486.541739
final  value 486.540903 
converged
# weights:  45
initial  value 657.198372 
iter  10 value 487.128870
iter  20 value 471.487867
iter  30 value 443.585867
iter  40 value 435.336595
iter  50 value 432.001559
iter  60 value 431.377520
iter  70 value 431.195751
iter  80 value 430.730998
iter  90 value 430.416810
iter 100 value 430.313193
final  value 430.313193 
stopped after 100 iterations
# weights:  34
initial  value 675.190716 
iter  10 value 475.647998
iter  20 value 460.551242
iter  30 value 459.400374
iter  40 value 459.363955
iter  50 value 459.362594
final  value 459.362567 
converged
# weights:  188
initial  value 844.741404 
iter  10 value 488.460947
iter  20 value 485.831685
iter  30 value 485.773403
final  value 485.773324 
converged
# weights:  210
initial  value 531.182183 
iter  10 value 487.534236
iter  20 value 467.721961
iter  30 value 440.433566
iter  40 value 421.612259
iter  50 value 411.342353
iter  60 value 405.600664
iter  70 value 396.797207
iter  80 value 388.249695
iter  90 value 381.732642
iter 100 value 375.758060
final  value 375.758060 
stopped after 100 iterations
# weights:  221
initial  value 671.069857 
iter  10 value 486.632076
iter  20 value 486.394673
final  value 486.393517 
converged
# weights:  89
initial  value 631.356970 
iter  10 value 486.594584
iter  20 value 486.394342
iter  30 value 486.394168
iter  40 value 486.393956
iter  50 value 486.393688
iter  60 value 486.393338
iter  70 value 486.392861
iter  80 value 486.392166
iter  90 value 486.391057
iter 100 value 486.389002
final  value 486.389002 
stopped after 100 iterations
# weights:  56
initial  value 563.634941 
iter  10 value 476.803056
iter  20 value 453.543239
iter  30 value 445.178483
iter  40 value 433.417565
iter  50 value 428.908065
iter  60 value 427.045207
iter  70 value 425.578173
iter  80 value 423.449608
iter  90 value 422.196948
iter 100 value 420.665097
final  value 420.665097 
stopped after 100 iterations
# weights:  199
initial  value 913.176147 
iter  10 value 495.079890
iter  20 value 494.234429
final  value 494.234325 
converged
# weights:  23
initial  value 573.012721 
iter  10 value 484.908692
iter  20 value 475.511642
iter  30 value 474.583745
iter  40 value 474.563187
final  value 474.563065 
converged
# weights:  23
initial  value 647.659424 
iter  10 value 499.634500
iter  20 value 499.525923
iter  30 value 499.525492
iter  40 value 499.524914
iter  50 value 499.524086
iter  60 value 499.522796
iter  70 value 499.520557
iter  80 value 499.516115
iter  90 value 499.505940
iter 100 value 499.478453
final  value 499.478453 
stopped after 100 iterations
# weights:  221
initial  value 681.977581 
iter  10 value 502.008777
iter  20 value 499.548796
iter  30 value 499.528681
iter  40 value 499.526660
iter  50 value 499.522237
iter  60 value 499.501346
iter  70 value 491.072445
iter  80 value 463.451997
iter  90 value 450.586930
iter 100 value 442.037918
final  value 442.037918 
stopped after 100 iterations
# weights:  177
initial  value 552.951720 
iter  10 value 499.565405
iter  20 value 499.518833
iter  30 value 499.517810
iter  40 value 499.515818
iter  50 value 499.510311
iter  60 value 499.460749
iter  70 value 486.863074
iter  80 value 457.232214
iter  90 value 453.376925
iter 100 value 450.567304
final  value 450.567304 
stopped after 100 iterations
# weights:  188
initial  value 625.588270 
iter  10 value 500.104733
iter  20 value 499.526817
iter  30 value 499.523158
iter  40 value 499.522861
iter  50 value 499.522468
iter  60 value 499.521914
iter  70 value 499.521061
iter  80 value 499.519553
iter  90 value 499.516113
iter 100 value 499.501301
final  value 499.501301 
stopped after 100 iterations
# weights:  67
initial  value 722.395919 
iter  10 value 513.113379
iter  20 value 512.937489
final  value 512.937196 
converged
# weights:  155
initial  value 718.691809 
iter  10 value 500.619671
iter  20 value 488.574611
iter  30 value 461.230742
iter  40 value 449.614918
iter  50 value 439.200942
iter  60 value 427.780216
iter  70 value 420.300569
iter  80 value 418.309851
iter  90 value 415.409536
iter 100 value 414.042325
final  value 414.042325 
stopped after 100 iterations
# weights:  210
initial  value 930.334087 
iter  10 value 503.491592
iter  20 value 502.625059
final  value 502.623673 
converged
# weights:  78
initial  value 724.271887 
iter  10 value 499.611323
iter  20 value 499.507350
iter  30 value 491.557090
iter  40 value 467.396230
iter  50 value 462.433563
iter  60 value 461.975933
iter  70 value 461.662318
iter  80 value 461.263206
iter  90 value 461.207008
iter 100 value 461.149491
final  value 461.149491 
stopped after 100 iterations
# weights:  111
initial  value 610.157193 
iter  10 value 499.789654
iter  20 value 499.524046
iter  30 value 499.523811
iter  40 value 499.523519
iter  50 value 499.523138
iter  60 value 499.522610
iter  70 value 499.521807
iter  80 value 499.520411
iter  90 value 499.517312
iter 100 value 499.505081
final  value 499.505081 
stopped after 100 iterations
# weights:  166
initial  value 745.279928 
iter  10 value 499.822955
iter  20 value 499.523561
iter  30 value 499.517513
iter  40 value 499.511743
iter  50 value 499.461867
iter  60 value 487.435783
iter  70 value 459.851930
iter  80 value 442.178186
iter  90 value 439.096733
iter 100 value 436.012333
final  value 436.012333 
stopped after 100 iterations
# weights:  221
initial  value 591.838588 
iter  10 value 501.343931
iter  20 value 500.669116
final  value 500.668430 
converged
# weights:  45
initial  value 579.358514 
iter  10 value 502.886566
iter  20 value 499.621244
iter  30 value 489.146180
iter  40 value 467.678620
iter  50 value 452.762646
iter  60 value 450.081205
iter  70 value 447.726686
iter  80 value 445.111535
iter  90 value 443.533858
iter 100 value 442.681761
final  value 442.681761 
stopped after 100 iterations
# weights:  34
initial  value 614.465442 
iter  10 value 486.308806
iter  20 value 476.350548
iter  30 value 472.107584
iter  40 value 470.192763
iter  50 value 465.372829
iter  60 value 464.029761
final  value 464.028580 
converged
# weights:  188
initial  value 580.083324 
iter  10 value 499.965747
iter  20 value 499.615206
iter  30 value 499.588949
final  value 499.588693 
converged
# weights:  210
initial  value 781.288367 
iter  10 value 500.782373
iter  20 value 471.996218
iter  30 value 450.817132
iter  40 value 440.761291
iter  50 value 430.197861
iter  60 value 419.720691
iter  70 value 399.135357
iter  80 value 394.905240
iter  90 value 392.019762
iter 100 value 388.776713
final  value 388.776713 
stopped after 100 iterations
# weights:  221
initial  value 691.777326 
iter  10 value 499.828893
iter  20 value 499.523664
iter  30 value 499.520523
iter  40 value 499.520251
iter  50 value 499.519889
iter  60 value 499.519373
iter  70 value 499.518565
iter  80 value 499.517101
iter  90 value 499.513662
iter 100 value 499.497958
final  value 499.497958 
stopped after 100 iterations
# weights:  89
initial  value 609.991364 
iter  10 value 499.671561
iter  20 value 499.511288
iter  30 value 499.297743
iter  40 value 478.208948
iter  50 value 461.835585
iter  60 value 457.237779
iter  70 value 454.042544
iter  80 value 453.919565
iter  90 value 453.872120
iter 100 value 452.840023
final  value 452.840023 
stopped after 100 iterations
# weights:  56
initial  value 583.179635 
iter  10 value 495.655973
iter  20 value 469.490367
iter  30 value 454.623787
iter  40 value 452.461324
iter  50 value 450.578749
iter  60 value 450.371093
iter  70 value 450.007933
iter  80 value 447.192469
iter  90 value 443.898986
iter 100 value 441.139948
final  value 441.139948 
stopped after 100 iterations
# weights:  199
initial  value 1007.281427 
iter  10 value 510.322069
iter  20 value 509.235408
final  value 509.234502 
converged
# weights:  89
initial  value 1003.043856 
iter  10 value 761.135493
iter  20 value 760.726418
iter  30 value 737.414816
iter  40 value 712.173535
iter  50 value 701.900230
iter  60 value 699.505081
iter  70 value 698.890447
iter  80 value 697.604173
iter  90 value 695.517440
iter 100 value 695.212344
final  value 695.212344 
stopped after 100 iterations
Neural Networks with Feature Extraction 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  size  decay         RMSE      Rsquared      MAE        Selected
   2    1.014357e-04  1.029586  0.0004292646  0.8147077          
   2    1.529916e-02  1.042440  0.0028290941  0.8199824          
   3    4.737428e-02  1.017827  0.0057766167  0.8028850          
   4    4.094652e-03  1.034345  0.0037230023  0.8126664          
   5    2.067995e-02  1.053646  0.0024390912  0.8366015          
   6    6.901896e+00  1.008265  0.0008386205  0.7930520          
   7    4.206524e-05  1.013654  0.0012980797  0.8045646          
   8    8.038078e-05  1.001078  0.0118540780  0.7886395  *       
  10    1.290063e-04  1.017937  0.0011573968  0.8004561          
  14    2.487225e-03  1.055977  0.0032807485  0.8383580          
  15    8.599043e-05  1.008727  0.0080228257  0.8011797          
  16    4.326445e-05  1.034073  0.0031061237  0.8170976          
  17    1.730345e-04  1.032550  0.0005860133  0.8145434          
  17    1.207437e+00  1.006091  0.0005558660  0.7932858          
  18    9.487641e+00  1.006696  0.0009238916  0.7924965          
  19    4.533650e-02  1.070854  0.0027764170  0.8460780          
  19    2.995945e+00  1.004980  0.0007727097  0.7925618          
  20    6.267988e-05  1.004839  0.0007703490  0.7962991          
  20    6.195024e-04  1.018334  0.0081442053  0.8062419          
  20    1.686089e+00  1.004801  0.0006232264  0.7927127          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 8 and decay = 8.038078e-05.
[1] "Sat Mar 03 14:38:39 2018"
Principal Component Analysis 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  ncomp  RMSE      Rsquared      MAE        Selected
  1      1.004487  0.0002628281  0.7943730  *       
  2      1.006488  0.0015712313  0.7956449          
  3      1.007602  0.0024091103  0.7964001          
  4      1.008718  0.0011163899  0.7973262          
  6      1.010505  0.0016693195  0.8007292          
  7      1.013411  0.0018951066  0.8025073          
  8      1.013805  0.0024505716  0.8060290          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 1.
[1] "Sat Mar 03 14:38:54 2018"
Loading required package: plsRglm
____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.059734767023474) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0212043744046241) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0412710868753493) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.194632281176746) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0798571716994047) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.182551128417254) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0207974446006119) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0370203687809408) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0311483374796808) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.17422934952192) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0870738992001861) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.122518087457865) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.169395478628576) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.121881599118933) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0265709382481873) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0301717398222536) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.110518319020048) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.199238608172163) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.059734767023474) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0212043744046241) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0412710868753493) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.194632281176746) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0798571716994047) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.182551128417254) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0207974446006119) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0370203687809408) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0311483374796808) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.17422934952192) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0870738992001861) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.122518087457865) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.169395478628576) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.121881599118933) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0265709382481873) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0301717398222536) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.110518319020048) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.199238608172163) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.059734767023474) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0212043744046241) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0412710868753493) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.194632281176746) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0798571716994047) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Component____ 2 ____
No more significant predictors (<0.182551128417254) found
Warning only 2 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0207974446006119) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0370203687809408) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0311483374796808) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Component____ 2 ____
No more significant predictors (<0.17422934952192) found
Warning only 2 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0870738992001861) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.122518087457865) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Component____ 2 ____
No more significant predictors (<0.169395478628576) found
Warning only 2 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.121881599118933) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0265709382481873) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0301717398222536) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.110518319020048) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.199238608172163) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.199238608172163) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

Partial Least Squares Generalized Linear Models  

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  nt  alpha.pvals.expli  RMSE      Rsquared      MAE        Selected
  1   0.03353969         1.017345  0.0009712322  0.8071581          
  1   0.10615559         1.013583  0.0005889734  0.8042446          
  2   0.08707390         1.013583  0.0005889734  0.8042446          
  2   0.12251809         1.013583  0.0005889734  0.8042446          
  3   0.02079744         1.017345  0.0009712322  0.8071581          
  3   0.11051832         1.013583  0.0005889734  0.8042446          
  3   0.19463228         1.012648  0.0005284870  0.8049429          
  4   0.03017174         1.017345  0.0009712322  0.8071581          
  5   0.03702037         1.017345  0.0009712322  0.8071581          
  6   0.07985717         1.013583  0.0005889734  0.8042446          
  7   0.02120437         1.017345  0.0009712322  0.8071581          
  7   0.03114834         1.017345  0.0009712322  0.8071581          
  8   0.04127109         1.013583  0.0005889734  0.8042446          
  8   0.16939548         1.013995  0.0006621418  0.8044109          
  8   0.19923861         1.012648  0.0005284870  0.8049429  *       
  9   0.02657094         1.017345  0.0009712322  0.8071581          
  9   0.05973477         1.013583  0.0005889734  0.8042446          
  9   0.12188160         1.013583  0.0005889734  0.8042446          
  9   0.17422935         1.013995  0.0006621418  0.8044109          
  9   0.18255113         1.013995  0.0006621418  0.8044109          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nt = 8 and alpha.pvals.expli
 = 0.1992386.
[1] "Sat Mar 03 14:39:49 2018"
Projection Pursuit Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  nterms  RMSE      Rsquared      MAE        Selected
   1      1.034419  0.0001382788  0.8182722  *       
   2      1.057156  0.0023382385  0.8306544          
   3      1.102363  0.0035350454  0.8668811          
   4      1.102811  0.0081668859  0.8610957          
   5      1.130402  0.0047560178  0.8901207          
   6      1.143582  0.0037875628  0.9038583          
   7      1.148929  0.0039165140  0.9195270          
   8      1.171170  0.0042421311  0.9390834          
   9      1.185220  0.0014635098  0.9462989          
  10      1.213497  0.0032269797  0.9688155          
  11      1.236414  0.0026293809  0.9809621          
  12      1.260420  0.0016550598  1.0120277          
  13      1.276007  0.0015121450  1.0218850          
  14      1.304141  0.0014555074  1.0362209          
  15      1.354029  0.0016390735  1.0714827          
  16      1.351088  0.0029877598  1.0636288          
  17      1.319842  0.0017618707  1.0490657          
  18      1.341434  0.0059144113  1.0601115          
  19      1.372710  0.0004182922  1.0971960          
  20      1.410592  0.0002345003  1.1311078          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was nterms = 1.
[1] "Sat Mar 03 14:40:19 2018"
Quantile Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  mtry  RMSE      Rsquared     MAE       Selected
  1     1.657614  0.003100231  1.407643  *       
  2     1.668579  0.005758977  1.412028          
  3     1.671939  0.002077430  1.415219          
  4     1.681592  0.003454064  1.424602          
  5     1.682073  0.001869833  1.423238          
  6     1.679867  0.002536679  1.420876          
  7     1.681752  0.005117045  1.419640          
  8     1.675512  0.002747400  1.416387          
  9     1.669563  0.001750078  1.410851          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 1.
[1] "Sat Mar 03 14:42:35 2018"
Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  min.node.size  mtry  splitrule   RMSE      Rsquared      MAE        Selected
   2             2     maxstat     1.011710  0.0011980447  0.8018131          
   2             5     maxstat     1.018732  0.0015873038  0.8095360          
   3             6     extratrees  1.030027  0.0021216268  0.8174705          
   4             4     maxstat     1.015095  0.0003169381  0.8046643          
   5             5     maxstat     1.018859  0.0011117899  0.8074795          
   6             9     variance    1.038395  0.0009039559  0.8237081          
   7             1     maxstat     1.008181  0.0006835177  0.7981260  *       
   8             2     variance    1.028472  0.0012151027  0.8153287          
  10             2     variance    1.028751  0.0010635817  0.8149064          
  14             4     maxstat     1.014656  0.0009951413  0.8045858          
  15             2     variance    1.028526  0.0017557102  0.8152184          
  16             1     extratrees  1.009146  0.0012955374  0.7971200          
  17             2     maxstat     1.011133  0.0002973406  0.8013775          
  17             8     maxstat     1.022180  0.0020011305  0.8133416          
  18             9     extratrees  1.021991  0.0016028489  0.8090016          
  19             6     extratrees  1.019867  0.0009797501  0.8069729          
  19             9     extratrees  1.022584  0.0012808433  0.8092001          
  20             2     extratrees  1.010336  0.0002648595  0.7992461          
  20             3     variance    1.027456  0.0013681918  0.8148579          
  20             8     extratrees  1.021678  0.0013629599  0.8088642          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mtry = 1, splitrule = maxstat
 and min.node.size = 7.
[1] "Sat Mar 03 14:43:21 2018"
Error in code$varImp(object$finalModel, ...) : 
  No importance values available
In addition: Warning messages:
1: package 'gpls' is not available (for R version 3.4.3) 
2: package 'rPython' is not available (for R version 3.4.3) 
Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  predFixed  minNode  RMSE      Rsquared      MAE        Selected
  1           4       1.022825  0.0003743222  0.8088115          
  1          11       1.019240  0.0013359640  0.8045008  *       
  2           9       1.028672  0.0010504164  0.8112046          
  2          13       1.030640  0.0018556171  0.8124074          
  3           3       1.037768  0.0003262549  0.8183441          
  3          12       1.035068  0.0011503256  0.8145619          
  3          20       1.030367  0.0012837850  0.8104514          
  4           4       1.041109  0.0013256633  0.8217273          
  5           4       1.041577  0.0006089729  0.8203486          
  6           8       1.039899  0.0009208610  0.8204169          
  7           3       1.044744  0.0010561787  0.8250102          
  7           4       1.042800  0.0007953743  0.8225350          
  8           5       1.046499  0.0006905960  0.8248540          
  8          17       1.041066  0.0013377386  0.8192199          
  8          20       1.040279  0.0014193992  0.8174761          
  9           3       1.046770  0.0003597851  0.8262103          
  9           6       1.044649  0.0014398456  0.8233368          
  9          13       1.043230  0.0008606760  0.8215663          
  9          18       1.042490  0.0024330796  0.8199845          
  9          19       1.038256  0.0015376739  0.8154036          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were predFixed = 1 and minNode = 11.
[1] "Sat Mar 03 14:55:51 2018"
Loading required package: lars
Loaded lars 1.2

Relaxed Lasso 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  phi        lambda       RMSE      Rsquared      MAE        Selected
  0.1039872   0.69443650  1.017615  0.0007220449  0.8079709          
  0.1060219  15.98457607  1.013469  0.0013008394  0.8051814          
  0.1328547  81.79898049  1.004841           NaN  0.7963011          
  0.1508587   1.00083165  1.017574  0.0007203529  0.8079475          
  0.1557417  10.36393038  1.016288  0.0004594343  0.8076001          
  0.1676985   0.09911835  1.017559  0.0007197445  0.8079391          
  0.1851018   2.05429326  1.017324  0.0007264321  0.8077349          
  0.2063554  26.92202345  1.006887  0.0055251463  0.8008958          
  0.2986738  69.21444708  1.004841           NaN  0.7963011          
  0.3992859   7.62276920  1.015714  0.0005558589  0.8069651          
  0.4353695   0.22357300  1.017326  0.0007100339  0.8078060          
  0.5307779   0.12219371  1.017243  0.0007065547  0.8077593          
  0.5525916   0.34572549  1.017225  0.0007057579  0.8077487          
  0.6094080  52.83133591  1.003824  0.0070187219  0.7947910          
  0.6125904   0.18599478  1.017173  0.0007035637  0.8077197          
  0.8469774  24.73118718  1.003780  0.0047380494  0.7967331          
  0.8711467  70.57939289  1.004841           NaN  0.7963011          
  0.9127556  55.50471820  1.004129  0.0070187219  0.7953697          
  0.9731614   0.47555335  1.016868  0.0006902982  0.8075590          
  0.9961930  29.12823954  1.002327  0.0088462676  0.7949019  *       

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 29.12824 and phi = 0.996193.
[1] "Sat Mar 03 14:56:08 2018"
Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  mtry  RMSE      Rsquared      MAE        Selected
  1     1.023882  0.0018554528  0.8107309  *       
  2     1.030679  0.0013911319  0.8167889          
  3     1.032737  0.0013360063  0.8213571          
  4     1.036364  0.0013717177  0.8226714          
  5     1.035347  0.0007361062  0.8232035          
  6     1.035949  0.0004667166  0.8218383          
  7     1.039674  0.0020356347  0.8252015          
  8     1.033536  0.0011594325  0.8223372          
  9     1.039876  0.0014836638  0.8271034          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 1.
[1] "Sat Mar 03 14:57:45 2018"
Error in varImp[, "%IncMSE"] : subscript out of bounds
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Ridge Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  lambda        RMSE      Rsquared      MAE        Selected
  2.104616e-05  1.017875  0.0007808006  0.8068751          
  3.161887e-05  1.017875  0.0007808028  0.8068751          
  7.157828e-05  1.017875  0.0007808109  0.8068750          
  1.023783e-04  1.017875  0.0007808172  0.8068749          
  2.389928e-04  1.017874  0.0007808449  0.8068747          
  4.443028e-04  1.017874  0.0007808867  0.8068744          
  9.278360e-04  1.017873  0.0007809849  0.8068736          
  1.888725e-03  1.017871  0.0007811797  0.8068720          
  7.647805e-03  1.017861  0.0007823392  0.8068624          
  9.795166e-02  1.017714  0.0007988535  0.8067331          
  1.780216e-01  1.017608  0.0008112797  0.8066385          
  4.134675e-01  1.017382  0.0008393188  0.8064704          
  9.662041e-01  1.017102  0.0008778811  0.8062712          
  1.139620e+00  1.017049  0.0008857374  0.8062331          
  1.328267e+00  1.017002  0.0008929119  0.8061991          
  4.228343e+00  1.016739  0.0009370692  0.8060385          
  4.654401e+00  1.016724  0.0009396844  0.8060306          
  7.150016e+00  1.016673  0.0009494524  0.8060022          
  7.426792e+00  1.016669  0.0009501756  0.8060001          
  9.894764e+00  1.016645  0.0009549859  0.8059867  *       

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was lambda = 9.894764.
[1] "Sat Mar 03 14:58:02 2018"
Robust Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  intercept  psi           RMSE      Rsquared      MAE        Selected
  FALSE      psi.huber     1.020483  0.0013956159  0.8107570          
  FALSE      psi.hampel    1.018984  0.0009121746  0.8088185  *       
  FALSE      psi.bisquare  1.020297  0.0013782983  0.8104530          
   TRUE      psi.huber     1.020644  0.0014271370  0.8097985          
   TRUE      psi.hampel    1.019164  0.0009938670  0.8076592          
   TRUE      psi.bisquare  1.020471  0.0014181497  0.8092617          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were intercept = FALSE and psi = psi.hampel.
[1] "Sat Mar 03 14:58:18 2018"
CART 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  cp            RMSE      Rsquared     MAE        Selected
  0.0007060474  1.183845  0.002145839  0.9513989          
  0.0020198398  1.183509  0.002144989  0.9504280          
  0.0028732945  1.184906  0.002206754  0.9513946          
  0.0030042002  1.184906  0.002206754  0.9513946          
  0.0031307949  1.184906  0.002206754  0.9513946          
  0.0036639053  1.184906  0.002206754  0.9513946          
  0.0041928825  1.184595  0.002292973  0.9526010          
  0.0043954281  1.186137  0.001460686  0.9531661          
  0.0045730787  1.183630  0.001804935  0.9513069          
  0.0060632336  1.172363  0.002635988  0.9400543          
  0.0074324689  1.155639  0.002545748  0.9293234          
  0.0083162701  1.144228  0.001841226  0.9215915          
  0.0091588566  1.131483  0.002284609  0.9075534          
  0.0124970186  1.057851  0.004623759  0.8459325          
  0.0128569454  1.057851  0.004623759  0.8459325          
  0.0143660286  1.044870  0.005625198  0.8275401  *       

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.01436603.
[1] "Sat Mar 03 14:58:34 2018"
CART 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.115343  0.002847393  0.8899869

[1] "Sat Mar 03 14:58:49 2018"
CART 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  maxdepth  RMSE      Rsquared     MAE        Selected
   1        1.033385  0.001528870  0.8148955  *       
   2        1.033385  0.001528870  0.8148955          
   3        1.033385  0.001528870  0.8148955          
  14        1.101002  0.001857771  0.8725528          
  15        1.101002  0.001857771  0.8725528          
  16        1.102366  0.001888240  0.8752785          
  17        1.109169  0.002514919  0.8793164          
  18        1.109169  0.002514919  0.8793164          
  19        1.115343  0.002847393  0.8899869          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was maxdepth = 1.
[1] "Sat Mar 03 14:59:05 2018"
Quantile Regression with LASSO penalty 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  lambda        RMSE      Rsquared     MAE        Selected
  2.104616e-05  1.026890  0.001710591  0.8144817          
  3.161887e-05  1.026766  0.001663131  0.8143371          
  7.157828e-05  1.026766  0.001663127  0.8143370          
  1.023783e-04  1.026766  0.001663127  0.8143370          
  2.389928e-04  1.026766  0.001663127  0.8143370          
  4.443028e-04  1.026614  0.001668094  0.8141957          
  9.278360e-04  1.026190  0.001708796  0.8138873          
  1.888725e-03  1.023751  0.001537095  0.8118372          
  7.647805e-03  1.019071  0.001162476  0.8065394          
  9.795166e-02  1.005585          NaN  0.7923948  *       
  1.780216e-01  1.005593          NaN  0.7923948          
  4.134675e-01  1.005596          NaN  0.7923948          
  9.662041e-01  1.005659          NaN  0.7923977          
  1.139620e+00  1.005644          NaN  0.7923951          
  1.328267e+00  1.005633          NaN  0.7923948          
  4.228343e+00  1.005590          NaN  0.7923948          
  4.654401e+00  1.005590          NaN  0.7923948          
  7.150016e+00  1.005590          NaN  0.7923948          
  7.426792e+00  1.005590          NaN  0.7923948          
  9.894764e+00  1.005590          NaN  0.7923948          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was lambda = 0.09795166.
[1] "Sat Mar 03 14:59:22 2018"
Non-Convex Penalized Quantile Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  lambda        penalty  RMSE      Rsquared     MAE        Selected
  2.104616e-05  MCP      1.026890  0.001710591  0.8144817          
  3.161887e-05  SCAD     1.026890  0.001710591  0.8144817          
  7.157828e-05  SCAD     1.026890  0.001710591  0.8144817          
  1.023783e-04  MCP      1.026890  0.001710591  0.8144817          
  2.389928e-04  SCAD     1.026890  0.001710591  0.8144817          
  4.443028e-04  SCAD     1.026890  0.001710591  0.8144817          
  9.278360e-04  MCP      1.026890  0.001710591  0.8144817          
  1.888725e-03  MCP      1.026766  0.001663127  0.8143370          
  7.647805e-03  MCP      1.026025  0.001589009  0.8130868          
  9.795166e-02  MCP      1.005585          NaN  0.7923948  *       
  1.780216e-01  MCP      1.005593          NaN  0.7923948          
  4.134675e-01  MCP      1.005596          NaN  0.7923948          
  9.662041e-01  SCAD     1.005659          NaN  0.7923977          
  1.139620e+00  MCP      1.005644          NaN  0.7923951          
  1.328267e+00  SCAD     1.005633          NaN  0.7923948          
  4.228343e+00  SCAD     1.005590          NaN  0.7923948          
  4.654401e+00  SCAD     1.005590          NaN  0.7923948          
  7.150016e+00  MCP      1.005590          NaN  0.7923948          
  7.426792e+00  SCAD     1.005590          NaN  0.7923948          
  9.894764e+00  MCP      1.005590          NaN  0.7923948          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 0.09795166 and penalty = MCP.
[1] "Sat Mar 03 14:59:39 2018"
Regularized Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  mtry  coefReg    coefImp     RMSE      Rsquared      MAE        Selected
  1     0.1676985  0.98272419  1.004666  0.0005179219  0.7948293          
  1     0.5307779  0.99049985  1.003904  0.0022862472  0.7935149  *       
  2     0.4353695  0.86659838  1.007972  0.0005327123  0.8000104          
  2     0.6125904  0.39407338  1.019905  0.0022727335  0.8074447          
  3     0.1039872  0.86558349  1.022828  0.0022671937  0.8143603          
  3     0.5525916  0.80700771  1.024243  0.0010849784  0.8154913          
  3     0.9731614  0.14084884  1.030057  0.0009558185  0.8170950          
  4     0.1508587  0.25702471  1.036340  0.0032281707  0.8226235          
  5     0.1851018  0.01643214  1.036859  0.0018340332  0.8233330          
  6     0.3992859  0.74508078  1.029020  0.0039346469  0.8185887          
  7     0.1060219  0.41769700  1.031520  0.0014608342  0.8216953          
  7     0.1557417  0.27342888  1.035523  0.0011298407  0.8234516          
  8     0.2063554  0.77557101  1.033334  0.0015715186  0.8221725          
  8     0.8469774  0.68603172  1.056797  0.0049765893  0.8414292          
  8     0.9961930  0.49610207  1.071483  0.0045518874  0.8497268          
  9     0.1328547  0.40862324  1.058972  0.0043024674  0.8396215          
  9     0.2986738  0.32219953  1.055532  0.0032333013  0.8398804          
  9     0.6094080  0.61660168  1.096722  0.0028486382  0.8738233          
  9     0.8711467  0.44213045  1.039101  0.0014844678  0.8240715          
  9     0.9127556  0.53017697  1.045989  0.0029824071  0.8266007          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mtry = 1, coefReg = 0.5307779
 and coefImp = 0.9904999.
[1] "Sat Mar 03 15:07:04 2018"
Error in varImp[, "%IncMSE"] : subscript out of bounds
In addition: Warning messages:
1: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
2: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
3: model fit failed for Fold1: mtry=8, coefReg=0.9962, coefImp=0.49610 Error in RRF.default(x, y, mtry = param$mtry, coefReg = firstImp, ...) : 
  coefReg can not be greater than 1
 
4: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Regularized Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 503, 501, 500 
Resampling results across tuning parameters:

  mtry  coefReg    RMSE      Rsquared     MAE        Selected
  1     0.1676985  1.025776  0.002080133  0.8117354          
  1     0.5307779  1.024934  0.001884052  0.8105651  *       
  2     0.4353695  1.031281  0.001985721  0.8155809          
  2     0.6125904  1.032102  0.001671745  0.8176164          
  3     0.1039872  1.035065  0.001399352  0.8189665          
  3     0.5525916  1.036042  0.002973746  0.8213157          
  3     0.9731614  1.035222  0.002208949  0.8216951          
  4     0.1508587  1.034235  0.002074838  0.8198995          
  5     0.1851018  1.035030  0.001084726  0.8203811          
  6     0.3992859  1.037939  0.001098276  0.8242435          
  7     0.1060219  1.046919  0.005188516  0.8315297          
  7     0.1557417  1.040472  0.001633474  0.8294241          
  8     0.2063554  1.042991  0.002396390  0.8286481          
  8     0.8469774  1.036356  0.001296354  0.8233892          
  8     0.9961930  1.042079  0.002195129  0.8271997          
  9     0.1328547  1.057201  0.003290129  0.8329593          
  9     0.2986738  1.035574  0.001231348  0.8228583          
  9     0.6094080  1.038386  0.001518676  0.8247747          
  9     0.8711467  1.038057  0.001274562  0.8253847          
  9     0.9127556  1.036928  0.001033825  0.8234399          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mtry = 1 and coefReg = 0.5307779.
[1] "Sat Mar 03 15:10:32 2018"
Error in varImp[, "%IncMSE"] : subscript out of bounds
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
In addition: Warning messages:
1: model fit failed for Resample01: parameter=none Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
2: model fit failed for Resample03: parameter=none Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
3: In max(abs(logtheta[thetavec[which(nzindex)] != 0] + log(thetavec[thetavec !=  :
  no non-missing arguments to max; returning -Inf
4: In max(abs(logtheta[thetavec[which(nzindex)] != 0] + log(thetavec[thetavec !=  :
  no non-missing arguments to max; returning -Inf
5: In max(abs(logtheta[thetavec[which(nzindex)] != 0] + log(thetavec[thetavec !=  :
  no non-missing arguments to max; returning -Inf
6: model fit failed for Resample12: parameter=none Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
7: In max(abs(logtheta[thetavec[which(nzindex)] != 0] + log(thetavec[thetavec !=  :
  no non-missing arguments to max; returning -Inf
8: model fit failed for Resample17: parameter=none Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
9: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 15:15:48 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "rvmLinear"               
Timing stopped at: 10.23 0.09 10.33
Error in chol.default(crossprod(Kr)/var + diag(1/thetatmp)) : 
  the leading minor of order 521 is not positive definite
In addition: There were 43 warnings (use warnings() to see them)
Error in .local(object, ...) : test vector does not match model !
In addition: There were 11 warnings (use warnings() to see them)
Error in .local(object, ...) : test vector does not match model !
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 16:23:37 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "rvmPoly"                 
Error in .local(object, ...) : test vector does not match model !
Timing stopped at: 13.81 0 13.81
Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
In addition: Warning messages:
1: model fit failed for Fold2: sigma=0.02917 Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
2: In max(abs(logtheta[thetavec[which(nzindex)] != 0] + log(thetavec[thetavec !=  :
  no non-missing arguments to max; returning -Inf
3: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Error in .local(object, ...) : test vector does not match model !
In addition: Warning messages:
1: In max(abs(logtheta[thetavec[which(nzindex)] != 0] + log(thetavec[thetavec !=  :
  no non-missing arguments to max; returning -Inf
2: In max(abs(logtheta[thetavec[which(nzindex)] != 0] + log(thetavec[thetavec !=  :
  no non-missing arguments to max; returning -Inf
3: model fit failed for Resample10: sigma=0.07378 Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
4: model fit failed for Resample12: sigma=0.07378 Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
5: In max(abs(logtheta[thetavec[which(nzindex)] != 0] + log(thetavec[thetavec !=  :
  no non-missing arguments to max; returning -Inf
6: model fit failed for Resample16: sigma=0.07378 Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
7: model fit failed for Resample18: sigma=0.07378 Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
8: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
 [1] "failed"                   "failed"                  
 [3] "Sat Mar 03 16:38:45 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "centernscale"             "HOPPER"                  
 [9] "14th20hp3cv"              "rvmRadial"               
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
