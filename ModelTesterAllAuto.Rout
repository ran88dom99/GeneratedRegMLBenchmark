
R version 3.4.3 (2017-11-30) -- "Kite-Eating Tree"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> options(repos=structure(c(CRAN="https://rweb.crmda.ku.edu/cran/")))
> ## capture messages and errors to a file.https://rweb.crmda.ku.edu/cran/
> #zz <- file("all.Rout", open="wt")https://cran.cnr.berkeley.edu
> #sink(zz, type="message") edit for rebaseless
> #chek for R package updates
> #try(log("a")) ## test --no-edit
> #devtools::install_github("berndbischl/ParamHelpers") # version >= 1.11 needed.
> #devtools::install_github("jakob-r/mlrHyperopt", dependencies = TRUE)
> task.subject<-"14th20hp3cv"
> pc.mlr<-c("ACE")#"ALTA","HOPPER"
> which.computer<-Sys.info()[['nodename']]
> out.file<-paste("out",task.subject,which.computer,.Platform$OS.type,.Platform$r_arch,".csv",sep="")
> importance.file<-paste("importance",task.subject,which.computer,.Platform$OS.type,.Platform$r_arch,sep="")
> 
> base.folder<-getwd()
> cpout.folder<-paste(base.folder,"/",which.computer,sep = "")
> setwd(cpout.folder)
> 
> if(length(which(list.files() == out.file))<1) write.table( "0.01,0.01,100,100,100,Wed Aug 02 16:37:25 2017,dummy,8,1,basic latent features,ignore,none,asis,1.12784979099243,random,333,53,adaptive_cv,16,5,2,2,19,0.0107744822639878,FALSE,,,,,,,,,," ,file =,out.file,  quote = F, sep = ",", row.names = F,col.names = F)
> if(length(which(list.files() == paste(importance.file,".csv",sep="")))<1) write.table( ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,," ,file = paste(importance.file,".csv",sep=""),  quote = F, sep = ",", row.names = F,col.names = F)
> if(length(which(list.files() == paste(importance.file,"mlr.csv",sep="")))<1) write.table( ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,," ,file = paste(importance.file,"mlr.csv",sep=""),  quote = F, sep = ",", row.names = F,col.names = F)
> 
> cv.iters=3
> tuneLength=20
> tuneLength2=8
> normings=c("YeoJohnson","ICA", "centernscale","expoTrans","range01","asis","quantile")#,"centernscale"
> 
> gensTTesto<-c(56,53,4,12,13,14,15,20,45,54,55, 44,3,1,52)#,  51,c(4)#c(1:40)#c(5,10,11,13,14,15,16,17,18,19,20,21,24,28,38,39,40)
> gensTTest<-vector()
> write.table( t(gensTTesto),file = "initial tasks to test.csv",  quote = F, sep = ",", row.names = F,col.names = F)
> try({
+   gensTTest<-t(read.csv("tasks to test.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   gensTTest<-as.vector(gensTTest)
+ })
> if(!exists("gensTTest")) gensTTest<-c(gensTTesto)#reversion[length(reversion):1]
> gensTTesto<-c(gensTTesto[length(gensTTesto):1])
> if(length(gensTTest)<1) gensTTest<-c(gensTTesto)#reversion[length(reversion):1]
> 
> 
> ########packages install check######
> 
> #list.of.packages <- c("caret","caretEnsemble","mlr","MLmetrics","tgp")
> #list.of.packages <- c("gower","dimRed","DEoptimR","caretEnsemble","logicFS"," RWeka","ordinalNet","xgboost","mlr","caret","MLmetrics","bartMachine","spikeslab","party","rqPen","monomvn","foba","logicFS","rPython","qrnn","randomGLM","msaenet","Rborist","relaxo","ordinalNet","rrf","frbs","extraTrees","ipred","elasticnet","bst","brnn","Boruta","arm","elmNN","evtree","extraTrees","deepnet","kknn","KRLS","RSNNS","partDSA","plsRglm","quantregForest","ranger","inTrees")
> #new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
> #if(length(new.packages)) install.packages(new.packages, dep = TRUE)
> 
> 
> #install.packages("mlr", dependencies = c("Depends", "Suggests"))
> #install.packages("caret", dependencies = c("Depends", "Suggests"))
> #install.packages("caret",repos = "http://cran.r-project.org",dependencies = c("Depends", "Imports", "Suggests"))
> #install.packages("SuperLearner", dependencies = c("Depends", "Suggests"))
> #install.packages("rattle", dependencies = c("Depends", "Suggests"))
> 
> # Load libraries
> #library(mlbench)
> 
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
> #library(caretEnsemble)
> library(MLmetrics)

Attaching package: 'MLmetrics'

The following objects are masked from 'package:caret':

    MAE, RMSE

The following object is masked from 'package:base':

    Recall

> 
> ########error no repeat#########
> 
> 
> try({
+   before.last.alg<-as.matrix(read.csv("beforelast algorithm.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   last.alg<-as.matrix(read.csv("last algorithm tried.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   #write.table(paste(date(), last.alg,.Platform$OS.type,.Platform$r_arch,which.computer,sep=" "),file = "algos after which reset.csv",  quote = F, row.names = F,col.names = F,append = T)
+   if(last.alg==before.last.alg){print("algorithm may be broken")}
+   write.table(last.alg,file = "beforelast algorithm.csv",  quote = F, row.names = F,col.names = F)
+ })
[1] "algorithm may be broken"
> try({
+   before.last.tsk<-as.matrix(read.csv("beforelast task.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   last.tsk<-as.matrix(read.csv("last task tried.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   write.table(paste(date(),last.alg, last.tsk,cv.iters,tuneLength,.Platform$OS.type,.Platform$r_arch,which.computer,sep=","),file = "test after which reset.csv",  quote = F, row.names = F,col.names = F,append = T)
+   if(last.tsk==before.last.tsk){print("task may be broken")}
+   write.table(last.tsk,file = "beforelast task.csv",  quote = F, row.names = F,col.names = F)
+ })
[1] "task may be broken"
> bad.models=c("spaccceeee")
> previous.fails<-(read.csv("test after which reset.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
> previous.fails<-previous.fails[previous.fails[,8]==which.computer,]
> lgf<-length(previous.fails[,2])
> for(lt in 2:lgf)  {
+   if(previous.fails[lt,2]==previous.fails[lt-1,2])  {
+     bad.models=union(bad.models,c(paste(previous.fails[lt,2])))  }}
> 
> #######not to redo a test function#####
> check.redundant<-function(df=df.previous.calcs,norming="asis",trans.y=1,withextra="missing",missingdata="leaveempty",datasource="mean" ,column.to.predict=200,allmodel="ctree")
+ {
+   for(intern in 1:length(df[,1])){
+     if((any(df[intern,] == norming, na.rm=T))&&
+        (any(df[intern,] == withextra, na.rm=T))&&
+        (any(df[intern,] == missingdata, na.rm=T))&&
+        (any(df[intern,] == datasource, na.rm=T))&&
+        (any(df[intern,] == column.to.predict, na.rm=T))&&
+        (any(df[intern,] == allmodel, na.rm=T))&&
+        (  (df[intern,9] == trans.y)))
+     {return(TRUE)}
+   }
+   return(FALSE)
+ }
> #####caret init#####
> best.ranged <- c("avNNet", "nnet", "pcaNNet", "glm.nb")
> best.asis <- c("svmLinear3", "relaxo", "superpc", "xgbTree")
> best.cns <- c("gam", "bam", "svmLinear2", "msaenet", "BstLm", "gbm") 
> 
> cv6hp5 <- c( "BstLm", "qrnn")#earth
> cv3hp32 <- c("Rborist", "pcaNNet", "SBC")
> cv7x5hp32 <- c("gbm", "krlsPoly", "kknn", "xgbLinear","RRF", "cubist", "rlm" )
> cv6hp5.avoid <- c("pcaNNet")
> cv3hp32.avoid <- c("glm.nb", "gamboost", "ctree2","glmboost", "leapSeq","ctree","svmLinear2")
> cv7x5hp32.avoid <- c("SBC","bagearthgcv","gcvearth","lmStepAIC","glmStepAIC","bridge","lm","glm","bayesglm","blassoAveraged","treebag","rpart1SE")
> 
> allmodels <- c("avNNet", "bagEarth", "bagEarthGCV",
+                "bayesglm", "bdk", "blackboost", "Boruta", "brnn", "BstLm" ,
+                "bstTree", "cforest", "ctree", "ctree2", "cubist", "DENFIS",
+                "dnn", "earth", "elm", "enet",   "evtree",
+                "extraTrees",  "gamLoess",  "gaussprLinear", "gaussprPoly", "gaussprRadial",
+                "gcvEarth","glm", "glmboost",  "icr", "kernelpls",
+                "kknn", "knn",  "krlsRadial", "lars" , "lasso",
+                "leapBackward", "leapForward", "leapSeq", "lm", "M5", "M5Rules",
+                "mlpWeightDecay", "neuralnet" , "partDSA",
+                "pcaNNet", "pcr", "penalized", "pls", "plsRglm", "ppr",
+                "qrf" , "ranger",  "rf")
> allmodels <- c("rlm", "rpart", "rpart2",
+                "RRF", "RRFglobal",  "simpls",
+                "svmLinear", "svmPoly", "svmRadial", "svmRadialCost",
+                "widekernelpls",  "xgbLinear",
+                "xgbTree")
> allmodels <- c("avNNet","BstLm","bstTree","cforest","ctree","ctree2",
+                "cubist","earth","enet","evtree","glmboost",
+                "icr","kernelpls","kknn","lasso","pcaNNet",
+                "pcr","pls","qrf","ranger","rf")
> 
> allmodels <- c("kknn", "cubist", "avNNet", "xgbLinear", "RRF", "pcaNNet","earth","nnet","gbm","enet","lasso","BstLm",
+                "foba", "leapBackward", "gcvEarth", "SBC","glm.nb","gamboost","ctree2","relaxo", 
+                "bartMachine","extraTrees","bam","gam","randomGLM")
> #allmodels <- c("bam")
> #allmodels <- c("rf")"rqlasso",, "xyf" "rvmPoly", "rvmRadial",    "spls", "superpc" ,   "treebag",  "svmLinear2",  "SBC",
> #allmodels <- c("bartMachine", "xgbLinear", "pcaNNet","svmLinear","glmnet","cforest","cubist","rf","ranger")"glmnet",
> #wow rfRules is really slow "rfRules","WM", takes 50min
> # brak everythig "rbfDDA","ridge","rqnc",
> # use "rf" to test all
> library(caret)
> allmodels <- unique(modelLookup()[modelLookup()$forReg,c(1)])
> #allmodels <-c("avNNet", "nnet", "pcaNNet",  "glm.nb", "gam" ,
> #              "bam","msaenet", "svmLinear2","svmLinear3",
> #              "relaxo",  "superpc", "xgbTree", "BstLm")
> #allmodels<- c("svmLinear","svmPoly","svmRadial")
> #library(doParallel); cl <- makeCluster(detectCores()); registerDoParallel(cl)
> #allmodels<-c("bartMachine","extraTrees")#,"randomGLM"
> 
> 
> adaptControl <- trainControl(method = "adaptive_cv",
+                              number = 7, repeats = 5,
+                              adaptive = list(min = 4, alpha = 0.05,
+                                              method = "gls", complete = FALSE),
+                              search = "random")
> adaptControl <-trainControl(method = "cv", number = cv.iters,  search = "random")
> simpleControl <- trainControl(method = "cv",
+                               number = cv.iters,
+                               search = "random")
> 
> 
> #########MLR init######
> #R.utils::gcDLLs()
> #list.of.packages <- c("ParamHelpers","devtools","mlrMBO","RJSONIO","plot3D","plotly")
> #install.packages("mlrMBO", dependencies = c("Depends", "Suggests"))
> list.of.packages <- c("caretEnsemble","logicFS"," RWeka","ordinalNet","xgboost","mlr","caret","MLmetrics","bartMachine","spikeslab","party","rqPen","monomvn","foba","logicFS","rPython","qrnn","randomGLM","msaenet","Rborist","relaxo","ordinalNet","rrf","frbs","extraTrees","ipred","elasticnet","bst","brnn","Boruta","arm","elmNN","evtree","extraTrees","deepnet","kknn","KRLS","RSNNS","partDSA","plsRglm","quantregForest","ranger","inTrees")
> new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
> if(length(new.packages)) install.packages(new.packages, dep = TRUE)
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/src/contrib:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/src/contrib/PACKAGES'
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4/PACKAGES'
Warning message:
packages 'logicFS', ' RWeka', 'rPython', 'rrf' are not available (for R version 3.4.3) 
> 
> #devtools::install_github("berndbischl/ParamHelpers") # version >= 1.11 needed.
> #devtools::install_github("jakob-r/mlrHyperopt", dependencies = TRUE)
> 
> tuneLengthMLR<-tuneLength
> mlr.iters<-cv.iters
> #######data read process start#####
> seed.var =222+round(runif(1,min=0,max=100))
> column.to.predict=1
> print(date());
[1] "Mon Mar 05 05:53:48 2018"
> 
> setwd(base.folder)
> if(!exists("gen.count")){gen.count=56}
> gens.names<-as.matrix(read.table("gens names.csv", sep = ",",header = FALSE,row.names=1,fill=TRUE, quote="",dec="."))
> count.toy.data.passed<-1
> for(gend.data in gensTTest){
+   count.toy.data.passed<-count.toy.data.passed+1
+   setwd(base.folder)
+   data.source<-as.matrix(read.csv(paste("Generats/",gens.names[gend.data],".csv", sep = ""), sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   datasource<-gens.names[gend.data,1]
+   setwd(cpout.folder)
+   missingdatas=c("ignore")
+   for(missingdata in missingdatas){
+     withextras=c("none")
+     for(withextra in withextras){
+       ################data wrestling###############
+       
+       dependant.selection=complete.cases(data.source[,column.to.predict])
+       df.previous.calcs=as.data.frame(read.csv(file=out.file, header = FALSE, sep = ",", quote = "",
+                                                dec = ".", fill = TRUE, comment.char = ""))
+       unimportant.computations<-vector(mode = "logical",length=length(df.previous.calcs[,1])  )
+       for(intern in 1:length(df.previous.calcs[,1])){
+         if((any(df.previous.calcs[intern,] == withextra, na.rm=T))&&
+            (any(df.previous.calcs[intern,] == missingdata, na.rm=T))&&
+            (any(df.previous.calcs[intern,] == datasource, na.rm=T))&&
+            (any(df.previous.calcs[intern,] == column.to.predict, na.rm=T)))
+         {unimportant.computations[intern]<-T}}
+       
+       df.previous.calcs<-df.previous.calcs[unimportant.computations,]
+       
+       #data.source=data.frame( data.source[,column.to.predict],data.source[,1:2], data.source[,4:(column.to.predict-1)], data.source[,(column.to.predict+1):length( data.source[1,])])
+       
+         for(norming in normings) {
+         for(trans.y in 1:2) {
+           df.toprocess=data.source
+           y.untransformed<-df.toprocess[,1]
+           
+           if(norming=="centernscale"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("center", "scale"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           if(norming=="range01"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("range"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           if(norming=="expoTrans"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("expoTrans"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           if(norming=="YeoJohnson"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("YeoJohnson"))#"center", "scale",
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           
+           if((norming=="asis")&&(trans.y==2)){next}
+           
+           
+           ################preprocess###########
+           df.toprocess=data.frame(df.toprocess[dependant.selection,])
+           y.untransformed=y.untransformed[dependant.selection]
+           if(norming=="quantile"){
+             for(Clol in trans.y:length(data.source[1,])){
+               df.toprocess[,Clol]<- (rank(df.toprocess[,Clol],na.last = "keep",ties.method = "average")-1) }
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("range"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           
+           loess.model<-loess(y.untransformed~ df.toprocess[,1],span = 0.21, degree = 1)
+   
+           #df.toprocess = data.frame(df.toprocess,)
+           nzv <- nearZeroVar(df.toprocess[,])#, saveMetrics= TRUE
+           #nzv[nzv$nzv,][1:10,]
+           if(length(nzv)>1){
+             df.toprocess = (df.toprocess[, -nzv])}
+           df.toprocess = signif(df.toprocess,digits = 3)
+           
+           seed.var =222+round(runif(1,min=0,max=100))
+           set.seed(seed.var)
+           inTrain <- createDataPartition(y = df.toprocess[,1],
+                                          p = .75,
+                                          list = FALSE)
+           training <- df.toprocess[ inTrain,]
+           testing  <- df.toprocess[-inTrain,]
+           write.table(df.toprocess,file = "sanity check 1.csv",  quote = F, row.names = F,col.names = F)
+           
+           ###########for all models#################
+           setwd(base.folder)
+           if(max(which.computer==pc.mlr)>0)
+             source("MLR part.R")
+           else
+             source("Caret part.R")
+           
+          setwd(cpout.folder)
+           if(norming == normings[length(normings)]){
+             if(count.toy.data.passed>length(gensTTest)){gensTTest<-c(gensTTesto)}
+             write.table( t(gensTTest[count.toy.data.passed:length(gensTTest)]),file = "tasks to test.csv",  quote = F, sep = ",", row.names = F,col.names = F)
+             
+             }
+           
+         }
+       }
+     }
+   }
+   
+ }
Warning in preProcess.default(df.toprocess[, trans.y:length(df.toprocess[1,  :
  These variables have zero variances: V11, V12
Warning in preProcess.default(df.toprocess[, trans.y:length(df.toprocess[1,  :
  These variables have zero variances: V11, V12
eXtreme Gradient Boosting 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 501, 502 
Resampling results across tuning parameters:

  max_depth  eta         rate_drop   skip_drop   min_child_weight  subsample
   1         0.35710054  0.24702582  0.74278275   8                0.6552438
   2         0.07075847  0.45954870  0.63343225  15                0.7668918
   3         0.07043836  0.31990059  0.85046099  15                0.4166463
   3         0.19180042  0.41274680  0.81948621   7                0.3100309
   3         0.51597559  0.37198434  0.26300969   2                0.7493792
   4         0.16318421  0.28832368  0.20824705  12                0.7000721
   4         0.52399585  0.23132687  0.60467204   0                0.5845326
   4         0.55235016  0.16700947  0.76626503   9                0.9947534
   5         0.11232638  0.45315698  0.73255355   3                0.9754920
   5         0.17451121  0.29163584  0.26778387  20                0.7526245
   5         0.41219359  0.08822553  0.05355776   0                0.6946752
   6         0.25935152  0.21921198  0.32968113   7                0.3194357
   6         0.42096999  0.20191014  0.24918405  11                0.4160672
   6         0.44296073  0.01272761  0.33283959  19                0.7281330
   7         0.03847935  0.09137695  0.30658288  10                0.6891222
   8         0.51858291  0.27117090  0.89205386   8                0.9644514
   9         0.19171492  0.05100005  0.41808565  10                0.5249949
   9         0.50945754  0.29681578  0.68927144  11                0.5374232
   9         0.53512064  0.36885042  0.93128964  20                0.6694696
  10         0.44703714  0.35027345  0.82790577  16                0.5973596
  colsample_bytree  gamma      nrounds  RMSE      Rsquared     MAE      
  0.3744563         2.4955695  266      1.093187  0.006028633  0.8556050
  0.4442687         1.0249790  493      1.074434  0.004517716  0.8448747
  0.6125573         6.9589163  142      1.035466  0.004222162  0.8138447
  0.4269539         6.3944422   80      1.055495  0.004615802  0.8298559
  0.4175189         5.5325969  454      1.067716  0.004316341  0.8322373
  0.5726256         8.3356157  833      1.028318  0.004485442  0.8101585
  0.5523745         6.0101686  122      1.125753  0.011349558  0.8840797
  0.5115102         2.4578104  129      1.109068  0.006783359  0.8761318
  0.4128153         3.3346768   51      1.049049  0.003643999  0.8233577
  0.4039819         0.1135171  639      1.104056  0.003605062  0.8740621
  0.4901114         1.7836434  293      1.082120  0.014751740  0.8631640
  0.5765949         5.1331138  196      1.113284  0.004139994  0.8752934
  0.5223517         8.5991670  847      1.069073  0.003450331  0.8571197
  0.4205045         6.1117261  792      1.077962  0.007277370  0.8519540
  0.6847233         8.2176808  413      1.022238  0.001926697  0.8039679
  0.5211406         0.7399643  882      1.187640  0.009582823  0.9433949
  0.6296380         2.2972647  383      1.113834  0.006494774  0.8695684
  0.3256555         3.6786563  285      1.153738  0.003816652  0.9146500
  0.5542213         8.0239327  665      1.126479  0.001413817  0.8968560
  0.5111450         8.7747573  951      1.128916  0.003208577  0.8919129
  Selected
          
          
          
          
          
          
          
          
          
          
          
          
          
          
  *       
          
          
          
          
          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nrounds = 413, max_depth = 7, eta
 = 0.6847233, rate_drop = 0.09137695, skip_drop = 0.3065829
 and min_child_weight = 10.
[1] "Mon Mar 05 07:47:54 2018"
eXtreme Gradient Boosting 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 501, 502 
Resampling results across tuning parameters:

  lambda        alpha         nrounds  eta         RMSE      Rsquared    
  1.795623e-05  1.874473e-03  19       1.00040304  1.123765  0.0012004945
  2.487460e-05  1.626940e-04  32       1.91833266  1.136060  0.0019006339
  4.066070e-05  9.224941e-04  88       1.80305059  1.154771  0.0006113002
  4.406076e-05  6.806098e-04  93       0.73734312  1.148733  0.0010480678
  5.115789e-05  1.962497e-04  12       2.08767490  1.096006  0.0018733233
  9.477400e-05  4.476055e-03  44       1.53993415  1.156729  0.0013858902
  2.114470e-04  1.779397e-05  60       0.74867085  1.145595  0.0021567226
  2.640324e-04  2.019483e-01  85       1.10359689  1.172945  0.0081305327
  2.911033e-04  3.021445e-03  69       0.53509301  1.157178  0.0021213731
  8.178893e-04  2.943442e-01  32       0.68917941  1.128855  0.0004834453
  1.154212e-03  1.494309e-02   7       2.46530424  1.073748  0.0006887664
  1.846029e-03  2.084935e-04  86       1.65977906  1.152496  0.0011155502
  2.893266e-03  8.344113e-05  12       0.30749369  1.095218  0.0011985779
  1.558693e-02  2.346905e-03  29       0.03405514  1.134633  0.0011185807
  2.093131e-02  1.861909e-01  90       2.40717981  1.157947  0.0036785447
  9.018747e-02  8.817757e-03  74       1.83351783  1.172503  0.0012414655
  1.456634e-01  7.200620e-04  28       2.50068471  1.125698  0.0015064337
  1.705307e-01  6.554783e-03  71       2.57975011  1.172221  0.0015924023
  2.554988e-01  5.721171e-02  87       0.22198929  1.164095  0.0024479944
  5.665963e-01  8.955631e-01  75       2.63242720  1.159241  0.0059746039
  MAE        Selected
  0.8727409          
  0.8869220          
  0.8972974          
  0.8898619          
  0.8505338          
  0.9114204          
  0.8928677          
  0.9203380          
  0.9083515          
  0.8882416          
  0.8340873  *       
  0.8965564          
  0.8549997          
  0.8866720          
  0.9080542          
  0.9160963          
  0.8804761          
  0.9155752          
  0.9133565          
  0.9190803          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nrounds = 7, lambda =
 0.001154212, alpha = 0.01494309 and eta = 2.465304.
[1] "Mon Mar 05 07:48:53 2018"
eXtreme Gradient Boosting 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 501, 502 
Resampling results across tuning parameters:

  eta         max_depth  gamma      colsample_bytree  min_child_weight
  0.03847935   7         8.2176808  0.5341985         20              
  0.07043836   3         6.9589163  0.3888780         16              
  0.07075847   2         1.0249790  0.5756756          7              
  0.11232638   5         3.3346768  0.6869291          5              
  0.16318421   4         8.3356157  0.5400385         14              
  0.17451121   5         0.1135171  0.5680664          5              
  0.19171492   9         2.2972647  0.4466639         17              
  0.19180042   3         6.3944422  0.3320165          6              
  0.25935152   6         5.1331138  0.3370324         14              
  0.35710054   1         2.4955695  0.5161300          3              
  0.41219359   5         1.7836434  0.5371601          9              
  0.42096999   6         8.5991670  0.3885692         11              
  0.44296073   6         6.1117261  0.5550043          6              
  0.44703714  10         8.7747573  0.4852585         11              
  0.50945754   9         3.6786563  0.4532924          1              
  0.51597559   3         5.5325969  0.5663356          6              
  0.51858291   8         0.7399643  0.6810408         11              
  0.52399585   4         6.0101686  0.4784174         13              
  0.53512064   9         8.0239327  0.5237171         13              
  0.55235016   4         2.4578104  0.6972018         11              
  subsample  nrounds  RMSE      Rsquared     MAE        Selected
  0.3745566  413      1.028417  0.004023789  0.8079170  *       
  0.7243376  142      1.028662  0.006264403  0.8089671          
  0.9380847  493      1.109480  0.005191854  0.8732993          
  0.9283015   51      1.066182  0.004296229  0.8425689          
  0.6760056  833      1.056593  0.009767560  0.8337003          
  0.6810753  639      1.151573  0.002985276  0.9177515          
  0.3127552  383      1.194656  0.006136076  0.9422504          
  0.8664492   80      1.032111  0.006229675  0.8130295          
  0.5702224  196      1.122931  0.003650326  0.8967597          
  0.6127946  266      1.143035  0.010819757  0.8905037          
  0.3697329  293      1.355456  0.003647640  1.0612157          
  0.5437400  847      1.156185  0.003237024  0.9119948          
  0.2541749  792      1.441494  0.001983641  1.1574537          
  0.7708267  951      1.130219  0.004320770  0.8951713          
  0.6890037  285      1.239127  0.004933246  0.9909061          
  0.8040577  454      1.151572  0.005036623  0.9069576          
  0.6497514  882      1.237894  0.004311961  0.9937980          
  0.5887656  122      1.136193  0.004642503  0.9041995          
  0.7992608  665      1.128197  0.004400962  0.8877238          
  0.4903206  129      1.277820  0.001509341  1.0079768          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nrounds = 413, max_depth = 7, eta
 = 0.03847935, gamma = 8.217681, colsample_bytree = 0.5341985,
 min_child_weight = 20 and subsample = 0.3745566.
[1] "Mon Mar 05 07:53:25 2018"
Self-Organizing Maps 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 501, 502 
Resampling results across tuning parameters:

  xdim  ydim  topo         user.weights  RMSE      Rsquared      MAE      
   2     5    hexagonal    0.41324653    1.013196  0.0089902247  0.7988701
   2     5    rectangular  0.28773101    1.028382  0.0046070399  0.8037010
   2    19    hexagonal    0.05562116    1.090839  0.0010043831  0.8628195
   3    10    hexagonal    0.48148479    1.071183  0.0012008654  0.8444264
   3    13    rectangular  0.07667168    1.067473  0.0045561403  0.8419065
   3    14    hexagonal    0.88438120    1.069697  0.0017364230  0.8411789
   4     4    hexagonal    0.81750724    1.034247  0.0023435535  0.8130224
   4    19    rectangular  0.79669674    1.120272  0.0011768497  0.8946840
   5    17    hexagonal    0.66484241    1.141813  0.0056717687  0.9026931
   6     7    rectangular  0.53592306    1.072155  0.0121607649  0.8470553
   6    18    rectangular  0.67969338    1.197969  0.0011317629  0.9525326
   9    15    hexagonal    0.68394480    1.222925  0.0060847291  0.9697071
  10    14    hexagonal    0.70995878    1.204937  0.0063013752  0.9439695
  10    15    rectangular  0.39607535    1.230082  0.0056527429  0.9850175
  10    19    rectangular  0.28715510    1.299471  0.0013894165  1.0218958
  10    20    hexagonal    0.73062052    1.263395  0.0042088433  1.0146760
  13    20    rectangular  0.14129008    1.351692  0.0021782719  1.0710042
  16    19    rectangular  0.71002419    1.301480  0.0006531887  1.0334324
  17    20    hexagonal    0.90208219    1.269183  0.0024251113  1.0102013
  18    20    rectangular  0.45232901    1.349918  0.0053067175  1.0746304
  Selected
  *       
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were xdim = 2, ydim = 5, user.weights
 = 0.4132465 and topo = hexagonal.
[1] "Mon Mar 05 07:54:18 2018"
Fitting Repeat 1 

# weights:  221
initial  value 513.860425 
iter  10 value 489.104868
iter  20 value 485.847184
iter  30 value 436.535577
iter  40 value 412.960252
iter  50 value 406.343552
iter  60 value 400.940550
iter  70 value 396.720289
iter  80 value 394.947320
iter  90 value 390.809973
iter 100 value 386.564131
final  value 386.564131 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  221
initial  value 568.461149 
iter  10 value 489.191038
iter  20 value 469.031713
iter  30 value 424.632747
iter  40 value 414.669344
iter  50 value 406.794913
iter  60 value 392.843769
iter  70 value 389.589879
iter  80 value 387.586719
iter  90 value 384.437031
iter 100 value 381.140135
final  value 381.140135 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  221
initial  value 783.853078 
iter  10 value 489.244283
iter  20 value 458.533900
iter  30 value 430.844287
iter  40 value 420.494414
iter  50 value 416.323230
iter  60 value 413.126171
iter  70 value 403.453736
iter  80 value 395.931344
iter  90 value 385.466205
iter 100 value 381.351859
final  value 381.351859 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  221
initial  value 570.800915 
iter  10 value 489.129501
iter  20 value 461.474449
iter  30 value 421.106840
iter  40 value 400.894920
iter  50 value 395.411815
iter  60 value 392.727451
iter  70 value 387.739694
iter  80 value 383.066671
iter  90 value 382.097874
iter 100 value 379.259087
final  value 379.259087 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  221
initial  value 660.631841 
iter  10 value 484.651820
iter  20 value 447.539038
iter  30 value 406.377781
iter  40 value 397.213621
iter  50 value 387.190807
iter  60 value 376.773863
iter  70 value 374.282386
iter  80 value 371.074625
iter  90 value 367.886014
iter 100 value 365.081349
final  value 365.081349 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 567.954781 
iter  10 value 469.512095
iter  20 value 391.572946
iter  30 value 364.071474
iter  40 value 346.639278
iter  50 value 341.223272
iter  60 value 337.171259
iter  70 value 334.071544
iter  80 value 333.026997
iter  90 value 332.500514
iter 100 value 330.896750
final  value 330.896750 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 716.940990 
iter  10 value 470.488151
iter  20 value 433.922249
iter  30 value 426.545328
iter  40 value 421.738920
iter  50 value 415.248857
iter  60 value 403.469565
iter  70 value 397.116108
iter  80 value 394.329609
iter  90 value 389.254508
iter 100 value 379.118357
final  value 379.118357 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 629.700942 
iter  10 value 447.786942
iter  20 value 395.602083
iter  30 value 381.842143
iter  40 value 374.786229
iter  50 value 369.553495
iter  60 value 358.872017
iter  70 value 356.165730
iter  80 value 353.567560
iter  90 value 352.618064
iter 100 value 351.745377
final  value 351.745377 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 612.913599 
iter  10 value 584.920449
iter  20 value 486.509634
iter  30 value 452.078397
iter  40 value 433.995284
iter  50 value 425.086983
iter  60 value 417.474395
iter  70 value 414.632880
iter  80 value 409.945051
iter  90 value 408.337296
iter 100 value 407.330434
final  value 407.330434 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 717.562629 
iter  10 value 507.581460
iter  20 value 462.371411
iter  30 value 427.911563
iter  40 value 408.180887
iter  50 value 400.803774
iter  60 value 393.798357
iter  70 value 385.612081
iter  80 value 381.859941
iter  90 value 379.802850
iter 100 value 379.013357
final  value 379.013357 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 792.815875 
iter  10 value 494.260867
iter  20 value 493.598185
final  value 493.597640 
converged
Fitting Repeat 2 

# weights:  122
initial  value 604.754357 
iter  10 value 493.765040
iter  20 value 493.598129
final  value 493.597637 
converged
Fitting Repeat 3 

# weights:  122
initial  value 742.043302 
iter  10 value 494.722429
iter  20 value 493.598146
final  value 493.597638 
converged
Fitting Repeat 4 

# weights:  122
initial  value 615.392719 
iter  10 value 493.833119
iter  20 value 493.598001
final  value 493.597638 
converged
Fitting Repeat 5 

# weights:  122
initial  value 649.282079 
iter  10 value 494.258452
iter  20 value 493.597997
final  value 493.597638 
converged
Fitting Repeat 1 

# weights:  45
initial  value 631.155778 
iter  10 value 489.150936
final  value 489.022787 
converged
Fitting Repeat 2 

# weights:  45
initial  value 573.141218 
iter  10 value 489.094769
iter  20 value 489.021090
iter  30 value 489.020889
iter  40 value 489.020642
iter  50 value 489.020325
iter  60 value 489.019901
iter  70 value 489.019297
iter  80 value 489.018357
iter  90 value 489.016697
iter 100 value 489.013065
final  value 489.013065 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  45
initial  value 520.685906 
iter  10 value 489.037094
iter  20 value 489.020691
iter  30 value 489.020491
iter  40 value 489.020246
iter  50 value 489.019935
iter  60 value 489.019525
iter  70 value 489.018955
iter  80 value 489.018103
iter  90 value 489.016688
iter 100 value 489.013910
final  value 489.013910 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  45
initial  value 524.550908 
iter  10 value 489.044331
iter  20 value 489.006250
iter  30 value 488.922896
iter  40 value 463.700908
iter  50 value 448.083292
iter  60 value 445.669819
iter  70 value 445.410050
iter  80 value 444.976581
iter  90 value 444.467405
iter 100 value 444.219068
final  value 444.219068 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  45
initial  value 594.072273 
iter  10 value 489.114404
iter  20 value 487.729422
iter  30 value 453.751562
iter  40 value 448.425549
iter  50 value 448.113526
iter  60 value 447.914642
iter  70 value 446.821799
iter  80 value 446.358182
iter  90 value 445.705104
iter 100 value 445.518682
final  value 445.518682 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  166
initial  value 711.254807 
iter  10 value 443.019558
iter  20 value 432.200887
iter  30 value 428.753325
iter  40 value 428.558170
iter  50 value 428.525139
iter  60 value 428.524118
iter  60 value 428.524114
iter  60 value 428.524114
final  value 428.524114 
converged
Fitting Repeat 2 

# weights:  166
initial  value 667.494523 
iter  10 value 499.112690
iter  20 value 495.887449
iter  30 value 495.678935
iter  40 value 495.654574
final  value 495.654229 
converged
Fitting Repeat 3 

# weights:  166
initial  value 574.939056 
iter  10 value 481.315458
iter  20 value 478.598476
iter  30 value 478.413117
iter  40 value 478.406708
final  value 478.406653 
converged
Fitting Repeat 4 

# weights:  166
initial  value 531.375256 
iter  10 value 485.936763
iter  20 value 481.579186
iter  30 value 481.049056
iter  40 value 481.037761
final  value 481.037572 
converged
Fitting Repeat 5 

# weights:  166
initial  value 628.440070 
iter  10 value 473.429931
iter  20 value 467.819961
iter  30 value 467.638111
iter  40 value 467.617112
iter  50 value 467.600387
final  value 467.599556 
converged
Fitting Repeat 1 

# weights:  122
initial  value 447.864237 
iter  10 value 438.761732
iter  20 value 438.641054
iter  30 value 438.638022
iter  40 value 438.632269
iter  50 value 438.612253
iter  60 value 425.763954
iter  70 value 375.389800
iter  80 value 368.165102
iter  90 value 364.916661
iter 100 value 359.875377
final  value 359.875377 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 578.413900 
iter  10 value 501.072549
iter  20 value 499.461415
iter  30 value 454.486205
iter  40 value 414.514517
iter  50 value 402.865770
iter  60 value 394.259431
iter  70 value 393.049270
iter  80 value 391.989867
iter  90 value 383.475228
iter 100 value 376.139799
final  value 376.139799 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 587.492791 
iter  10 value 551.430271
iter  20 value 550.971251
iter  30 value 550.958793
iter  40 value 539.203647
iter  50 value 480.169860
iter  60 value 461.061136
iter  70 value 455.903966
iter  80 value 455.017726
iter  90 value 454.665392
iter 100 value 448.497119
final  value 448.497119 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 823.355426 
iter  10 value 492.217584
iter  20 value 490.907709
iter  30 value 466.132511
iter  40 value 427.247600
iter  50 value 416.034213
iter  60 value 413.646361
iter  70 value 407.684975
iter  80 value 404.421941
iter  90 value 403.719896
iter 100 value 403.431957
final  value 403.431957 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 625.279794 
iter  10 value 494.275291
iter  20 value 492.388126
iter  30 value 492.386636
iter  40 value 492.384699
iter  50 value 492.381824
iter  60 value 492.376333
iter  70 value 492.355612
iter  80 value 477.673058
iter  90 value 444.207704
iter 100 value 438.090030
final  value 438.090030 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  221
initial  value 604.779819 
iter  10 value 478.536780
iter  20 value 477.450625
iter  30 value 476.774600
iter  40 value 424.930378
iter  50 value 404.220407
iter  60 value 393.241105
iter  70 value 390.767922
iter  80 value 383.248481
iter  90 value 377.900445
iter 100 value 375.987273
final  value 375.987273 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  221
initial  value 618.782953 
iter  10 value 521.090820
iter  20 value 519.951237
iter  30 value 519.945130
iter  40 value 519.944688
iter  50 value 519.944126
iter  60 value 519.943365
iter  70 value 519.942233
iter  80 value 519.940282
iter  90 value 519.935855
iter 100 value 519.914872
final  value 519.914872 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  221
initial  value 863.489970 
iter  10 value 501.225722
iter  20 value 500.354640
iter  30 value 500.346474
iter  40 value 500.338937
iter  50 value 499.984650
iter  60 value 469.685373
iter  70 value 457.780257
iter  80 value 451.397838
iter  90 value 449.360836
iter 100 value 446.458904
final  value 446.458904 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  221
initial  value 609.859783 
iter  10 value 529.874273
iter  20 value 528.943708
iter  30 value 521.735284
iter  40 value 475.409669
iter  50 value 472.726294
iter  60 value 470.685636
iter  70 value 469.290913
iter  80 value 467.797389
iter  90 value 466.181475
iter 100 value 463.791758
final  value 463.791758 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  221
initial  value 699.706854 
iter  10 value 520.496894
iter  20 value 518.677461
iter  30 value 518.658872
iter  40 value 518.654087
iter  50 value 518.620685
iter  60 value 485.801126
iter  70 value 462.812918
iter  80 value 456.553004
iter  90 value 450.194632
iter 100 value 445.853475
final  value 445.853475 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  100
initial  value 559.973906 
iter  10 value 483.471039
iter  20 value 455.239147
iter  30 value 447.323642
iter  40 value 438.402718
iter  50 value 436.000075
iter  60 value 433.442088
iter  70 value 431.517765
iter  80 value 427.344425
iter  90 value 424.368130
iter 100 value 423.233720
final  value 423.233720 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  100
initial  value 549.392985 
iter  10 value 478.271312
iter  20 value 455.046022
iter  30 value 445.887945
iter  40 value 442.286956
iter  50 value 440.467575
iter  60 value 438.935905
iter  70 value 438.220642
iter  80 value 437.417012
iter  90 value 433.276738
iter 100 value 430.675728
final  value 430.675728 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  100
initial  value 529.687567 
iter  10 value 485.236850
iter  20 value 462.222141
iter  30 value 445.885041
iter  40 value 436.329146
iter  50 value 429.719681
iter  60 value 427.050240
iter  70 value 424.888641
iter  80 value 423.480932
iter  90 value 422.013895
iter 100 value 418.630326
final  value 418.630326 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  100
initial  value 556.843818 
iter  10 value 487.597764
iter  20 value 459.607647
iter  30 value 439.952682
iter  40 value 428.833492
iter  50 value 426.246078
iter  60 value 425.210009
iter  70 value 425.113353
iter  80 value 425.082631
iter  90 value 425.042898
iter 100 value 425.008370
final  value 425.008370 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  100
initial  value 655.239656 
iter  10 value 485.889021
iter  20 value 458.178807
iter  30 value 444.314544
iter  40 value 437.673663
iter  50 value 435.675725
iter  60 value 430.059066
iter  70 value 423.743138
iter  80 value 422.657986
iter  90 value 422.447230
iter 100 value 421.808975
final  value 421.808975 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  12
initial  value 576.743968 
iter  10 value 452.024996
iter  20 value 451.531659
iter  30 value 435.291293
iter  40 value 422.810248
iter  50 value 422.453402
final  value 422.453300 
converged
Fitting Repeat 2 

# weights:  12
initial  value 472.760729 
iter  10 value 420.951966
iter  20 value 398.466980
iter  30 value 397.795820
final  value 397.788859 
converged
Fitting Repeat 3 

# weights:  12
initial  value 572.096580 
iter  10 value 483.768879
iter  20 value 471.324225
iter  30 value 469.570707
final  value 469.558160 
converged
Fitting Repeat 4 

# weights:  12
initial  value 541.767307 
iter  10 value 473.285478
iter  20 value 456.765137
iter  30 value 444.923349
iter  40 value 443.031809
iter  50 value 442.933941
iter  50 value 442.933938
iter  50 value 442.933938
final  value 442.933938 
converged
Fitting Repeat 5 

# weights:  12
initial  value 534.931185 
iter  10 value 479.875254
iter  20 value 465.429084
iter  30 value 461.523971
final  value 461.487753 
converged
Fitting Repeat 1 

# weights:  89
initial  value 646.911692 
iter  10 value 472.610370
iter  20 value 472.028390
final  value 472.027258 
converged
Fitting Repeat 2 

# weights:  89
initial  value 664.023663 
iter  10 value 537.339583
iter  20 value 536.853293
final  value 536.853099 
converged
Fitting Repeat 3 

# weights:  89
initial  value 689.096277 
iter  10 value 510.376600
iter  20 value 509.828489
final  value 509.827859 
converged
Fitting Repeat 4 

# weights:  89
initial  value 613.010866 
iter  10 value 512.774370
iter  20 value 512.419983
final  value 512.419367 
converged
Fitting Repeat 5 

# weights:  89
initial  value 584.443270 
iter  10 value 488.677229
iter  20 value 488.586565
final  value 488.586426 
converged
Fitting Repeat 1 

# weights:  56
initial  value 496.341827 
iter  10 value 464.980520
iter  20 value 419.222736
iter  30 value 409.482857
iter  40 value 401.671477
iter  50 value 393.149841
iter  60 value 386.257350
iter  70 value 384.257464
iter  80 value 384.007295
iter  90 value 383.620588
iter 100 value 383.603214
final  value 383.603214 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  56
initial  value 694.912059 
iter  10 value 438.220781
iter  20 value 395.897691
iter  30 value 377.750319
iter  40 value 371.280019
iter  50 value 364.896195
iter  60 value 361.009763
iter  70 value 358.613636
iter  80 value 357.352617
iter  90 value 355.900594
iter 100 value 355.043856
final  value 355.043856 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  56
initial  value 734.642937 
iter  10 value 424.407325
iter  20 value 397.664376
iter  30 value 379.722733
iter  40 value 367.869890
iter  50 value 365.059462
iter  60 value 361.099057
iter  70 value 356.372535
iter  80 value 353.362950
iter  90 value 352.669380
iter 100 value 352.357656
final  value 352.357656 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  56
initial  value 652.717481 
iter  10 value 463.208406
iter  20 value 417.210082
iter  30 value 408.477793
iter  40 value 406.859888
iter  50 value 404.640408
iter  60 value 403.735307
iter  70 value 403.626107
iter  80 value 403.621670
final  value 403.621566 
converged
Fitting Repeat 5 

# weights:  56
initial  value 612.678058 
iter  10 value 531.247195
iter  20 value 471.912708
iter  30 value 454.467723
iter  40 value 446.119325
iter  50 value 439.490947
iter  60 value 436.698950
iter  70 value 433.435563
iter  80 value 431.042103
iter  90 value 430.113932
iter 100 value 429.899139
final  value 429.899139 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  144
initial  value 633.365997 
iter  10 value 499.398560
iter  20 value 458.809550
iter  30 value 441.525308
iter  40 value 433.983067
iter  50 value 425.961494
iter  60 value 416.195849
iter  70 value 400.558967
iter  80 value 394.357356
iter  90 value 390.591406
iter 100 value 388.679865
final  value 388.679865 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  144
initial  value 596.482568 
iter  10 value 421.834534
iter  20 value 382.177928
iter  30 value 368.792453
iter  40 value 362.744999
iter  50 value 350.329351
iter  60 value 344.332793
iter  70 value 343.774646
iter  80 value 343.005810
iter  90 value 342.120240
iter 100 value 341.489046
final  value 341.489046 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  144
initial  value 624.911042 
iter  10 value 457.890550
iter  20 value 436.207310
iter  30 value 426.707324
iter  40 value 415.792165
iter  50 value 412.655555
iter  60 value 405.387387
iter  70 value 396.865307
iter  80 value 388.235414
iter  90 value 384.553264
iter 100 value 378.751712
final  value 378.751712 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  144
initial  value 631.924201 
iter  10 value 511.517452
iter  20 value 471.290408
iter  30 value 455.738927
iter  40 value 447.391889
iter  50 value 441.894065
iter  60 value 438.898248
iter  70 value 426.937726
iter  80 value 416.842325
iter  90 value 414.926273
iter 100 value 414.345121
final  value 414.345121 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  144
initial  value 592.956808 
iter  10 value 522.481286
iter  20 value 498.604450
iter  30 value 488.370508
iter  40 value 478.169969
iter  50 value 463.368223
iter  60 value 454.742284
iter  70 value 451.078379
iter  80 value 442.844707
iter  90 value 434.188315
iter 100 value 432.420025
final  value 432.420025 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  133
initial  value 599.952069 
iter  10 value 493.035507
iter  20 value 489.060512
iter  30 value 488.946439
iter  40 value 471.298625
iter  50 value 442.960561
iter  60 value 428.471825
iter  70 value 423.157694
iter  80 value 414.165797
iter  90 value 404.739607
iter 100 value 400.298705
final  value 400.298705 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  133
initial  value 541.531721 
iter  10 value 490.590363
iter  20 value 489.055550
iter  30 value 489.047934
iter  40 value 489.028296
iter  50 value 486.182133
iter  60 value 455.124334
iter  70 value 442.189203
iter  80 value 435.802450
iter  90 value 431.978054
iter 100 value 427.795571
final  value 427.795571 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  133
initial  value 493.095596 
iter  10 value 489.125472
iter  20 value 489.039409
iter  30 value 488.836909
iter  40 value 454.699136
iter  50 value 442.051047
iter  60 value 434.059009
iter  70 value 429.223480
iter  80 value 424.229046
iter  90 value 421.217273
iter 100 value 418.803662
final  value 418.803662 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  133
initial  value 562.797809 
iter  10 value 491.366886
iter  20 value 489.051486
iter  30 value 489.039212
iter  40 value 488.926455
iter  50 value 462.613354
iter  60 value 438.471650
iter  70 value 435.772855
iter  80 value 433.479289
iter  90 value 432.409096
iter 100 value 428.670087
final  value 428.670087 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  133
initial  value 612.255502 
iter  10 value 489.641330
iter  20 value 489.036819
iter  30 value 457.413082
iter  40 value 434.070691
iter  50 value 429.538520
iter  60 value 424.984687
iter  70 value 417.113512
iter  80 value 412.537351
iter  90 value 407.556314
iter 100 value 404.443812
final  value 404.443812 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  34
initial  value 605.933754 
iter  10 value 531.915612
iter  20 value 502.472850
iter  30 value 491.181580
iter  40 value 483.534834
iter  50 value 481.334175
iter  60 value 481.271102
final  value 481.270694 
converged
Fitting Repeat 2 

# weights:  34
initial  value 588.231905 
iter  10 value 495.137148
iter  20 value 486.613460
iter  30 value 481.592615
iter  40 value 478.787623
iter  50 value 477.911280
iter  60 value 475.735795
iter  70 value 471.917972
iter  80 value 471.722641
iter  90 value 471.671396
iter 100 value 471.335330
final  value 471.335330 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  34
initial  value 714.064707 
iter  10 value 512.566445
iter  20 value 481.808282
iter  30 value 472.146338
iter  40 value 471.070189
iter  50 value 471.022680
final  value 471.022583 
converged
Fitting Repeat 4 

# weights:  34
initial  value 620.494602 
iter  10 value 547.480458
iter  20 value 528.111189
iter  30 value 524.465029
iter  40 value 522.943302
iter  50 value 522.629633
iter  60 value 520.670507
iter  70 value 518.777000
iter  80 value 517.249671
iter  90 value 516.114004
iter 100 value 515.756506
final  value 515.756506 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  34
initial  value 654.513774 
iter  10 value 423.987561
iter  20 value 407.265988
iter  30 value 403.111669
iter  40 value 400.547126
iter  50 value 399.332787
iter  60 value 397.722060
iter  70 value 396.980030
iter  80 value 395.423129
iter  90 value 393.383819
iter 100 value 393.298895
final  value 393.298895 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  78
initial  value 538.198030 
iter  10 value 483.302699
iter  20 value 447.568274
iter  30 value 436.887574
iter  40 value 424.671896
iter  50 value 415.364276
iter  60 value 412.245984
iter  70 value 411.484114
iter  80 value 411.297762
iter  90 value 410.585800
iter 100 value 407.836004
final  value 407.836004 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  78
initial  value 646.115247 
iter  10 value 488.036600
iter  20 value 456.717390
iter  30 value 428.294260
iter  40 value 416.349272
iter  50 value 407.115129
iter  60 value 402.241705
iter  70 value 401.047287
iter  80 value 399.870725
iter  90 value 399.350608
iter 100 value 399.099151
final  value 399.099151 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  78
initial  value 592.934261 
iter  10 value 485.297955
iter  20 value 447.295614
iter  30 value 413.558603
iter  40 value 400.400174
iter  50 value 395.940560
iter  60 value 392.941115
iter  70 value 392.202195
iter  80 value 392.057855
iter  90 value 392.016907
iter 100 value 392.001704
final  value 392.001704 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  78
initial  value 707.370582 
iter  10 value 481.071767
iter  20 value 450.673805
iter  30 value 429.570894
iter  40 value 420.651190
iter  50 value 417.259206
iter  60 value 408.981532
iter  70 value 404.132284
iter  80 value 402.728968
iter  90 value 400.399317
iter 100 value 399.120965
final  value 399.120965 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  78
initial  value 638.672402 
iter  10 value 489.149526
iter  20 value 452.701005
iter  30 value 433.864931
iter  40 value 428.051734
iter  50 value 425.381337
iter  60 value 422.836337
iter  70 value 421.156579
iter  80 value 418.758074
iter  90 value 417.429324
iter 100 value 415.310298
final  value 415.310298 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  78
initial  value 643.218917 
iter  10 value 479.949964
iter  20 value 449.430310
iter  30 value 434.250219
iter  40 value 423.688245
iter  50 value 414.975670
iter  60 value 411.335797
iter  70 value 409.943545
iter  80 value 408.362815
iter  90 value 408.053683
iter 100 value 407.897538
final  value 407.897538 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  78
initial  value 689.922972 
iter  10 value 464.219483
iter  20 value 443.222180
iter  30 value 436.139624
iter  40 value 420.432309
iter  50 value 411.239615
iter  60 value 409.129864
iter  70 value 407.874348
iter  80 value 407.005286
iter  90 value 405.861957
iter 100 value 405.561912
final  value 405.561912 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  78
initial  value 564.464587 
iter  10 value 475.210514
iter  20 value 456.707267
iter  30 value 436.192279
iter  40 value 426.794834
iter  50 value 423.457617
iter  60 value 419.784090
iter  70 value 417.484886
iter  80 value 416.851986
iter  90 value 414.170523
iter 100 value 411.624356
final  value 411.624356 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  78
initial  value 502.689133 
iter  10 value 483.549661
iter  20 value 454.271737
iter  30 value 436.689308
iter  40 value 432.352052
iter  50 value 426.283391
iter  60 value 423.952927
iter  70 value 420.615668
iter  80 value 415.914189
iter  90 value 413.104984
iter 100 value 410.313760
final  value 410.313760 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  78
initial  value 645.257720 
iter  10 value 481.694273
iter  20 value 452.613538
iter  30 value 436.018372
iter  40 value 427.024294
iter  50 value 420.136102
iter  60 value 417.307337
iter  70 value 416.252256
iter  80 value 415.518490
iter  90 value 415.380625
iter 100 value 415.343405
final  value 415.343405 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  177
initial  value 533.115402 
iter  10 value 488.339999
iter  20 value 484.771311
iter  30 value 484.485905
iter  40 value 484.324992
iter  50 value 484.310385
final  value 484.310249 
converged
Fitting Repeat 2 

# weights:  177
initial  value 547.302090 
iter  10 value 487.500205
iter  20 value 484.825495
iter  30 value 484.406298
iter  40 value 484.360758
iter  50 value 484.351172
iter  60 value 484.347697
iter  60 value 484.347693
iter  60 value 484.347693
final  value 484.347693 
converged
Fitting Repeat 3 

# weights:  177
initial  value 550.954926 
iter  10 value 487.368239
iter  20 value 484.607840
iter  30 value 484.386654
iter  40 value 484.324110
iter  50 value 484.310526
final  value 484.310248 
converged
Fitting Repeat 4 

# weights:  177
initial  value 509.933801 
iter  10 value 485.302749
iter  20 value 484.420771
iter  30 value 484.332628
iter  40 value 484.310396
final  value 484.310249 
converged
Fitting Repeat 5 

# weights:  177
initial  value 629.767045 
iter  10 value 492.988647
iter  20 value 485.980307
iter  30 value 484.646371
iter  40 value 484.371437
iter  50 value 484.351597
iter  60 value 484.347823
final  value 484.347687 
converged
Fitting Repeat 1 

# weights:  89
initial  value 619.489469 
iter  10 value 489.087537
final  value 489.019063 
converged
Fitting Repeat 2 

# weights:  89
initial  value 643.992223 
iter  10 value 489.088786
final  value 489.019136 
converged
Fitting Repeat 3 

# weights:  89
initial  value 553.461552 
iter  10 value 489.053286
iter  20 value 489.016904
iter  30 value 489.016476
iter  40 value 489.015885
iter  50 value 489.014987
iter  60 value 489.013424
iter  70 value 489.009990
iter  80 value 488.997247
iter  90 value 487.845909
iter 100 value 447.824869
final  value 447.824869 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  89
initial  value 555.091041 
iter  10 value 489.050105
iter  20 value 488.291913
iter  30 value 449.006429
iter  40 value 437.321487
iter  50 value 436.929443
iter  60 value 436.786625
iter  70 value 436.260862
iter  80 value 436.171054
iter  90 value 436.099682
iter 100 value 435.428218
final  value 435.428218 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  89
initial  value 522.756473 
iter  10 value 489.031316
iter  20 value 488.972011
iter  30 value 471.464551
iter  40 value 442.596691
iter  50 value 439.235034
iter  60 value 438.913561
iter  70 value 437.722839
iter  80 value 437.008757
iter  90 value 436.876730
iter 100 value 436.612628
final  value 436.612628 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 765.829946 
iter  10 value 491.230883
iter  20 value 490.297708
iter  30 value 490.295815
iter  30 value 490.295811
iter  30 value 490.295811
final  value 490.295811 
converged
Fitting Repeat 2 

# weights:  122
initial  value 590.832964 
iter  10 value 490.656847
iter  20 value 490.298731
iter  30 value 490.295817
final  value 490.295809 
converged
Fitting Repeat 3 

# weights:  122
initial  value 627.266814 
iter  10 value 490.831680
iter  20 value 490.302158
iter  30 value 490.295825
iter  30 value 490.295824
iter  30 value 490.295824
final  value 490.295824 
converged
Fitting Repeat 4 

# weights:  122
initial  value 786.561204 
iter  10 value 491.252151
iter  20 value 490.301018
final  value 490.295960 
converged
Fitting Repeat 5 

# weights:  122
initial  value 534.487470 
iter  10 value 490.478750
iter  20 value 490.296255
final  value 490.295974 
converged
Fitting Repeat 1 

# weights:  221
initial  value 801.167794 
iter  10 value 489.256378
iter  20 value 489.019875
iter  30 value 489.018107
iter  40 value 489.017940
iter  50 value 489.017733
iter  60 value 489.017469
iter  70 value 489.017121
iter  80 value 489.016637
iter  90 value 489.015912
iter 100 value 489.014703
final  value 489.014703 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  221
initial  value 531.991835 
iter  10 value 489.113047
iter  20 value 488.096983
iter  30 value 466.515599
iter  40 value 435.884181
iter  50 value 434.191612
iter  60 value 432.826585
iter  70 value 429.693037
iter  80 value 425.934758
iter  90 value 422.691208
iter 100 value 422.156305
final  value 422.156305 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  221
initial  value 616.281373 
iter  10 value 489.298821
iter  20 value 489.020422
iter  30 value 489.017903
iter  40 value 489.017696
iter  50 value 489.017431
iter  60 value 489.017078
iter  70 value 489.016584
iter  80 value 489.015839
iter  90 value 489.014579
iter 100 value 489.011998
final  value 489.011998 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  221
initial  value 526.466711 
iter  10 value 489.073418
final  value 489.019536 
converged
Fitting Repeat 5 

# weights:  221
initial  value 572.973760 
iter  10 value 489.209757
iter  20 value 489.019222
iter  20 value 489.019219
final  value 489.019219 
converged
Fitting Repeat 1 

# weights:  221
initial  value 638.168779 
iter  10 value 500.927520
iter  20 value 451.340318
iter  30 value 406.853371
iter  40 value 379.461113
iter  50 value 367.128723
iter  60 value 361.052300
iter  70 value 358.043280
iter  80 value 356.334642
iter  90 value 354.895772
iter 100 value 354.037381
final  value 354.037381 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  221
initial  value 694.338410 
iter  10 value 502.252312
iter  20 value 460.484121
iter  30 value 423.140083
iter  40 value 417.392599
iter  50 value 413.853427
iter  60 value 410.122619
iter  70 value 405.844320
iter  80 value 395.073462
iter  90 value 384.651987
iter 100 value 380.629282
final  value 380.629282 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  221
initial  value 726.939545 
iter  10 value 501.815145
iter  20 value 457.252990
iter  30 value 438.000202
iter  40 value 423.456228
iter  50 value 390.307314
iter  60 value 374.188641
iter  70 value 368.442136
iter  80 value 364.543252
iter  90 value 363.030459
iter 100 value 361.088403
final  value 361.088403 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  221
initial  value 701.967394 
iter  10 value 500.523932
iter  20 value 455.984594
iter  30 value 425.537853
iter  40 value 407.548497
iter  50 value 392.247608
iter  60 value 386.027290
iter  70 value 381.200220
iter  80 value 376.719957
iter  90 value 374.725237
iter 100 value 373.741197
final  value 373.741197 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  221
initial  value 616.475715 
iter  10 value 502.580635
iter  20 value 470.710752
iter  30 value 448.403193
iter  40 value 440.075706
iter  50 value 427.365955
iter  60 value 419.292506
iter  70 value 409.383411
iter  80 value 404.141738
iter  90 value 400.624037
iter 100 value 396.305326
final  value 396.305326 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 647.011809 
iter  10 value 459.790399
iter  20 value 428.178127
iter  30 value 412.478107
iter  40 value 398.216436
iter  50 value 379.149475
iter  60 value 374.917221
iter  70 value 369.038117
iter  80 value 365.319782
iter  90 value 362.510553
iter 100 value 356.925184
final  value 356.925184 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 706.556394 
iter  10 value 482.339544
iter  20 value 419.853665
iter  30 value 401.693115
iter  40 value 386.565104
iter  50 value 381.081300
iter  60 value 374.746237
iter  70 value 369.444269
iter  80 value 366.748957
iter  90 value 364.055453
iter 100 value 361.212378
final  value 361.212378 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 739.648047 
iter  10 value 484.644512
iter  20 value 458.011444
iter  30 value 432.947646
iter  40 value 425.364838
iter  50 value 420.290272
iter  60 value 414.683470
iter  70 value 412.551094
iter  80 value 407.057389
iter  90 value 399.063383
iter 100 value 381.442204
final  value 381.442204 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 637.965622 
iter  10 value 449.089521
iter  20 value 415.073523
iter  30 value 394.119977
iter  40 value 380.076982
iter  50 value 373.460524
iter  60 value 363.542841
iter  70 value 350.756190
iter  80 value 329.781986
iter  90 value 321.514369
iter 100 value 316.002013
final  value 316.002013 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 614.802653 
iter  10 value 483.048496
iter  20 value 450.795179
iter  30 value 436.729896
iter  40 value 431.318191
iter  50 value 427.764213
iter  60 value 423.966262
iter  70 value 417.263942
iter  80 value 410.835862
iter  90 value 395.495406
iter 100 value 389.767999
final  value 389.767999 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 712.921145 
iter  10 value 508.784039
iter  20 value 507.385597
final  value 507.383953 
converged
Fitting Repeat 2 

# weights:  122
initial  value 791.730148 
iter  10 value 508.508637
iter  20 value 507.387999
final  value 507.383951 
converged
Fitting Repeat 3 

# weights:  122
initial  value 666.181772 
iter  10 value 508.602278
iter  20 value 507.390035
final  value 507.383952 
converged
Fitting Repeat 4 

# weights:  122
initial  value 616.599844 
iter  10 value 507.456321
iter  20 value 507.384119
final  value 507.383952 
converged
Fitting Repeat 5 

# weights:  122
initial  value 645.689342 
iter  10 value 507.689514
iter  20 value 507.385973
final  value 507.383953 
converged
Fitting Repeat 1 

# weights:  45
initial  value 568.109489 
iter  10 value 502.206930
iter  20 value 502.121855
iter  30 value 492.683596
iter  40 value 461.220386
iter  50 value 451.992745
iter  60 value 449.942708
iter  70 value 449.753784
iter  80 value 449.708245
iter  90 value 447.172845
iter 100 value 445.284694
final  value 445.284694 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  45
initial  value 649.053676 
iter  10 value 502.259808
iter  20 value 502.149447
iter  30 value 502.148710
iter  40 value 502.147583
iter  50 value 502.145564
iter  60 value 502.140838
iter  70 value 502.121474
iter  80 value 501.726122
iter  90 value 469.298960
iter 100 value 445.100866
final  value 445.100866 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  45
initial  value 607.830888 
iter  10 value 502.240927
iter  20 value 501.656321
iter  30 value 464.167026
iter  40 value 456.691268
iter  50 value 455.314982
iter  60 value 453.293669
iter  70 value 453.011040
iter  80 value 451.633081
iter  90 value 451.384410
iter 100 value 451.306689
final  value 451.306689 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  45
initial  value 688.993528 
iter  10 value 502.289777
iter  20 value 500.740005
iter  30 value 468.737687
iter  40 value 462.471355
iter  50 value 461.343879
iter  60 value 460.785572
iter  70 value 459.713248
iter  80 value 459.621751
iter  90 value 459.590314
iter 100 value 459.564643
final  value 459.564643 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  45
initial  value 610.480126 
iter  10 value 502.252575
iter  20 value 502.147200
iter  30 value 502.144601
iter  40 value 502.136837
iter  50 value 502.037653
iter  60 value 481.272052
iter  70 value 455.789021
iter  80 value 447.994158
iter  90 value 445.491841
iter 100 value 445.052574
final  value 445.052574 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  166
initial  value 819.191986 
iter  10 value 456.517422
iter  20 value 449.619696
iter  30 value 449.262152
iter  40 value 449.183945
iter  50 value 449.182569
final  value 449.182551 
converged
Fitting Repeat 2 

# weights:  166
initial  value 566.424064 
iter  10 value 520.649490
iter  20 value 519.315786
final  value 519.292769 
converged
Fitting Repeat 3 

# weights:  166
initial  value 584.715115 
iter  10 value 534.764464
iter  20 value 533.405952
iter  30 value 533.400107
final  value 533.399390 
converged
Fitting Repeat 4 

# weights:  166
initial  value 556.515269 
iter  10 value 511.015368
iter  20 value 509.328474
iter  30 value 509.311081
iter  40 value 509.308696
final  value 509.308654 
converged
Fitting Repeat 5 

# weights:  166
initial  value 784.193748 
iter  10 value 479.256978
iter  20 value 470.208508
iter  30 value 469.846526
iter  40 value 469.688456
iter  50 value 469.679125
iter  60 value 469.674903
final  value 469.674742 
converged
Fitting Repeat 1 

# weights:  122
initial  value 504.863418 
iter  10 value 468.687818
iter  20 value 468.262165
iter  30 value 468.239711
iter  40 value 455.060147
iter  50 value 402.226948
iter  60 value 392.878442
iter  70 value 391.796117
iter  80 value 386.326707
iter  90 value 385.524117
iter 100 value 385.048918
final  value 385.048918 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 517.892894 
iter  10 value 483.693045
iter  20 value 483.303739
iter  30 value 462.363646
iter  40 value 417.229170
iter  50 value 404.629681
iter  60 value 400.848402
iter  70 value 400.293503
iter  80 value 399.764653
iter  90 value 399.514670
iter 100 value 397.479613
final  value 397.479613 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 622.691217 
iter  10 value 461.709758
iter  20 value 459.872273
iter  30 value 459.870172
iter  40 value 459.866586
iter  50 value 459.857494
iter  60 value 459.747234
iter  70 value 418.700037
iter  80 value 401.225475
iter  90 value 396.998644
iter 100 value 393.156431
final  value 393.156431 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 538.880344 
iter  10 value 460.914925
iter  20 value 460.082570
iter  30 value 455.142849
iter  40 value 413.439489
iter  50 value 400.661662
iter  60 value 397.959402
iter  70 value 392.531136
iter  80 value 388.435291
iter  90 value 386.448988
iter 100 value 382.036844
final  value 382.036844 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 635.031733 
iter  10 value 542.536247
iter  20 value 541.487908
iter  30 value 524.460934
iter  40 value 491.426517
iter  50 value 481.105190
iter  60 value 476.714513
iter  70 value 474.364396
iter  80 value 472.062410
iter  90 value 471.072012
iter 100 value 470.615547
final  value 470.615547 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  221
initial  value 564.508384 
iter  10 value 468.670770
iter  20 value 412.297072
iter  30 value 403.521261
iter  40 value 376.924422
iter  50 value 371.028936
iter  60 value 368.438935
iter  70 value 361.982333
iter  80 value 356.895396
iter  90 value 352.348876
iter 100 value 348.395987
final  value 348.395987 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  221
initial  value 838.609917 
iter  10 value 543.587946
iter  20 value 542.194255
iter  30 value 538.595610
iter  40 value 486.305094
iter  50 value 475.826469
iter  60 value 473.374292
iter  70 value 471.430010
iter  80 value 471.051594
iter  90 value 470.896527
iter 100 value 470.778191
final  value 470.778191 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  221
initial  value 901.895939 
iter  10 value 532.847578
iter  20 value 531.682384
iter  30 value 509.074542
iter  40 value 477.469761
iter  50 value 470.572677
iter  60 value 468.436283
iter  70 value 466.541435
iter  80 value 464.111963
iter  90 value 463.193114
iter 100 value 463.104270
final  value 463.104270 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  221
initial  value 520.582245 
iter  10 value 464.851439
iter  20 value 421.977981
iter  30 value 417.509283
iter  40 value 415.500624
iter  50 value 414.868976
iter  60 value 414.180855
iter  70 value 410.740091
iter  80 value 409.630847
iter  90 value 409.330682
iter 100 value 409.113592
final  value 409.113592 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  221
initial  value 644.422510 
iter  10 value 550.036760
iter  20 value 549.029080
iter  30 value 549.021707
iter  40 value 549.018004
iter  50 value 548.999208
iter  60 value 529.682665
iter  70 value 484.695046
iter  80 value 459.134994
iter  90 value 447.658919
iter 100 value 442.054276
final  value 442.054276 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  100
initial  value 566.798614 
iter  10 value 494.109972
iter  20 value 465.557324
iter  30 value 454.877987
iter  40 value 440.712931
iter  50 value 433.603388
iter  60 value 430.394118
iter  70 value 430.058748
iter  80 value 429.956084
iter  90 value 429.942030
iter 100 value 429.940834
final  value 429.940834 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  100
initial  value 714.006680 
iter  10 value 503.617554
iter  20 value 486.489561
iter  30 value 467.478134
iter  40 value 457.046321
iter  50 value 444.316860
iter  60 value 438.015691
iter  70 value 433.315271
iter  80 value 431.652860
iter  90 value 430.825935
iter 100 value 429.006026
final  value 429.006026 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  100
initial  value 589.091431 
iter  10 value 500.088216
iter  20 value 475.978583
iter  30 value 463.135479
iter  40 value 456.088378
iter  50 value 449.779739
iter  60 value 441.860122
iter  70 value 440.261352
iter  80 value 438.576869
iter  90 value 434.690347
iter 100 value 433.719649
final  value 433.719649 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  100
initial  value 748.339849 
iter  10 value 499.185170
iter  20 value 472.805068
iter  30 value 458.978091
iter  40 value 448.512958
iter  50 value 446.023596
iter  60 value 441.303921
iter  70 value 438.856674
iter  80 value 436.584972
iter  90 value 435.535054
iter 100 value 435.415538
final  value 435.415538 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  100
initial  value 643.108382 
iter  10 value 493.160720
iter  20 value 467.721306
iter  30 value 454.326319
iter  40 value 450.105994
iter  50 value 446.327699
iter  60 value 439.231984
iter  70 value 433.893355
iter  80 value 429.042800
iter  90 value 428.239167
iter 100 value 428.203698
final  value 428.203698 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  12
initial  value 615.060894 
iter  10 value 459.743759
iter  20 value 451.127793
iter  30 value 445.355555
iter  40 value 443.559267
final  value 443.482904 
converged
Fitting Repeat 2 

# weights:  12
initial  value 526.315388 
iter  10 value 458.549572
iter  20 value 444.855054
iter  30 value 440.140521
iter  40 value 439.568361
final  value 439.567366 
converged
Fitting Repeat 3 

# weights:  12
initial  value 570.170434 
iter  10 value 505.330731
iter  20 value 481.735921
iter  30 value 463.601626
iter  40 value 460.131372
iter  50 value 459.547546
iter  60 value 459.011597
final  value 459.010407 
converged
Fitting Repeat 4 

# weights:  12
initial  value 667.595501 
iter  10 value 496.224947
iter  20 value 494.631592
iter  30 value 463.695981
iter  40 value 460.503474
iter  50 value 460.490002
final  value 460.489707 
converged
Fitting Repeat 5 

# weights:  12
initial  value 660.298374 
iter  10 value 504.880804
iter  20 value 504.109691
iter  30 value 494.451326
iter  40 value 489.408501
iter  50 value 488.745863
final  value 488.745793 
converged
Fitting Repeat 1 

# weights:  89
initial  value 553.625954 
iter  10 value 502.872007
iter  20 value 502.813227
iter  20 value 502.813226
iter  20 value 502.813225
final  value 502.813225 
converged
Fitting Repeat 2 

# weights:  89
initial  value 658.593783 
iter  10 value 512.465115
iter  20 value 511.935132
final  value 511.934516 
converged
Fitting Repeat 3 

# weights:  89
initial  value 640.301418 
iter  10 value 516.123432
iter  20 value 515.936927
final  value 515.936493 
converged
Fitting Repeat 4 

# weights:  89
initial  value 799.449143 
iter  10 value 548.773021
iter  20 value 548.055960
final  value 548.055445 
converged
Fitting Repeat 5 

# weights:  89
initial  value 730.054917 
iter  10 value 597.475495
iter  20 value 596.474701
final  value 596.460020 
converged
Fitting Repeat 1 

# weights:  56
initial  value 655.894842 
iter  10 value 468.322239
iter  20 value 443.506269
iter  30 value 431.638514
iter  40 value 427.380307
iter  50 value 423.364113
iter  60 value 416.405950
iter  70 value 414.289920
iter  80 value 412.919344
iter  90 value 412.586673
iter 100 value 412.545038
final  value 412.545038 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  56
initial  value 580.515996 
iter  10 value 536.153457
iter  20 value 493.838384
iter  30 value 463.869247
iter  40 value 455.410464
iter  50 value 450.391606
iter  60 value 449.159705
iter  70 value 448.520831
iter  80 value 448.432522
iter  90 value 448.413693
final  value 448.413295 
converged
Fitting Repeat 3 

# weights:  56
initial  value 513.941768 
iter  10 value 461.275218
iter  20 value 421.985313
iter  30 value 412.816217
iter  40 value 405.684972
iter  50 value 392.711911
iter  60 value 387.140178
iter  70 value 384.435382
iter  80 value 380.625108
iter  90 value 378.147352
iter 100 value 376.169354
final  value 376.169354 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  56
initial  value 612.644897 
iter  10 value 445.814214
iter  20 value 416.692035
iter  30 value 408.434806
iter  40 value 389.809262
iter  50 value 379.786465
iter  60 value 375.163820
iter  70 value 372.968715
iter  80 value 372.274091
iter  90 value 371.561793
iter 100 value 371.525831
final  value 371.525831 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  56
initial  value 514.591937 
iter  10 value 460.660588
iter  20 value 422.575356
iter  30 value 406.360199
iter  40 value 395.085645
iter  50 value 387.421324
iter  60 value 383.139348
iter  70 value 380.830755
iter  80 value 379.031731
iter  90 value 378.227452
iter 100 value 377.189095
final  value 377.189095 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  144
initial  value 514.850432 
iter  10 value 477.986965
iter  20 value 460.141882
iter  30 value 443.720875
iter  40 value 422.201169
iter  50 value 405.880641
iter  60 value 398.991284
iter  70 value 393.182745
iter  80 value 391.037232
iter  90 value 389.458066
iter 100 value 388.557273
final  value 388.557273 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  144
initial  value 626.236535 
iter  10 value 541.885194
iter  20 value 506.863790
iter  30 value 490.597901
iter  40 value 483.854648
iter  50 value 474.599647
iter  60 value 461.555065
iter  70 value 449.849202
iter  80 value 441.474762
iter  90 value 434.882812
iter 100 value 432.702098
final  value 432.702098 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  144
initial  value 557.039745 
iter  10 value 508.145094
iter  20 value 463.848341
iter  30 value 437.236123
iter  40 value 421.098392
iter  50 value 409.738687
iter  60 value 405.263940
iter  70 value 403.395956
iter  80 value 402.196387
iter  90 value 400.856190
iter 100 value 399.850456
final  value 399.850456 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  144
initial  value 637.378469 
iter  10 value 530.588558
iter  20 value 499.415812
iter  30 value 482.133904
iter  40 value 458.852638
iter  50 value 448.236899
iter  60 value 443.360544
iter  70 value 439.657626
iter  80 value 437.421113
iter  90 value 434.166876
iter 100 value 432.922878
final  value 432.922878 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  144
initial  value 582.989271 
iter  10 value 497.937539
iter  20 value 467.261570
iter  30 value 448.983064
iter  40 value 426.998870
iter  50 value 409.708608
iter  60 value 400.183798
iter  70 value 397.217860
iter  80 value 393.196073
iter  90 value 390.127713
iter 100 value 388.266338
final  value 388.266338 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  133
initial  value 619.365790 
iter  10 value 502.920237
iter  20 value 488.485217
iter  30 value 447.789448
iter  40 value 435.463489
iter  50 value 427.443903
iter  60 value 416.174792
iter  70 value 413.095085
iter  80 value 401.705227
iter  90 value 395.859670
iter 100 value 393.763177
final  value 393.763177 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  133
initial  value 748.187419 
iter  10 value 502.834863
iter  20 value 486.738732
iter  30 value 455.847438
iter  40 value 444.462051
iter  50 value 441.946511
iter  60 value 434.545898
iter  70 value 431.740938
iter  80 value 426.177386
iter  90 value 424.025738
iter 100 value 420.498797
final  value 420.498797 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  133
initial  value 561.889505 
iter  10 value 504.245663
iter  20 value 502.171168
iter  30 value 502.107688
iter  40 value 483.567223
iter  50 value 446.233537
iter  60 value 432.720460
iter  70 value 422.115948
iter  80 value 416.013877
iter  90 value 411.172761
iter 100 value 406.591530
final  value 406.591530 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  133
initial  value 795.913144 
iter  10 value 506.481646
iter  20 value 502.194634
iter  30 value 482.179687
iter  40 value 448.873829
iter  50 value 444.571987
iter  60 value 438.189085
iter  70 value 422.667207
iter  80 value 418.806941
iter  90 value 417.205182
iter 100 value 416.556186
final  value 416.556186 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  133
initial  value 617.175012 
iter  10 value 506.602862
iter  20 value 502.196476
iter  30 value 491.118605
iter  40 value 460.731266
iter  50 value 447.142108
iter  60 value 439.440463
iter  70 value 437.237287
iter  80 value 435.069873
iter  90 value 434.347797
iter 100 value 430.449393
final  value 430.449393 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  34
initial  value 639.546705 
iter  10 value 508.337337
iter  20 value 489.548914
iter  30 value 469.053234
iter  40 value 462.923335
iter  50 value 460.727756
iter  60 value 458.926079
iter  70 value 458.890135
final  value 458.890127 
converged
Fitting Repeat 2 

# weights:  34
initial  value 648.895198 
iter  10 value 540.118682
iter  20 value 518.199665
iter  30 value 500.199415
iter  40 value 493.558591
iter  50 value 492.541961
iter  60 value 492.422955
final  value 492.421854 
converged
Fitting Repeat 3 

# weights:  34
initial  value 610.628924 
iter  10 value 480.564748
iter  20 value 443.585285
iter  30 value 432.722527
iter  40 value 428.637757
iter  50 value 424.008692
iter  60 value 419.891908
iter  70 value 418.753877
iter  80 value 418.747006
final  value 418.746995 
converged
Fitting Repeat 4 

# weights:  34
initial  value 662.357288 
iter  10 value 525.626970
iter  20 value 501.527318
iter  30 value 488.788654
iter  40 value 484.951413
iter  50 value 484.376849
iter  60 value 484.357760
final  value 484.357691 
converged
Fitting Repeat 5 

# weights:  34
initial  value 722.797761 
iter  10 value 481.335906
iter  20 value 451.649375
iter  30 value 439.296456
iter  40 value 436.838762
iter  50 value 434.939594
iter  60 value 434.612170
final  value 434.609030 
converged
Fitting Repeat 1 

# weights:  78
initial  value 634.854332 
iter  10 value 479.160795
iter  20 value 458.726627
iter  30 value 440.168539
iter  40 value 433.064326
iter  50 value 426.061371
iter  60 value 421.386878
iter  70 value 418.954430
iter  80 value 416.781455
iter  90 value 416.387011
iter 100 value 415.945264
final  value 415.945264 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  78
initial  value 791.967980 
iter  10 value 488.094642
iter  20 value 462.249013
iter  30 value 456.738088
iter  40 value 451.692275
iter  50 value 450.292142
iter  60 value 446.608855
iter  70 value 443.461676
iter  80 value 438.201184
iter  90 value 436.077648
iter 100 value 433.588222
final  value 433.588222 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  78
initial  value 631.516380 
iter  10 value 481.678795
iter  20 value 455.164189
iter  30 value 448.929453
iter  40 value 445.910118
iter  50 value 439.662092
iter  60 value 431.817459
iter  70 value 421.379326
iter  80 value 417.978671
iter  90 value 417.315553
iter 100 value 417.034661
final  value 417.034661 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  78
initial  value 670.583816 
iter  10 value 496.444186
iter  20 value 458.177565
iter  30 value 448.153982
iter  40 value 435.584160
iter  50 value 428.252432
iter  60 value 422.334459
iter  70 value 419.354621
iter  80 value 418.294409
iter  90 value 411.209225
iter 100 value 408.558669
final  value 408.558669 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  78
initial  value 583.933638 
iter  10 value 494.874459
iter  20 value 458.482824
iter  30 value 446.693250
iter  40 value 440.143483
iter  50 value 438.235407
iter  60 value 435.420714
iter  70 value 435.013432
iter  80 value 434.738878
iter  90 value 433.673456
iter 100 value 433.148650
final  value 433.148650 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  78
initial  value 614.135099 
iter  10 value 498.515665
iter  20 value 469.912244
iter  30 value 451.567126
iter  40 value 441.181842
iter  50 value 435.605069
iter  60 value 431.927994
iter  70 value 429.253077
iter  80 value 427.301550
iter  90 value 422.741886
iter 100 value 418.628881
final  value 418.628881 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  78
initial  value 614.925721 
iter  10 value 497.593474
iter  20 value 455.836236
iter  30 value 437.273580
iter  40 value 427.499854
iter  50 value 423.568383
iter  60 value 420.821994
iter  70 value 416.643894
iter  80 value 412.707263
iter  90 value 411.309153
iter 100 value 410.556193
final  value 410.556193 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  78
initial  value 584.238423 
iter  10 value 498.662861
iter  20 value 475.599356
iter  30 value 460.092665
iter  40 value 449.299596
iter  50 value 444.792105
iter  60 value 442.600008
iter  70 value 439.451823
iter  80 value 437.449617
iter  90 value 435.933575
iter 100 value 433.957342
final  value 433.957342 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  78
initial  value 587.493945 
iter  10 value 502.029714
iter  20 value 453.955320
iter  30 value 427.807510
iter  40 value 419.749233
iter  50 value 416.176785
iter  60 value 414.982162
iter  70 value 414.365795
iter  80 value 413.974455
iter  90 value 412.656951
iter 100 value 411.917561
final  value 411.917561 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  78
initial  value 735.111636 
iter  10 value 492.380156
iter  20 value 455.896501
iter  30 value 438.735943
iter  40 value 425.724464
iter  50 value 419.039283
iter  60 value 414.381322
iter  70 value 412.618188
iter  80 value 406.034306
iter  90 value 402.968263
iter 100 value 402.234575
final  value 402.234575 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  177
initial  value 634.792291 
iter  10 value 505.359291
iter  20 value 497.963728
iter  30 value 496.359047
iter  40 value 496.156619
iter  50 value 496.117363
final  value 496.111957 
converged
Fitting Repeat 2 

# weights:  177
initial  value 583.264257 
iter  10 value 505.412411
iter  20 value 497.987859
iter  30 value 496.862585
iter  40 value 496.160507
iter  50 value 496.112165
final  value 496.111962 
converged
Fitting Repeat 3 

# weights:  177
initial  value 539.286896 
iter  10 value 498.782439
iter  20 value 496.265777
iter  30 value 496.120209
iter  40 value 496.111978
final  value 496.111958 
converged
Fitting Repeat 4 

# weights:  177
initial  value 612.945462 
iter  10 value 497.825385
iter  20 value 496.358986
iter  30 value 496.094367
iter  40 value 496.059753
iter  50 value 496.057781
final  value 496.057765 
converged
Fitting Repeat 5 

# weights:  177
initial  value 652.170719 
iter  10 value 506.142661
iter  20 value 498.004539
iter  30 value 497.466184
iter  40 value 496.347661
iter  50 value 496.119963
iter  60 value 496.085990
iter  70 value 496.074389
final  value 496.074335 
converged
Fitting Repeat 1 

# weights:  89
initial  value 605.064765 
iter  10 value 502.216527
iter  20 value 498.113927
iter  30 value 461.058248
iter  40 value 448.667058
iter  50 value 448.063279
iter  60 value 446.614172
iter  70 value 446.066594
iter  80 value 442.095577
iter  90 value 440.294335
iter 100 value 438.796934
final  value 438.796934 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  89
initial  value 726.532485 
iter  10 value 502.225420
iter  20 value 502.007568
iter  30 value 476.733131
iter  40 value 446.706576
iter  50 value 438.523863
iter  60 value 436.847802
iter  70 value 436.563104
iter  80 value 436.469519
iter  90 value 436.384695
iter 100 value 436.063848
final  value 436.063848 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  89
initial  value 698.413942 
iter  10 value 502.230887
iter  20 value 502.144694
iter  30 value 502.142302
iter  40 value 502.135604
iter  50 value 502.057153
iter  60 value 478.403244
iter  70 value 448.369745
iter  80 value 445.372946
iter  90 value 444.595393
iter 100 value 443.612580
final  value 443.612580 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  89
initial  value 628.353944 
iter  10 value 502.206359
final  value 502.147949 
converged
Fitting Repeat 5 

# weights:  89
initial  value 534.531710 
iter  10 value 502.159640
iter  20 value 493.133426
iter  30 value 466.856898
iter  40 value 463.899097
iter  50 value 462.364750
iter  60 value 462.173343
iter  70 value 462.122355
iter  80 value 462.066041
iter  90 value 462.005562
iter 100 value 461.300226
final  value 461.300226 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 701.073926 
iter  10 value 504.540463
iter  20 value 503.751770
iter  30 value 503.723664
final  value 503.723563 
converged
Fitting Repeat 2 

# weights:  122
initial  value 633.655924 
iter  10 value 504.388171
iter  20 value 503.725988
final  value 503.723562 
converged
Fitting Repeat 3 

# weights:  122
initial  value 689.418025 
iter  10 value 504.199220
iter  20 value 503.724987
final  value 503.723571 
converged
Fitting Repeat 4 

# weights:  122
initial  value 605.415296 
iter  10 value 504.065677
iter  20 value 503.725586
final  value 503.723569 
converged
Fitting Repeat 5 

# weights:  122
initial  value 624.927165 
iter  10 value 504.378753
iter  20 value 503.737215
iter  30 value 503.723579
final  value 503.723567 
converged
Fitting Repeat 1 

# weights:  221
initial  value 543.937988 
iter  10 value 502.228683
final  value 502.148682 
converged
Fitting Repeat 2 

# weights:  221
initial  value 639.213123 
iter  10 value 502.500826
iter  20 value 502.150654
iter  30 value 484.749298
iter  40 value 448.435982
iter  50 value 440.718112
iter  60 value 436.329406
iter  70 value 433.962166
iter  80 value 430.917329
iter  90 value 429.840053
iter 100 value 429.647271
final  value 429.647271 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  221
initial  value 588.923102 
iter  10 value 502.382068
iter  20 value 502.149232
iter  30 value 495.609256
iter  40 value 458.648411
iter  50 value 454.284732
iter  60 value 453.192317
iter  70 value 450.756141
iter  80 value 443.066940
iter  90 value 440.073202
iter 100 value 439.291907
final  value 439.291907 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  221
initial  value 680.275989 
iter  10 value 502.513263
iter  20 value 502.150797
iter  30 value 499.027956
iter  40 value 466.208672
iter  50 value 440.894816
iter  60 value 437.240016
iter  70 value 435.843622
iter  80 value 432.145561
iter  90 value 424.087500
iter 100 value 422.492938
final  value 422.492938 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  221
initial  value 632.154339 
iter  10 value 502.544580
iter  20 value 502.151158
iter  30 value 502.144653
iter  40 value 502.141946
iter  50 value 502.132382
iter  60 value 500.419818
iter  70 value 472.274385
iter  80 value 452.210078
iter  90 value 451.324633
iter 100 value 449.982907
final  value 449.982907 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  221
initial  value 525.014469 
iter  10 value 513.812925
iter  20 value 487.354080
iter  30 value 459.587529
iter  40 value 450.885369
iter  50 value 444.368831
iter  60 value 439.943135
iter  70 value 436.522026
iter  80 value 433.064919
iter  90 value 424.759607
iter 100 value 422.520002
final  value 422.520002 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  221
initial  value 570.845477 
iter  10 value 514.999172
iter  20 value 507.518935
iter  30 value 471.208781
iter  40 value 450.652052
iter  50 value 436.523410
iter  60 value 422.005717
iter  70 value 409.361979
iter  80 value 392.974479
iter  90 value 386.891655
iter 100 value 380.436957
final  value 380.436957 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  221
initial  value 549.508468 
iter  10 value 514.986328
iter  20 value 474.583708
iter  30 value 461.273019
iter  40 value 449.300486
iter  50 value 434.900024
iter  60 value 422.672588
iter  70 value 414.660144
iter  80 value 410.741780
iter  90 value 405.912129
iter 100 value 398.839110
final  value 398.839110 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  221
initial  value 609.317894 
iter  10 value 515.099060
iter  20 value 503.317849
iter  30 value 444.486322
iter  40 value 431.633007
iter  50 value 418.986720
iter  60 value 404.754913
iter  70 value 399.073473
iter  80 value 394.959008
iter  90 value 392.829403
iter 100 value 390.140413
final  value 390.140413 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  221
initial  value 765.586926 
iter  10 value 515.051496
iter  20 value 490.482536
iter  30 value 454.078348
iter  40 value 436.918708
iter  50 value 427.360781
iter  60 value 415.854233
iter  70 value 402.392592
iter  80 value 387.036918
iter  90 value 377.583868
iter 100 value 367.048015
final  value 367.048015 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 553.577255 
iter  10 value 512.492229
iter  20 value 452.591608
iter  30 value 430.773815
iter  40 value 421.881872
iter  50 value 412.628584
iter  60 value 407.731602
iter  70 value 399.967919
iter  80 value 394.691845
iter  90 value 393.465086
iter 100 value 390.456666
final  value 390.456666 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 592.372615 
iter  10 value 549.872079
iter  20 value 524.040473
iter  30 value 485.135957
iter  40 value 478.172428
iter  50 value 462.381211
iter  60 value 453.812399
iter  70 value 449.356237
iter  80 value 447.279182
iter  90 value 445.866015
iter 100 value 444.821808
final  value 444.821808 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 558.353374 
iter  10 value 454.357845
iter  20 value 414.270150
iter  30 value 394.367209
iter  40 value 377.486851
iter  50 value 371.023370
iter  60 value 361.725435
iter  70 value 351.418234
iter  80 value 349.286836
iter  90 value 346.281781
iter 100 value 342.886625
final  value 342.886625 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 672.764751 
iter  10 value 465.596380
iter  20 value 414.419445
iter  30 value 388.985761
iter  40 value 372.248422
iter  50 value 352.368862
iter  60 value 343.875461
iter  70 value 337.921647
iter  80 value 335.746440
iter  90 value 331.189371
iter 100 value 327.526915
final  value 327.526915 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 560.132469 
iter  10 value 489.228565
iter  20 value 454.886305
iter  30 value 423.887937
iter  40 value 405.013586
iter  50 value 395.075207
iter  60 value 386.939399
iter  70 value 384.867886
iter  80 value 382.966275
iter  90 value 379.836700
iter 100 value 376.792487
final  value 376.792487 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 651.087807 
iter  10 value 519.172704
iter  20 value 518.803955
final  value 518.802231 
converged
Fitting Repeat 2 

# weights:  122
initial  value 790.427975 
iter  10 value 519.577024
iter  20 value 518.805066
iter  30 value 518.802232
iter  30 value 518.802230
iter  30 value 518.802230
final  value 518.802230 
converged
Fitting Repeat 3 

# weights:  122
initial  value 651.114576 
iter  10 value 519.159676
iter  20 value 518.803033
final  value 518.802229 
converged
Fitting Repeat 4 

# weights:  122
initial  value 735.856419 
iter  10 value 520.053533
iter  20 value 518.802507
final  value 518.802231 
converged
Fitting Repeat 5 

# weights:  122
initial  value 703.420308 
iter  10 value 519.624142
iter  20 value 518.802317
final  value 518.802230 
converged
Fitting Repeat 1 

# weights:  45
initial  value 542.955594 
iter  10 value 514.942765
iter  20 value 514.925908
iter  30 value 514.925597
iter  40 value 514.925164
iter  50 value 514.924512
iter  60 value 514.923417
iter  70 value 514.921212
iter  80 value 514.915050
iter  90 value 514.878150
iter 100 value 506.787859
final  value 506.787859 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  45
initial  value 652.792303 
iter  10 value 515.044274
iter  20 value 514.920817
iter  30 value 514.916429
iter  40 value 514.898861
iter  50 value 513.603230
iter  60 value 482.451199
iter  70 value 478.560840
iter  80 value 478.490104
iter  90 value 478.369462
iter 100 value 476.992287
final  value 476.992287 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  45
initial  value 573.724189 
iter  10 value 514.978501
final  value 514.928316 
converged
Fitting Repeat 4 

# weights:  45
initial  value 573.502830 
iter  10 value 514.974659
iter  20 value 514.926989
iter  30 value 514.926893
iter  40 value 514.926784
iter  50 value 514.926660
iter  60 value 514.926516
iter  70 value 514.926345
iter  80 value 514.926137
iter  90 value 514.925875
iter 100 value 514.925534
final  value 514.925534 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  45
initial  value 595.241574 
iter  10 value 514.994636
iter  20 value 514.924448
iter  30 value 514.923784
iter  40 value 514.922739
iter  50 value 514.920827
iter  60 value 514.916250
iter  70 value 514.896187
iter  80 value 513.312560
iter  90 value 482.241221
iter 100 value 480.034109
final  value 480.034109 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  166
initial  value 646.595519 
iter  10 value 557.565154
iter  20 value 554.064174
iter  30 value 552.926887
iter  40 value 552.784738
iter  50 value 552.776557
final  value 552.776426 
converged
Fitting Repeat 2 

# weights:  166
initial  value 548.520177 
iter  10 value 512.043220
iter  20 value 511.400900
iter  30 value 511.272075
iter  40 value 511.264635
final  value 511.264607 
converged
Fitting Repeat 3 

# weights:  166
initial  value 645.883211 
iter  10 value 523.179465
iter  20 value 516.567591
iter  30 value 516.232739
iter  40 value 516.223809
final  value 516.223597 
converged
Fitting Repeat 4 

# weights:  166
initial  value 583.646510 
iter  10 value 481.465114
iter  20 value 475.009728
iter  30 value 474.976738
final  value 474.976473 
converged
Fitting Repeat 5 

# weights:  166
initial  value 682.153644 
iter  10 value 460.258423
iter  20 value 456.101011
iter  30 value 455.863142
iter  40 value 455.854948
final  value 455.854910 
converged
Fitting Repeat 1 

# weights:  122
initial  value 545.759718 
iter  10 value 535.386706
iter  20 value 481.777648
iter  30 value 449.792105
iter  40 value 447.041194
iter  50 value 445.229290
iter  60 value 440.791731
iter  70 value 438.289962
iter  80 value 437.081943
iter  90 value 435.314309
iter 100 value 430.698189
final  value 430.698189 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 654.601583 
iter  10 value 525.116696
iter  20 value 523.500709
iter  30 value 500.883358
iter  40 value 461.191837
iter  50 value 451.332107
iter  60 value 449.098361
iter  70 value 448.563707
iter  80 value 447.394820
iter  90 value 447.071362
iter 100 value 447.006686
final  value 447.006686 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 881.080880 
iter  10 value 527.336023
iter  20 value 526.473290
iter  30 value 510.600657
iter  40 value 477.137466
iter  50 value 460.577602
iter  60 value 456.474349
iter  70 value 444.920152
iter  80 value 442.858447
iter  90 value 440.959295
iter 100 value 436.531857
final  value 436.531857 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 747.187554 
iter  10 value 531.692842
iter  20 value 529.645966
iter  30 value 526.255119
iter  40 value 498.463221
iter  50 value 480.806776
iter  60 value 478.448048
iter  70 value 475.778689
iter  80 value 474.085436
iter  90 value 473.216384
iter 100 value 471.914958
final  value 471.914958 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 663.161441 
iter  10 value 552.127741
iter  20 value 550.579876
iter  30 value 535.962639
iter  40 value 487.714319
iter  50 value 473.881788
iter  60 value 469.300942
iter  70 value 464.228582
iter  80 value 461.704185
iter  90 value 460.263398
iter 100 value 454.578350
final  value 454.578350 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  221
initial  value 600.409403 
iter  10 value 539.564380
iter  20 value 539.020053
iter  30 value 512.923330
iter  40 value 487.191848
iter  50 value 470.620947
iter  60 value 465.783649
iter  70 value 463.826605
iter  80 value 461.415882
iter  90 value 458.406563
iter 100 value 457.928302
final  value 457.928302 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  221
initial  value 572.611540 
iter  10 value 560.943305
iter  20 value 560.793938
iter  30 value 560.776919
iter  40 value 551.520778
iter  50 value 465.780311
iter  60 value 450.345777
iter  70 value 440.164354
iter  80 value 435.648545
iter  90 value 431.758252
iter 100 value 417.118623
final  value 417.118623 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  221
initial  value 643.422167 
iter  10 value 531.775706
iter  20 value 530.452078
iter  30 value 525.361132
iter  40 value 478.512989
iter  50 value 459.324721
iter  60 value 457.591315
iter  70 value 456.222514
iter  80 value 452.026975
iter  90 value 450.747050
iter 100 value 448.992623
final  value 448.992623 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  221
initial  value 463.038638 
iter  10 value 455.375521
iter  20 value 436.039962
iter  30 value 396.584776
iter  40 value 394.269119
iter  50 value 389.096178
iter  60 value 385.924432
iter  70 value 375.869636
iter  80 value 374.064861
iter  90 value 373.552004
iter 100 value 373.054906
final  value 373.054906 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  221
initial  value 859.853305 
iter  10 value 513.739825
iter  20 value 512.618366
iter  30 value 487.903178
iter  40 value 456.393182
iter  50 value 434.876289
iter  60 value 431.848763
iter  70 value 419.700208
iter  80 value 417.347977
iter  90 value 416.064404
iter 100 value 414.084735
final  value 414.084735 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  100
initial  value 544.057055 
iter  10 value 512.289467
iter  20 value 487.096806
iter  30 value 472.791078
iter  40 value 463.840553
iter  50 value 460.993020
iter  60 value 458.775336
iter  70 value 456.140560
iter  80 value 451.731222
iter  90 value 448.631484
iter 100 value 446.913976
final  value 446.913976 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  100
initial  value 692.505848 
iter  10 value 507.292343
iter  20 value 482.833301
iter  30 value 467.566219
iter  40 value 459.172959
iter  50 value 454.880908
iter  60 value 450.276227
iter  70 value 449.025103
iter  80 value 448.408986
iter  90 value 447.131061
iter 100 value 444.848468
final  value 444.848468 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  100
initial  value 598.093830 
iter  10 value 512.441537
iter  20 value 489.803975
iter  30 value 473.595705
iter  40 value 461.410167
iter  50 value 453.173256
iter  60 value 448.706801
iter  70 value 445.901546
iter  80 value 442.365326
iter  90 value 440.054642
iter 100 value 439.338373
final  value 439.338373 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  100
initial  value 701.788620 
iter  10 value 504.462658
iter  20 value 481.649666
iter  30 value 462.394481
iter  40 value 449.783022
iter  50 value 445.116135
iter  60 value 444.362212
iter  70 value 444.280580
iter  80 value 443.348474
iter  90 value 440.194609
iter 100 value 438.702590
final  value 438.702590 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  100
initial  value 534.142320 
iter  10 value 512.341160
iter  20 value 488.563546
iter  30 value 480.147685
iter  40 value 463.529350
iter  50 value 457.532578
iter  60 value 454.672284
iter  70 value 449.023063
iter  80 value 445.956624
iter  90 value 444.478935
iter 100 value 444.286483
final  value 444.286483 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  12
initial  value 529.283853 
iter  10 value 490.822130
iter  20 value 480.060794
iter  30 value 479.209360
final  value 479.205543 
converged
Fitting Repeat 2 

# weights:  12
initial  value 628.640438 
iter  10 value 534.746820
iter  20 value 531.863887
iter  30 value 522.479630
iter  40 value 522.371939
final  value 522.371873 
converged
Fitting Repeat 3 

# weights:  12
initial  value 644.995098 
iter  10 value 520.913797
iter  20 value 511.668751
iter  30 value 505.505904
iter  40 value 504.972094
final  value 504.967650 
converged
Fitting Repeat 4 

# weights:  12
initial  value 541.017805 
iter  10 value 468.798098
iter  20 value 454.895538
iter  30 value 453.580892
iter  40 value 453.565502
final  value 453.565284 
converged
Fitting Repeat 5 

# weights:  12
initial  value 635.008898 
iter  10 value 542.453533
iter  20 value 528.838326
iter  30 value 524.636582
iter  40 value 524.531819
iter  50 value 524.528980
final  value 524.528914 
converged
Fitting Repeat 1 

# weights:  89
initial  value 767.337257 
iter  10 value 529.100417
iter  20 value 528.585440
final  value 528.584803 
converged
Fitting Repeat 2 

# weights:  89
initial  value 674.766803 
iter  10 value 502.450770
iter  20 value 502.172959
final  value 502.172639 
converged
Fitting Repeat 3 

# weights:  89
initial  value 839.142730 
iter  10 value 495.217575
iter  20 value 493.987996
final  value 493.981366 
converged
Fitting Repeat 4 

# weights:  89
initial  value 660.926945 
iter  10 value 572.608059
iter  20 value 572.561142
final  value 572.561002 
converged
Fitting Repeat 5 

# weights:  89
initial  value 508.855792 
iter  10 value 446.911726
iter  20 value 446.865178
final  value 446.865169 
converged
Fitting Repeat 1 

# weights:  56
initial  value 631.011259 
iter  10 value 522.236749
iter  20 value 469.892480
iter  30 value 454.238083
iter  40 value 441.974278
iter  50 value 439.151186
iter  60 value 438.197658
iter  70 value 437.013677
iter  80 value 436.284785
iter  90 value 434.766653
iter 100 value 432.705825
final  value 432.705825 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  56
initial  value 600.445825 
iter  10 value 447.167419
iter  20 value 418.627702
iter  30 value 409.625083
iter  40 value 399.008837
iter  50 value 391.440604
iter  60 value 388.112072
iter  70 value 382.865398
iter  80 value 375.855784
iter  90 value 372.151838
iter 100 value 371.391166
final  value 371.391166 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  56
initial  value 669.466745 
iter  10 value 528.118532
iter  20 value 510.584919
iter  30 value 465.863436
iter  40 value 448.804807
iter  50 value 442.141914
iter  60 value 437.525586
iter  70 value 435.652908
iter  80 value 434.101828
iter  90 value 433.193457
iter 100 value 433.012332
final  value 433.012332 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  56
initial  value 650.536751 
iter  10 value 501.029682
iter  20 value 468.266682
iter  30 value 459.942498
iter  40 value 453.596815
iter  50 value 443.797642
iter  60 value 439.263160
iter  70 value 438.013871
iter  80 value 429.936852
iter  90 value 426.872993
iter 100 value 426.110947
final  value 426.110947 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  56
initial  value 656.648272 
iter  10 value 535.585194
iter  20 value 492.492480
iter  30 value 470.582518
iter  40 value 459.106681
iter  50 value 450.837998
iter  60 value 442.012284
iter  70 value 440.135646
iter  80 value 439.829503
iter  90 value 439.809556
iter 100 value 439.544917
final  value 439.544917 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  144
initial  value 560.250715 
iter  10 value 509.186765
iter  20 value 470.142211
iter  30 value 441.565395
iter  40 value 432.625362
iter  50 value 426.310991
iter  60 value 424.082779
iter  70 value 422.655429
iter  80 value 421.509898
iter  90 value 420.157097
iter 100 value 418.892953
final  value 418.892953 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  144
initial  value 696.967457 
iter  10 value 537.739542
iter  20 value 506.882905
iter  30 value 482.091107
iter  40 value 461.411079
iter  50 value 448.723830
iter  60 value 440.176121
iter  70 value 437.810829
iter  80 value 436.121221
iter  90 value 430.702907
iter 100 value 428.352549
final  value 428.352549 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  144
initial  value 747.298606 
iter  10 value 529.974855
iter  20 value 493.693300
iter  30 value 472.335661
iter  40 value 464.796278
iter  50 value 454.153572
iter  60 value 445.991971
iter  70 value 443.549145
iter  80 value 441.209480
iter  90 value 434.660626
iter 100 value 431.494602
final  value 431.494602 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  144
initial  value 611.504767 
iter  10 value 484.759355
iter  20 value 467.349109
iter  30 value 451.981154
iter  40 value 425.284248
iter  50 value 410.366601
iter  60 value 406.769921
iter  70 value 402.633007
iter  80 value 400.231749
iter  90 value 399.262296
iter 100 value 397.711970
final  value 397.711970 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  144
initial  value 703.256375 
iter  10 value 487.505921
iter  20 value 458.735114
iter  30 value 448.612447
iter  40 value 432.421399
iter  50 value 420.583789
iter  60 value 410.168805
iter  70 value 403.951936
iter  80 value 402.439738
iter  90 value 401.641002
iter 100 value 401.179350
final  value 401.179350 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  133
initial  value 548.970815 
iter  10 value 515.770841
iter  20 value 514.917279
iter  30 value 500.471481
iter  40 value 473.430755
iter  50 value 470.277850
iter  60 value 468.559961
iter  70 value 464.866227
iter  80 value 463.709272
iter  90 value 462.152110
iter 100 value 459.137722
final  value 459.137722 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  133
initial  value 651.492502 
iter  10 value 515.577627
iter  20 value 507.004852
iter  30 value 471.188093
iter  40 value 458.442906
iter  50 value 454.226806
iter  60 value 451.131324
iter  70 value 448.176723
iter  80 value 442.674621
iter  90 value 440.717056
iter 100 value 435.947134
final  value 435.947134 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  133
initial  value 673.378619 
iter  10 value 515.620377
iter  20 value 514.978501
iter  30 value 512.486772
iter  40 value 474.505115
iter  50 value 459.645945
iter  60 value 453.516706
iter  70 value 442.644952
iter  80 value 438.702741
iter  90 value 437.714381
iter 100 value 434.249477
final  value 434.249477 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  133
initial  value 565.583300 
iter  10 value 516.533937
iter  20 value 514.933038
iter  30 value 511.933001
iter  40 value 485.705171
iter  50 value 462.532036
iter  60 value 451.214255
iter  70 value 443.488559
iter  80 value 435.135083
iter  90 value 428.465955
iter 100 value 426.627931
final  value 426.627931 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  133
initial  value 671.029212 
iter  10 value 515.496233
iter  20 value 499.859006
iter  30 value 472.714996
iter  40 value 456.365017
iter  50 value 447.883748
iter  60 value 436.620392
iter  70 value 434.154236
iter  80 value 424.116305
iter  90 value 413.445360
iter 100 value 408.791441
final  value 408.791441 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  34
initial  value 612.000768 
iter  10 value 458.668361
iter  20 value 434.084391
iter  30 value 417.484365
iter  40 value 403.571385
iter  50 value 401.902811
iter  60 value 401.836276
iter  70 value 401.580021
iter  80 value 399.945339
iter  90 value 399.502302
iter 100 value 399.442486
final  value 399.442486 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  34
initial  value 589.309427 
iter  10 value 471.818244
iter  20 value 453.744930
iter  30 value 447.430050
iter  40 value 443.300343
iter  50 value 442.301795
iter  60 value 442.062065
final  value 442.061973 
converged
Fitting Repeat 3 

# weights:  34
initial  value 623.810634 
iter  10 value 527.266184
iter  20 value 506.078246
iter  30 value 501.880367
iter  40 value 495.738968
iter  50 value 494.461314
iter  60 value 494.435281
iter  60 value 494.435278
iter  60 value 494.435278
final  value 494.435278 
converged
Fitting Repeat 4 

# weights:  34
initial  value 607.816495 
iter  10 value 491.784624
iter  20 value 470.497919
iter  30 value 460.663353
iter  40 value 457.844051
iter  50 value 448.770013
iter  60 value 441.796552
iter  70 value 439.937469
iter  80 value 438.502251
iter  90 value 438.310714
iter 100 value 438.301884
final  value 438.301884 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  34
initial  value 573.278604 
iter  10 value 493.612947
iter  20 value 473.955196
iter  30 value 460.065240
iter  40 value 453.840488
iter  50 value 453.451702
iter  60 value 453.306944
iter  70 value 449.151518
iter  80 value 440.555214
iter  90 value 438.591440
iter 100 value 438.477770
final  value 438.477770 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  78
initial  value 663.558556 
iter  10 value 511.119704
iter  20 value 482.963748
iter  30 value 466.455660
iter  40 value 454.890860
iter  50 value 446.838496
iter  60 value 442.697679
iter  70 value 439.278321
iter  80 value 437.517198
iter  90 value 435.907372
iter 100 value 435.704446
final  value 435.704446 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  78
initial  value 549.806164 
iter  10 value 501.114447
iter  20 value 463.963327
iter  30 value 447.716851
iter  40 value 440.241285
iter  50 value 434.089182
iter  60 value 431.937458
iter  70 value 430.338376
iter  80 value 427.966294
iter  90 value 426.335574
iter 100 value 426.073579
final  value 426.073579 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  78
initial  value 537.079711 
iter  10 value 512.574944
iter  20 value 485.071427
iter  30 value 450.660588
iter  40 value 441.279224
iter  50 value 436.621245
iter  60 value 434.965980
iter  70 value 433.857702
iter  80 value 433.460595
iter  90 value 433.071438
iter 100 value 432.749877
final  value 432.749877 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  78
initial  value 521.161130 
iter  10 value 508.031649
iter  20 value 475.756111
iter  30 value 456.914452
iter  40 value 450.068065
iter  50 value 444.238502
iter  60 value 440.628265
iter  70 value 437.709200
iter  80 value 433.876631
iter  90 value 432.148727
iter 100 value 428.231317
final  value 428.231317 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  78
initial  value 571.199468 
iter  10 value 513.166589
iter  20 value 489.209059
iter  30 value 468.425339
iter  40 value 461.018329
iter  50 value 457.513757
iter  60 value 453.566672
iter  70 value 451.031975
iter  80 value 443.897282
iter  90 value 437.007149
iter 100 value 433.572053
final  value 433.572053 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  78
initial  value 558.847051 
iter  10 value 505.630263
iter  20 value 477.453115
iter  30 value 455.477526
iter  40 value 447.310288
iter  50 value 440.098470
iter  60 value 437.279436
iter  70 value 435.332954
iter  80 value 434.122132
iter  90 value 432.690087
iter 100 value 432.329605
final  value 432.329605 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  78
initial  value 572.268468 
iter  10 value 513.838348
iter  20 value 489.034482
iter  30 value 461.549435
iter  40 value 452.667573
iter  50 value 445.933443
iter  60 value 438.877946
iter  70 value 433.634098
iter  80 value 429.484115
iter  90 value 425.975800
iter 100 value 424.706287
final  value 424.706287 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  78
initial  value 736.034904 
iter  10 value 504.190693
iter  20 value 465.422942
iter  30 value 442.743243
iter  40 value 430.109195
iter  50 value 423.154947
iter  60 value 413.668139
iter  70 value 408.094776
iter  80 value 406.063761
iter  90 value 405.286219
iter 100 value 403.463472
final  value 403.463472 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  78
initial  value 738.109746 
iter  10 value 510.644503
iter  20 value 470.668930
iter  30 value 438.543084
iter  40 value 425.832129
iter  50 value 419.382900
iter  60 value 416.088698
iter  70 value 415.258806
iter  80 value 415.109884
iter  90 value 415.074191
iter 100 value 414.888191
final  value 414.888191 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  78
initial  value 700.128058 
iter  10 value 509.882872
iter  20 value 468.846073
iter  30 value 451.109144
iter  40 value 436.347587
iter  50 value 429.179978
iter  60 value 426.317797
iter  70 value 424.201996
iter  80 value 421.587612
iter  90 value 420.567193
iter 100 value 420.156315
final  value 420.156315 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  177
initial  value 562.434832 
iter  10 value 511.370023
iter  20 value 509.522475
iter  30 value 509.476067
final  value 509.475681 
converged
Fitting Repeat 2 

# weights:  177
initial  value 546.814748 
iter  10 value 512.088119
iter  20 value 509.680738
iter  30 value 509.498725
iter  40 value 509.475724
final  value 509.475687 
converged
Fitting Repeat 3 

# weights:  177
initial  value 618.776387 
iter  10 value 511.261917
iter  20 value 509.612371
iter  30 value 509.497103
iter  40 value 509.490316
final  value 509.490225 
converged
Fitting Repeat 4 

# weights:  177
initial  value 760.120991 
iter  10 value 518.989604
iter  20 value 511.020131
iter  30 value 510.629304
iter  40 value 509.577452
iter  50 value 509.556802
final  value 509.556617 
converged
Fitting Repeat 5 

# weights:  177
initial  value 560.222424 
iter  10 value 511.659448
iter  20 value 509.649821
iter  30 value 509.559593
iter  40 value 509.556527
iter  50 value 509.556294
final  value 509.556267 
converged
Fitting Repeat 1 

# weights:  89
initial  value 766.110092 
iter  10 value 514.999465
final  value 514.924504 
converged
Fitting Repeat 2 

# weights:  89
initial  value 818.164215 
iter  10 value 514.975366
iter  20 value 514.922570
iter  30 value 514.922186
iter  40 value 514.921660
iter  50 value 514.920859
iter  60 value 514.919432
iter  70 value 514.916144
iter  80 value 514.902425
iter  90 value 512.355154
iter 100 value 484.281962
final  value 484.281962 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  89
initial  value 542.387622 
iter  10 value 514.935423
iter  20 value 514.922754
iter  30 value 514.922604
iter  40 value 514.922414
iter  50 value 514.922164
iter  60 value 514.921820
iter  70 value 514.921316
iter  80 value 514.920510
iter  90 value 514.919028
iter 100 value 514.915514
final  value 514.915514 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  89
initial  value 714.297545 
iter  10 value 515.003369
iter  20 value 513.312097
iter  30 value 491.729380
iter  40 value 468.047852
iter  50 value 466.682671
iter  60 value 466.105696
iter  70 value 464.794295
iter  80 value 464.400965
iter  90 value 464.223761
iter 100 value 463.160276
final  value 463.160276 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  89
initial  value 566.783829 
iter  10 value 514.946284
final  value 514.923741 
converged
Fitting Repeat 1 

# weights:  122
initial  value 612.718319 
iter  10 value 515.951889
iter  20 value 515.657251
final  value 515.655896 
converged
Fitting Repeat 2 

# weights:  122
initial  value 695.410684 
iter  10 value 516.359012
iter  20 value 515.657603
final  value 515.655923 
converged
Fitting Repeat 3 

# weights:  122
initial  value 621.275307 
iter  10 value 516.050612
iter  20 value 515.656534
final  value 515.655914 
converged
Fitting Repeat 4 

# weights:  122
initial  value 712.357358 
iter  10 value 516.624562
iter  20 value 515.659168
final  value 515.655914 
converged
Fitting Repeat 5 

# weights:  122
initial  value 712.825278 
iter  10 value 517.469129
iter  20 value 515.660917
iter  30 value 515.655915
final  value 515.655902 
converged
Fitting Repeat 1 

# weights:  221
initial  value 822.390863 
iter  10 value 515.159116
iter  20 value 514.925075
iter  30 value 511.097219
iter  40 value 475.430613
iter  50 value 461.853843
iter  60 value 455.319914
iter  70 value 450.855354
iter  80 value 441.744552
iter  90 value 438.983061
iter 100 value 438.372012
final  value 438.372012 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  221
initial  value 537.324810 
iter  10 value 514.962569
iter  20 value 514.922871
iter  30 value 514.922615
iter  40 value 514.922275
iter  50 value 514.921799
iter  60 value 514.921080
iter  70 value 514.919862
iter  80 value 514.917351
iter  90 value 514.909436
iter 100 value 514.706440
final  value 514.706440 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  221
initial  value 655.698115 
iter  10 value 515.277871
iter  20 value 514.926537
iter  30 value 514.923074
iter  40 value 514.922872
iter  50 value 514.922615
iter  60 value 514.922272
iter  70 value 514.921791
iter  80 value 514.921064
iter  90 value 514.919826
iter 100 value 514.917256
final  value 514.917256 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  221
initial  value 523.060575 
iter  10 value 514.933162
iter  20 value 506.175897
iter  30 value 469.704709
iter  40 value 451.421847
iter  50 value 450.141156
iter  60 value 448.616380
iter  70 value 448.195982
iter  80 value 447.773655
iter  90 value 445.723294
iter 100 value 439.220852
final  value 439.220852 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  221
initial  value 761.640809 
iter  10 value 515.280371
iter  20 value 514.926566
iter  30 value 514.921077
iter  40 value 514.919889
iter  50 value 514.917469
iter  60 value 514.910013
iter  70 value 514.752275
iter  80 value 492.520204
iter  90 value 480.534276
iter 100 value 477.287138
final  value 477.287138 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  221
initial  value 1158.708435 
iter  10 value 753.752413
iter  20 value 753.051280
iter  30 value 753.042865
iter  40 value 753.042264
iter  50 value 753.041283
iter  60 value 753.039394
iter  70 value 753.034333
iter  80 value 752.994347
iter  90 value 728.032828
iter 100 value 687.318096
final  value 687.318096 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  221
initial  value 961.483709 
iter  10 value 753.922740
iter  20 value 753.053244
final  value 753.045646 
converged
Fitting Repeat 3 

# weights:  221
initial  value 796.903068 
iter  10 value 753.160350
iter  20 value 753.043103
iter  30 value 753.042630
iter  40 value 753.041902
iter  50 value 753.040630
iter  60 value 753.037857
iter  70 value 753.027686
iter  80 value 747.702895
iter  90 value 697.803538
iter 100 value 683.222184
final  value 683.222184 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  221
initial  value 829.179462 
iter  10 value 753.264188
iter  20 value 753.045457
iter  20 value 753.045455
final  value 753.045455 
converged
Fitting Repeat 5 

# weights:  221
initial  value 1146.473050 
iter  10 value 753.824551
iter  20 value 753.052112
final  value 753.045190 
converged
Model Averaged Neural Network 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  size  decay         bag    RMSE       Rsquared      MAE        Selected
   1    1.810456e-02   TRUE  1.0027249  0.0044003940  0.7917705          
   3    8.809574e-02   TRUE  1.0107793  0.0024773770  0.7987063          
   4    8.122348e-05  FALSE  0.9990334  0.0080611502  0.7952725          
   5    1.634087e-02   TRUE  1.0163409  0.0071245626  0.8049855          
   7    1.418191e-02  FALSE  1.0147454  0.0116632838  0.7997734          
   7    1.426626e-02  FALSE  1.0275123  0.0073374492  0.8160827          
   8    3.366673e-05  FALSE  1.0038856  0.0035141209  0.7948119          
   8    3.528491e+00   TRUE  1.0020873  0.0018098995  0.7908535          
   9    6.671715e-02  FALSE  1.0177784  0.0063122391  0.8063516          
  11    6.546499e-04   TRUE  1.0144862  0.0029029286  0.8045218          
  11    5.849359e-03   TRUE  1.0205343  0.0043368197  0.8029360          
  11    1.711692e+00  FALSE  1.0002417  0.0010061787  0.7903999          
  11    3.730599e+00  FALSE  1.0008814  0.0009320735  0.7903111          
  12    1.704722e-03  FALSE  1.0193788  0.0063132233  0.8087208          
  13    1.351855e-01   TRUE  1.0429038  0.0057713923  0.8224493          
  15    9.575963e-01   TRUE  1.0057058  0.0016941024  0.7940455          
  16    5.985918e-01  FALSE  1.0033208  0.0016856274  0.7930979          
  20    8.526253e-05  FALSE  0.9969806  0.0085787912  0.7913258  *       
  20    3.754391e-04   TRUE  1.0176284  0.0001899067  0.8080071          
  20    3.973042e-03  FALSE  1.0270351  0.0037882811  0.8157190          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 20, decay = 8.526253e-05
 and bag = FALSE.
[1] "Mon Mar 05 07:55:54 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :1     NA's   :1     NA's   :1    
Error : Stopping
In addition: Warning messages:
1: executing %dopar% sequentially: no parallel backend registered 
2: model fit failed for Fold1: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
3: model fit failed for Fold2: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
4: model fit failed for Fold3: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
5: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :1     NA's   :1     NA's   :1    
Error : Stopping
In addition: Warning messages:
1: model fit failed for Fold1: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
2: model fit failed for Fold2: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
3: model fit failed for Fold3: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
4: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :1     NA's   :1     NA's   :1    
Error : Stopping
In addition: There were 26 warnings (use warnings() to see them)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 07:56:07 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "bag"                     
Loading required package: earth
Loading required package: plotmo
Loading required package: plotrix
Loading required package: TeachingDemos
Bagged MARS 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  degree  nprune  RMSE      Rsquared      MAE        Selected
  1        4      1.007845  0.0016002393  0.7972358          
  1        6      1.015706  0.0027815220  0.8047877          
  1        8      1.017059  0.0007889730  0.8059984          
  1        9      1.024190  0.0024705110  0.8125192          
  1       14      1.029134  0.0023976052  0.8180910          
  2        2      1.000104  0.0019150147  0.7914756  *       
  2        3      1.005015  0.0019651781  0.7965744          
  2        4      1.011408  0.0009661310  0.8023573          
  2        5      1.009669  0.0009367522  0.8008616          
  2        6      1.017052  0.0028544016  0.8066275          
  2        7      1.017037  0.0030910171  0.8054561          
  2        8      1.023710  0.0049475766  0.8106265          
  2        9      1.024922  0.0020320906  0.8116083          
  2       11      1.028197  0.0027450263  0.8174596          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nprune = 2 and degree = 2.
[1] "Mon Mar 05 07:58:23 2018"
Bagged MARS using gCV Pruning 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.028675  0.002727505  0.8178386

Tuning parameter 'degree' was held constant at a value of 1
[1] "Mon Mar 05 07:59:15 2018"
Loading required package: mgcv
Loading required package: nlme
This is mgcv 1.8-22. For overview type 'help("mgcv-package")'.
Generalized Additive Model using Splines 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  select  method  RMSE      Rsquared     MAE        Selected
  FALSE   GCV.Cp  1.034024  0.001899381  0.8192422          
  FALSE   ML      1.012999  0.001748260  0.8005566          
  FALSE   REML    1.019668  0.002055392  0.8093732          
   TRUE   GCV.Cp  1.027308  0.001970305  0.8104053          
   TRUE   ML      1.006038  0.003342591  0.7954572          
   TRUE   REML    1.006013  0.003344374  0.7954334  *       

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were select = TRUE and method = REML.
[1] "Mon Mar 05 08:01:54 2018"
bartMachine initializing with 100 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 68.8/477.6MB
Iteration 200/1250  mem: 159/477.6MB
Iteration 300/1250  mem: 102.7/477.6MB
Iteration 400/1250  mem: 173.2/477.6MB
Iteration 500/1250  mem: 112.1/477.6MB
Iteration 600/1250  mem: 177.2/477.6MB
Iteration 700/1250  mem: 116.8/477.6MB
Iteration 800/1250  mem: 182.1/477.6MB
Iteration 900/1250  mem: 116.9/477.6MB
Iteration 1000/1250  mem: 194.9/477.6MB
Iteration 1100/1250  mem: 110.1/477.6MB
Iteration 1200/1250  mem: 186.1/477.6MB
done building BART in 8.895 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 55 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 176.3/477.6MB
Iteration 200/1250  mem: 224.6/477.6MB
Iteration 300/1250  mem: 156.6/477.6MB
Iteration 400/1250  mem: 237.6/477.6MB
Iteration 500/1250  mem: 178.8/477.6MB
Iteration 600/1250  mem: 255.7/477.6MB
Iteration 700/1250  mem: 184.8/477.6MB
Iteration 800/1250  mem: 265.3/477.6MB
Iteration 900/1250  mem: 197.2/477.6MB
Iteration 1000/1250  mem: 267.8/477.6MB
Iteration 1100/1250  mem: 335.6/477.6MB
Iteration 1200/1250  mem: 260.4/477.6MB
done building BART in 4.324 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 57 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 299.8/477.6MB
Iteration 200/1250  mem: 365.5/477.6MB
Iteration 300/1250  mem: 282.5/477.6MB
Iteration 400/1250  mem: 355.4/477.6MB
Iteration 500/1250  mem: 278.1/477.6MB
Iteration 600/1250  mem: 347.2/477.6MB
Iteration 700/1250  mem: 268.4/477.6MB
Iteration 800/1250  mem: 338.4/477.6MB
Iteration 900/1250  mem: 265.7/477.6MB
Iteration 1000/1250  mem: 339.2/477.6MB
Iteration 1100/1250  mem: 283.8/477.6MB
Iteration 1200/1250  mem: 247.4/477.6MB
done building BART in 3.927 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 26 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 349.3/477.6MB
Iteration 200/1250  mem: 328/477.6MB
Iteration 300/1250  mem: 313.9/477.6MB
Iteration 400/1250  mem: 299.5/477.6MB
Iteration 500/1250  mem: 293.5/477.6MB
Iteration 600/1250  mem: 283.6/477.6MB
Iteration 700/1250  mem: 279.7/477.6MB
Iteration 800/1250  mem: 273.6/477.6MB
Iteration 900/1250  mem: 268.9/477.6MB
Iteration 1000/1250  mem: 262.2/477.6MB
Iteration 1100/1250  mem: 354.9/477.6MB
Iteration 1200/1250  mem: 347.7/477.6MB
done building BART in 1.797 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 74 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 278.7/477.6MB
Iteration 200/1250  mem: 338.9/477.6MB
Iteration 300/1250  mem: 278.9/477.6MB
Iteration 400/1250  mem: 327.3/477.6MB
Iteration 500/1250  mem: 372.3/477.6MB
Iteration 600/1250  mem: 288.8/477.6MB
Iteration 700/1250  mem: 95.7/477.6MB
Iteration 800/1250  mem: 147.6/477.6MB
Iteration 900/1250  mem: 93/477.6MB
Iteration 1000/1250  mem: 152.4/477.6MB
Iteration 1100/1250  mem: 83.5/477.6MB
Iteration 1200/1250  mem: 124.7/477.6MB
done building BART in 5.39 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 57 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 137.3/477.6MB
Iteration 200/1250  mem: 121.3/477.6MB
Iteration 300/1250  mem: 120.5/477.6MB
Iteration 400/1250  mem: 122.6/477.6MB
Iteration 500/1250  mem: 119.1/477.6MB
Iteration 600/1250  mem: 111.4/477.6MB
Iteration 700/1250  mem: 96.9/477.6MB
Iteration 800/1250  mem: 85/477.6MB
Iteration 900/1250  mem: 186.2/477.6MB
Iteration 1000/1250  mem: 165.2/477.6MB
Iteration 1100/1250  mem: 136.8/477.6MB
Iteration 1200/1250  mem: 100.6/477.6MB
done building BART in 4.063 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 99 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 139.3/477.6MB
Iteration 200/1250  mem: 188.6/477.6MB
Iteration 300/1250  mem: 80.4/477.6MB
Iteration 400/1250  mem: 137.3/477.6MB
Iteration 500/1250  mem: 87.3/477.6MB
Iteration 600/1250  mem: 130.2/477.6MB
Iteration 700/1250  mem: 147/477.6MB
Iteration 800/1250  mem: 141.6/477.6MB
Iteration 900/1250  mem: 122.8/477.6MB
Iteration 1000/1250  mem: 94.4/477.6MB
Iteration 1100/1250  mem: 194.9/477.6MB
Iteration 1200/1250  mem: 147/477.6MB
done building BART in 6.982 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 47 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 109.9/477.6MB
Iteration 200/1250  mem: 152.2/477.6MB
Iteration 300/1250  mem: 192.9/477.6MB
Iteration 400/1250  mem: 100/477.6MB
Iteration 500/1250  mem: 145.8/477.6MB
Iteration 600/1250  mem: 190/477.6MB
Iteration 700/1250  mem: 102.5/477.6MB
Iteration 800/1250  mem: 146.7/477.6MB
Iteration 900/1250  mem: 194.8/477.6MB
Iteration 1000/1250  mem: 239.4/477.6MB
Iteration 1100/1250  mem: 150.5/477.6MB
Iteration 1200/1250  mem: 194.3/477.6MB
done building BART in 3.294 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 14 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 212.8/477.6MB
Iteration 200/1250  mem: 130.8/477.6MB
Iteration 300/1250  mem: 184.9/477.6MB
Iteration 400/1250  mem: 238.9/477.6MB
Iteration 500/1250  mem: 150.9/477.6MB
Iteration 600/1250  mem: 201.3/477.6MB
Iteration 700/1250  mem: 117.4/477.6MB
Iteration 800/1250  mem: 169.7/477.6MB
Iteration 900/1250  mem: 222.1/477.6MB
Iteration 1000/1250  mem: 135.1/477.6MB
Iteration 1100/1250  mem: 188.9/477.6MB
Iteration 1200/1250  mem: 242.7/477.6MB
done building BART in 0.92 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 46 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 197.8/477.6MB
Iteration 200/1250  mem: 237.8/477.6MB
Iteration 300/1250  mem: 158.2/477.6MB
Iteration 400/1250  mem: 96.1/477.6MB
Iteration 500/1250  mem: 145.2/477.6MB
Iteration 600/1250  mem: 67.1/477.6MB
Iteration 700/1250  mem: 119.1/477.6MB
Iteration 800/1250  mem: 42.6/477.6MB
Iteration 900/1250  mem: 94/477.6MB
Iteration 1000/1250  mem: 142/477.6MB
Iteration 1100/1250  mem: 56.5/477.6MB
Iteration 1200/1250  mem: 101.9/477.6MB
done building BART in 3.238 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 30 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 53.6/477.6MB
Iteration 200/1250  mem: 169.4/477.6MB
Iteration 300/1250  mem: 145.7/477.6MB
Iteration 400/1250  mem: 121/477.6MB
Iteration 500/1250  mem: 99.5/477.6MB
Iteration 600/1250  mem: 77/477.6MB
Iteration 700/1250  mem: 56.6/477.6MB
Iteration 800/1250  mem: 170.7/477.6MB
Iteration 900/1250  mem: 148.7/477.6MB
Iteration 1000/1250  mem: 128/477.6MB
Iteration 1100/1250  mem: 108.1/477.6MB
Iteration 1200/1250  mem: 84.5/477.6MB
done building BART in 2.053 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 65 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 141.8/477.6MB
Iteration 200/1250  mem: 119/477.6MB
Iteration 300/1250  mem: 107.4/477.6MB
Iteration 400/1250  mem: 94.7/477.6MB
Iteration 500/1250  mem: 169/477.6MB
Iteration 600/1250  mem: 154.7/477.6MB
Iteration 700/1250  mem: 136.7/477.6MB
Iteration 800/1250  mem: 107/477.6MB
Iteration 900/1250  mem: 217.1/477.6MB
Iteration 1000/1250  mem: 186.7/477.6MB
Iteration 1100/1250  mem: 145/477.6MB
Iteration 1200/1250  mem: 229.1/477.6MB
done building BART in 4.616 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 61 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 185/477.6MB
Iteration 200/1250  mem: 275.8/477.6MB
Iteration 300/1250  mem: 225/477.6MB
Iteration 400/1250  mem: 182.2/477.6MB
Iteration 500/1250  mem: 278.8/477.6MB
Iteration 600/1250  mem: 244.2/477.6MB
Iteration 700/1250  mem: 204.4/477.6MB
Iteration 800/1250  mem: 297.7/477.6MB
Iteration 900/1250  mem: 247.5/477.6MB
Iteration 1000/1250  mem: 305.7/477.6MB
Iteration 1100/1250  mem: 255.1/477.6MB
Iteration 1200/1250  mem: 201.3/477.6MB
done building BART in 4.39 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 22 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 276.3/477.6MB
Iteration 200/1250  mem: 210.9/477.6MB
Iteration 300/1250  mem: 296.6/477.6MB
Iteration 400/1250  mem: 230/477.6MB
Iteration 500/1250  mem: 312.5/477.6MB
Iteration 600/1250  mem: 249.4/477.6MB
Iteration 700/1250  mem: 333.6/477.6MB
Iteration 800/1250  mem: 269.1/477.6MB
Iteration 900/1250  mem: 355.4/477.6MB
Iteration 1000/1250  mem: 292/477.6MB
Iteration 1100/1250  mem: 228.8/477.6MB
Iteration 1200/1250  mem: 312.8/477.6MB
done building BART in 1.468 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 38 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 223.6/477.6MB
Iteration 200/1250  mem: 364.9/477.6MB
Iteration 300/1250  mem: 361.1/477.6MB
Iteration 400/1250  mem: 356.2/477.6MB
Iteration 500/1250  mem: 360/477.6MB
Iteration 600/1250  mem: 362.1/477.6MB
Iteration 700/1250  mem: 368.8/477.6MB
Iteration 800/1250  mem: 242.8/477.6MB
Iteration 900/1250  mem: 251.4/477.6MB
Iteration 1000/1250  mem: 259.3/477.6MB
Iteration 1100/1250  mem: 268.6/477.6MB
Iteration 1200/1250  mem: 275.8/477.6MB
done building BART in 2.453 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 37 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 370.8/477.6MB
Iteration 200/1250  mem: 158.1/477.6MB
Iteration 300/1250  mem: 157.2/477.6MB
Iteration 400/1250  mem: 157.2/477.6MB
Iteration 500/1250  mem: 157/477.6MB
Iteration 600/1250  mem: 155.4/477.6MB
Iteration 700/1250  mem: 156.2/477.6MB
Iteration 800/1250  mem: 152.6/477.6MB
Iteration 900/1250  mem: 153/477.6MB
Iteration 1000/1250  mem: 149.2/477.6MB
Iteration 1100/1250  mem: 145.9/477.6MB
Iteration 1200/1250  mem: 141.3/477.6MB
done building BART in 2.648 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 79 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 105.8/477.6MB
Iteration 200/1250  mem: 133.9/477.6MB
Iteration 300/1250  mem: 162.7/477.6MB
Iteration 400/1250  mem: 191.5/477.6MB
Iteration 500/1250  mem: 214.5/477.6MB
Iteration 600/1250  mem: 234.2/477.6MB
Iteration 700/1250  mem: 103.8/477.6MB
Iteration 800/1250  mem: 113.3/477.6MB
Iteration 900/1250  mem: 116.4/477.6MB
Iteration 1000/1250  mem: 119.2/477.6MB
Iteration 1100/1250  mem: 115.7/477.6MB
Iteration 1200/1250  mem: 116/477.6MB
done building BART in 5.386 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 44 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 159.6/477.6MB
Iteration 200/1250  mem: 177.1/477.6MB
Iteration 300/1250  mem: 196/477.6MB
Iteration 400/1250  mem: 217.6/477.6MB
Iteration 500/1250  mem: 239.8/477.6MB
Iteration 600/1250  mem: 259.6/477.6MB
Iteration 700/1250  mem: 128.5/477.6MB
Iteration 800/1250  mem: 147.7/477.6MB
Iteration 900/1250  mem: 167.3/477.6MB
Iteration 1000/1250  mem: 183.3/477.6MB
Iteration 1100/1250  mem: 200.6/477.6MB
Iteration 1200/1250  mem: 216.8/477.6MB
done building BART in 2.96 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 58 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 241.4/477.6MB
Iteration 200/1250  mem: 164/477.6MB
Iteration 300/1250  mem: 240.4/477.6MB
Iteration 400/1250  mem: 179.6/477.6MB
Iteration 500/1250  mem: 258.6/477.6MB
Iteration 600/1250  mem: 193.4/477.6MB
Iteration 700/1250  mem: 269/477.6MB
Iteration 800/1250  mem: 90.1/477.6MB
Iteration 900/1250  mem: 164.3/477.6MB
Iteration 1000/1250  mem: 94.1/477.6MB
Iteration 1100/1250  mem: 169.4/477.6MB
Iteration 1200/1250  mem: 91.2/477.6MB
done building BART in 4.007 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 99 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 168.4/477.6MB
Iteration 200/1250  mem: 111.9/477.6MB
Iteration 300/1250  mem: 188.2/477.6MB
Iteration 400/1250  mem: 110.9/477.6MB
Iteration 500/1250  mem: 174.5/477.6MB
Iteration 600/1250  mem: 238.4/477.6MB
Iteration 700/1250  mem: 142.5/477.6MB
Iteration 800/1250  mem: 203.4/477.6MB
Iteration 900/1250  mem: 259.5/477.6MB
Iteration 1000/1250  mem: 153.6/477.6MB
Iteration 1100/1250  mem: 154.9/477.6MB
Iteration 1200/1250  mem: 206.5/477.6MB
done building BART in 6.526 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 100 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 195.9/477.6MB
Iteration 200/1250  mem: 286.3/477.6MB
Iteration 300/1250  mem: 228.6/477.6MB
Iteration 400/1250  mem: 313.5/477.6MB
Iteration 500/1250  mem: 250.9/477.6MB
Iteration 600/1250  mem: 330.2/477.6MB
Iteration 700/1250  mem: 187.3/477.6MB
Iteration 800/1250  mem: 272/477.6MB
Iteration 900/1250  mem: 201.6/477.6MB
Iteration 1000/1250  mem: 283.1/477.6MB
Iteration 1100/1250  mem: 212.6/477.6MB
Iteration 1200/1250  mem: 292.6/477.6MB
done building BART in 6.747 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 55 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 270.5/477.6MB
Iteration 200/1250  mem: 332.4/477.6MB
Iteration 300/1250  mem: 249.4/477.6MB
Iteration 400/1250  mem: 318/477.6MB
Iteration 500/1250  mem: 389.8/477.6MB
Iteration 600/1250  mem: 217.4/477.6MB
Iteration 700/1250  mem: 288/477.6MB
Iteration 800/1250  mem: 217.8/477.6MB
Iteration 900/1250  mem: 290.6/477.6MB
Iteration 1000/1250  mem: 215.3/477.6MB
Iteration 1100/1250  mem: 285.6/477.6MB
Iteration 1200/1250  mem: 354.6/477.6MB
done building BART in 3.948 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 57 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 278.6/477.6MB
Iteration 200/1250  mem: 353.8/477.6MB
Iteration 300/1250  mem: 282.7/477.6MB
Iteration 400/1250  mem: 364.3/477.6MB
Iteration 500/1250  mem: 301.6/477.6MB
Iteration 600/1250  mem: 380.4/477.6MB
Iteration 700/1250  mem: 316.3/477.6MB
Iteration 800/1250  mem: 250.3/477.6MB
Iteration 900/1250  mem: 322/477.6MB
Iteration 1000/1250  mem: 397.1/477.6MB
Iteration 1100/1250  mem: 317.7/477.6MB
Iteration 1200/1250  mem: 385.6/477.6MB
done building BART in 3.846 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 26 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 308.8/477.6MB
Iteration 200/1250  mem: 407.7/477.6MB
Iteration 300/1250  mem: 123.3/477.6MB
Iteration 400/1250  mem: 70.6/477.6MB
Iteration 500/1250  mem: 164.4/477.6MB
Iteration 600/1250  mem: 108.2/477.6MB
Iteration 700/1250  mem: 54.3/477.6MB
Iteration 800/1250  mem: 148/477.6MB
Iteration 900/1250  mem: 92.7/477.6MB
Iteration 1000/1250  mem: 189.6/477.6MB
Iteration 1100/1250  mem: 132.1/477.6MB
Iteration 1200/1250  mem: 74.1/477.6MB
done building BART in 1.738 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 74 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 127.6/477.6MB
Iteration 200/1250  mem: 106.2/477.6MB
Iteration 300/1250  mem: 81.8/477.6MB
Iteration 400/1250  mem: 211.3/477.6MB
Iteration 500/1250  mem: 186.5/477.6MB
Iteration 600/1250  mem: 159.4/477.6MB
Iteration 700/1250  mem: 127.6/477.6MB
Iteration 800/1250  mem: 95.4/477.6MB
Iteration 900/1250  mem: 218.2/477.6MB
Iteration 1000/1250  mem: 179.9/477.6MB
Iteration 1100/1250  mem: 136.4/477.6MB
Iteration 1200/1250  mem: 257.4/477.6MB
done building BART in 4.973 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 57 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 151.7/477.6MB
Iteration 200/1250  mem: 215.5/477.6MB
Iteration 300/1250  mem: 121.3/477.6MB
Iteration 400/1250  mem: 183.2/477.6MB
Iteration 500/1250  mem: 244.2/477.6MB
Iteration 600/1250  mem: 150.3/477.6MB
Iteration 700/1250  mem: 210.1/477.6MB
Iteration 800/1250  mem: 268.9/477.6MB
Iteration 900/1250  mem: 167.1/477.6MB
Iteration 1000/1250  mem: 224.3/477.6MB
Iteration 1100/1250  mem: 278.5/477.6MB
Iteration 1200/1250  mem: 173.7/477.6MB
done building BART in 3.805 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 99 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 226.6/477.6MB
Iteration 200/1250  mem: 158.5/477.6MB
Iteration 300/1250  mem: 238.6/477.6MB
Iteration 400/1250  mem: 161.1/477.6MB
Iteration 500/1250  mem: 230.1/477.6MB
Iteration 600/1250  mem: 299.1/477.6MB
Iteration 700/1250  mem: 201.1/477.6MB
Iteration 800/1250  mem: 154.5/477.6MB
Iteration 900/1250  mem: 210.2/477.6MB
Iteration 1000/1250  mem: 104.4/477.6MB
Iteration 1100/1250  mem: 153.9/477.6MB
Iteration 1200/1250  mem: 204.2/477.6MB
done building BART in 6.75 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 47 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 111/477.6MB
Iteration 200/1250  mem: 127.1/477.6MB
Iteration 300/1250  mem: 144.3/477.6MB
Iteration 400/1250  mem: 163.4/477.6MB
Iteration 500/1250  mem: 185.3/477.6MB
Iteration 600/1250  mem: 204.5/477.6MB
Iteration 700/1250  mem: 223.5/477.6MB
Iteration 800/1250  mem: 242.4/477.6MB
Iteration 900/1250  mem: 260.9/477.6MB
Iteration 1000/1250  mem: 118.7/477.6MB
Iteration 1100/1250  mem: 137/477.6MB
Iteration 1200/1250  mem: 154.6/477.6MB
done building BART in 3.183 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 14 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 149.2/477.6MB
Iteration 200/1250  mem: 202.7/477.6MB
Iteration 300/1250  mem: 254.4/477.6MB
Iteration 400/1250  mem: 144.4/477.6MB
Iteration 500/1250  mem: 196.4/477.6MB
Iteration 600/1250  mem: 248.3/477.6MB
Iteration 700/1250  mem: 137.7/477.6MB
Iteration 800/1250  mem: 188.9/477.6MB
Iteration 900/1250  mem: 242.9/477.6MB
Iteration 1000/1250  mem: 132.9/477.6MB
Iteration 1100/1250  mem: 185.4/477.6MB
Iteration 1200/1250  mem: 237.9/477.6MB
done building BART in 0.857 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 46 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 137.7/477.6MB
Iteration 200/1250  mem: 153.1/477.6MB
Iteration 300/1250  mem: 166.5/477.6MB
Iteration 400/1250  mem: 182/477.6MB
Iteration 500/1250  mem: 200.3/477.6MB
Iteration 600/1250  mem: 216.2/477.6MB
Iteration 700/1250  mem: 231.2/477.6MB
Iteration 800/1250  mem: 247.8/477.6MB
Iteration 900/1250  mem: 262.3/477.6MB
Iteration 1000/1250  mem: 275.7/477.6MB
Iteration 1100/1250  mem: 290.8/477.6MB
Iteration 1200/1250  mem: 302.4/477.6MB
done building BART in 3.106 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 30 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 196.3/477.6MB
Iteration 200/1250  mem: 312.9/477.6MB
Iteration 300/1250  mem: 265.5/477.6MB
Iteration 400/1250  mem: 217.1/477.6MB
Iteration 500/1250  mem: 169.9/477.6MB
Iteration 600/1250  mem: 282.2/477.6MB
Iteration 700/1250  mem: 234.3/477.6MB
Iteration 800/1250  mem: 186.9/477.6MB
Iteration 900/1250  mem: 301.4/477.6MB
Iteration 1000/1250  mem: 253.8/477.6MB
Iteration 1100/1250  mem: 206.9/477.6MB
Iteration 1200/1250  mem: 321/477.6MB
done building BART in 1.984 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 65 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 323.6/477.6MB
Iteration 200/1250  mem: 252.6/477.6MB
Iteration 300/1250  mem: 341/477.6MB
Iteration 400/1250  mem: 281.2/477.6MB
Iteration 500/1250  mem: 67.2/477.6MB
Iteration 600/1250  mem: 169.8/477.6MB
Iteration 700/1250  mem: 126.9/477.6MB
Iteration 800/1250  mem: 93.2/477.6MB
Iteration 900/1250  mem: 199.2/477.6MB
Iteration 1000/1250  mem: 158/477.6MB
Iteration 1100/1250  mem: 260/477.6MB
Iteration 1200/1250  mem: 222.7/477.6MB
done building BART in 4.336 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 61 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 168.4/477.6MB
Iteration 200/1250  mem: 256.8/477.6MB
Iteration 300/1250  mem: 204.5/477.6MB
Iteration 400/1250  mem: 299.5/477.6MB
Iteration 500/1250  mem: 258.4/477.6MB
Iteration 600/1250  mem: 215.9/477.6MB
Iteration 700/1250  mem: 309.2/477.6MB
Iteration 800/1250  mem: 214.4/477.6MB
Iteration 900/1250  mem: 309.4/477.6MB
Iteration 1000/1250  mem: 256.8/477.6MB
Iteration 1100/1250  mem: 201.4/477.6MB
Iteration 1200/1250  mem: 288.6/477.6MB
done building BART in 4.334 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 22 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 212.1/477.6MB
Iteration 200/1250  mem: 297.5/477.6MB
Iteration 300/1250  mem: 228.4/477.6MB
Iteration 400/1250  mem: 314.2/477.6MB
Iteration 500/1250  mem: 247.7/477.6MB
Iteration 600/1250  mem: 333.2/477.6MB
Iteration 700/1250  mem: 267.2/477.6MB
Iteration 800/1250  mem: 352.5/477.6MB
Iteration 900/1250  mem: 284.8/477.6MB
Iteration 1000/1250  mem: 219.1/477.6MB
Iteration 1100/1250  mem: 304.7/477.6MB
Iteration 1200/1250  mem: 238.3/477.6MB
done building BART in 1.477 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 38 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 296.3/477.6MB
Iteration 200/1250  mem: 289.2/477.6MB
Iteration 300/1250  mem: 284.8/477.6MB
Iteration 400/1250  mem: 280.4/477.6MB
Iteration 500/1250  mem: 275.6/477.6MB
Iteration 600/1250  mem: 269/477.6MB
Iteration 700/1250  mem: 261.4/477.6MB
Iteration 800/1250  mem: 253.4/477.6MB
Iteration 900/1250  mem: 396/477.6MB
Iteration 1000/1250  mem: 389.8/477.6MB
Iteration 1100/1250  mem: 379.2/477.6MB
Iteration 1200/1250  mem: 371.4/477.6MB
done building BART in 2.416 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 37 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 302.1/477.6MB
Iteration 200/1250  mem: 289.2/477.6MB
Iteration 300/1250  mem: 427.4/477.6MB
Iteration 400/1250  mem: 416.8/477.6MB
Iteration 500/1250  mem: 405.7/477.6MB
Iteration 600/1250  mem: 394.1/477.6MB
Iteration 700/1250  mem: 384.3/477.6MB
Iteration 800/1250  mem: 370.9/477.6MB
Iteration 900/1250  mem: 360/477.6MB
Iteration 1000/1250  mem: 346.6/477.6MB
Iteration 1100/1250  mem: 335.8/477.6MB
Iteration 1200/1250  mem: 321.9/477.6MB
done building BART in 2.513 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 79 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 151.1/477.6MB
Iteration 200/1250  mem: 149.5/477.6MB
Iteration 300/1250  mem: 146.8/477.6MB
Iteration 400/1250  mem: 141.8/477.6MB
Iteration 500/1250  mem: 135.1/477.6MB
Iteration 600/1250  mem: 119.8/477.6MB
Iteration 700/1250  mem: 104.8/477.6MB
Iteration 800/1250  mem: 85/477.6MB
Iteration 900/1250  mem: 62.4/477.6MB
Iteration 1000/1250  mem: 199.2/477.6MB
Iteration 1100/1250  mem: 173.2/477.6MB
Iteration 1200/1250  mem: 146.9/477.6MB
done building BART in 5.418 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 44 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 169.7/477.6MB
Iteration 200/1250  mem: 174.9/477.6MB
Iteration 300/1250  mem: 184.3/477.6MB
Iteration 400/1250  mem: 195.3/477.6MB
Iteration 500/1250  mem: 205.2/477.6MB
Iteration 600/1250  mem: 217.5/477.6MB
Iteration 700/1250  mem: 226.1/477.6MB
Iteration 800/1250  mem: 237.3/477.6MB
Iteration 900/1250  mem: 86.5/477.6MB
Iteration 1000/1250  mem: 96.9/477.6MB
Iteration 1100/1250  mem: 107.6/477.6MB
Iteration 1200/1250  mem: 115/477.6MB
done building BART in 2.915 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 58 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 131.5/477.6MB
Iteration 200/1250  mem: 195.6/477.6MB
Iteration 300/1250  mem: 100.3/477.6MB
Iteration 400/1250  mem: 162.6/477.6MB
Iteration 500/1250  mem: 226.2/477.6MB
Iteration 600/1250  mem: 126/477.6MB
Iteration 700/1250  mem: 186.7/477.6MB
Iteration 800/1250  mem: 247.9/477.6MB
Iteration 900/1250  mem: 143.7/477.6MB
Iteration 1000/1250  mem: 201.4/477.6MB
Iteration 1100/1250  mem: 259.9/477.6MB
Iteration 1200/1250  mem: 153.6/477.6MB
done building BART in 3.9 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 99 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 202/477.6MB
Iteration 200/1250  mem: 268.2/477.6MB
Iteration 300/1250  mem: 182.1/477.6MB
Iteration 400/1250  mem: 246.9/477.6MB
Iteration 500/1250  mem: 311.8/477.6MB
Iteration 600/1250  mem: 217.1/477.6MB
Iteration 700/1250  mem: 274.5/477.6MB
Iteration 800/1250  mem: 333.7/477.6MB
Iteration 900/1250  mem: 119.6/477.6MB
Iteration 1000/1250  mem: 174.1/477.6MB
Iteration 1100/1250  mem: 228.4/477.6MB
Iteration 1200/1250  mem: 124.5/477.6MB
done building BART in 6.586 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 100 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 253.3/477.6MB
Iteration 200/1250  mem: 203.6/477.6MB
Iteration 300/1250  mem: 290.8/477.6MB
Iteration 400/1250  mem: 240.1/477.6MB
Iteration 500/1250  mem: 321.4/477.6MB
Iteration 600/1250  mem: 256.3/477.6MB
Iteration 700/1250  mem: 339.1/477.6MB
Iteration 800/1250  mem: 270.3/477.6MB
Iteration 900/1250  mem: 247.1/477.6MB
Iteration 1000/1250  mem: 178.5/477.6MB
Iteration 1100/1250  mem: 255.6/477.6MB
Iteration 1200/1250  mem: 336/477.6MB
done building BART in 6.757 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 55 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 300.7/477.6MB
Iteration 200/1250  mem: 216.1/477.6MB
Iteration 300/1250  mem: 278.9/477.6MB
Iteration 400/1250  mem: 353.4/477.6MB
Iteration 500/1250  mem: 281.6/477.6MB
Iteration 600/1250  mem: 352.9/477.6MB
Iteration 700/1250  mem: 282.5/477.6MB
Iteration 800/1250  mem: 356.4/477.6MB
Iteration 900/1250  mem: 425/477.6MB
Iteration 1000/1250  mem: 345.4/477.6MB
Iteration 1100/1250  mem: 415.7/477.6MB
Iteration 1200/1250  mem: 221.7/523.8MB
done building BART in 4.045 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 57 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 283.4/523.8MB
Iteration 200/1250  mem: 350.3/513.3MB
Iteration 300/1250  mem: 265.5/510.1MB
Iteration 400/1250  mem: 335/521.7MB
Iteration 500/1250  mem: 257.9/521.7MB
Iteration 600/1250  mem: 330.1/510.1MB
Iteration 700/1250  mem: 254.4/521.1MB
Iteration 800/1250  mem: 325.5/522.2MB
Iteration 900/1250  mem: 247.5/522.7MB
Iteration 1000/1250  mem: 315.6/522.7MB
Iteration 1100/1250  mem: 383/523.8MB
Iteration 1200/1250  mem: 297.6/524.8MB
done building BART in 3.85 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 26 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 367.3/524.8MB
Iteration 200/1250  mem: 311.8/525.3MB
Iteration 300/1250  mem: 250.1/525.3MB
Iteration 400/1250  mem: 342.4/525.3MB
Iteration 500/1250  mem: 282.5/525.3MB
Iteration 600/1250  mem: 374.1/525.3MB
Iteration 700/1250  mem: 313.7/525.9MB
Iteration 800/1250  mem: 406.5/525.9MB
Iteration 900/1250  mem: 342.9/525.9MB
Iteration 1000/1250  mem: 279.9/526.4MB
Iteration 1100/1250  mem: 374.7/526.4MB
Iteration 1200/1250  mem: 311.8/528MB
done building BART in 1.555 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 74 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 357.8/522.7MB
Iteration 200/1250  mem: 331.2/525.3MB
Iteration 300/1250  mem: 302.4/524.3MB
Iteration 400/1250  mem: 431.5/524.8MB
Iteration 500/1250  mem: 404.3/525.3MB
Iteration 600/1250  mem: 374.1/526.4MB
Iteration 700/1250  mem: 343.1/526.9MB
Iteration 800/1250  mem: 307.3/528MB
Iteration 900/1250  mem: 430.4/529MB
Iteration 1000/1250  mem: 388.1/529MB
Iteration 1100/1250  mem: 345.2/529.5MB
Iteration 1200/1250  mem: 465.7/529.5MB
done building BART in 4.968 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 57 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 364.3/522.7MB
Iteration 200/1250  mem: 423.5/526.4MB
Iteration 300/1250  mem: 327.1/526.4MB
Iteration 400/1250  mem: 389.6/525.9MB
Iteration 500/1250  mem: 447/526.4MB
Iteration 600/1250  mem: 349.8/527.4MB
Iteration 700/1250  mem: 408.9/527.4MB
Iteration 800/1250  mem: 465.3/527.4MB
Iteration 900/1250  mem: 362.8/528.5MB
Iteration 1000/1250  mem: 420.8/528.5MB
Iteration 1100/1250  mem: 474.3/529MB
Iteration 1200/1250  mem: 369.5/529.5MB
done building BART in 3.886 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 99 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 105.1/477.6MB
Iteration 200/1250  mem: 178.5/477.6MB
Iteration 300/1250  mem: 92.9/477.6MB
Iteration 400/1250  mem: 162.5/477.6MB
Iteration 500/1250  mem: 72/477.6MB
Iteration 600/1250  mem: 129.5/477.6MB
Iteration 700/1250  mem: 189.4/477.6MB
Iteration 800/1250  mem: 79.9/477.6MB
Iteration 900/1250  mem: 132.7/477.6MB
Iteration 1000/1250  mem: 182.8/477.6MB
Iteration 1100/1250  mem: 232.7/477.6MB
Iteration 1200/1250  mem: 115.1/477.6MB
done building BART in 6.742 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 47 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 180.8/477.6MB
Iteration 200/1250  mem: 201.6/477.6MB
Iteration 300/1250  mem: 218.2/477.6MB
Iteration 400/1250  mem: 238.3/477.6MB
Iteration 500/1250  mem: 258.7/477.6MB
Iteration 600/1250  mem: 118.5/477.6MB
Iteration 700/1250  mem: 139.4/477.6MB
Iteration 800/1250  mem: 157.4/477.6MB
Iteration 900/1250  mem: 175.3/477.6MB
Iteration 1000/1250  mem: 193.8/477.6MB
Iteration 1100/1250  mem: 208.4/477.6MB
Iteration 1200/1250  mem: 226.5/477.6MB
done building BART in 3.116 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 14 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 220.8/477.6MB
Iteration 200/1250  mem: 273.4/477.6MB
Iteration 300/1250  mem: 164.2/477.6MB
Iteration 400/1250  mem: 214.3/477.6MB
Iteration 500/1250  mem: 267.1/477.6MB
Iteration 600/1250  mem: 154.7/477.6MB
Iteration 700/1250  mem: 207.9/477.6MB
Iteration 800/1250  mem: 258.2/477.6MB
Iteration 900/1250  mem: 149.4/477.6MB
Iteration 1000/1250  mem: 202.1/477.6MB
Iteration 1100/1250  mem: 254.7/477.6MB
Iteration 1200/1250  mem: 142.7/477.6MB
done building BART in 0.833 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 46 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 205.9/477.6MB
Iteration 200/1250  mem: 220.5/477.6MB
Iteration 300/1250  mem: 236.5/477.6MB
Iteration 400/1250  mem: 255.3/477.6MB
Iteration 500/1250  mem: 271.5/477.6MB
Iteration 600/1250  mem: 289.9/477.6MB
Iteration 700/1250  mem: 147.6/477.6MB
Iteration 800/1250  mem: 162.5/477.6MB
Iteration 900/1250  mem: 180.3/477.6MB
Iteration 1000/1250  mem: 191.8/477.6MB
Iteration 1100/1250  mem: 206.4/477.6MB
Iteration 1200/1250  mem: 221.9/477.6MB
done building BART in 3.084 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 30 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 278.3/477.6MB
Iteration 200/1250  mem: 230.8/477.6MB
Iteration 300/1250  mem: 182.3/477.6MB
Iteration 400/1250  mem: 296.1/477.6MB
Iteration 500/1250  mem: 249.5/477.6MB
Iteration 600/1250  mem: 199.1/477.6MB
Iteration 700/1250  mem: 313.5/477.6MB
Iteration 800/1250  mem: 266.3/477.6MB
Iteration 900/1250  mem: 218.7/477.6MB
Iteration 1000/1250  mem: 171/477.6MB
Iteration 1100/1250  mem: 286.5/477.6MB
Iteration 1200/1250  mem: 235.9/477.6MB
done building BART in 1.973 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 65 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 245.7/477.6MB
Iteration 200/1250  mem: 334.7/477.6MB
Iteration 300/1250  mem: 269.1/477.6MB
Iteration 400/1250  mem: 210.6/477.6MB
Iteration 500/1250  mem: 315.3/477.6MB
Iteration 600/1250  mem: 119.8/477.6MB
Iteration 700/1250  mem: 90.5/477.6MB
Iteration 800/1250  mem: 193.6/477.6MB
Iteration 900/1250  mem: 158.9/477.6MB
Iteration 1000/1250  mem: 121.3/477.6MB
Iteration 1100/1250  mem: 229.2/477.6MB
Iteration 1200/1250  mem: 193/477.6MB
done building BART in 4.386 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 61 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 290.5/477.6MB
Iteration 200/1250  mem: 232.4/477.6MB
Iteration 300/1250  mem: 183.5/477.6MB
Iteration 400/1250  mem: 275.5/477.6MB
Iteration 500/1250  mem: 228.4/477.6MB
Iteration 600/1250  mem: 320.1/477.6MB
Iteration 700/1250  mem: 271.9/477.6MB
Iteration 800/1250  mem: 219.1/477.6MB
Iteration 900/1250  mem: 306.7/477.6MB
Iteration 1000/1250  mem: 253.9/477.6MB
Iteration 1100/1250  mem: 343.8/477.6MB
Iteration 1200/1250  mem: 232.4/521.7MB
done building BART in 4.418 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 22 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 304.3/523.8MB
Iteration 200/1250  mem: 242.1/523.8MB
Iteration 300/1250  mem: 324.6/523.8MB
Iteration 400/1250  mem: 257.3/521.7MB
Iteration 500/1250  mem: 340.8/521.7MB
Iteration 600/1250  mem: 277.3/522.7MB
Iteration 700/1250  mem: 211.4/521.7MB
Iteration 800/1250  mem: 296.5/521.7MB
Iteration 900/1250  mem: 233.5/522.2MB
Iteration 1000/1250  mem: 319.2/522.2MB
Iteration 1100/1250  mem: 255.8/522.2MB
Iteration 1200/1250  mem: 338.9/522.2MB
done building BART in 1.493 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 38 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 251.5/521.1MB
Iteration 200/1250  mem: 246.8/521.7MB
Iteration 300/1250  mem: 241.3/521.1MB
Iteration 400/1250  mem: 236.6/521.7MB
Iteration 500/1250  mem: 232.2/522.2MB
Iteration 600/1250  mem: 374.9/522.2MB
Iteration 700/1250  mem: 368.7/522.7MB
Iteration 800/1250  mem: 363.9/524.3MB
Iteration 900/1250  mem: 356.5/519MB
Iteration 1000/1250  mem: 349.5/523.8MB
Iteration 1100/1250  mem: 342.2/523.8MB
Iteration 1200/1250  mem: 335/524.3MB
done building BART in 2.394 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 37 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 270.5/524.3MB
Iteration 200/1250  mem: 410/524.3MB
Iteration 300/1250  mem: 399.1/524.8MB
Iteration 400/1250  mem: 384.7/524.3MB
Iteration 500/1250  mem: 374.2/524.8MB
Iteration 600/1250  mem: 363.9/524.8MB
Iteration 700/1250  mem: 349.7/524.8MB
Iteration 800/1250  mem: 339.1/524.3MB
Iteration 900/1250  mem: 328.3/524.8MB
Iteration 1000/1250  mem: 314.3/524.8MB
Iteration 1100/1250  mem: 299.9/525.3MB
Iteration 1200/1250  mem: 285.9/525.3MB
done building BART in 2.48 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 79 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 381.2/522.7MB
Iteration 200/1250  mem: 376.3/523.8MB
Iteration 300/1250  mem: 369.7/523.8MB
Iteration 400/1250  mem: 362.5/524.8MB
Iteration 500/1250  mem: 357.4/525.9MB
Iteration 600/1250  mem: 342.1/528MB
Iteration 700/1250  mem: 326.2/528MB
Iteration 800/1250  mem: 467.3/528MB
Iteration 900/1250  mem: 446.4/529MB
Iteration 1000/1250  mem: 423.8/526.9MB
Iteration 1100/1250  mem: 400.1/529.5MB
Iteration 1200/1250  mem: 374.5/530.1MB
done building BART in 5.338 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 44 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 394.6/531.1MB
Iteration 200/1250  mem: 396.5/525.9MB
Iteration 300/1250  mem: 405/521.1MB
Iteration 400/1250  mem: 416/528MB
Iteration 500/1250  mem: 424.8/521.1MB
Iteration 600/1250  mem: 435.6/527.4MB
Iteration 700/1250  mem: 443.2/527.4MB
Iteration 800/1250  mem: 451.8/528MB
Iteration 900/1250  mem: 462.4/528MB
Iteration 1000/1250  mem: 470.6/528.5MB
Iteration 1100/1250  mem: 477.8/528.5MB
Iteration 1200/1250  mem: 486.1/528.5MB
done building BART in 2.913 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 58 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 493.7/524.8MB
Iteration 200/1250  mem: 68.6/477.6MB
Iteration 300/1250  mem: 135.3/477.6MB
Iteration 400/1250  mem: 36.8/477.6MB
Iteration 500/1250  mem: 99.1/477.6MB
Iteration 600/1250  mem: 156.6/477.6MB
Iteration 700/1250  mem: 57.1/477.6MB
Iteration 800/1250  mem: 114.9/477.6MB
Iteration 900/1250  mem: 169/477.6MB
Iteration 1000/1250  mem: 64.2/477.6MB
Iteration 1100/1250  mem: 122.2/477.6MB
Iteration 1200/1250  mem: 177.5/477.6MB
done building BART in 3.953 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 99 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 213.9/477.6MB
Iteration 200/1250  mem: 146.7/477.6MB
Iteration 300/1250  mem: 212.9/477.6MB
Iteration 400/1250  mem: 125.2/477.6MB
Iteration 500/1250  mem: 187.1/477.6MB
Iteration 600/1250  mem: 244.3/477.6MB
Iteration 700/1250  mem: 151.3/477.6MB
Iteration 800/1250  mem: 206.6/477.6MB
Iteration 900/1250  mem: 265.5/477.6MB
Iteration 1000/1250  mem: 161.3/477.6MB
Iteration 1100/1250  mem: 211.1/477.6MB
Iteration 1200/1250  mem: 260.4/477.6MB
done building BART in 6.361 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 44 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 260.7/477.6MB
Iteration 200/1250  mem: 201.6/477.6MB
Iteration 300/1250  mem: 302.2/477.6MB
Iteration 400/1250  mem: 252.3/477.6MB
Iteration 500/1250  mem: 196.8/477.6MB
Iteration 600/1250  mem: 298.4/477.6MB
Iteration 700/1250  mem: 241.6/477.6MB
Iteration 800/1250  mem: 339.9/477.6MB
Iteration 900/1250  mem: 282.6/477.6MB
Iteration 1000/1250  mem: 219.9/477.6MB
Iteration 1100/1250  mem: 316.3/477.6MB
Iteration 1200/1250  mem: 250.6/477.6MB
done building BART in 4.227 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
Bayesian Additive Regression Trees 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  num_trees  k          alpha      beta       nu         RMSE      Rsquared   
   14        2.7148234  0.9331791  1.5136072  3.1485015  1.030273  0.004189625
   22        3.2874624  0.9166493  3.6077072  1.1986053  1.025563  0.005280245
   26        0.7580680  0.9652392  0.9253685  4.2743589  1.076260  0.002879682
   30        2.6777293  0.9188500  2.6047989  2.2437451  1.032651  0.006300482
   37        2.6285918  0.9997581  3.8290755  0.1679372  1.034101  0.006233754
   38        2.6264457  0.9606071  0.8137340  1.1011356  1.046094  0.003258795
   44        0.4393341  0.9613964  0.1103416  2.9661700  1.020150  0.003496434
   46        4.6229908  0.9492211  3.5759217  2.2139172  1.024991  0.007309700
   47        3.1868646  0.9753453  3.4396197  3.9470110  1.033494  0.007000589
   55        2.3059236  0.9458608  0.4781301  2.4416929  1.077319  0.004575642
   57        1.5133409  0.9297123  3.6743977  4.6878873  1.053476  0.006249079
   57        4.6431488  0.9726740  2.7253831  3.5793098  1.025048  0.006471906
   58        4.3611880  0.9518751  2.5295225  1.4421024  1.026539  0.006500980
   61        1.8597112  0.9747610  0.2845036  2.9219564  1.082799  0.004735189
   65        3.4424417  0.9022043  0.5550034  2.7711046  1.044500  0.004883954
   74        4.1509854  0.9491896  3.9553628  2.8230027  1.028312  0.007530178
   79        3.9809423  0.9679711  2.9539714  2.7967521  1.029712  0.006533056
   99        0.7756319  0.9842955  1.5071722  1.1110782  1.127730  0.009703582
   99        1.3121162  0.9360328  3.4837476  0.8268274  1.069763  0.007709198
  100        2.1659360  0.9700233  0.8567971  0.8428567  1.064397  0.003392534
  MAE        Selected
  0.8162766          
  0.8121154          
  0.8587666          
  0.8185648          
  0.8206100          
  0.8305765          
  0.8074403  *       
  0.8114262          
  0.8191629          
  0.8595459          
  0.8365287          
  0.8110378          
  0.8125849          
  0.8634111          
  0.8251163          
  0.8141006          
  0.8155518          
  0.8994524          
  0.8517983          
  0.8451067          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were num_trees = 44, k = 0.4393341, alpha
 = 0.9613964, beta = 0.1103416 and nu = 2.96617.
[1] "Mon Mar 05 08:14:40 2018"
Error in investigate_var_importance(object, plot = FALSE) : 
  could not find function "investigate_var_importance"
Error : package arm is required
Error : package arm is required
Error : package arm is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 08:14:52 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "bayesglm"                
t=100, m=1
t=200, m=5
t=300, m=5
t=400, m=5
t=500, m=3
t=600, m=3
t=700, m=4
t=800, m=5
t=900, m=6
t=100, m=2
t=200, m=2
t=300, m=4
t=400, m=2
t=500, m=6
t=600, m=6
t=700, m=4
t=800, m=3
t=900, m=5
t=100, m=3
t=200, m=4
t=300, m=4
t=400, m=4
t=500, m=5
t=600, m=2
t=700, m=3
t=800, m=6
t=900, m=5
t=100, m=5
t=200, m=4
t=300, m=1
t=400, m=2
t=500, m=8
t=600, m=7
t=700, m=5
t=800, m=3
t=900, m=6
The Bayesian lasso 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  sparsity    RMSE       Rsquared     MAE        Selected
  0.04423375  0.9997737  0.002272782  0.7913982          
  0.13484489  0.9997737  0.002272782  0.7913982          
  0.17607728  0.9997737  0.002272782  0.7913982          
  0.23010151  0.9997737  0.002272782  0.7913982          
  0.30582363  0.9997737  0.002272782  0.7913982          
  0.31743816  0.9997737  0.002272782  0.7913982          
  0.37748590  0.9997737  0.002272782  0.7913982          
  0.39695999  0.9997737  0.002272782  0.7913982          
  0.40861725  0.9997737  0.002272782  0.7913982          
  0.50541101  0.9996816  0.002734439  0.7912566          
  0.51879696  0.9997882  0.006229406  0.7914058          
  0.52011220  0.9997882  0.006229406  0.7914058          
  0.52839347  0.9997868  0.010318515  0.7914066          
  0.56068793  0.9995196          NaN  0.7913172          
  0.60951029  0.9995196          NaN  0.7913172          
  0.70553546  0.9995196          NaN  0.7913172          
  0.76703082  0.9995196          NaN  0.7913172          
  0.97967031  0.9995196          NaN  0.7913172          
  0.98457705  0.9995196          NaN  0.7913172          
  0.99928846  0.9995196          NaN  0.7913172  *       

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was sparsity = 0.9992885.
[1] "Mon Mar 05 08:15:15 2018"
t=100, m=4
t=200, m=3
t=300, m=5
t=400, m=6
t=500, m=4
t=600, m=5
t=700, m=2
t=800, m=4
t=900, m=7
t=100, m=4
t=200, m=5
t=300, m=3
t=400, m=5
t=500, m=7
t=600, m=4
t=700, m=5
t=800, m=1
t=900, m=7
t=100, m=1
t=200, m=4
t=300, m=7
t=400, m=4
t=500, m=8
t=600, m=4
t=700, m=4
t=800, m=5
t=900, m=4
t=100, m=1
t=200, m=4
t=300, m=5
t=400, m=1
t=500, m=2
t=600, m=7
t=700, m=5
t=800, m=6
t=900, m=7
Bayesian Ridge Regression (Model Averaged) 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  0.999795  0.001751765  0.7913596

[1] "Mon Mar 05 08:15:36 2018"
t=100, m=2
t=200, m=3
t=300, m=5
t=400, m=3
t=500, m=5
t=600, m=4
t=700, m=7
t=800, m=3
t=900, m=5
t=100, m=6
t=200, m=4
t=300, m=6
t=400, m=3
t=500, m=6
t=600, m=4
t=700, m=3
t=800, m=5
t=900, m=3
t=100, m=6
t=200, m=3
t=300, m=6
t=400, m=6
t=500, m=5
t=600, m=5
t=700, m=4
t=800, m=5
t=900, m=7
t=100, m=4
t=200, m=4
t=300, m=6
t=400, m=3
t=500, m=5
t=600, m=5
t=700, m=5
t=800, m=5
t=900, m=5
Bayesian Ridge Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE       Rsquared     MAE      
  0.9995685  0.001293952  0.7913729

[1] "Mon Mar 05 08:15:58 2018"
Boosted Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  nu          mstop  RMSE      Rsquared     MAE        Selected
  0.05363222  189    1.007320  0.001544343  0.7960288          
  0.09181655   88    1.006615  0.001577990  0.7954135  *       
  0.09392070  492    1.010037  0.001376674  0.7985378          
  0.15819152  489    1.010077  0.001375079  0.7985754          
  0.18229824  260    1.010050  0.001376447  0.7985506          
  0.22379340  280    1.010075  0.001375139  0.7985732          
  0.26047913  499    1.010078  0.001375038  0.7985761          
  0.27724964  253    1.010077  0.001375083  0.7985753          
  0.31564820  159    1.010067  0.001375515  0.7985660          
  0.31590530  153    1.010064  0.001375549  0.7985634          
  0.32179197  115    1.010013  0.001376127  0.7985172          
  0.32623584   23    1.007126  0.001907901  0.7958205          
  0.38278637  204    1.010078  0.001375045  0.7985760          
  0.39483800   68    1.009863  0.001382981  0.7983790          
  0.41340452  305    1.010078  0.001375038  0.7985761          
  0.47791689  383    1.010078  0.001375038  0.7985761          
  0.49828805  353    1.010078  0.001375038  0.7985761          
  0.52347032  264    1.010078  0.001375038  0.7985761          
  0.55483430  199    1.010078  0.001375038  0.7985761          
  0.55724923  259    1.010078  0.001375038  0.7985761          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mstop = 88 and nu = 0.09181655.
[1] "Mon Mar 05 08:17:32 2018"
Conditional Inference Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  mtry  RMSE       Rsquared     MAE        Selected
  1     0.9999597  0.003607325  0.7918883  *       
  2     1.0002616  0.002933232  0.7923619          
  3     1.0007895  0.003391519  0.7929840          
  4     1.0014247  0.003205913  0.7938119          
  5     1.0020664  0.003234909  0.7944484          
  6     1.0027072  0.004206197  0.7954850          
  7     1.0034530  0.003280883  0.7963783          
  9     1.0052831  0.004127061  0.7980849          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 1.
[1] "Mon Mar 05 08:19:06 2018"
Error in varimp(object, ...) : could not find function "varimp"
In addition: Warning message:
In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Conditional Inference Tree 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  mincriterion  RMSE       Rsquared     MAE        Selected
  0.04423375    1.1277554  0.005643753  0.8960016          
  0.13484489    1.0953340  0.003525612  0.8672073          
  0.17607728    1.0794537  0.002582994  0.8534408          
  0.23010151    1.0669680  0.001958855  0.8442757          
  0.30582363    1.0141707  0.013527187  0.8005223          
  0.31743816    1.0141707  0.013527187  0.8005223          
  0.37748590    1.0141707  0.013527187  0.8005223          
  0.39695999    1.0070938  0.007840065  0.7963106          
  0.40861725    1.0091749  0.003497909  0.7976397          
  0.50541101    0.9995283          NaN  0.7913185          
  0.51879696    0.9995283          NaN  0.7913185          
  0.52011220    0.9995283          NaN  0.7913185          
  0.52839347    0.9995283          NaN  0.7913185          
  0.56068793    0.9995283          NaN  0.7913185          
  0.60951029    0.9995283          NaN  0.7913185          
  0.70553546    0.9995283          NaN  0.7913185          
  0.76703082    0.9995283          NaN  0.7913185          
  0.97967031    0.9995283          NaN  0.7913185          
  0.98457705    0.9995283          NaN  0.7913185          
  0.99928846    0.9995283          NaN  0.7913185  *       

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mincriterion = 0.9992885.
[1] "Mon Mar 05 08:19:21 2018"
Conditional Inference Tree 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  maxdepth  mincriterion  RMSE       Rsquared     MAE        Selected
   1        0.54296467    0.9995283          NaN  0.7913185  *       
   3        0.15161360    1.0405222  0.001545834  0.8241111          
   3        0.65749249    0.9995283          NaN  0.7913185          
   4        0.53554587    0.9995283          NaN  0.7913185          
   5        0.52528915    0.9995283          NaN  0.7913185          
   5        0.52571837    0.9995283          NaN  0.7913185          
   6        0.08786682    1.1108256  0.003592859  0.8825632          
   6        0.92459816    0.9995283          NaN  0.7913185          
   7        0.63737291    0.9995283          NaN  0.7913185          
   8        0.30266818    1.0141707  0.013527187  0.8005223          
   8        0.46118471    1.0091749  0.003497909  0.7976397          
   8        0.87223760    0.9995283          NaN  0.7913185          
   8        0.92862976    0.9995283          NaN  0.7913185          
   9        0.37194224    1.0141707  0.013527187  0.8005223          
  10        0.68848834    0.9995283          NaN  0.7913185          
  11        0.83019707    0.9995283          NaN  0.7913185          
  12        0.79618846    0.9995283          NaN  0.7913185          
  15        0.15512637    1.0864109  0.002097950  0.8586013          
  15        0.26242324    1.0187398  0.010223430  0.8049972          
  15        0.43318719    1.0091749  0.003497909  0.7976397          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were maxdepth = 1 and mincriterion
 = 0.5429647.
[1] "Mon Mar 05 08:19:36 2018"
Cubist 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  committees  neighbors  RMSE      Rsquared      MAE        Selected
   9          3          1.148873  0.0002659785  0.9202986          
  16          1          1.345676  0.0016532818  1.0750963          
  16          9          1.053958  0.0004621731  0.8395683          
  27          9          1.054039  0.0004605566  0.8396303          
  31          5          1.097118  0.0003300500  0.8718994          
  38          5          1.097078  0.0003295032  0.8718727          
  44          9          1.054011  0.0004610974  0.8396078          
  47          5          1.097119  0.0003300631  0.8718993          
  53          3          1.148876  0.0002662241  0.9202970          
  54          2          1.204441  0.0002692538  0.9685506          
  55          0          1.001203  0.0003470882  0.7900776  *       
  64          4          1.119053  0.0006707779  0.8943050          
  66          1          1.345770  0.0016563034  1.0751633          
  69          6          1.082079  0.0004227430  0.8603161          
  80          7          1.073943  0.0009470213  0.8563147          
  84          7          1.073944  0.0009469764  0.8563150          
  88          5          1.097101  0.0003298359  0.8718878          
  93          3          1.148877  0.0002662458  0.9202969          
  93          5          1.097119  0.0003300756  0.8718993          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were committees = 55 and neighbors = 0.
[1] "Mon Mar 05 08:21:37 2018"
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
Stacked AutoEncoder Deep Neural Network 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  layer1  layer2  layer3  hidden_dropout  visible_dropout  RMSE    
   2      12       8      0.26488126      0.4407902        1.209553
   4      14       5      0.63134877      0.1678047        1.035078
   5       4      14      0.16193949      0.5984102        1.115997
   6      12       5      0.45583982      0.3141243        1.048529
   7      11      20      0.67008822      0.0235112        1.024738
   8      11      13      0.14240345      0.1541590        1.125953
   9       3      13      0.01930977      0.4152638        1.086290
   9      14      16      0.60193345      0.5525815        1.102361
   9      19      11      0.62578630      0.3099484        1.075111
  11       7       7      0.64301960      0.6563042        1.001339
  11      10      10      0.08367276      0.3418370        1.006988
  11      19      15      0.47694203      0.5011034        1.017232
  12       9      16      0.04978813      0.4090739        1.085346
  12      18      11      0.44266644      0.2018943        1.226628
  13      15       2      0.09712559      0.3879546        1.019666
  15      17      11      0.69218849      0.3952204        1.126858
  16      17      14      0.51694499      0.3915453        1.036844
  20       4      18      0.26375513      0.1555509        1.214200
  20       6       8      0.60965584      0.1157558        1.063334
  20      10      15      0.14993949      0.1179999        1.098378
  Rsquared      MAE        Selected
  0.0039986811  0.9821999          
  0.0014457049  0.8224222          
  0.0009966111  0.8983936          
  0.0035782958  0.8279525          
  0.0010956139  0.8078590          
  0.0043805193  0.9018666          
  0.0060810075  0.8656307          
  0.0122119222  0.8790570          
  0.0023685344  0.8499651          
  0.0026549884  0.7909349  *       
  0.0092848336  0.7962749          
  0.0056371365  0.8005112          
  0.0021857540  0.8689887          
  0.0125517593  0.9968071          
  0.0037608982  0.8026244          
  0.0033744085  0.9090287          
  0.0069202618  0.8200185          
  0.0068224749  0.9807989          
  0.0011961361  0.8391516          
  0.0058036412  0.8808322          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were layer1 = 11, layer2 = 7, layer3 =
 7, hidden_dropout = 0.6430196 and visible_dropout = 0.6563042.
[1] "Mon Mar 05 08:21:57 2018"
Multivariate Adaptive Regression Spline 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  degree  nprune  RMSE      Rsquared      MAE        Selected
  1        4      1.016916  0.0001894066  0.8065464          
  1        6      1.018668  0.0001414516  0.8083371          
  1        8      1.018668  0.0001414516  0.8083371          
  1        9      1.018668  0.0001414516  0.8083371          
  1       14      1.018668  0.0001414516  0.8083371          
  2        2      1.007562  0.0036521017  0.7982832  *       
  2        3      1.012411  0.0002688947  0.8026036          
  2        4      1.015956  0.0002529510  0.8050346          
  2        5      1.022081  0.0017806598  0.8092520          
  2        6      1.032231  0.0019250382  0.8190227          
  2        7      1.036136  0.0016064156  0.8239122          
  2        8      1.036136  0.0016064156  0.8239122          
  2        9      1.036136  0.0016064156  0.8239122          
  2       11      1.036136  0.0016064156  0.8239122          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nprune = 2 and degree = 2.
[1] "Mon Mar 05 08:22:13 2018"
Loading required package: MASS
Extreme Learning Machine 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  nhid  actfun   RMSE      Rsquared      MAE        Selected
   1    purelin  1.002079  0.0034946003  0.7942285          
   3    purelin  1.005188  0.0026587733  0.7966366          
   4    sin      1.001437  0.0031268892  0.7920367  *       
   5    purelin  1.007169  0.0023315849  0.7991652          
   6    purelin  1.007663  0.0042212837  0.7968844          
   7    purelin  1.006038  0.0012252458  0.7950814          
   8    purelin  1.008880  0.0012941884  0.7971420          
   8    sin      1.025258  0.0087359889  0.8128526          
   8    tansig   1.015238  0.0032508570  0.8074944          
  10    radbas   1.011124  0.0014140019  0.8026293          
  10    tansig   1.009489  0.0058764313  0.8018957          
  11    radbas   1.010774  0.0007186635  0.8067839          
  11    tansig   1.008537  0.0043092378  0.8049071          
  12    purelin  1.010177  0.0013913804  0.7986530          
  14    tansig   1.004911  0.0017398873  0.7918409          
  15    tansig   1.009369  0.0012216372  0.8012131          
  19    radbas   1.014012  0.0033471532  0.8065881          
  19    sin      1.033190  0.0058964371  0.8170566          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nhid = 4 and actfun = sin.
[1] "Mon Mar 05 08:22:26 2018"
Elasticnet 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  lambda        fraction    RMSE      Rsquared     MAE        Selected
  1.842479e-05  0.54296467  1.005165  0.001968707  0.7938879          
  6.442721e-05  0.65749249  1.006420  0.001648940  0.7951559          
  1.138842e-04  0.15161360  1.000766  0.004057693  0.7911136          
  2.402199e-04  0.53554587  1.005086  0.001996730  0.7938201          
  6.838200e-04  0.52571837  1.004982  0.002035005  0.7937303          
  8.028400e-04  0.52528915  1.004977  0.002036683  0.7937263          
  1.840414e-03  0.08786682  1.000276  0.003951502  0.7912187  *       
  2.408574e-03  0.92459816  1.009278  0.001440072  0.7977708          
  2.829460e-03  0.63737291  1.006186  0.001694739  0.7949281          
  1.077621e-02  0.46118471  1.004318  0.002328480  0.7931872          
  1.296528e-02  0.92862976  1.009313  0.001436713  0.7978044          
  1.320302e-02  0.30266818  1.002539  0.003357666  0.7921849          
  1.480338e-02  0.87223760  1.008679  0.001475947  0.7971922          
  2.312744e-02  0.37194224  1.003275  0.002825180  0.7925744          
  4.540062e-02  0.68848834  1.006714  0.001636258  0.7954265          
  1.710853e-01  0.83019707  1.008095  0.001497881  0.7966595          
  4.001151e-01  0.79618846  1.007605  0.001515958  0.7962266          
  7.551302e+00  0.26242324  1.002037  0.003618328  0.7918453          
  8.080948e+00  0.15512637  1.000767  0.004221326  0.7911160          
  9.902178e+00  0.43318719  1.003710  0.002236078  0.7928176          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were fraction = 0.08786682 and lambda
 = 0.001840414.
[1] "Mon Mar 05 08:22:40 2018"
Error : package evtree is required
In addition: There were 46 warnings (use warnings() to see them)
Error : package evtree is required
Error : package evtree is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 08:22:53 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "evtree"                  
Random Forest by Randomization 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  mtry  numRandomCuts  RMSE      Rsquared     MAE        Selected
  1     14             1.034614  0.005649832  0.8223208  *       
  2      4             1.040287  0.005872116  0.8275349          
  2     17             1.050873  0.006617760  0.8390658          
  3     14             1.065183  0.007136629  0.8442510          
  4      3             1.052311  0.006331142  0.8362002          
  4     16             1.072913  0.009231888  0.8501248          
  4     24             1.076897  0.009163346  0.8540090          
  5      8             1.070741  0.008599339  0.8487911          
  5     12             1.075629  0.008286752  0.8525394          
  5     22             1.084118  0.010520100  0.8573918          
  5     24             1.086512  0.010918693  0.8623793          
  6     10             1.080087  0.006905892  0.8623954          
  6     18             1.088267  0.007890257  0.8724184          
  7     20             1.091412  0.006426643  0.8744608          
  7     21             1.099940  0.011092530  0.8727452          
  9      4             1.074847  0.007885233  0.8509929          
  9      7             1.086774  0.010958196  0.8604963          
  9     11             1.095318  0.011663426  0.8657241          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mtry = 1 and numRandomCuts = 14.
[1] "Mon Mar 05 08:34:27 2018"
Ridge Regression with Variable Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  lambda        k  RMSE      Rsquared     MAE        Selected
  1.842479e-05  5  1.009122  0.001359192  0.7977456          
  6.442721e-05  6  1.009331  0.001258538  0.7983947          
  1.138842e-04  2  1.006270  0.004003856  0.7939391          
  2.402199e-04  5  1.009118  0.001359129  0.7977415          
  6.838200e-04  5  1.009110  0.001359002  0.7977334          
  8.028400e-04  5  1.009108  0.001358968  0.7977312          
  1.840414e-03  1  1.005835  0.007337152  0.7940704          
  2.408574e-03  9  1.010130  0.001391222  0.7986071          
  2.829460e-03  6  1.009281  0.001257838  0.7983433          
  1.077621e-02  5  1.008930  0.001356145  0.7975497          
  1.296528e-02  9  1.009930  0.001390524  0.7984107          
  1.320302e-02  3  1.009694  0.004106224  0.7975432          
  1.480338e-02  8  1.009634  0.001272281  0.7985179          
  2.312744e-02  4  1.008026  0.002026628  0.7959978          
  4.540062e-02  7  1.009271  0.001454203  0.7979128          
  1.710853e-01  8  1.007337  0.001230878  0.7964225          
  4.001151e-01  8  1.005100  0.001191321  0.7944289          
  7.551302e+00  3  1.001443  0.009050938  0.7847461          
  8.080948e+00  2  1.001358  0.009052442  0.7847143          
  9.902178e+00  4  1.001131  0.009057151  0.7846287  *       

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were k = 4 and lambda = 9.902178.
[1] "Mon Mar 05 08:34:41 2018"
Generalized Additive Model using Splines 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  select  method  RMSE      Rsquared     MAE        Selected
  FALSE   GCV.Cp  1.034024  0.001899379  0.8192421          
  FALSE   ML      1.012999  0.001748258  0.8005567          
   TRUE   GCV.Cp  1.027499  0.001866773  0.8106490          
   TRUE   ML      1.006035  0.003338691  0.7954536  *       

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were select = TRUE and method = ML.
[1] "Mon Mar 05 08:35:49 2018"
Boosted Generalized Additive Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  mstop  prune  RMSE      Rsquared     MAE        Selected
    45   no     1.008371  0.001116136  0.8002610          
   135   no     1.020929  0.001440915  0.8117644          
   177   yes    1.005235  0.001906018  0.7959487  *       
   231   no     1.028635  0.002291939  0.8188473          
   306   no     1.033155  0.002887569  0.8229260          
   318   no     1.033856  0.002903395  0.8235264          
   378   yes    1.005235  0.001906018  0.7959487          
   397   no     1.037675  0.003322843  0.8269253          
   409   no     1.038238  0.003366355  0.8274241          
   506   yes    1.005235  0.001906018  0.7959487          
   519   no     1.042338  0.003704519  0.8309891          
   521   yes    1.005235  0.001906018  0.7959487          
   529   no     1.042666  0.003753455  0.8312513          
   561   yes    1.005235  0.001906018  0.7959487          
   610   no     1.045171  0.003907382  0.8334089          
   706   no     1.047793  0.004043580  0.8355772          
   768   no     1.049221  0.004081063  0.8367568          
   980   yes    1.005235  0.001906018  0.7959487          
   985   yes    1.005235  0.001906018  0.7959487          
  1000   yes    1.005235  0.001906018  0.7959487          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mstop = 177 and prune = yes.
[1] "Mon Mar 05 08:56:17 2018"
Loading required package: gam
Loading required package: splines
Loading required package: foreach
Loaded gam 1.14-4


Attaching package: 'gam'

The following objects are masked from 'package:mgcv':

    gam, gam.control, gam.fit, plot.gam, predict.gam, s, summary.gam

Generalized Additive Model using Splines 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  df         RMSE      Rsquared     MAE        Selected
  0.2211688  1.010178  0.001391438  0.7986533  *       
  0.6742244  1.010178  0.001391438  0.7986533          
  0.8803864  1.010178  0.001391438  0.7986533          
  1.1505076  1.011591  0.001602559  0.8003004          
  1.5291182  1.015781  0.002749768  0.8048550          
  1.5871908  1.016474  0.002931011  0.8055488          
  1.8874295  1.020119  0.003726180  0.8091689          
  1.9848000  1.021291  0.003928835  0.8103599          
  2.0430862  1.021985  0.004036401  0.8110756          
  2.5270551  1.027415  0.004629442  0.8165317          
  2.5939848  1.028118  0.004676884  0.8172139          
  2.6005610  1.028186  0.004680948  0.8172829          
  2.6419674  1.028613  0.004705802  0.8177154          
  2.8034396  1.030236  0.004782366  0.8193177          
  3.0475515  1.032585  0.004847868  0.8216113          
  3.5276773  1.036902  0.004863993  0.8256403          
  3.8351541  1.039531  0.004831107  0.8280286          
  4.8983516  1.048483  0.004612620  0.8364280          
  4.9228853  1.048695  0.004606043  0.8366191          
  4.9964423  1.049332  0.004588790  0.8371847          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was df = 0.2211688.
[1] "Mon Mar 05 08:56:46 2018"
Error in .local(object, ...) : test vector does not match model !
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 08:57:46 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "gaussprLinear"           
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:05:21 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "gaussprPoly"             
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:07:16 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "gaussprRadial"           
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9702             nan     0.0142   -0.0005
     2        0.9670             nan     0.0142    0.0002
     3        0.9641             nan     0.0142   -0.0007
     4        0.9616             nan     0.0142    0.0005
     5        0.9586             nan     0.0142    0.0002
     6        0.9563             nan     0.0142   -0.0005
     7        0.9536             nan     0.0142   -0.0000
     8        0.9505             nan     0.0142   -0.0006
     9        0.9483             nan     0.0142   -0.0015
    10        0.9459             nan     0.0142   -0.0007
    20        0.9225             nan     0.0142    0.0002
    40        0.8803             nan     0.0142    0.0006
    60        0.8462             nan     0.0142   -0.0022
    80        0.8132             nan     0.0142   -0.0017
   100        0.7806             nan     0.0142   -0.0001
   120        0.7507             nan     0.0142   -0.0019
   140        0.7234             nan     0.0142   -0.0005
   160        0.6982             nan     0.0142   -0.0006
   180        0.6730             nan     0.0142   -0.0001
   200        0.6521             nan     0.0142   -0.0009
   220        0.6306             nan     0.0142   -0.0015
   240        0.6105             nan     0.0142   -0.0005
   260        0.5893             nan     0.0142   -0.0007
   280        0.5714             nan     0.0142   -0.0016
   300        0.5532             nan     0.0142   -0.0010
   320        0.5358             nan     0.0142   -0.0010
   340        0.5195             nan     0.0142   -0.0010
   360        0.5039             nan     0.0142   -0.0003
   380        0.4898             nan     0.0142   -0.0011
   400        0.4753             nan     0.0142   -0.0003
   420        0.4629             nan     0.0142   -0.0003
   440        0.4495             nan     0.0142   -0.0006
   460        0.4366             nan     0.0142   -0.0009
   480        0.4239             nan     0.0142   -0.0003
   500        0.4134             nan     0.0142   -0.0011
   520        0.4011             nan     0.0142   -0.0003
   540        0.3896             nan     0.0142   -0.0008
   560        0.3788             nan     0.0142   -0.0001
   580        0.3681             nan     0.0142   -0.0004
   600        0.3581             nan     0.0142   -0.0009
   620        0.3484             nan     0.0142   -0.0008
   640        0.3387             nan     0.0142   -0.0006
   660        0.3295             nan     0.0142   -0.0005
   680        0.3209             nan     0.0142   -0.0008
   700        0.3113             nan     0.0142   -0.0004
   720        0.3033             nan     0.0142   -0.0005
   740        0.2949             nan     0.0142   -0.0007
   760        0.2866             nan     0.0142   -0.0006
   780        0.2791             nan     0.0142   -0.0003
   800        0.2721             nan     0.0142   -0.0005
   820        0.2659             nan     0.0142   -0.0003
   840        0.2587             nan     0.0142   -0.0002
   860        0.2520             nan     0.0142   -0.0004
   880        0.2461             nan     0.0142   -0.0004
   900        0.2398             nan     0.0142   -0.0004
   920        0.2335             nan     0.0142   -0.0003
   940        0.2277             nan     0.0142   -0.0003
   960        0.2218             nan     0.0142   -0.0003
   980        0.2163             nan     0.0142   -0.0003
  1000        0.2103             nan     0.0142   -0.0002
  1020        0.2046             nan     0.0142   -0.0005
  1040        0.1994             nan     0.0142   -0.0002
  1060        0.1939             nan     0.0142   -0.0003
  1080        0.1895             nan     0.0142   -0.0004
  1100        0.1846             nan     0.0142   -0.0002
  1120        0.1799             nan     0.0142   -0.0001
  1140        0.1754             nan     0.0142   -0.0005
  1160        0.1712             nan     0.0142   -0.0004
  1180        0.1670             nan     0.0142   -0.0001
  1200        0.1627             nan     0.0142   -0.0003
  1220        0.1588             nan     0.0142   -0.0004
  1240        0.1550             nan     0.0142   -0.0002
  1260        0.1509             nan     0.0142   -0.0002
  1280        0.1473             nan     0.0142   -0.0003
  1300        0.1437             nan     0.0142   -0.0002
  1320        0.1404             nan     0.0142   -0.0001
  1340        0.1370             nan     0.0142   -0.0002
  1360        0.1337             nan     0.0142   -0.0003
  1380        0.1306             nan     0.0142   -0.0002
  1400        0.1273             nan     0.0142   -0.0002
  1420        0.1243             nan     0.0142   -0.0001
  1440        0.1213             nan     0.0142   -0.0002
  1460        0.1187             nan     0.0142   -0.0003
  1480        0.1159             nan     0.0142   -0.0003
  1500        0.1129             nan     0.0142   -0.0003
  1520        0.1106             nan     0.0142   -0.0002
  1540        0.1081             nan     0.0142   -0.0002
  1560        0.1053             nan     0.0142   -0.0001
  1580        0.1028             nan     0.0142   -0.0002
  1600        0.1006             nan     0.0142   -0.0001
  1620        0.0983             nan     0.0142   -0.0002
  1640        0.0959             nan     0.0142   -0.0002
  1660        0.0937             nan     0.0142   -0.0002
  1680        0.0915             nan     0.0142   -0.0001
  1700        0.0892             nan     0.0142   -0.0002
  1720        0.0872             nan     0.0142   -0.0001
  1740        0.0853             nan     0.0142   -0.0002
  1760        0.0831             nan     0.0142   -0.0001
  1780        0.0811             nan     0.0142   -0.0002
  1800        0.0792             nan     0.0142   -0.0001
  1820        0.0774             nan     0.0142   -0.0001
  1840        0.0756             nan     0.0142   -0.0002
  1860        0.0738             nan     0.0142   -0.0002
  1880        0.0720             nan     0.0142   -0.0001
  1900        0.0705             nan     0.0142   -0.0001
  1920        0.0688             nan     0.0142   -0.0001
  1940        0.0673             nan     0.0142   -0.0002
  1960        0.0658             nan     0.0142   -0.0002
  1980        0.0642             nan     0.0142   -0.0001
  2000        0.0629             nan     0.0142   -0.0001
  2020        0.0614             nan     0.0142   -0.0002
  2040        0.0601             nan     0.0142   -0.0001
  2060        0.0587             nan     0.0142   -0.0001
  2080        0.0574             nan     0.0142   -0.0001
  2100        0.0562             nan     0.0142   -0.0001
  2120        0.0549             nan     0.0142   -0.0001
  2140        0.0537             nan     0.0142   -0.0001
  2160        0.0525             nan     0.0142   -0.0001
  2180        0.0514             nan     0.0142   -0.0001
  2200        0.0503             nan     0.0142   -0.0001
  2220        0.0493             nan     0.0142   -0.0001
  2240        0.0482             nan     0.0142   -0.0001
  2260        0.0472             nan     0.0142   -0.0001
  2280        0.0461             nan     0.0142   -0.0001
  2300        0.0450             nan     0.0142   -0.0001
  2320        0.0441             nan     0.0142   -0.0001
  2340        0.0431             nan     0.0142   -0.0001
  2360        0.0421             nan     0.0142   -0.0001
  2380        0.0412             nan     0.0142   -0.0001
  2400        0.0402             nan     0.0142   -0.0001
  2420        0.0393             nan     0.0142   -0.0001
  2440        0.0385             nan     0.0142   -0.0001
  2460        0.0376             nan     0.0142   -0.0001
  2480        0.0368             nan     0.0142   -0.0000
  2500        0.0361             nan     0.0142   -0.0000
  2520        0.0354             nan     0.0142   -0.0001
  2540        0.0346             nan     0.0142   -0.0001
  2560        0.0337             nan     0.0142   -0.0000
  2580        0.0330             nan     0.0142   -0.0000
  2600        0.0322             nan     0.0142   -0.0001
  2620        0.0316             nan     0.0142   -0.0001
  2640        0.0309             nan     0.0142   -0.0001
  2660        0.0303             nan     0.0142   -0.0000
  2680        0.0296             nan     0.0142   -0.0000
  2700        0.0290             nan     0.0142   -0.0000
  2720        0.0284             nan     0.0142   -0.0001
  2740        0.0277             nan     0.0142   -0.0001
  2760        0.0271             nan     0.0142   -0.0000
  2780        0.0265             nan     0.0142   -0.0001
  2800        0.0259             nan     0.0142   -0.0000
  2820        0.0254             nan     0.0142   -0.0000
  2840        0.0248             nan     0.0142   -0.0001
  2860        0.0243             nan     0.0142   -0.0000
  2880        0.0238             nan     0.0142   -0.0001
  2900        0.0233             nan     0.0142   -0.0001
  2920        0.0228             nan     0.0142   -0.0000
  2940        0.0224             nan     0.0142   -0.0001
  2960        0.0219             nan     0.0142   -0.0000
  2980        0.0215             nan     0.0142   -0.0001
  3000        0.0210             nan     0.0142   -0.0000
  3020        0.0206             nan     0.0142   -0.0000
  3040        0.0201             nan     0.0142   -0.0000
  3047        0.0200             nan     0.0142   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9578             nan     0.1007   -0.0002
     2        0.9460             nan     0.1007   -0.0012
     3        0.9338             nan     0.1007   -0.0037
     4        0.9240             nan     0.1007   -0.0060
     5        0.9118             nan     0.1007   -0.0051
     6        0.9024             nan     0.1007   -0.0051
     7        0.8886             nan     0.1007   -0.0042
     8        0.8814             nan     0.1007   -0.0057
     9        0.8706             nan     0.1007   -0.0031
    10        0.8607             nan     0.1007   -0.0037
    20        0.7742             nan     0.1007   -0.0063
    40        0.6544             nan     0.1007   -0.0076
    60        0.5713             nan     0.1007   -0.0084
    80        0.4972             nan     0.1007   -0.0023
   100        0.4301             nan     0.1007   -0.0050
   120        0.3802             nan     0.1007   -0.0042
   140        0.3389             nan     0.1007   -0.0045
   160        0.3021             nan     0.1007   -0.0025
   180        0.2705             nan     0.1007   -0.0040
   200        0.2406             nan     0.1007   -0.0019
   220        0.2163             nan     0.1007   -0.0031
   240        0.1907             nan     0.1007   -0.0013
   260        0.1717             nan     0.1007   -0.0017
   280        0.1537             nan     0.1007   -0.0028
   300        0.1374             nan     0.1007   -0.0018
   320        0.1227             nan     0.1007   -0.0014
   340        0.1108             nan     0.1007   -0.0008
   360        0.1012             nan     0.1007   -0.0017
   380        0.0904             nan     0.1007   -0.0010
   400        0.0810             nan     0.1007   -0.0010
   420        0.0731             nan     0.1007   -0.0005
   440        0.0666             nan     0.1007   -0.0006
   460        0.0603             nan     0.1007   -0.0008
   480        0.0542             nan     0.1007   -0.0008
   500        0.0489             nan     0.1007   -0.0005
   520        0.0444             nan     0.1007   -0.0005
   540        0.0404             nan     0.1007   -0.0005
   560        0.0370             nan     0.1007   -0.0002
   580        0.0337             nan     0.1007   -0.0003
   600        0.0306             nan     0.1007   -0.0004
   620        0.0278             nan     0.1007   -0.0003
   640        0.0251             nan     0.1007   -0.0003
   660        0.0230             nan     0.1007   -0.0003
   675        0.0216             nan     0.1007   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9549             nan     0.1139   -0.0032
     2        0.9415             nan     0.1139   -0.0005
     3        0.9281             nan     0.1139   -0.0024
     4        0.9132             nan     0.1139    0.0030
     5        0.9022             nan     0.1139   -0.0069
     6        0.8950             nan     0.1139   -0.0110
     7        0.8852             nan     0.1139   -0.0056
     8        0.8716             nan     0.1139   -0.0009
     9        0.8643             nan     0.1139   -0.0070
    10        0.8542             nan     0.1139   -0.0060
    20        0.7731             nan     0.1139   -0.0083
    40        0.6425             nan     0.1139   -0.0050
    60        0.5561             nan     0.1139   -0.0074
    80        0.4746             nan     0.1139   -0.0044
   100        0.4052             nan     0.1139   -0.0062
   120        0.3562             nan     0.1139   -0.0043
   140        0.3080             nan     0.1139   -0.0033
   160        0.2673             nan     0.1139   -0.0009
   180        0.2330             nan     0.1139   -0.0013
   200        0.2024             nan     0.1139   -0.0013
   220        0.1793             nan     0.1139   -0.0019
   240        0.1586             nan     0.1139   -0.0021
   260        0.1406             nan     0.1139   -0.0014
   280        0.1243             nan     0.1139   -0.0017
   300        0.1089             nan     0.1139   -0.0012
   320        0.0960             nan     0.1139   -0.0018
   340        0.0866             nan     0.1139   -0.0012
   360        0.0771             nan     0.1139   -0.0014
   380        0.0700             nan     0.1139   -0.0008
   400        0.0629             nan     0.1139   -0.0009
   420        0.0563             nan     0.1139   -0.0010
   440        0.0508             nan     0.1139   -0.0002
   460        0.0456             nan     0.1139   -0.0004
   480        0.0407             nan     0.1139   -0.0005
   500        0.0362             nan     0.1139   -0.0005
   520        0.0329             nan     0.1139   -0.0008
   540        0.0292             nan     0.1139   -0.0005
   560        0.0260             nan     0.1139   -0.0003
   580        0.0235             nan     0.1139   -0.0003
   600        0.0211             nan     0.1139   -0.0003
   620        0.0190             nan     0.1139   -0.0003
   640        0.0174             nan     0.1139   -0.0001
   660        0.0159             nan     0.1139   -0.0001
   680        0.0143             nan     0.1139   -0.0001
   700        0.0129             nan     0.1139   -0.0002
   720        0.0117             nan     0.1139   -0.0001
   740        0.0105             nan     0.1139   -0.0002
   760        0.0095             nan     0.1139   -0.0001
   780        0.0087             nan     0.1139   -0.0001
   800        0.0078             nan     0.1139   -0.0001
   820        0.0070             nan     0.1139   -0.0001
   840        0.0064             nan     0.1139   -0.0001
   860        0.0057             nan     0.1139   -0.0001
   880        0.0053             nan     0.1139   -0.0001
   900        0.0048             nan     0.1139   -0.0001
   920        0.0044             nan     0.1139   -0.0001
   940        0.0040             nan     0.1139   -0.0000
   960        0.0036             nan     0.1139   -0.0000
   980        0.0033             nan     0.1139   -0.0000
  1000        0.0030             nan     0.1139   -0.0000
  1020        0.0027             nan     0.1139   -0.0000
  1040        0.0024             nan     0.1139   -0.0000
  1060        0.0022             nan     0.1139   -0.0000
  1080        0.0020             nan     0.1139   -0.0000
  1100        0.0018             nan     0.1139   -0.0000
  1120        0.0017             nan     0.1139   -0.0000
  1140        0.0015             nan     0.1139   -0.0000
  1151        0.0014             nan     0.1139   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9525             nan     0.1790   -0.0034
     2        0.9427             nan     0.1790   -0.0066
     3        0.9347             nan     0.1790   -0.0174
     4        0.9201             nan     0.1790    0.0070
     5        0.9084             nan     0.1790   -0.0005
     6        0.9000             nan     0.1790   -0.0099
     7        0.8882             nan     0.1790   -0.0129
     8        0.8835             nan     0.1790   -0.0109
     9        0.8751             nan     0.1790   -0.0100
    10        0.8692             nan     0.1790   -0.0201
    20        0.7911             nan     0.1790   -0.0116
    40        0.6807             nan     0.1790   -0.0114
    60        0.5937             nan     0.1790   -0.0071
    80        0.5285             nan     0.1790   -0.0073
   100        0.4768             nan     0.1790   -0.0041
   120        0.4256             nan     0.1790   -0.0087
   140        0.3781             nan     0.1790   -0.0074
   160        0.3382             nan     0.1790   -0.0056
   180        0.3014             nan     0.1790   -0.0026
   200        0.2655             nan     0.1790   -0.0036
   220        0.2418             nan     0.1790   -0.0053
   240        0.2173             nan     0.1790   -0.0015
   260        0.1986             nan     0.1790   -0.0026
   280        0.1816             nan     0.1790   -0.0034
   300        0.1667             nan     0.1790   -0.0034
   320        0.1513             nan     0.1790   -0.0018
   340        0.1375             nan     0.1790   -0.0026
   360        0.1238             nan     0.1790   -0.0024
   380        0.1154             nan     0.1790   -0.0027
   400        0.1039             nan     0.1790   -0.0015
   420        0.0959             nan     0.1790   -0.0017
   440        0.0868             nan     0.1790   -0.0013
   460        0.0782             nan     0.1790   -0.0015
   480        0.0712             nan     0.1790   -0.0012
   500        0.0644             nan     0.1790   -0.0011
   520        0.0593             nan     0.1790   -0.0013
   540        0.0543             nan     0.1790   -0.0011
   560        0.0500             nan     0.1790   -0.0007
   580        0.0462             nan     0.1790   -0.0010
   600        0.0426             nan     0.1790   -0.0010
   620        0.0390             nan     0.1790   -0.0005
   640        0.0358             nan     0.1790   -0.0008
   660        0.0332             nan     0.1790   -0.0006
   680        0.0310             nan     0.1790   -0.0008
   700        0.0281             nan     0.1790   -0.0005
   720        0.0259             nan     0.1790   -0.0003
   740        0.0238             nan     0.1790   -0.0005
   760        0.0218             nan     0.1790   -0.0003
   780        0.0200             nan     0.1790   -0.0004
   800        0.0184             nan     0.1790   -0.0003
   820        0.0171             nan     0.1790   -0.0003
   840        0.0157             nan     0.1790   -0.0002
   860        0.0145             nan     0.1790   -0.0001
   880        0.0133             nan     0.1790   -0.0001
   900        0.0123             nan     0.1790   -0.0002
   920        0.0115             nan     0.1790   -0.0002
   940        0.0107             nan     0.1790   -0.0002
   960        0.0099             nan     0.1790   -0.0003
   980        0.0091             nan     0.1790   -0.0001
  1000        0.0085             nan     0.1790   -0.0002
  1020        0.0077             nan     0.1790   -0.0001
  1040        0.0072             nan     0.1790   -0.0001
  1060        0.0067             nan     0.1790   -0.0001
  1080        0.0063             nan     0.1790   -0.0001
  1100        0.0058             nan     0.1790   -0.0001
  1120        0.0053             nan     0.1790   -0.0001
  1140        0.0049             nan     0.1790   -0.0002
  1160        0.0045             nan     0.1790   -0.0001
  1180        0.0042             nan     0.1790   -0.0001
  1200        0.0038             nan     0.1790   -0.0001
  1220        0.0035             nan     0.1790   -0.0001
  1240        0.0032             nan     0.1790   -0.0001
  1260        0.0031             nan     0.1790   -0.0001
  1280        0.0028             nan     0.1790   -0.0001
  1300        0.0026             nan     0.1790   -0.0000
  1320        0.0024             nan     0.1790   -0.0000
  1340        0.0023             nan     0.1790   -0.0000
  1360        0.0021             nan     0.1790   -0.0000
  1380        0.0020             nan     0.1790   -0.0001
  1400        0.0018             nan     0.1790   -0.0000
  1420        0.0017             nan     0.1790   -0.0000
  1440        0.0015             nan     0.1790   -0.0000
  1460        0.0014             nan     0.1790   -0.0000
  1480        0.0013             nan     0.1790   -0.0000
  1500        0.0012             nan     0.1790   -0.0000
  1520        0.0011             nan     0.1790   -0.0000
  1540        0.0011             nan     0.1790   -0.0000
  1560        0.0010             nan     0.1790   -0.0000
  1580        0.0009             nan     0.1790   -0.0000
  1600        0.0008             nan     0.1790   -0.0000
  1620        0.0008             nan     0.1790   -0.0000
  1640        0.0007             nan     0.1790   -0.0000
  1660        0.0007             nan     0.1790   -0.0000
  1680        0.0006             nan     0.1790   -0.0000
  1700        0.0006             nan     0.1790   -0.0000
  1720        0.0005             nan     0.1790   -0.0000
  1740        0.0005             nan     0.1790   -0.0000
  1760        0.0005             nan     0.1790   -0.0000
  1780        0.0004             nan     0.1790   -0.0000
  1800        0.0004             nan     0.1790   -0.0000
  1820        0.0004             nan     0.1790   -0.0000
  1840        0.0004             nan     0.1790   -0.0000
  1860        0.0003             nan     0.1790   -0.0000
  1880        0.0003             nan     0.1790   -0.0000
  1900        0.0003             nan     0.1790   -0.0000
  1920        0.0003             nan     0.1790   -0.0000
  1940        0.0002             nan     0.1790   -0.0000
  1960        0.0002             nan     0.1790   -0.0000
  1980        0.0002             nan     0.1790   -0.0000
  2000        0.0002             nan     0.1790   -0.0000
  2020        0.0002             nan     0.1790   -0.0000
  2040        0.0002             nan     0.1790   -0.0000
  2060        0.0002             nan     0.1790   -0.0000
  2080        0.0001             nan     0.1790   -0.0000
  2100        0.0001             nan     0.1790   -0.0000
  2120        0.0001             nan     0.1790   -0.0000
  2140        0.0001             nan     0.1790   -0.0000
  2160        0.0001             nan     0.1790   -0.0000
  2180        0.0001             nan     0.1790   -0.0000
  2200        0.0001             nan     0.1790   -0.0000
  2220        0.0001             nan     0.1790   -0.0000
  2240        0.0001             nan     0.1790   -0.0000
  2260        0.0001             nan     0.1790   -0.0000
  2280        0.0001             nan     0.1790   -0.0000
  2300        0.0001             nan     0.1790   -0.0000
  2320        0.0001             nan     0.1790   -0.0000
  2340        0.0001             nan     0.1790   -0.0000
  2360        0.0001             nan     0.1790   -0.0000
  2380        0.0001             nan     0.1790   -0.0000
  2400        0.0000             nan     0.1790   -0.0000
  2420        0.0000             nan     0.1790   -0.0000
  2440        0.0000             nan     0.1790   -0.0000
  2460        0.0000             nan     0.1790   -0.0000
  2480        0.0000             nan     0.1790   -0.0000
  2500        0.0000             nan     0.1790   -0.0000
  2520        0.0000             nan     0.1790   -0.0000
  2540        0.0000             nan     0.1790   -0.0000
  2560        0.0000             nan     0.1790   -0.0000
  2580        0.0000             nan     0.1790   -0.0000
  2600        0.0000             nan     0.1790   -0.0000
  2601        0.0000             nan     0.1790   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9521             nan     0.1997   -0.0137
     2        0.9224             nan     0.1997   -0.0158
     3        0.9059             nan     0.1997   -0.0087
     4        0.8963             nan     0.1997   -0.0232
     5        0.8821             nan     0.1997   -0.0050
     6        0.8612             nan     0.1997   -0.0127
     7        0.8472             nan     0.1997   -0.0260
     8        0.8334             nan     0.1997   -0.0204
     9        0.8119             nan     0.1997   -0.0097
    10        0.7989             nan     0.1997   -0.0216
    20        0.6813             nan     0.1997   -0.0161
    40        0.5140             nan     0.1997   -0.0075
    60        0.3920             nan     0.1997   -0.0092
    80        0.2999             nan     0.1997   -0.0076
   100        0.2368             nan     0.1997   -0.0069
   120        0.1784             nan     0.1997   -0.0056
   140        0.1402             nan     0.1997   -0.0025
   160        0.1092             nan     0.1997   -0.0036
   180        0.0891             nan     0.1997   -0.0016
   200        0.0702             nan     0.1997   -0.0014
   220        0.0563             nan     0.1997   -0.0015
   222        0.0550             nan     0.1997   -0.0019

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9590             nan     0.2168   -0.0072
     2        0.9402             nan     0.2168    0.0079
     3        0.9274             nan     0.2168   -0.0003
     4        0.9165             nan     0.2168   -0.0020
     5        0.9036             nan     0.2168   -0.0029
     6        0.8906             nan     0.2168   -0.0053
     7        0.8797             nan     0.2168   -0.0095
     8        0.8676             nan     0.2168   -0.0241
     9        0.8597             nan     0.2168   -0.0144
    10        0.8563             nan     0.2168   -0.0120
    20        0.8041             nan     0.2168   -0.0123
    40        0.6874             nan     0.2168   -0.0102
    60        0.6108             nan     0.2168   -0.0062
    80        0.5373             nan     0.2168   -0.0022
   100        0.4817             nan     0.2168   -0.0173
   120        0.4294             nan     0.2168   -0.0071
   140        0.3957             nan     0.2168   -0.0006
   160        0.3680             nan     0.2168   -0.0093
   180        0.3350             nan     0.2168   -0.0062
   200        0.3120             nan     0.2168   -0.0057
   220        0.2840             nan     0.2168   -0.0061
   240        0.2581             nan     0.2168   -0.0040
   260        0.2375             nan     0.2168   -0.0039
   280        0.2163             nan     0.2168   -0.0039
   300        0.2013             nan     0.2168   -0.0053
   320        0.1862             nan     0.2168   -0.0019
   340        0.1714             nan     0.2168   -0.0038
   360        0.1588             nan     0.2168   -0.0022
   380        0.1468             nan     0.2168   -0.0025
   400        0.1358             nan     0.2168   -0.0019
   420        0.1243             nan     0.2168   -0.0023
   440        0.1160             nan     0.2168   -0.0020
   460        0.1090             nan     0.2168   -0.0018
   480        0.1018             nan     0.2168   -0.0007
   500        0.0949             nan     0.2168   -0.0015
   520        0.0892             nan     0.2168   -0.0005
   540        0.0832             nan     0.2168   -0.0013
   560        0.0785             nan     0.2168   -0.0008
   580        0.0722             nan     0.2168   -0.0009
   600        0.0679             nan     0.2168   -0.0008
   620        0.0623             nan     0.2168   -0.0008
   640        0.0586             nan     0.2168   -0.0019
   660        0.0547             nan     0.2168   -0.0011
   680        0.0511             nan     0.2168   -0.0010
   700        0.0475             nan     0.2168   -0.0005
   720        0.0443             nan     0.2168   -0.0006
   740        0.0412             nan     0.2168   -0.0009
   760        0.0384             nan     0.2168   -0.0007
   780        0.0357             nan     0.2168   -0.0005
   800        0.0338             nan     0.2168   -0.0008
   820        0.0321             nan     0.2168   -0.0005
   840        0.0299             nan     0.2168   -0.0004
   860        0.0284             nan     0.2168   -0.0004
   880        0.0266             nan     0.2168   -0.0005
   900        0.0248             nan     0.2168   -0.0003
   920        0.0232             nan     0.2168   -0.0003
   940        0.0216             nan     0.2168   -0.0004
   960        0.0199             nan     0.2168   -0.0003
   980        0.0189             nan     0.2168   -0.0004
  1000        0.0178             nan     0.2168   -0.0003
  1020        0.0167             nan     0.2168   -0.0004
  1040        0.0160             nan     0.2168   -0.0004
  1060        0.0148             nan     0.2168   -0.0004
  1080        0.0139             nan     0.2168   -0.0003
  1100        0.0129             nan     0.2168   -0.0003
  1120        0.0122             nan     0.2168   -0.0001
  1140        0.0113             nan     0.2168   -0.0001
  1160        0.0107             nan     0.2168   -0.0003
  1180        0.0099             nan     0.2168   -0.0003
  1200        0.0094             nan     0.2168   -0.0001
  1220        0.0089             nan     0.2168   -0.0002
  1240        0.0084             nan     0.2168   -0.0001
  1260        0.0079             nan     0.2168   -0.0002
  1280        0.0074             nan     0.2168   -0.0001
  1300        0.0070             nan     0.2168   -0.0000
  1320        0.0066             nan     0.2168   -0.0002
  1340        0.0062             nan     0.2168   -0.0001
  1360        0.0058             nan     0.2168   -0.0001
  1380        0.0055             nan     0.2168   -0.0001
  1400        0.0051             nan     0.2168   -0.0001
  1420        0.0048             nan     0.2168   -0.0001
  1440        0.0045             nan     0.2168   -0.0001
  1460        0.0043             nan     0.2168   -0.0000
  1480        0.0040             nan     0.2168   -0.0001
  1500        0.0038             nan     0.2168   -0.0001
  1520        0.0036             nan     0.2168   -0.0001
  1540        0.0033             nan     0.2168   -0.0001
  1560        0.0031             nan     0.2168   -0.0001
  1580        0.0029             nan     0.2168   -0.0000
  1600        0.0028             nan     0.2168   -0.0000
  1620        0.0026             nan     0.2168   -0.0001
  1640        0.0024             nan     0.2168   -0.0000
  1660        0.0023             nan     0.2168   -0.0000
  1680        0.0022             nan     0.2168   -0.0000
  1700        0.0020             nan     0.2168   -0.0000
  1720        0.0019             nan     0.2168   -0.0000
  1740        0.0018             nan     0.2168   -0.0000
  1760        0.0017             nan     0.2168   -0.0000
  1780        0.0016             nan     0.2168   -0.0000
  1800        0.0015             nan     0.2168   -0.0000
  1820        0.0014             nan     0.2168   -0.0000
  1840        0.0013             nan     0.2168   -0.0000
  1860        0.0012             nan     0.2168   -0.0000
  1880        0.0012             nan     0.2168   -0.0000
  1900        0.0011             nan     0.2168   -0.0000
  1920        0.0010             nan     0.2168   -0.0000
  1940        0.0010             nan     0.2168   -0.0000
  1960        0.0009             nan     0.2168   -0.0000
  1980        0.0009             nan     0.2168   -0.0000
  2000        0.0008             nan     0.2168   -0.0000
  2020        0.0007             nan     0.2168   -0.0000
  2040        0.0007             nan     0.2168   -0.0000
  2060        0.0007             nan     0.2168   -0.0000
  2080        0.0006             nan     0.2168   -0.0000
  2100        0.0006             nan     0.2168   -0.0000
  2120        0.0005             nan     0.2168   -0.0000
  2140        0.0005             nan     0.2168   -0.0000
  2160        0.0005             nan     0.2168   -0.0000
  2180        0.0005             nan     0.2168   -0.0000
  2200        0.0004             nan     0.2168   -0.0000
  2220        0.0004             nan     0.2168   -0.0000
  2240        0.0004             nan     0.2168   -0.0000
  2260        0.0004             nan     0.2168   -0.0000
  2280        0.0003             nan     0.2168   -0.0000
  2300        0.0003             nan     0.2168   -0.0000
  2320        0.0003             nan     0.2168   -0.0000
  2340        0.0003             nan     0.2168   -0.0000
  2360        0.0003             nan     0.2168   -0.0000
  2380        0.0003             nan     0.2168   -0.0000
  2400        0.0002             nan     0.2168   -0.0000
  2420        0.0002             nan     0.2168   -0.0000
  2440        0.0002             nan     0.2168   -0.0000
  2460        0.0002             nan     0.2168   -0.0000
  2480        0.0002             nan     0.2168   -0.0000
  2500        0.0002             nan     0.2168   -0.0000
  2520        0.0002             nan     0.2168   -0.0000
  2540        0.0002             nan     0.2168   -0.0000
  2560        0.0002             nan     0.2168   -0.0000
  2580        0.0001             nan     0.2168   -0.0000
  2600        0.0001             nan     0.2168   -0.0000
  2620        0.0001             nan     0.2168   -0.0000
  2640        0.0001             nan     0.2168   -0.0000
  2660        0.0001             nan     0.2168   -0.0000
  2680        0.0001             nan     0.2168   -0.0000
  2700        0.0001             nan     0.2168   -0.0000
  2720        0.0001             nan     0.2168   -0.0000
  2740        0.0001             nan     0.2168   -0.0000
  2760        0.0001             nan     0.2168   -0.0000
  2780        0.0001             nan     0.2168   -0.0000
  2800        0.0001             nan     0.2168   -0.0000
  2820        0.0001             nan     0.2168   -0.0000
  2840        0.0001             nan     0.2168   -0.0000
  2860        0.0001             nan     0.2168   -0.0000
  2880        0.0001             nan     0.2168   -0.0000
  2900        0.0001             nan     0.2168   -0.0000
  2920        0.0001             nan     0.2168   -0.0000
  2940        0.0001             nan     0.2168   -0.0000
  2960        0.0001             nan     0.2168   -0.0000
  2980        0.0001             nan     0.2168   -0.0000
  3000        0.0000             nan     0.2168   -0.0000
  3020        0.0000             nan     0.2168   -0.0000
  3040        0.0000             nan     0.2168   -0.0000
  3060        0.0000             nan     0.2168   -0.0000
  3080        0.0000             nan     0.2168   -0.0000
  3100        0.0000             nan     0.2168   -0.0000
  3120        0.0000             nan     0.2168   -0.0000
  3140        0.0000             nan     0.2168   -0.0000
  3160        0.0000             nan     0.2168   -0.0000
  3180        0.0000             nan     0.2168   -0.0000
  3200        0.0000             nan     0.2168   -0.0000
  3220        0.0000             nan     0.2168   -0.0000
  3240        0.0000             nan     0.2168   -0.0000
  3260        0.0000             nan     0.2168   -0.0000
  3280        0.0000             nan     0.2168   -0.0000
  3300        0.0000             nan     0.2168   -0.0000
  3320        0.0000             nan     0.2168   -0.0000
  3340        0.0000             nan     0.2168   -0.0000
  3360        0.0000             nan     0.2168   -0.0000
  3380        0.0000             nan     0.2168   -0.0000
  3400        0.0000             nan     0.2168   -0.0000
  3420        0.0000             nan     0.2168   -0.0000
  3440        0.0000             nan     0.2168   -0.0000
  3460        0.0000             nan     0.2168   -0.0000
  3480        0.0000             nan     0.2168   -0.0000
  3500        0.0000             nan     0.2168   -0.0000
  3520        0.0000             nan     0.2168   -0.0000
  3540        0.0000             nan     0.2168   -0.0000
  3560        0.0000             nan     0.2168   -0.0000
  3580        0.0000             nan     0.2168   -0.0000
  3600        0.0000             nan     0.2168   -0.0000
  3620        0.0000             nan     0.2168   -0.0000
  3640        0.0000             nan     0.2168   -0.0000
  3660        0.0000             nan     0.2168   -0.0000
  3680        0.0000             nan     0.2168   -0.0000
  3700        0.0000             nan     0.2168   -0.0000
  3720        0.0000             nan     0.2168   -0.0000
  3740        0.0000             nan     0.2168   -0.0000
  3760        0.0000             nan     0.2168   -0.0000
  3780        0.0000             nan     0.2168   -0.0000
  3800        0.0000             nan     0.2168   -0.0000
  3820        0.0000             nan     0.2168   -0.0000
  3840        0.0000             nan     0.2168   -0.0000
  3860        0.0000             nan     0.2168   -0.0000
  3880        0.0000             nan     0.2168   -0.0000
  3900        0.0000             nan     0.2168   -0.0000
  3920        0.0000             nan     0.2168   -0.0000
  3940        0.0000             nan     0.2168   -0.0000
  3960        0.0000             nan     0.2168   -0.0000
  3980        0.0000             nan     0.2168   -0.0000
  4000        0.0000             nan     0.2168   -0.0000
  4020        0.0000             nan     0.2168   -0.0000
  4040        0.0000             nan     0.2168   -0.0000
  4060        0.0000             nan     0.2168   -0.0000
  4080        0.0000             nan     0.2168   -0.0000
  4100        0.0000             nan     0.2168   -0.0000
  4120        0.0000             nan     0.2168   -0.0000
  4140        0.0000             nan     0.2168   -0.0000
  4160        0.0000             nan     0.2168   -0.0000
  4180        0.0000             nan     0.2168   -0.0000
  4200        0.0000             nan     0.2168   -0.0000
  4220        0.0000             nan     0.2168   -0.0000
  4240        0.0000             nan     0.2168   -0.0000
  4260        0.0000             nan     0.2168   -0.0000
  4280        0.0000             nan     0.2168   -0.0000
  4300        0.0000             nan     0.2168   -0.0000
  4320        0.0000             nan     0.2168   -0.0000
  4340        0.0000             nan     0.2168   -0.0000
  4360        0.0000             nan     0.2168   -0.0000
  4380        0.0000             nan     0.2168   -0.0000
  4400        0.0000             nan     0.2168   -0.0000
  4420        0.0000             nan     0.2168   -0.0000
  4440        0.0000             nan     0.2168   -0.0000
  4460        0.0000             nan     0.2168   -0.0000
  4480        0.0000             nan     0.2168   -0.0000
  4500        0.0000             nan     0.2168   -0.0000
  4520        0.0000             nan     0.2168   -0.0000
  4540        0.0000             nan     0.2168   -0.0000
  4560        0.0000             nan     0.2168   -0.0000
  4580        0.0000             nan     0.2168   -0.0000
  4600        0.0000             nan     0.2168   -0.0000
  4620        0.0000             nan     0.2168   -0.0000
  4640        0.0000             nan     0.2168   -0.0000
  4660        0.0000             nan     0.2168   -0.0000
  4680        0.0000             nan     0.2168   -0.0000
  4700        0.0000             nan     0.2168   -0.0000
  4720        0.0000             nan     0.2168   -0.0000
  4740        0.0000             nan     0.2168   -0.0000
  4760        0.0000             nan     0.2168   -0.0000
  4780        0.0000             nan     0.2168   -0.0000
  4800        0.0000             nan     0.2168   -0.0000
  4820        0.0000             nan     0.2168   -0.0000
  4840        0.0000             nan     0.2168   -0.0000
  4860        0.0000             nan     0.2168   -0.0000
  4880        0.0000             nan     0.2168   -0.0000
  4898        0.0000             nan     0.2168   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9420             nan     0.2757   -0.0075
     2        0.9113             nan     0.2757   -0.0092
     3        0.9069             nan     0.2757   -0.0436
     4        0.8947             nan     0.2757   -0.0350
     5        0.8772             nan     0.2757   -0.0224
     6        0.8601             nan     0.2757   -0.0209
     7        0.8402             nan     0.2757   -0.0197
     8        0.8181             nan     0.2757   -0.0061
     9        0.8046             nan     0.2757   -0.0148
    10        0.7869             nan     0.2757   -0.0236
    20        0.6597             nan     0.2757   -0.0197
    40        0.4767             nan     0.2757   -0.0164
    60        0.3495             nan     0.2757   -0.0090
    80        0.2571             nan     0.2757   -0.0109
   100        0.1953             nan     0.2757   -0.0055
   120        0.1431             nan     0.2757   -0.0037
   140        0.1123             nan     0.2757   -0.0046
   160        0.0860             nan     0.2757   -0.0032
   180        0.0660             nan     0.2757   -0.0004
   200        0.0523             nan     0.2757   -0.0013
   220        0.0409             nan     0.2757   -0.0008
   240        0.0314             nan     0.2757   -0.0010
   260        0.0250             nan     0.2757   -0.0005
   280        0.0198             nan     0.2757   -0.0006
   300        0.0155             nan     0.2757   -0.0004
   320        0.0120             nan     0.2757   -0.0004
   340        0.0091             nan     0.2757   -0.0004
   360        0.0073             nan     0.2757   -0.0005
   380        0.0059             nan     0.2757   -0.0003
   400        0.0047             nan     0.2757   -0.0002
   420        0.0037             nan     0.2757   -0.0001
   440        0.0029             nan     0.2757   -0.0001
   460        0.0023             nan     0.2757   -0.0001
   480        0.0019             nan     0.2757   -0.0001
   500        0.0014             nan     0.2757   -0.0000
   520        0.0011             nan     0.2757   -0.0000
   540        0.0009             nan     0.2757   -0.0000
   560        0.0007             nan     0.2757   -0.0000
   580        0.0006             nan     0.2757   -0.0000
   600        0.0005             nan     0.2757   -0.0000
   620        0.0004             nan     0.2757   -0.0000
   640        0.0003             nan     0.2757   -0.0000
   660        0.0002             nan     0.2757   -0.0000
   680        0.0002             nan     0.2757   -0.0000
   700        0.0001             nan     0.2757   -0.0000
   720        0.0001             nan     0.2757   -0.0000
   740        0.0001             nan     0.2757   -0.0000
   760        0.0001             nan     0.2757   -0.0000
   780        0.0001             nan     0.2757   -0.0000
   800        0.0001             nan     0.2757   -0.0000
   820        0.0000             nan     0.2757   -0.0000
   840        0.0000             nan     0.2757   -0.0000
   860        0.0000             nan     0.2757   -0.0000
   880        0.0000             nan     0.2757   -0.0000
   900        0.0000             nan     0.2757   -0.0000
   920        0.0000             nan     0.2757   -0.0000
   940        0.0000             nan     0.2757   -0.0000
   960        0.0000             nan     0.2757   -0.0000
   980        0.0000             nan     0.2757   -0.0000
  1000        0.0000             nan     0.2757   -0.0000
  1020        0.0000             nan     0.2757   -0.0000
  1040        0.0000             nan     0.2757   -0.0000
  1060        0.0000             nan     0.2757   -0.0000
  1080        0.0000             nan     0.2757   -0.0000
  1100        0.0000             nan     0.2757   -0.0000
  1120        0.0000             nan     0.2757   -0.0000
  1140        0.0000             nan     0.2757   -0.0000
  1160        0.0000             nan     0.2757   -0.0000
  1180        0.0000             nan     0.2757   -0.0000
  1200        0.0000             nan     0.2757   -0.0000
  1220        0.0000             nan     0.2757   -0.0000
  1240        0.0000             nan     0.2757   -0.0000
  1260        0.0000             nan     0.2757   -0.0000
  1280        0.0000             nan     0.2757   -0.0000
  1300        0.0000             nan     0.2757   -0.0000
  1320        0.0000             nan     0.2757   -0.0000
  1340        0.0000             nan     0.2757   -0.0000
  1360        0.0000             nan     0.2757   -0.0000
  1380        0.0000             nan     0.2757   -0.0000
  1400        0.0000             nan     0.2757   -0.0000
  1420        0.0000             nan     0.2757   -0.0000
  1440        0.0000             nan     0.2757   -0.0000
  1460        0.0000             nan     0.2757   -0.0000
  1480        0.0000             nan     0.2757   -0.0000
  1500        0.0000             nan     0.2757   -0.0000
  1520        0.0000             nan     0.2757   -0.0000
  1540        0.0000             nan     0.2757   -0.0000
  1560        0.0000             nan     0.2757   -0.0000
  1580        0.0000             nan     0.2757   -0.0000
  1600        0.0000             nan     0.2757   -0.0000
  1620        0.0000             nan     0.2757   -0.0000
  1640        0.0000             nan     0.2757   -0.0000
  1660        0.0000             nan     0.2757   -0.0000
  1680        0.0000             nan     0.2757   -0.0000
  1700        0.0000             nan     0.2757   -0.0000
  1720        0.0000             nan     0.2757   -0.0000
  1740        0.0000             nan     0.2757   -0.0000
  1760        0.0000             nan     0.2757   -0.0000
  1780        0.0000             nan     0.2757   -0.0000
  1800        0.0000             nan     0.2757   -0.0000
  1820        0.0000             nan     0.2757   -0.0000
  1840        0.0000             nan     0.2757   -0.0000
  1860        0.0000             nan     0.2757   -0.0000
  1880        0.0000             nan     0.2757   -0.0000
  1900        0.0000             nan     0.2757   -0.0000
  1920        0.0000             nan     0.2757   -0.0000
  1940        0.0000             nan     0.2757   -0.0000
  1960        0.0000             nan     0.2757   -0.0000
  1980        0.0000             nan     0.2757   -0.0000
  2000        0.0000             nan     0.2757   -0.0000
  2020        0.0000             nan     0.2757   -0.0000
  2040        0.0000             nan     0.2757   -0.0000
  2060        0.0000             nan     0.2757   -0.0000
  2080        0.0000             nan     0.2757   -0.0000
  2100        0.0000             nan     0.2757   -0.0000
  2120        0.0000             nan     0.2757   -0.0000
  2140        0.0000             nan     0.2757   -0.0000
  2160        0.0000             nan     0.2757   -0.0000
  2180        0.0000             nan     0.2757   -0.0000
  2200        0.0000             nan     0.2757   -0.0000
  2220        0.0000             nan     0.2757   -0.0000
  2240        0.0000             nan     0.2757   -0.0000
  2260        0.0000             nan     0.2757   -0.0000
  2280        0.0000             nan     0.2757   -0.0000
  2300        0.0000             nan     0.2757   -0.0000
  2320        0.0000             nan     0.2757   -0.0000
  2340        0.0000             nan     0.2757   -0.0000
  2360        0.0000             nan     0.2757   -0.0000
  2380        0.0000             nan     0.2757   -0.0000
  2400        0.0000             nan     0.2757   -0.0000
  2420        0.0000             nan     0.2757   -0.0000
  2440        0.0000             nan     0.2757   -0.0000
  2460        0.0000             nan     0.2757   -0.0000
  2480        0.0000             nan     0.2757   -0.0000
  2500        0.0000             nan     0.2757   -0.0000
  2520        0.0000             nan     0.2757   -0.0000
  2527        0.0000             nan     0.2757   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9484             nan     0.2956   -0.0215
     2        0.9261             nan     0.2956   -0.0460
     3        0.9104             nan     0.2956   -0.0250
     4        0.8791             nan     0.2956    0.0056
     5        0.8684             nan     0.2956   -0.0257
     6        0.8463             nan     0.2956   -0.0239
     7        0.8378             nan     0.2956   -0.0434
     8        0.8194             nan     0.2956   -0.0254
     9        0.8036             nan     0.2956   -0.0320
    10        0.7870             nan     0.2956   -0.0202
    20        0.6509             nan     0.2956   -0.0023
    40        0.4686             nan     0.2956   -0.0113
    60        0.3553             nan     0.2956   -0.0128
    80        0.2699             nan     0.2956   -0.0151
   100        0.2019             nan     0.2956   -0.0084
   120        0.1538             nan     0.2956   -0.0060
   140        0.1162             nan     0.2956   -0.0043
   160        0.0857             nan     0.2956   -0.0011
   180        0.0668             nan     0.2956   -0.0025
   200        0.0546             nan     0.2956   -0.0010
   220        0.0432             nan     0.2956   -0.0013
   240        0.0331             nan     0.2956   -0.0016
   260        0.0257             nan     0.2956   -0.0010
   280        0.0208             nan     0.2956   -0.0007
   300        0.0167             nan     0.2956   -0.0007
   320        0.0137             nan     0.2956   -0.0004
   340        0.0110             nan     0.2956   -0.0004
   360        0.0087             nan     0.2956   -0.0005
   380        0.0070             nan     0.2956   -0.0002
   400        0.0054             nan     0.2956   -0.0001
   420        0.0044             nan     0.2956   -0.0003
   440        0.0036             nan     0.2956   -0.0002
   460        0.0029             nan     0.2956   -0.0001
   480        0.0023             nan     0.2956   -0.0000
   500        0.0019             nan     0.2956   -0.0000
   520        0.0015             nan     0.2956   -0.0001
   540        0.0013             nan     0.2956   -0.0000
   560        0.0010             nan     0.2956   -0.0000
   580        0.0008             nan     0.2956   -0.0000
   600        0.0006             nan     0.2956   -0.0000
   620        0.0005             nan     0.2956   -0.0000
   640        0.0004             nan     0.2956   -0.0000
   660        0.0003             nan     0.2956   -0.0000
   680        0.0003             nan     0.2956   -0.0000
   700        0.0002             nan     0.2956   -0.0000
   720        0.0002             nan     0.2956   -0.0000
   740        0.0001             nan     0.2956   -0.0000
   760        0.0001             nan     0.2956   -0.0000
   780        0.0001             nan     0.2956   -0.0000
   800        0.0001             nan     0.2956   -0.0000
   820        0.0001             nan     0.2956   -0.0000
   840        0.0000             nan     0.2956   -0.0000
   860        0.0000             nan     0.2956   -0.0000
   880        0.0000             nan     0.2956   -0.0000
   900        0.0000             nan     0.2956   -0.0000
   920        0.0000             nan     0.2956   -0.0000
   940        0.0000             nan     0.2956   -0.0000
   960        0.0000             nan     0.2956   -0.0000
   980        0.0000             nan     0.2956   -0.0000
  1000        0.0000             nan     0.2956   -0.0000
  1020        0.0000             nan     0.2956   -0.0000
  1040        0.0000             nan     0.2956   -0.0000
  1060        0.0000             nan     0.2956   -0.0000
  1080        0.0000             nan     0.2956   -0.0000
  1100        0.0000             nan     0.2956   -0.0000
  1120        0.0000             nan     0.2956   -0.0000
  1140        0.0000             nan     0.2956   -0.0000
  1160        0.0000             nan     0.2956   -0.0000
  1180        0.0000             nan     0.2956   -0.0000
  1200        0.0000             nan     0.2956   -0.0000
  1220        0.0000             nan     0.2956   -0.0000
  1240        0.0000             nan     0.2956   -0.0000
  1260        0.0000             nan     0.2956   -0.0000
  1280        0.0000             nan     0.2956   -0.0000
  1300        0.0000             nan     0.2956   -0.0000
  1320        0.0000             nan     0.2956   -0.0000
  1340        0.0000             nan     0.2956   -0.0000
  1360        0.0000             nan     0.2956   -0.0000
  1380        0.0000             nan     0.2956   -0.0000
  1400        0.0000             nan     0.2956   -0.0000
  1420        0.0000             nan     0.2956   -0.0000
  1440        0.0000             nan     0.2956   -0.0000
  1460        0.0000             nan     0.2956   -0.0000
  1480        0.0000             nan     0.2956   -0.0000
  1500        0.0000             nan     0.2956   -0.0000
  1520        0.0000             nan     0.2956   -0.0000
  1540        0.0000             nan     0.2956   -0.0000
  1560        0.0000             nan     0.2956   -0.0000
  1580        0.0000             nan     0.2956   -0.0000
  1600        0.0000             nan     0.2956   -0.0000
  1620        0.0000             nan     0.2956   -0.0000
  1640        0.0000             nan     0.2956   -0.0000
  1660        0.0000             nan     0.2956   -0.0000
  1680        0.0000             nan     0.2956   -0.0000
  1700        0.0000             nan     0.2956   -0.0000
  1720        0.0000             nan     0.2956   -0.0000
  1740        0.0000             nan     0.2956   -0.0000
  1760        0.0000             nan     0.2956   -0.0000
  1780        0.0000             nan     0.2956   -0.0000
  1800        0.0000             nan     0.2956   -0.0000
  1820        0.0000             nan     0.2956   -0.0000
  1840        0.0000             nan     0.2956   -0.0000
  1860        0.0000             nan     0.2956   -0.0000
  1880        0.0000             nan     0.2956   -0.0000
  1900        0.0000             nan     0.2956   -0.0000
  1920        0.0000             nan     0.2956   -0.0000
  1940        0.0000             nan     0.2956   -0.0000
  1960        0.0000             nan     0.2956   -0.0000
  1980        0.0000             nan     0.2956   -0.0000
  2000        0.0000             nan     0.2956   -0.0000
  2020        0.0000             nan     0.2956   -0.0000
  2040        0.0000             nan     0.2956   -0.0000
  2060        0.0000             nan     0.2956   -0.0000
  2080        0.0000             nan     0.2956   -0.0000
  2100        0.0000             nan     0.2956   -0.0000
  2120        0.0000             nan     0.2956   -0.0000
  2140        0.0000             nan     0.2956   -0.0000
  2160        0.0000             nan     0.2956   -0.0000
  2180        0.0000             nan     0.2956   -0.0000
  2200        0.0000             nan     0.2956   -0.0000
  2220        0.0000             nan     0.2956   -0.0000
  2240        0.0000             nan     0.2956   -0.0000
  2260        0.0000             nan     0.2956   -0.0000
  2280        0.0000             nan     0.2956   -0.0000
  2300        0.0000             nan     0.2956   -0.0000
  2320        0.0000             nan     0.2956   -0.0000
  2340        0.0000             nan     0.2956   -0.0000
  2360        0.0000             nan     0.2956   -0.0000
  2380        0.0000             nan     0.2956   -0.0000
  2400        0.0000             nan     0.2956   -0.0000
  2420        0.0000             nan     0.2956   -0.0000
  2440        0.0000             nan     0.2956   -0.0000
  2460        0.0000             nan     0.2956   -0.0000
  2480        0.0000             nan     0.2956   -0.0000
  2500        0.0000             nan     0.2956   -0.0000
  2520        0.0000             nan     0.2956   -0.0000
  2540        0.0000             nan     0.2956   -0.0000
  2560        0.0000             nan     0.2956   -0.0000
  2580        0.0000             nan     0.2956   -0.0000
  2600        0.0000             nan     0.2956   -0.0000
  2620        0.0000             nan     0.2956   -0.0000
  2640        0.0000             nan     0.2956   -0.0000
  2660        0.0000             nan     0.2956   -0.0000
  2680        0.0000             nan     0.2956   -0.0000
  2700        0.0000             nan     0.2956   -0.0000
  2720        0.0000             nan     0.2956   -0.0000
  2740        0.0000             nan     0.2956   -0.0000
  2760        0.0000             nan     0.2956   -0.0000
  2780        0.0000             nan     0.2956   -0.0000
  2800        0.0000             nan     0.2956   -0.0000
  2820        0.0000             nan     0.2956   -0.0000
  2840        0.0000             nan     0.2956   -0.0000
  2860        0.0000             nan     0.2956   -0.0000
  2880        0.0000             nan     0.2956   -0.0000
  2900        0.0000             nan     0.2956   -0.0000
  2920        0.0000             nan     0.2956   -0.0000
  2940        0.0000             nan     0.2956   -0.0000
  2960        0.0000             nan     0.2956   -0.0000
  2980        0.0000             nan     0.2956   -0.0000
  3000        0.0000             nan     0.2956   -0.0000
  3020        0.0000             nan     0.2956   -0.0000
  3040        0.0000             nan     0.2956   -0.0000
  3060        0.0000             nan     0.2956   -0.0000
  3080        0.0000             nan     0.2956   -0.0000
  3100        0.0000             nan     0.2956   -0.0000
  3120        0.0000             nan     0.2956   -0.0000
  3140        0.0000             nan     0.2956   -0.0000
  3160        0.0000             nan     0.2956   -0.0000
  3180        0.0000             nan     0.2956   -0.0000
  3200        0.0000             nan     0.2956   -0.0000
  3220        0.0000             nan     0.2956   -0.0000
  3240        0.0000             nan     0.2956   -0.0000
  3260        0.0000             nan     0.2956   -0.0000
  3280        0.0000             nan     0.2956   -0.0000
  3300        0.0000             nan     0.2956   -0.0000
  3320        0.0000             nan     0.2956   -0.0000
  3340        0.0000             nan     0.2956    0.0000
  3360        0.0000             nan     0.2956   -0.0000
  3380        0.0000             nan     0.2956   -0.0000
  3400        0.0000             nan     0.2956   -0.0000
  3420        0.0000             nan     0.2956   -0.0000
  3440        0.0000             nan     0.2956   -0.0000
  3460        0.0000             nan     0.2956   -0.0000
  3480        0.0000             nan     0.2956   -0.0000
  3500        0.0000             nan     0.2956   -0.0000
  3520        0.0000             nan     0.2956   -0.0000
  3527        0.0000             nan     0.2956   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9566             nan     0.2958   -0.0389
     2        0.9280             nan     0.2958   -0.0034
     3        0.8906             nan     0.2958   -0.0167
     4        0.8583             nan     0.2958   -0.0175
     5        0.8423             nan     0.2958   -0.0182
     6        0.8168             nan     0.2958   -0.0121
     7        0.8049             nan     0.2958   -0.0281
     8        0.7912             nan     0.2958   -0.0287
     9        0.7802             nan     0.2958   -0.0274
    10        0.7634             nan     0.2958   -0.0205
    20        0.6306             nan     0.2958   -0.0252
    40        0.4349             nan     0.2958   -0.0182
    60        0.3163             nan     0.2958   -0.0115
    80        0.2214             nan     0.2958   -0.0043
   100        0.1659             nan     0.2958   -0.0091
   120        0.1255             nan     0.2958   -0.0030
   140        0.0914             nan     0.2958   -0.0007
   160        0.0659             nan     0.2958   -0.0018
   180        0.0489             nan     0.2958   -0.0015
   200        0.0368             nan     0.2958   -0.0015
   220        0.0280             nan     0.2958   -0.0009
   240        0.0214             nan     0.2958   -0.0007
   260        0.0161             nan     0.2958   -0.0007
   280        0.0120             nan     0.2958   -0.0005
   300        0.0090             nan     0.2958   -0.0004
   320        0.0067             nan     0.2958   -0.0004
   340        0.0051             nan     0.2958   -0.0002
   360        0.0040             nan     0.2958   -0.0002
   380        0.0031             nan     0.2958   -0.0001
   400        0.0025             nan     0.2958   -0.0001
   420        0.0020             nan     0.2958   -0.0001
   440        0.0015             nan     0.2958   -0.0000
   460        0.0012             nan     0.2958   -0.0000
   480        0.0009             nan     0.2958   -0.0001
   500        0.0007             nan     0.2958   -0.0000
   520        0.0006             nan     0.2958   -0.0000
   540        0.0004             nan     0.2958   -0.0000
   560        0.0003             nan     0.2958   -0.0000
   580        0.0003             nan     0.2958   -0.0000
   600        0.0002             nan     0.2958   -0.0000
   620        0.0002             nan     0.2958   -0.0000
   640        0.0001             nan     0.2958   -0.0000
   660        0.0001             nan     0.2958   -0.0000
   680        0.0001             nan     0.2958   -0.0000
   700        0.0001             nan     0.2958   -0.0000
   720        0.0001             nan     0.2958   -0.0000
   740        0.0000             nan     0.2958   -0.0000
   760        0.0000             nan     0.2958   -0.0000
   780        0.0000             nan     0.2958   -0.0000
   800        0.0000             nan     0.2958   -0.0000
   820        0.0000             nan     0.2958   -0.0000
   840        0.0000             nan     0.2958   -0.0000
   860        0.0000             nan     0.2958   -0.0000
   880        0.0000             nan     0.2958   -0.0000
   900        0.0000             nan     0.2958   -0.0000
   920        0.0000             nan     0.2958   -0.0000
   940        0.0000             nan     0.2958   -0.0000
   960        0.0000             nan     0.2958   -0.0000
   980        0.0000             nan     0.2958   -0.0000
  1000        0.0000             nan     0.2958   -0.0000
  1020        0.0000             nan     0.2958   -0.0000
  1040        0.0000             nan     0.2958   -0.0000
  1060        0.0000             nan     0.2958   -0.0000
  1080        0.0000             nan     0.2958   -0.0000
  1100        0.0000             nan     0.2958   -0.0000
  1120        0.0000             nan     0.2958   -0.0000
  1140        0.0000             nan     0.2958   -0.0000
  1160        0.0000             nan     0.2958   -0.0000
  1180        0.0000             nan     0.2958   -0.0000
  1200        0.0000             nan     0.2958   -0.0000
  1220        0.0000             nan     0.2958   -0.0000
  1240        0.0000             nan     0.2958   -0.0000
  1260        0.0000             nan     0.2958   -0.0000
  1280        0.0000             nan     0.2958   -0.0000
  1300        0.0000             nan     0.2958   -0.0000
  1320        0.0000             nan     0.2958   -0.0000
  1340        0.0000             nan     0.2958   -0.0000
  1360        0.0000             nan     0.2958   -0.0000
  1380        0.0000             nan     0.2958   -0.0000
  1400        0.0000             nan     0.2958   -0.0000
  1420        0.0000             nan     0.2958   -0.0000
  1440        0.0000             nan     0.2958   -0.0000
  1460        0.0000             nan     0.2958   -0.0000
  1480        0.0000             nan     0.2958   -0.0000
  1500        0.0000             nan     0.2958   -0.0000
  1520        0.0000             nan     0.2958   -0.0000
  1540        0.0000             nan     0.2958   -0.0000
  1560        0.0000             nan     0.2958   -0.0000
  1580        0.0000             nan     0.2958   -0.0000
  1600        0.0000             nan     0.2958   -0.0000
  1620        0.0000             nan     0.2958   -0.0000
  1640        0.0000             nan     0.2958   -0.0000
  1660        0.0000             nan     0.2958   -0.0000
  1680        0.0000             nan     0.2958   -0.0000
  1700        0.0000             nan     0.2958   -0.0000
  1720        0.0000             nan     0.2958   -0.0000
  1740        0.0000             nan     0.2958   -0.0000
  1760        0.0000             nan     0.2958   -0.0000
  1780        0.0000             nan     0.2958   -0.0000
  1800        0.0000             nan     0.2958   -0.0000
  1820        0.0000             nan     0.2958   -0.0000
  1840        0.0000             nan     0.2958   -0.0000
  1860        0.0000             nan     0.2958   -0.0000
  1880        0.0000             nan     0.2958   -0.0000
  1900        0.0000             nan     0.2958   -0.0000
  1920        0.0000             nan     0.2958   -0.0000
  1940        0.0000             nan     0.2958   -0.0000
  1960        0.0000             nan     0.2958   -0.0000
  1980        0.0000             nan     0.2958   -0.0000
  1985        0.0000             nan     0.2958   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9462             nan     0.3117   -0.0473
     2        0.9167             nan     0.3117   -0.0165
     3        0.9071             nan     0.3117   -0.0586
     4        0.8622             nan     0.3117   -0.0091
     5        0.8319             nan     0.3117   -0.0233
     6        0.8162             nan     0.3117   -0.0612
     7        0.7906             nan     0.3117   -0.0471
     8        0.7732             nan     0.3117   -0.0290
     9        0.7518             nan     0.3117   -0.0164
    10        0.7330             nan     0.3117   -0.0314
    20        0.5606             nan     0.3117   -0.0270
    40        0.3328             nan     0.3117   -0.0070
    60        0.2034             nan     0.3117   -0.0084
    80        0.1305             nan     0.3117   -0.0048
   100        0.0861             nan     0.3117   -0.0033
   120        0.0556             nan     0.3117   -0.0012
   140        0.0385             nan     0.3117   -0.0011
   160        0.0261             nan     0.3117   -0.0015
   180        0.0179             nan     0.3117   -0.0009
   200        0.0117             nan     0.3117   -0.0005
   220        0.0077             nan     0.3117   -0.0006
   240        0.0051             nan     0.3117   -0.0003
   260        0.0034             nan     0.3117   -0.0001
   280        0.0023             nan     0.3117   -0.0001
   300        0.0015             nan     0.3117   -0.0001
   320        0.0011             nan     0.3117   -0.0001
   340        0.0008             nan     0.3117   -0.0000
   360        0.0005             nan     0.3117   -0.0000
   380        0.0004             nan     0.3117   -0.0000
   400        0.0003             nan     0.3117   -0.0000
   420        0.0002             nan     0.3117   -0.0000
   440        0.0001             nan     0.3117   -0.0000
   460        0.0001             nan     0.3117   -0.0000
   480        0.0001             nan     0.3117   -0.0000
   500        0.0000             nan     0.3117   -0.0000
   520        0.0000             nan     0.3117   -0.0000
   540        0.0000             nan     0.3117   -0.0000
   560        0.0000             nan     0.3117   -0.0000
   580        0.0000             nan     0.3117   -0.0000
   600        0.0000             nan     0.3117   -0.0000
   620        0.0000             nan     0.3117   -0.0000
   640        0.0000             nan     0.3117   -0.0000
   660        0.0000             nan     0.3117   -0.0000
   680        0.0000             nan     0.3117   -0.0000
   700        0.0000             nan     0.3117   -0.0000
   720        0.0000             nan     0.3117   -0.0000
   740        0.0000             nan     0.3117   -0.0000
   760        0.0000             nan     0.3117   -0.0000
   780        0.0000             nan     0.3117   -0.0000
   800        0.0000             nan     0.3117   -0.0000
   820        0.0000             nan     0.3117   -0.0000
   840        0.0000             nan     0.3117   -0.0000
   860        0.0000             nan     0.3117   -0.0000
   880        0.0000             nan     0.3117   -0.0000
   900        0.0000             nan     0.3117   -0.0000
   920        0.0000             nan     0.3117   -0.0000
   940        0.0000             nan     0.3117   -0.0000
   960        0.0000             nan     0.3117   -0.0000
   980        0.0000             nan     0.3117   -0.0000
  1000        0.0000             nan     0.3117   -0.0000
  1020        0.0000             nan     0.3117   -0.0000
  1040        0.0000             nan     0.3117   -0.0000
  1060        0.0000             nan     0.3117   -0.0000
  1080        0.0000             nan     0.3117   -0.0000
  1100        0.0000             nan     0.3117   -0.0000
  1120        0.0000             nan     0.3117   -0.0000
  1140        0.0000             nan     0.3117   -0.0000
  1160        0.0000             nan     0.3117   -0.0000
  1180        0.0000             nan     0.3117   -0.0000
  1200        0.0000             nan     0.3117   -0.0000
  1220        0.0000             nan     0.3117   -0.0000
  1240        0.0000             nan     0.3117   -0.0000
  1260        0.0000             nan     0.3117   -0.0000
  1280        0.0000             nan     0.3117   -0.0000
  1300        0.0000             nan     0.3117   -0.0000
  1320        0.0000             nan     0.3117   -0.0000
  1340        0.0000             nan     0.3117   -0.0000
  1360        0.0000             nan     0.3117   -0.0000
  1380        0.0000             nan     0.3117   -0.0000
  1400        0.0000             nan     0.3117   -0.0000
  1420        0.0000             nan     0.3117   -0.0000
  1440        0.0000             nan     0.3117   -0.0000
  1460        0.0000             nan     0.3117   -0.0000
  1480        0.0000             nan     0.3117   -0.0000
  1500        0.0000             nan     0.3117   -0.0000
  1520        0.0000             nan     0.3117   -0.0000
  1540        0.0000             nan     0.3117   -0.0000
  1560        0.0000             nan     0.3117   -0.0000
  1580        0.0000             nan     0.3117   -0.0000
  1600        0.0000             nan     0.3117   -0.0000
  1620        0.0000             nan     0.3117   -0.0000
  1640        0.0000             nan     0.3117   -0.0000
  1660        0.0000             nan     0.3117   -0.0000
  1680        0.0000             nan     0.3117   -0.0000
  1700        0.0000             nan     0.3117   -0.0000
  1720        0.0000             nan     0.3117   -0.0000
  1740        0.0000             nan     0.3117   -0.0000
  1760        0.0000             nan     0.3117   -0.0000
  1780        0.0000             nan     0.3117   -0.0000
  1800        0.0000             nan     0.3117   -0.0000
  1820        0.0000             nan     0.3117   -0.0000
  1840        0.0000             nan     0.3117   -0.0000
  1860        0.0000             nan     0.3117   -0.0000
  1880        0.0000             nan     0.3117   -0.0000
  1900        0.0000             nan     0.3117   -0.0000
  1920        0.0000             nan     0.3117   -0.0000
  1940        0.0000             nan     0.3117   -0.0000
  1960        0.0000             nan     0.3117   -0.0000
  1980        0.0000             nan     0.3117   -0.0000
  2000        0.0000             nan     0.3117   -0.0000
  2020        0.0000             nan     0.3117   -0.0000
  2040        0.0000             nan     0.3117   -0.0000
  2060        0.0000             nan     0.3117   -0.0000
  2080        0.0000             nan     0.3117   -0.0000
  2100        0.0000             nan     0.3117   -0.0000
  2120        0.0000             nan     0.3117   -0.0000
  2140        0.0000             nan     0.3117   -0.0000
  2160        0.0000             nan     0.3117   -0.0000
  2180        0.0000             nan     0.3117   -0.0000
  2200        0.0000             nan     0.3117    0.0000
  2220        0.0000             nan     0.3117    0.0000
  2240        0.0000             nan     0.3117   -0.0000
  2260        0.0000             nan     0.3117   -0.0000
  2280        0.0000             nan     0.3117   -0.0000
  2300        0.0000             nan     0.3117   -0.0000
  2320        0.0000             nan     0.3117   -0.0000
  2340        0.0000             nan     0.3117   -0.0000
  2360        0.0000             nan     0.3117   -0.0000
  2380        0.0000             nan     0.3117   -0.0000
  2400        0.0000             nan     0.3117    0.0000
  2420        0.0000             nan     0.3117   -0.0000
  2440        0.0000             nan     0.3117   -0.0000
  2460        0.0000             nan     0.3117   -0.0000
  2480        0.0000             nan     0.3117   -0.0000
  2500        0.0000             nan     0.3117    0.0000
  2520        0.0000             nan     0.3117   -0.0000
  2540        0.0000             nan     0.3117   -0.0000
  2560        0.0000             nan     0.3117    0.0000
  2580        0.0000             nan     0.3117   -0.0000
  2600        0.0000             nan     0.3117   -0.0000
  2620        0.0000             nan     0.3117   -0.0000
  2640        0.0000             nan     0.3117    0.0000
  2642        0.0000             nan     0.3117   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9290             nan     0.3640   -0.0191
     2        0.8835             nan     0.3640   -0.0073
     3        0.8439             nan     0.3640   -0.0072
     4        0.8349             nan     0.3640   -0.0505
     5        0.8074             nan     0.3640   -0.0396
     6        0.7880             nan     0.3640   -0.0140
     7        0.7609             nan     0.3640   -0.0261
     8        0.7336             nan     0.3640   -0.0342
     9        0.7142             nan     0.3640   -0.0385
    10        0.6909             nan     0.3640   -0.0092
    20        0.5440             nan     0.3640   -0.0399
    40        0.3533             nan     0.3640   -0.0121
    60        0.2262             nan     0.3640   -0.0116
    80        0.1514             nan     0.3640   -0.0080
   100        0.1060             nan     0.3640   -0.0063
   120        0.0734             nan     0.3640   -0.0050
   140        0.0515             nan     0.3640   -0.0038
   160        0.0358             nan     0.3640   -0.0024
   180        0.0239             nan     0.3640   -0.0005
   200        0.0160             nan     0.3640   -0.0007
   220        0.0110             nan     0.3640   -0.0003
   240        0.0075             nan     0.3640   -0.0004
   260        0.0050             nan     0.3640   -0.0002
   280        0.0037             nan     0.3640   -0.0002
   300        0.0027             nan     0.3640   -0.0001
   320        0.0019             nan     0.3640   -0.0001
   340        0.0013             nan     0.3640   -0.0001
   360        0.0010             nan     0.3640   -0.0000
   380        0.0007             nan     0.3640   -0.0000
   400        0.0005             nan     0.3640   -0.0000
   420        0.0003             nan     0.3640   -0.0000
   440        0.0002             nan     0.3640   -0.0000
   460        0.0002             nan     0.3640   -0.0000
   480        0.0001             nan     0.3640   -0.0000
   500        0.0001             nan     0.3640   -0.0000
   520        0.0001             nan     0.3640   -0.0000
   540        0.0000             nan     0.3640   -0.0000
   560        0.0000             nan     0.3640   -0.0000
   580        0.0000             nan     0.3640   -0.0000
   600        0.0000             nan     0.3640   -0.0000
   620        0.0000             nan     0.3640   -0.0000
   640        0.0000             nan     0.3640   -0.0000
   660        0.0000             nan     0.3640   -0.0000
   680        0.0000             nan     0.3640   -0.0000
   700        0.0000             nan     0.3640   -0.0000
   720        0.0000             nan     0.3640   -0.0000
   740        0.0000             nan     0.3640   -0.0000
   760        0.0000             nan     0.3640   -0.0000
   780        0.0000             nan     0.3640   -0.0000
   800        0.0000             nan     0.3640   -0.0000
   820        0.0000             nan     0.3640   -0.0000
   840        0.0000             nan     0.3640   -0.0000
   860        0.0000             nan     0.3640   -0.0000
   880        0.0000             nan     0.3640   -0.0000
   900        0.0000             nan     0.3640   -0.0000
   920        0.0000             nan     0.3640   -0.0000
   940        0.0000             nan     0.3640   -0.0000
   960        0.0000             nan     0.3640   -0.0000
   980        0.0000             nan     0.3640   -0.0000
  1000        0.0000             nan     0.3640   -0.0000
  1020        0.0000             nan     0.3640   -0.0000
  1040        0.0000             nan     0.3640   -0.0000
  1060        0.0000             nan     0.3640   -0.0000
  1080        0.0000             nan     0.3640   -0.0000
  1100        0.0000             nan     0.3640   -0.0000
  1120        0.0000             nan     0.3640   -0.0000
  1140        0.0000             nan     0.3640   -0.0000
  1160        0.0000             nan     0.3640   -0.0000
  1180        0.0000             nan     0.3640   -0.0000
  1200        0.0000             nan     0.3640   -0.0000
  1220        0.0000             nan     0.3640   -0.0000
  1240        0.0000             nan     0.3640   -0.0000
  1260        0.0000             nan     0.3640   -0.0000
  1280        0.0000             nan     0.3640   -0.0000
  1300        0.0000             nan     0.3640   -0.0000
  1320        0.0000             nan     0.3640   -0.0000
  1340        0.0000             nan     0.3640   -0.0000
  1360        0.0000             nan     0.3640   -0.0000
  1380        0.0000             nan     0.3640   -0.0000
  1400        0.0000             nan     0.3640   -0.0000
  1420        0.0000             nan     0.3640   -0.0000
  1440        0.0000             nan     0.3640   -0.0000
  1460        0.0000             nan     0.3640   -0.0000
  1480        0.0000             nan     0.3640   -0.0000
  1500        0.0000             nan     0.3640   -0.0000
  1520        0.0000             nan     0.3640   -0.0000
  1540        0.0000             nan     0.3640   -0.0000
  1560        0.0000             nan     0.3640   -0.0000
  1580        0.0000             nan     0.3640   -0.0000
  1587        0.0000             nan     0.3640   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9682             nan     0.3688   -0.0047
     2        0.9610             nan     0.3688   -0.0133
     3        0.9530             nan     0.3688    0.0031
     4        0.9506             nan     0.3688   -0.0096
     5        0.9421             nan     0.3688    0.0008
     6        0.9458             nan     0.3688   -0.0328
     7        0.9502             nan     0.3688   -0.0245
     8        0.9371             nan     0.3688   -0.0118
     9        0.9279             nan     0.3688   -0.0043
    10        0.9195             nan     0.3688   -0.0038
    20        0.8907             nan     0.3688   -0.0187
    40        0.8493             nan     0.3688   -0.0127
    60        0.8001             nan     0.3688   -0.0092
    80        0.7787             nan     0.3688   -0.0047
   100        0.7501             nan     0.3688   -0.0088
   120        0.7269             nan     0.3688   -0.0009
   140        0.7040             nan     0.3688   -0.0128
   160        0.6793             nan     0.3688   -0.0182
   180        0.6533             nan     0.3688   -0.0021
   200        0.6292             nan     0.3688   -0.0024
   220        0.6192             nan     0.3688   -0.0027
   240        0.5982             nan     0.3688   -0.0128
   260        0.5814             nan     0.3688   -0.0049
   280        0.5619             nan     0.3688   -0.0026
   300        0.5448             nan     0.3688   -0.0142
   320        0.5232             nan     0.3688   -0.0062
   340        0.5221             nan     0.3688   -0.0050
   360        0.5042             nan     0.3688   -0.0055
   380        0.4917             nan     0.3688   -0.0074
   400        0.4802             nan     0.3688   -0.0081
   420        0.4657             nan     0.3688   -0.0042
   440        0.4581             nan     0.3688   -0.0072
   460        0.4489             nan     0.3688    0.0000
   480        0.4338             nan     0.3688   -0.0035
   500        0.4272             nan     0.3688   -0.0063
   520        0.4143             nan     0.3688   -0.0074
   540        0.4032             nan     0.3688   -0.0024
   560        0.3959             nan     0.3688   -0.0076
   580        0.3846             nan     0.3688   -0.0040
   600        0.3778             nan     0.3688   -0.0044
   620        0.3718             nan     0.3688   -0.0050
   640        0.3650             nan     0.3688   -0.0030
   660        0.3578             nan     0.3688   -0.0039
   680        0.3490             nan     0.3688   -0.0008
   700        0.3414             nan     0.3688   -0.0031
   720        0.3306             nan     0.3688   -0.0028
   740        0.3252             nan     0.3688   -0.0065
   760        0.3188             nan     0.3688   -0.0050
   780        0.3099             nan     0.3688   -0.0031
   800        0.3008             nan     0.3688   -0.0016
   820        0.3003             nan     0.3688   -0.0049
   840        0.2946             nan     0.3688   -0.0060
   860        0.2875             nan     0.3688   -0.0049
   880        0.2814             nan     0.3688   -0.0052
   900        0.2733             nan     0.3688   -0.0014
   920        0.2676             nan     0.3688   -0.0034
   940        0.2631             nan     0.3688   -0.0060
   960        0.2603             nan     0.3688   -0.0036
   980        0.2532             nan     0.3688   -0.0018
  1000        0.2458             nan     0.3688   -0.0032
  1020        0.2427             nan     0.3688   -0.0033
  1040        0.2355             nan     0.3688   -0.0032
  1060        0.2316             nan     0.3688   -0.0043
  1080        0.2259             nan     0.3688   -0.0054
  1100        0.2224             nan     0.3688   -0.0029
  1120        0.2172             nan     0.3688   -0.0009
  1140        0.2154             nan     0.3688   -0.0038
  1160        0.2108             nan     0.3688   -0.0031
  1180        0.2094             nan     0.3688   -0.0020
  1200        0.2051             nan     0.3688   -0.0023
  1220        0.2000             nan     0.3688   -0.0017
  1240        0.1927             nan     0.3688   -0.0022
  1260        0.1912             nan     0.3688   -0.0023
  1280        0.1860             nan     0.3688   -0.0020
  1300        0.1833             nan     0.3688   -0.0025
  1320        0.1812             nan     0.3688   -0.0031
  1340        0.1780             nan     0.3688   -0.0017
  1360        0.1740             nan     0.3688   -0.0008
  1380        0.1720             nan     0.3688   -0.0026
  1400        0.1679             nan     0.3688   -0.0018
  1420        0.1658             nan     0.3688   -0.0017
  1440        0.1636             nan     0.3688   -0.0027
  1460        0.1588             nan     0.3688   -0.0010
  1480        0.1583             nan     0.3688   -0.0070
  1500        0.1553             nan     0.3688   -0.0021
  1520        0.1533             nan     0.3688   -0.0018
  1540        0.1518             nan     0.3688   -0.0027
  1560        0.1497             nan     0.3688   -0.0023
  1580        0.1464             nan     0.3688   -0.0011
  1600        0.1427             nan     0.3688   -0.0018
  1620        0.1407             nan     0.3688   -0.0009
  1640        0.1381             nan     0.3688   -0.0018
  1660        0.1358             nan     0.3688   -0.0010
  1680        0.1330             nan     0.3688   -0.0020
  1700        0.1309             nan     0.3688   -0.0021
  1720        0.1283             nan     0.3688   -0.0011
  1740        0.1271             nan     0.3688   -0.0040
  1760        0.1247             nan     0.3688   -0.0022
  1780        0.1221             nan     0.3688   -0.0022
  1800        0.1194             nan     0.3688   -0.0006
  1820        0.1176             nan     0.3688   -0.0031
  1840        0.1151             nan     0.3688   -0.0012
  1860        0.1131             nan     0.3688   -0.0019
  1880        0.1113             nan     0.3688   -0.0015
  1888        0.1108             nan     0.3688   -0.0012

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9508             nan     0.3918   -0.0052
     2        0.9402             nan     0.3918   -0.0191
     3        0.9290             nan     0.3918   -0.0373
     4        0.9164             nan     0.3918   -0.0180
     5        0.9052             nan     0.3918   -0.0287
     6        0.8904             nan     0.3918   -0.0091
     7        0.8808             nan     0.3918   -0.0121
     8        0.8761             nan     0.3918   -0.0218
     9        0.8659             nan     0.3918   -0.0132
    10        0.8594             nan     0.3918   -0.0160
    20        0.7890             nan     0.3918   -0.0173
    40        0.6918             nan     0.3918   -0.0167
    60        0.6281             nan     0.3918   -0.0237
    80        0.5505             nan     0.3918   -0.0168
   100        0.5040             nan     0.3918   -0.0029
   120        0.4467             nan     0.3918   -0.0076
   140        0.4082             nan     0.3918   -0.0053
   160        0.3673             nan     0.3918   -0.0064
   180        0.3408             nan     0.3918   -0.0145
   200        0.3061             nan     0.3918   -0.0057
   220        0.2789             nan     0.3918   -0.0024
   240        0.2609             nan     0.3918   -0.0016
   260        0.2341             nan     0.3918   -0.0027
   280        0.2225             nan     0.3918   -0.0078
   300        0.2009             nan     0.3918   -0.0032
   320        0.1806             nan     0.3918   -0.0043
   340        0.1661             nan     0.3918   -0.0041
   360        0.1497             nan     0.3918   -0.0030
   380        0.1340             nan     0.3918   -0.0034
   400        0.1248             nan     0.3918   -0.0040
   420        0.1159             nan     0.3918   -0.0027
   440        0.1051             nan     0.3918   -0.0007
   460        0.0990             nan     0.3918   -0.0035
   480        0.0894             nan     0.3918   -0.0027
   500        0.0827             nan     0.3918   -0.0009
   520        0.0766             nan     0.3918   -0.0025
   540        0.0706             nan     0.3918   -0.0011
   560        0.0656             nan     0.3918   -0.0025
   580        0.0593             nan     0.3918   -0.0025
   600        0.0547             nan     0.3918   -0.0011
   620        0.0497             nan     0.3918   -0.0009
   640        0.0472             nan     0.3918   -0.0012
   660        0.0428             nan     0.3918   -0.0003
   680        0.0398             nan     0.3918   -0.0008
   700        0.0370             nan     0.3918   -0.0008
   720        0.0351             nan     0.3918   -0.0008
   740        0.0330             nan     0.3918   -0.0006
   760        0.0303             nan     0.3918   -0.0008
   780        0.0278             nan     0.3918   -0.0003
   800        0.0256             nan     0.3918   -0.0009
   820        0.0241             nan     0.3918   -0.0004
   840        0.0224             nan     0.3918   -0.0005
   860        0.0212             nan     0.3918   -0.0008
   880        0.0191             nan     0.3918   -0.0006
   881        0.0190             nan     0.3918   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9274             nan     0.4081   -0.0021
     2        0.9009             nan     0.4081   -0.0602
     3        0.8781             nan     0.4081   -0.0272
     4        0.8562             nan     0.4081   -0.0484
     5        0.8153             nan     0.4081    0.0011
     6        0.7821             nan     0.4081   -0.0396
     7        0.7417             nan     0.4081   -0.0161
     8        0.7256             nan     0.4081   -0.0504
     9        0.6991             nan     0.4081   -0.0418
    10        0.6952             nan     0.4081   -0.0581
    20        0.5390             nan     0.4081   -0.0451
    40        0.3254             nan     0.4081   -0.0169
    60        0.2108             nan     0.4081   -0.0114
    80        0.1388             nan     0.4081   -0.0047
   100        0.0935             nan     0.4081   -0.0063
   120        0.0579             nan     0.4081   -0.0028
   140        0.0361             nan     0.4081   -0.0010
   160        0.0247             nan     0.4081   -0.0014
   180        0.0169             nan     0.4081   -0.0008
   200        0.0114             nan     0.4081   -0.0007
   220        0.0075             nan     0.4081   -0.0005
   240        0.0053             nan     0.4081   -0.0003
   260        0.0036             nan     0.4081   -0.0002
   280        0.0024             nan     0.4081   -0.0001
   300        0.0016             nan     0.4081   -0.0001
   320        0.0011             nan     0.4081   -0.0001
   340        0.0008             nan     0.4081   -0.0000
   360        0.0005             nan     0.4081   -0.0000
   380        0.0004             nan     0.4081   -0.0000
   400        0.0002             nan     0.4081   -0.0000
   420        0.0002             nan     0.4081   -0.0000
   440        0.0001             nan     0.4081   -0.0000
   460        0.0001             nan     0.4081   -0.0000
   480        0.0001             nan     0.4081   -0.0000
   500        0.0000             nan     0.4081   -0.0000
   520        0.0000             nan     0.4081   -0.0000
   540        0.0000             nan     0.4081   -0.0000
   560        0.0000             nan     0.4081   -0.0000
   580        0.0000             nan     0.4081   -0.0000
   600        0.0000             nan     0.4081   -0.0000
   620        0.0000             nan     0.4081   -0.0000
   640        0.0000             nan     0.4081   -0.0000
   660        0.0000             nan     0.4081   -0.0000
   680        0.0000             nan     0.4081   -0.0000
   700        0.0000             nan     0.4081   -0.0000
   720        0.0000             nan     0.4081   -0.0000
   740        0.0000             nan     0.4081   -0.0000
   760        0.0000             nan     0.4081   -0.0000
   780        0.0000             nan     0.4081   -0.0000
   800        0.0000             nan     0.4081   -0.0000
   820        0.0000             nan     0.4081   -0.0000
   840        0.0000             nan     0.4081   -0.0000
   860        0.0000             nan     0.4081   -0.0000
   880        0.0000             nan     0.4081   -0.0000
   900        0.0000             nan     0.4081   -0.0000
   920        0.0000             nan     0.4081   -0.0000
   940        0.0000             nan     0.4081   -0.0000
   960        0.0000             nan     0.4081   -0.0000
   980        0.0000             nan     0.4081   -0.0000
  1000        0.0000             nan     0.4081   -0.0000
  1020        0.0000             nan     0.4081   -0.0000
  1040        0.0000             nan     0.4081   -0.0000
  1060        0.0000             nan     0.4081   -0.0000
  1080        0.0000             nan     0.4081   -0.0000
  1100        0.0000             nan     0.4081   -0.0000
  1120        0.0000             nan     0.4081   -0.0000
  1140        0.0000             nan     0.4081   -0.0000
  1160        0.0000             nan     0.4081   -0.0000
  1180        0.0000             nan     0.4081   -0.0000
  1200        0.0000             nan     0.4081   -0.0000
  1220        0.0000             nan     0.4081   -0.0000
  1240        0.0000             nan     0.4081   -0.0000
  1260        0.0000             nan     0.4081   -0.0000
  1280        0.0000             nan     0.4081   -0.0000
  1300        0.0000             nan     0.4081   -0.0000
  1320        0.0000             nan     0.4081   -0.0000
  1340        0.0000             nan     0.4081   -0.0000
  1360        0.0000             nan     0.4081   -0.0000
  1380        0.0000             nan     0.4081   -0.0000
  1400        0.0000             nan     0.4081   -0.0000
  1420        0.0000             nan     0.4081   -0.0000
  1440        0.0000             nan     0.4081   -0.0000
  1460        0.0000             nan     0.4081   -0.0000
  1480        0.0000             nan     0.4081   -0.0000
  1500        0.0000             nan     0.4081   -0.0000
  1520        0.0000             nan     0.4081   -0.0000
  1540        0.0000             nan     0.4081   -0.0000
  1560        0.0000             nan     0.4081   -0.0000
  1580        0.0000             nan     0.4081   -0.0000
  1600        0.0000             nan     0.4081   -0.0000
  1620        0.0000             nan     0.4081   -0.0000
  1640        0.0000             nan     0.4081   -0.0000
  1660        0.0000             nan     0.4081   -0.0000
  1680        0.0000             nan     0.4081   -0.0000
  1700        0.0000             nan     0.4081   -0.0000
  1720        0.0000             nan     0.4081   -0.0000
  1740        0.0000             nan     0.4081   -0.0000
  1760        0.0000             nan     0.4081   -0.0000
  1780        0.0000             nan     0.4081   -0.0000
  1800        0.0000             nan     0.4081   -0.0000
  1820        0.0000             nan     0.4081   -0.0000
  1840        0.0000             nan     0.4081   -0.0000
  1860        0.0000             nan     0.4081   -0.0000
  1880        0.0000             nan     0.4081   -0.0000
  1900        0.0000             nan     0.4081   -0.0000
  1920        0.0000             nan     0.4081   -0.0000
  1940        0.0000             nan     0.4081   -0.0000
  1960        0.0000             nan     0.4081   -0.0000
  1980        0.0000             nan     0.4081   -0.0000
  2000        0.0000             nan     0.4081   -0.0000
  2020        0.0000             nan     0.4081   -0.0000
  2040        0.0000             nan     0.4081   -0.0000
  2060        0.0000             nan     0.4081   -0.0000
  2080        0.0000             nan     0.4081   -0.0000
  2100        0.0000             nan     0.4081   -0.0000
  2120        0.0000             nan     0.4081   -0.0000
  2140        0.0000             nan     0.4081   -0.0000
  2160        0.0000             nan     0.4081   -0.0000
  2180        0.0000             nan     0.4081   -0.0000
  2200        0.0000             nan     0.4081   -0.0000
  2220        0.0000             nan     0.4081   -0.0000
  2240        0.0000             nan     0.4081    0.0000
  2260        0.0000             nan     0.4081   -0.0000
  2280        0.0000             nan     0.4081   -0.0000
  2300        0.0000             nan     0.4081   -0.0000
  2320        0.0000             nan     0.4081   -0.0000
  2340        0.0000             nan     0.4081   -0.0000
  2360        0.0000             nan     0.4081   -0.0000
  2380        0.0000             nan     0.4081   -0.0000
  2400        0.0000             nan     0.4081   -0.0000
  2420        0.0000             nan     0.4081   -0.0000
  2440        0.0000             nan     0.4081   -0.0000
  2460        0.0000             nan     0.4081   -0.0000
  2480        0.0000             nan     0.4081   -0.0000
  2500        0.0000             nan     0.4081   -0.0000
  2520        0.0000             nan     0.4081    0.0000
  2540        0.0000             nan     0.4081   -0.0000
  2560        0.0000             nan     0.4081   -0.0000
  2580        0.0000             nan     0.4081   -0.0000
  2600        0.0000             nan     0.4081   -0.0000
  2620        0.0000             nan     0.4081   -0.0000
  2640        0.0000             nan     0.4081   -0.0000
  2660        0.0000             nan     0.4081   -0.0000
  2680        0.0000             nan     0.4081   -0.0000
  2700        0.0000             nan     0.4081   -0.0000
  2720        0.0000             nan     0.4081   -0.0000
  2740        0.0000             nan     0.4081   -0.0000
  2760        0.0000             nan     0.4081   -0.0000
  2780        0.0000             nan     0.4081   -0.0000
  2800        0.0000             nan     0.4081   -0.0000
  2820        0.0000             nan     0.4081   -0.0000
  2840        0.0000             nan     0.4081   -0.0000
  2860        0.0000             nan     0.4081   -0.0000
  2880        0.0000             nan     0.4081   -0.0000
  2900        0.0000             nan     0.4081   -0.0000
  2920        0.0000             nan     0.4081   -0.0000
  2940        0.0000             nan     0.4081   -0.0000
  2960        0.0000             nan     0.4081   -0.0000
  2980        0.0000             nan     0.4081   -0.0000
  3000        0.0000             nan     0.4081   -0.0000
  3020        0.0000             nan     0.4081   -0.0000
  3040        0.0000             nan     0.4081   -0.0000
  3060        0.0000             nan     0.4081   -0.0000
  3080        0.0000             nan     0.4081   -0.0000
  3100        0.0000             nan     0.4081   -0.0000
  3120        0.0000             nan     0.4081   -0.0000
  3140        0.0000             nan     0.4081   -0.0000
  3160        0.0000             nan     0.4081   -0.0000
  3180        0.0000             nan     0.4081   -0.0000
  3200        0.0000             nan     0.4081   -0.0000
  3220        0.0000             nan     0.4081   -0.0000
  3240        0.0000             nan     0.4081   -0.0000
  3260        0.0000             nan     0.4081   -0.0000
  3280        0.0000             nan     0.4081   -0.0000
  3300        0.0000             nan     0.4081   -0.0000
  3320        0.0000             nan     0.4081   -0.0000
  3340        0.0000             nan     0.4081   -0.0000
  3360        0.0000             nan     0.4081   -0.0000
  3380        0.0000             nan     0.4081    0.0000
  3400        0.0000             nan     0.4081   -0.0000
  3420        0.0000             nan     0.4081   -0.0000
  3440        0.0000             nan     0.4081   -0.0000
  3460        0.0000             nan     0.4081   -0.0000
  3480        0.0000             nan     0.4081   -0.0000
  3500        0.0000             nan     0.4081   -0.0000
  3520        0.0000             nan     0.4081   -0.0000
  3540        0.0000             nan     0.4081   -0.0000
  3560        0.0000             nan     0.4081   -0.0000
  3580        0.0000             nan     0.4081   -0.0000
  3600        0.0000             nan     0.4081   -0.0000
  3620        0.0000             nan     0.4081   -0.0000
  3640        0.0000             nan     0.4081   -0.0000
  3660        0.0000             nan     0.4081   -0.0000
  3680        0.0000             nan     0.4081   -0.0000
  3700        0.0000             nan     0.4081   -0.0000
  3720        0.0000             nan     0.4081   -0.0000
  3740        0.0000             nan     0.4081   -0.0000
  3760        0.0000             nan     0.4081   -0.0000
  3780        0.0000             nan     0.4081   -0.0000
  3800        0.0000             nan     0.4081   -0.0000
  3820        0.0000             nan     0.4081   -0.0000
  3835        0.0000             nan     0.4081    0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9434             nan     0.4204   -0.0144
     2        0.9096             nan     0.4204   -0.0193
     3        0.8909             nan     0.4204   -0.0274
     4        0.8731             nan     0.4204   -0.0477
     5        0.8429             nan     0.4204   -0.0164
     6        0.8100             nan     0.4204   -0.0374
     7        0.7905             nan     0.4204   -0.0415
     8        0.7579             nan     0.4204   -0.0217
     9        0.7375             nan     0.4204   -0.0152
    10        0.7184             nan     0.4204   -0.0296
    20        0.5913             nan     0.4204   -0.0073
    40        0.4198             nan     0.4204   -0.0271
    60        0.2884             nan     0.4204   -0.0205
    80        0.2104             nan     0.4204   -0.0128
   100        0.1382             nan     0.4204   -0.0086
   120        0.1007             nan     0.4204    0.0004
   140        0.0711             nan     0.4204   -0.0027
   160        0.0484             nan     0.4204   -0.0007
   180        0.0336             nan     0.4204   -0.0010
   200        0.0231             nan     0.4204   -0.0012
   220        0.0167             nan     0.4204   -0.0014
   240        0.0125             nan     0.4204   -0.0005
   260        0.0092             nan     0.4204   -0.0003
   280        0.0069             nan     0.4204   -0.0003
   300        0.0048             nan     0.4204   -0.0002
   320        0.0035             nan     0.4204   -0.0002
   340        0.0026             nan     0.4204   -0.0001
   360        0.0019             nan     0.4204   -0.0001
   380        0.0014             nan     0.4204   -0.0001
   400        0.0010             nan     0.4204   -0.0001
   420        0.0007             nan     0.4204   -0.0000
   440        0.0005             nan     0.4204   -0.0000
   460        0.0004             nan     0.4204   -0.0000
   480        0.0003             nan     0.4204   -0.0000
   500        0.0002             nan     0.4204   -0.0000
   520        0.0002             nan     0.4204   -0.0000
   540        0.0001             nan     0.4204   -0.0000
   560        0.0001             nan     0.4204   -0.0000
   580        0.0001             nan     0.4204   -0.0000
   600        0.0000             nan     0.4204   -0.0000
   620        0.0000             nan     0.4204   -0.0000
   640        0.0000             nan     0.4204   -0.0000
   660        0.0000             nan     0.4204   -0.0000
   680        0.0000             nan     0.4204   -0.0000
   700        0.0000             nan     0.4204   -0.0000
   720        0.0000             nan     0.4204   -0.0000
   740        0.0000             nan     0.4204   -0.0000
   760        0.0000             nan     0.4204   -0.0000
   780        0.0000             nan     0.4204   -0.0000
   800        0.0000             nan     0.4204   -0.0000
   820        0.0000             nan     0.4204   -0.0000
   840        0.0000             nan     0.4204   -0.0000
   860        0.0000             nan     0.4204   -0.0000
   880        0.0000             nan     0.4204   -0.0000
   900        0.0000             nan     0.4204   -0.0000
   920        0.0000             nan     0.4204   -0.0000
   940        0.0000             nan     0.4204   -0.0000
   960        0.0000             nan     0.4204   -0.0000
   980        0.0000             nan     0.4204   -0.0000
  1000        0.0000             nan     0.4204   -0.0000
  1020        0.0000             nan     0.4204   -0.0000
  1040        0.0000             nan     0.4204   -0.0000
  1060        0.0000             nan     0.4204   -0.0000
  1080        0.0000             nan     0.4204   -0.0000
  1100        0.0000             nan     0.4204   -0.0000
  1120        0.0000             nan     0.4204   -0.0000
  1140        0.0000             nan     0.4204   -0.0000
  1160        0.0000             nan     0.4204   -0.0000
  1180        0.0000             nan     0.4204   -0.0000
  1200        0.0000             nan     0.4204   -0.0000
  1220        0.0000             nan     0.4204   -0.0000
  1240        0.0000             nan     0.4204   -0.0000
  1260        0.0000             nan     0.4204   -0.0000
  1280        0.0000             nan     0.4204   -0.0000
  1300        0.0000             nan     0.4204   -0.0000
  1320        0.0000             nan     0.4204   -0.0000
  1340        0.0000             nan     0.4204   -0.0000
  1360        0.0000             nan     0.4204   -0.0000
  1380        0.0000             nan     0.4204   -0.0000
  1400        0.0000             nan     0.4204   -0.0000
  1420        0.0000             nan     0.4204   -0.0000
  1440        0.0000             nan     0.4204   -0.0000
  1460        0.0000             nan     0.4204   -0.0000
  1480        0.0000             nan     0.4204   -0.0000
  1500        0.0000             nan     0.4204   -0.0000
  1520        0.0000             nan     0.4204   -0.0000
  1540        0.0000             nan     0.4204   -0.0000
  1560        0.0000             nan     0.4204   -0.0000
  1580        0.0000             nan     0.4204   -0.0000
  1600        0.0000             nan     0.4204   -0.0000
  1620        0.0000             nan     0.4204   -0.0000
  1640        0.0000             nan     0.4204   -0.0000
  1660        0.0000             nan     0.4204   -0.0000
  1680        0.0000             nan     0.4204   -0.0000
  1700        0.0000             nan     0.4204   -0.0000
  1720        0.0000             nan     0.4204   -0.0000
  1740        0.0000             nan     0.4204   -0.0000
  1760        0.0000             nan     0.4204   -0.0000
  1780        0.0000             nan     0.4204   -0.0000
  1800        0.0000             nan     0.4204   -0.0000
  1820        0.0000             nan     0.4204   -0.0000
  1840        0.0000             nan     0.4204   -0.0000
  1860        0.0000             nan     0.4204   -0.0000
  1880        0.0000             nan     0.4204   -0.0000
  1900        0.0000             nan     0.4204   -0.0000
  1920        0.0000             nan     0.4204   -0.0000
  1940        0.0000             nan     0.4204   -0.0000
  1960        0.0000             nan     0.4204   -0.0000
  1980        0.0000             nan     0.4204   -0.0000
  2000        0.0000             nan     0.4204   -0.0000
  2020        0.0000             nan     0.4204   -0.0000
  2040        0.0000             nan     0.4204   -0.0000
  2060        0.0000             nan     0.4204   -0.0000
  2080        0.0000             nan     0.4204   -0.0000
  2100        0.0000             nan     0.4204   -0.0000
  2120        0.0000             nan     0.4204   -0.0000
  2140        0.0000             nan     0.4204   -0.0000
  2160        0.0000             nan     0.4204   -0.0000
  2180        0.0000             nan     0.4204   -0.0000
  2200        0.0000             nan     0.4204   -0.0000
  2220        0.0000             nan     0.4204   -0.0000
  2240        0.0000             nan     0.4204   -0.0000
  2260        0.0000             nan     0.4204   -0.0000
  2280        0.0000             nan     0.4204   -0.0000
  2300        0.0000             nan     0.4204   -0.0000
  2320        0.0000             nan     0.4204   -0.0000
  2340        0.0000             nan     0.4204   -0.0000
  2360        0.0000             nan     0.4204   -0.0000
  2380        0.0000             nan     0.4204   -0.0000
  2400        0.0000             nan     0.4204   -0.0000
  2420        0.0000             nan     0.4204   -0.0000
  2440        0.0000             nan     0.4204   -0.0000
  2460        0.0000             nan     0.4204   -0.0000
  2480        0.0000             nan     0.4204   -0.0000
  2500        0.0000             nan     0.4204   -0.0000
  2520        0.0000             nan     0.4204   -0.0000
  2540        0.0000             nan     0.4204   -0.0000
  2560        0.0000             nan     0.4204   -0.0000
  2580        0.0000             nan     0.4204   -0.0000
  2600        0.0000             nan     0.4204   -0.0000
  2620        0.0000             nan     0.4204   -0.0000
  2640        0.0000             nan     0.4204   -0.0000
  2660        0.0000             nan     0.4204   -0.0000
  2680        0.0000             nan     0.4204   -0.0000
  2700        0.0000             nan     0.4204   -0.0000
  2720        0.0000             nan     0.4204   -0.0000
  2740        0.0000             nan     0.4204   -0.0000
  2760        0.0000             nan     0.4204   -0.0000
  2780        0.0000             nan     0.4204   -0.0000
  2800        0.0000             nan     0.4204   -0.0000
  2820        0.0000             nan     0.4204   -0.0000
  2840        0.0000             nan     0.4204   -0.0000
  2860        0.0000             nan     0.4204   -0.0000
  2880        0.0000             nan     0.4204   -0.0000
  2900        0.0000             nan     0.4204   -0.0000
  2920        0.0000             nan     0.4204   -0.0000
  2940        0.0000             nan     0.4204   -0.0000
  2960        0.0000             nan     0.4204   -0.0000
  2980        0.0000             nan     0.4204   -0.0000
  3000        0.0000             nan     0.4204   -0.0000
  3020        0.0000             nan     0.4204   -0.0000
  3040        0.0000             nan     0.4204   -0.0000
  3060        0.0000             nan     0.4204   -0.0000
  3080        0.0000             nan     0.4204   -0.0000
  3100        0.0000             nan     0.4204   -0.0000
  3120        0.0000             nan     0.4204   -0.0000
  3140        0.0000             nan     0.4204   -0.0000
  3160        0.0000             nan     0.4204   -0.0000
  3180        0.0000             nan     0.4204   -0.0000
  3200        0.0000             nan     0.4204   -0.0000
  3220        0.0000             nan     0.4204   -0.0000
  3240        0.0000             nan     0.4204   -0.0000
  3260        0.0000             nan     0.4204   -0.0000
  3280        0.0000             nan     0.4204   -0.0000
  3300        0.0000             nan     0.4204   -0.0000
  3320        0.0000             nan     0.4204   -0.0000
  3340        0.0000             nan     0.4204   -0.0000
  3360        0.0000             nan     0.4204   -0.0000
  3380        0.0000             nan     0.4204   -0.0000
  3400        0.0000             nan     0.4204   -0.0000
  3420        0.0000             nan     0.4204   -0.0000
  3440        0.0000             nan     0.4204   -0.0000
  3460        0.0000             nan     0.4204   -0.0000
  3480        0.0000             nan     0.4204   -0.0000
  3500        0.0000             nan     0.4204   -0.0000
  3520        0.0000             nan     0.4204   -0.0000
  3540        0.0000             nan     0.4204   -0.0000
  3560        0.0000             nan     0.4204   -0.0000
  3580        0.0000             nan     0.4204   -0.0000
  3600        0.0000             nan     0.4204   -0.0000
  3620        0.0000             nan     0.4204   -0.0000
  3640        0.0000             nan     0.4204   -0.0000
  3660        0.0000             nan     0.4204   -0.0000
  3680        0.0000             nan     0.4204   -0.0000
  3700        0.0000             nan     0.4204   -0.0000
  3720        0.0000             nan     0.4204   -0.0000
  3740        0.0000             nan     0.4204   -0.0000
  3760        0.0000             nan     0.4204   -0.0000
  3780        0.0000             nan     0.4204   -0.0000
  3800        0.0000             nan     0.4204   -0.0000
  3820        0.0000             nan     0.4204   -0.0000
  3840        0.0000             nan     0.4204   -0.0000
  3860        0.0000             nan     0.4204   -0.0000
  3880        0.0000             nan     0.4204   -0.0000
  3900        0.0000             nan     0.4204   -0.0000
  3920        0.0000             nan     0.4204   -0.0000
  3940        0.0000             nan     0.4204   -0.0000
  3960        0.0000             nan     0.4204   -0.0000
  3980        0.0000             nan     0.4204   -0.0000
  4000        0.0000             nan     0.4204   -0.0000
  4020        0.0000             nan     0.4204   -0.0000
  4040        0.0000             nan     0.4204   -0.0000
  4060        0.0000             nan     0.4204   -0.0000
  4080        0.0000             nan     0.4204   -0.0000
  4100        0.0000             nan     0.4204   -0.0000
  4120        0.0000             nan     0.4204   -0.0000
  4140        0.0000             nan     0.4204   -0.0000
  4160        0.0000             nan     0.4204   -0.0000
  4180        0.0000             nan     0.4204   -0.0000
  4200        0.0000             nan     0.4204   -0.0000
  4220        0.0000             nan     0.4204   -0.0000
  4240        0.0000             nan     0.4204   -0.0000
  4260        0.0000             nan     0.4204   -0.0000
  4280        0.0000             nan     0.4204   -0.0000
  4300        0.0000             nan     0.4204   -0.0000
  4320        0.0000             nan     0.4204   -0.0000
  4340        0.0000             nan     0.4204   -0.0000
  4360        0.0000             nan     0.4204   -0.0000
  4380        0.0000             nan     0.4204   -0.0000
  4400        0.0000             nan     0.4204   -0.0000
  4420        0.0000             nan     0.4204   -0.0000
  4440        0.0000             nan     0.4204   -0.0000
  4460        0.0000             nan     0.4204   -0.0000
  4480        0.0000             nan     0.4204   -0.0000
  4500        0.0000             nan     0.4204   -0.0000
  4520        0.0000             nan     0.4204   -0.0000
  4540        0.0000             nan     0.4204   -0.0000
  4560        0.0000             nan     0.4204   -0.0000
  4580        0.0000             nan     0.4204   -0.0000
  4600        0.0000             nan     0.4204   -0.0000
  4620        0.0000             nan     0.4204   -0.0000
  4640        0.0000             nan     0.4204   -0.0000
  4660        0.0000             nan     0.4204   -0.0000
  4680        0.0000             nan     0.4204   -0.0000
  4700        0.0000             nan     0.4204   -0.0000
  4720        0.0000             nan     0.4204   -0.0000
  4740        0.0000             nan     0.4204   -0.0000
  4760        0.0000             nan     0.4204   -0.0000
  4780        0.0000             nan     0.4204   -0.0000
  4800        0.0000             nan     0.4204   -0.0000
  4820        0.0000             nan     0.4204   -0.0000
  4840        0.0000             nan     0.4204   -0.0000
  4860        0.0000             nan     0.4204   -0.0000
  4880        0.0000             nan     0.4204   -0.0000
  4900        0.0000             nan     0.4204   -0.0000
  4920        0.0000             nan     0.4204   -0.0000
  4940        0.0000             nan     0.4204   -0.0000
  4960        0.0000             nan     0.4204   -0.0000
  4980        0.0000             nan     0.4204   -0.0000
  4996        0.0000             nan     0.4204   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9238             nan     0.4363   -0.0422
     2        0.8887             nan     0.4363   -0.0776
     3        0.8508             nan     0.4363   -0.0482
     4        0.8067             nan     0.4363   -0.0181
     5        0.7798             nan     0.4363   -0.0466
     6        0.7538             nan     0.4363   -0.0341
     7        0.7298             nan     0.4363   -0.0817
     8        0.7117             nan     0.4363   -0.0519
     9        0.6860             nan     0.4363   -0.0267
    10        0.6629             nan     0.4363   -0.0381
    20        0.4655             nan     0.4363   -0.0320
    40        0.2822             nan     0.4363   -0.0157
    60        0.1646             nan     0.4363   -0.0027
    80        0.0988             nan     0.4363   -0.0101
   100        0.0579             nan     0.4363   -0.0040
   120        0.0323             nan     0.4363   -0.0023
   140        0.0193             nan     0.4363   -0.0013
   160        0.0118             nan     0.4363   -0.0006
   180        0.0074             nan     0.4363   -0.0003
   200        0.0045             nan     0.4363   -0.0005
   220        0.0028             nan     0.4363   -0.0002
   240        0.0017             nan     0.4363   -0.0001
   260        0.0011             nan     0.4363   -0.0001
   280        0.0007             nan     0.4363   -0.0000
   300        0.0004             nan     0.4363   -0.0000
   320        0.0003             nan     0.4363   -0.0000
   340        0.0002             nan     0.4363   -0.0000
   360        0.0001             nan     0.4363   -0.0000
   380        0.0001             nan     0.4363   -0.0000
   400        0.0000             nan     0.4363   -0.0000
   420        0.0000             nan     0.4363   -0.0000
   440        0.0000             nan     0.4363   -0.0000
   460        0.0000             nan     0.4363   -0.0000
   480        0.0000             nan     0.4363   -0.0000
   500        0.0000             nan     0.4363   -0.0000
   520        0.0000             nan     0.4363   -0.0000
   540        0.0000             nan     0.4363   -0.0000
   560        0.0000             nan     0.4363   -0.0000
   580        0.0000             nan     0.4363   -0.0000
   600        0.0000             nan     0.4363   -0.0000
   620        0.0000             nan     0.4363   -0.0000
   640        0.0000             nan     0.4363   -0.0000
   660        0.0000             nan     0.4363   -0.0000
   680        0.0000             nan     0.4363   -0.0000
   700        0.0000             nan     0.4363   -0.0000
   720        0.0000             nan     0.4363   -0.0000
   740        0.0000             nan     0.4363   -0.0000
   760        0.0000             nan     0.4363   -0.0000
   780        0.0000             nan     0.4363   -0.0000
   800        0.0000             nan     0.4363   -0.0000
   820        0.0000             nan     0.4363   -0.0000
   840        0.0000             nan     0.4363   -0.0000
   860        0.0000             nan     0.4363   -0.0000
   880        0.0000             nan     0.4363   -0.0000
   900        0.0000             nan     0.4363   -0.0000
   920        0.0000             nan     0.4363   -0.0000
   940        0.0000             nan     0.4363   -0.0000
   960        0.0000             nan     0.4363   -0.0000
   980        0.0000             nan     0.4363   -0.0000
  1000        0.0000             nan     0.4363   -0.0000
  1020        0.0000             nan     0.4363   -0.0000
  1040        0.0000             nan     0.4363   -0.0000
  1060        0.0000             nan     0.4363   -0.0000
  1080        0.0000             nan     0.4363   -0.0000
  1100        0.0000             nan     0.4363   -0.0000
  1120        0.0000             nan     0.4363   -0.0000
  1140        0.0000             nan     0.4363   -0.0000
  1160        0.0000             nan     0.4363   -0.0000
  1180        0.0000             nan     0.4363   -0.0000
  1200        0.0000             nan     0.4363   -0.0000
  1220        0.0000             nan     0.4363   -0.0000
  1240        0.0000             nan     0.4363   -0.0000
  1260        0.0000             nan     0.4363   -0.0000
  1280        0.0000             nan     0.4363   -0.0000
  1300        0.0000             nan     0.4363   -0.0000
  1320        0.0000             nan     0.4363   -0.0000
  1340        0.0000             nan     0.4363   -0.0000
  1360        0.0000             nan     0.4363   -0.0000
  1380        0.0000             nan     0.4363   -0.0000
  1400        0.0000             nan     0.4363   -0.0000
  1420        0.0000             nan     0.4363   -0.0000
  1440        0.0000             nan     0.4363   -0.0000
  1460        0.0000             nan     0.4363   -0.0000
  1480        0.0000             nan     0.4363   -0.0000
  1500        0.0000             nan     0.4363   -0.0000
  1520        0.0000             nan     0.4363   -0.0000
  1540        0.0000             nan     0.4363   -0.0000
  1560        0.0000             nan     0.4363   -0.0000
  1580        0.0000             nan     0.4363   -0.0000
  1600        0.0000             nan     0.4363   -0.0000
  1620        0.0000             nan     0.4363   -0.0000
  1640        0.0000             nan     0.4363   -0.0000
  1660        0.0000             nan     0.4363   -0.0000
  1680        0.0000             nan     0.4363   -0.0000
  1700        0.0000             nan     0.4363   -0.0000
  1720        0.0000             nan     0.4363   -0.0000
  1740        0.0000             nan     0.4363   -0.0000
  1760        0.0000             nan     0.4363   -0.0000
  1780        0.0000             nan     0.4363   -0.0000
  1800        0.0000             nan     0.4363   -0.0000
  1820        0.0000             nan     0.4363   -0.0000
  1840        0.0000             nan     0.4363   -0.0000
  1860        0.0000             nan     0.4363   -0.0000
  1880        0.0000             nan     0.4363   -0.0000
  1900        0.0000             nan     0.4363   -0.0000
  1920        0.0000             nan     0.4363   -0.0000
  1940        0.0000             nan     0.4363   -0.0000
  1960        0.0000             nan     0.4363   -0.0000
  1980        0.0000             nan     0.4363   -0.0000
  2000        0.0000             nan     0.4363   -0.0000
  2020        0.0000             nan     0.4363   -0.0000
  2040        0.0000             nan     0.4363   -0.0000
  2060        0.0000             nan     0.4363   -0.0000
  2080        0.0000             nan     0.4363   -0.0000
  2100        0.0000             nan     0.4363   -0.0000
  2120        0.0000             nan     0.4363   -0.0000
  2140        0.0000             nan     0.4363   -0.0000
  2160        0.0000             nan     0.4363   -0.0000
  2180        0.0000             nan     0.4363   -0.0000
  2200        0.0000             nan     0.4363   -0.0000
  2220        0.0000             nan     0.4363   -0.0000
  2240        0.0000             nan     0.4363   -0.0000
  2260        0.0000             nan     0.4363   -0.0000
  2280        0.0000             nan     0.4363   -0.0000
  2300        0.0000             nan     0.4363   -0.0000
  2320        0.0000             nan     0.4363   -0.0000
  2340        0.0000             nan     0.4363   -0.0000
  2360        0.0000             nan     0.4363   -0.0000
  2380        0.0000             nan     0.4363   -0.0000
  2400        0.0000             nan     0.4363   -0.0000
  2420        0.0000             nan     0.4363   -0.0000
  2440        0.0000             nan     0.4363   -0.0000
  2460        0.0000             nan     0.4363   -0.0000
  2480        0.0000             nan     0.4363   -0.0000
  2500        0.0000             nan     0.4363   -0.0000
  2520        0.0000             nan     0.4363   -0.0000
  2540        0.0000             nan     0.4363   -0.0000
  2560        0.0000             nan     0.4363   -0.0000
  2580        0.0000             nan     0.4363    0.0000
  2594        0.0000             nan     0.4363   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9550             nan     0.4488   -0.0513
     2        0.9373             nan     0.4488   -0.0339
     3        0.9051             nan     0.4488   -0.0014
     4        0.8718             nan     0.4488   -0.0168
     5        0.8553             nan     0.4488   -0.0244
     6        0.8445             nan     0.4488   -0.0403
     7        0.8390             nan     0.4488   -0.0627
     8        0.8170             nan     0.4488   -0.0172
     9        0.7946             nan     0.4488   -0.0302
    10        0.7868             nan     0.4488   -0.0331
    20        0.6845             nan     0.4488   -0.0241
    40        0.4677             nan     0.4488   -0.0105
    60        0.3535             nan     0.4488   -0.0141
    80        0.2720             nan     0.4488   -0.0122
   100        0.2075             nan     0.4488   -0.0081
   120        0.1611             nan     0.4488   -0.0068
   140        0.1211             nan     0.4488   -0.0054
   160        0.0929             nan     0.4488   -0.0038
   180        0.0732             nan     0.4488   -0.0029
   200        0.0551             nan     0.4488   -0.0009
   220        0.0418             nan     0.4488   -0.0025
   240        0.0340             nan     0.4488   -0.0019
   260        0.0260             nan     0.4488   -0.0007
   280        0.0206             nan     0.4488   -0.0014
   300        0.0165             nan     0.4488   -0.0007
   320        0.0124             nan     0.4488   -0.0006
   340        0.0099             nan     0.4488   -0.0005
   360        0.0075             nan     0.4488   -0.0003
   380        0.0060             nan     0.4488   -0.0006
   400        0.0046             nan     0.4488   -0.0002
   420        0.0036             nan     0.4488   -0.0002
   440        0.0029             nan     0.4488   -0.0002
   460        0.0022             nan     0.4488   -0.0001
   480        0.0017             nan     0.4488   -0.0001
   500        0.0013             nan     0.4488   -0.0000
   520        0.0010             nan     0.4488   -0.0001
   540        0.0008             nan     0.4488   -0.0000
   560        0.0006             nan     0.4488   -0.0000
   580        0.0004             nan     0.4488   -0.0000
   600        0.0003             nan     0.4488   -0.0000
   620        0.0003             nan     0.4488   -0.0000
   640        0.0002             nan     0.4488   -0.0000
   660        0.0002             nan     0.4488   -0.0000
   680        0.0001             nan     0.4488   -0.0000
   700        0.0001             nan     0.4488   -0.0000
   720        0.0001             nan     0.4488   -0.0000
   740        0.0001             nan     0.4488   -0.0000
   760        0.0000             nan     0.4488   -0.0000
   780        0.0000             nan     0.4488   -0.0000
   800        0.0000             nan     0.4488   -0.0000
   820        0.0000             nan     0.4488   -0.0000
   840        0.0000             nan     0.4488   -0.0000
   860        0.0000             nan     0.4488   -0.0000
   880        0.0000             nan     0.4488   -0.0000
   900        0.0000             nan     0.4488   -0.0000
   920        0.0000             nan     0.4488   -0.0000
   940        0.0000             nan     0.4488   -0.0000
   960        0.0000             nan     0.4488   -0.0000
   980        0.0000             nan     0.4488   -0.0000
  1000        0.0000             nan     0.4488   -0.0000
  1020        0.0000             nan     0.4488   -0.0000
  1040        0.0000             nan     0.4488   -0.0000
  1060        0.0000             nan     0.4488   -0.0000
  1080        0.0000             nan     0.4488   -0.0000
  1100        0.0000             nan     0.4488   -0.0000
  1120        0.0000             nan     0.4488   -0.0000
  1140        0.0000             nan     0.4488   -0.0000
  1160        0.0000             nan     0.4488   -0.0000
  1180        0.0000             nan     0.4488   -0.0000
  1200        0.0000             nan     0.4488   -0.0000
  1220        0.0000             nan     0.4488   -0.0000
  1240        0.0000             nan     0.4488   -0.0000
  1260        0.0000             nan     0.4488   -0.0000
  1280        0.0000             nan     0.4488   -0.0000
  1300        0.0000             nan     0.4488   -0.0000
  1320        0.0000             nan     0.4488   -0.0000
  1340        0.0000             nan     0.4488   -0.0000
  1360        0.0000             nan     0.4488   -0.0000
  1380        0.0000             nan     0.4488   -0.0000
  1400        0.0000             nan     0.4488   -0.0000
  1420        0.0000             nan     0.4488   -0.0000
  1440        0.0000             nan     0.4488   -0.0000
  1460        0.0000             nan     0.4488   -0.0000
  1480        0.0000             nan     0.4488   -0.0000
  1500        0.0000             nan     0.4488   -0.0000
  1520        0.0000             nan     0.4488   -0.0000
  1540        0.0000             nan     0.4488   -0.0000
  1560        0.0000             nan     0.4488   -0.0000
  1580        0.0000             nan     0.4488   -0.0000
  1600        0.0000             nan     0.4488   -0.0000
  1620        0.0000             nan     0.4488   -0.0000
  1640        0.0000             nan     0.4488   -0.0000
  1660        0.0000             nan     0.4488   -0.0000
  1680        0.0000             nan     0.4488   -0.0000
  1700        0.0000             nan     0.4488   -0.0000
  1720        0.0000             nan     0.4488   -0.0000
  1740        0.0000             nan     0.4488   -0.0000
  1760        0.0000             nan     0.4488   -0.0000
  1780        0.0000             nan     0.4488   -0.0000
  1800        0.0000             nan     0.4488   -0.0000
  1820        0.0000             nan     0.4488   -0.0000
  1840        0.0000             nan     0.4488   -0.0000
  1860        0.0000             nan     0.4488   -0.0000
  1880        0.0000             nan     0.4488   -0.0000
  1900        0.0000             nan     0.4488   -0.0000
  1920        0.0000             nan     0.4488   -0.0000
  1940        0.0000             nan     0.4488   -0.0000
  1960        0.0000             nan     0.4488   -0.0000
  1980        0.0000             nan     0.4488   -0.0000
  2000        0.0000             nan     0.4488   -0.0000
  2020        0.0000             nan     0.4488   -0.0000
  2040        0.0000             nan     0.4488   -0.0000
  2060        0.0000             nan     0.4488   -0.0000
  2080        0.0000             nan     0.4488   -0.0000
  2100        0.0000             nan     0.4488   -0.0000
  2120        0.0000             nan     0.4488   -0.0000
  2140        0.0000             nan     0.4488   -0.0000
  2160        0.0000             nan     0.4488   -0.0000
  2180        0.0000             nan     0.4488   -0.0000
  2200        0.0000             nan     0.4488   -0.0000
  2220        0.0000             nan     0.4488   -0.0000
  2240        0.0000             nan     0.4488   -0.0000
  2260        0.0000             nan     0.4488   -0.0000
  2280        0.0000             nan     0.4488   -0.0000
  2300        0.0000             nan     0.4488   -0.0000
  2320        0.0000             nan     0.4488   -0.0000
  2340        0.0000             nan     0.4488   -0.0000
  2360        0.0000             nan     0.4488   -0.0000
  2380        0.0000             nan     0.4488   -0.0000
  2400        0.0000             nan     0.4488   -0.0000
  2420        0.0000             nan     0.4488   -0.0000
  2440        0.0000             nan     0.4488   -0.0000
  2460        0.0000             nan     0.4488   -0.0000
  2480        0.0000             nan     0.4488   -0.0000
  2500        0.0000             nan     0.4488   -0.0000
  2520        0.0000             nan     0.4488   -0.0000
  2540        0.0000             nan     0.4488   -0.0000
  2560        0.0000             nan     0.4488   -0.0000
  2580        0.0000             nan     0.4488   -0.0000
  2600        0.0000             nan     0.4488   -0.0000
  2620        0.0000             nan     0.4488   -0.0000
  2640        0.0000             nan     0.4488   -0.0000
  2660        0.0000             nan     0.4488   -0.0000
  2680        0.0000             nan     0.4488   -0.0000
  2700        0.0000             nan     0.4488   -0.0000
  2720        0.0000             nan     0.4488   -0.0000
  2740        0.0000             nan     0.4488   -0.0000
  2760        0.0000             nan     0.4488   -0.0000
  2780        0.0000             nan     0.4488   -0.0000
  2800        0.0000             nan     0.4488   -0.0000
  2803        0.0000             nan     0.4488   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9612             nan     0.4523   -0.0533
     2        0.9223             nan     0.4523   -0.0453
     3        0.9069             nan     0.4523   -0.0585
     4        0.8878             nan     0.4523   -0.0640
     5        0.8500             nan     0.4523   -0.0220
     6        0.8298             nan     0.4523   -0.0466
     7        0.7956             nan     0.4523   -0.0159
     8        0.7696             nan     0.4523   -0.0310
     9        0.7509             nan     0.4523   -0.0513
    10        0.7294             nan     0.4523   -0.0416
    20        0.5498             nan     0.4523   -0.0496
    40        0.3490             nan     0.4523   -0.0136
    60        0.2229             nan     0.4523   -0.0081
    80        0.1587             nan     0.4523   -0.0122
   100        0.1024             nan     0.4523   -0.0069
   120        0.0690             nan     0.4523   -0.0028
   140        0.0445             nan     0.4523   -0.0021
   160        0.0306             nan     0.4523   -0.0010
   180        0.0209             nan     0.4523   -0.0014
   200        0.0149             nan     0.4523   -0.0006
   220        0.0108             nan     0.4523   -0.0004
   240        0.0076             nan     0.4523   -0.0005
   260        0.0056             nan     0.4523   -0.0004
   280        0.0040             nan     0.4523   -0.0002
   300        0.0027             nan     0.4523   -0.0002
   320        0.0019             nan     0.4523   -0.0002
   340        0.0013             nan     0.4523   -0.0001
   360        0.0009             nan     0.4523   -0.0001
   380        0.0007             nan     0.4523   -0.0001
   400        0.0005             nan     0.4523   -0.0000
   420        0.0003             nan     0.4523   -0.0000
   440        0.0003             nan     0.4523   -0.0000
   460        0.0002             nan     0.4523   -0.0000
   480        0.0001             nan     0.4523   -0.0000
   500        0.0001             nan     0.4523   -0.0000
   520        0.0001             nan     0.4523   -0.0000
   540        0.0001             nan     0.4523   -0.0000
   560        0.0000             nan     0.4523   -0.0000
   580        0.0000             nan     0.4523   -0.0000
   600        0.0000             nan     0.4523   -0.0000
   620        0.0000             nan     0.4523   -0.0000
   640        0.0000             nan     0.4523   -0.0000
   660        0.0000             nan     0.4523   -0.0000
   680        0.0000             nan     0.4523   -0.0000
   700        0.0000             nan     0.4523   -0.0000
   720        0.0000             nan     0.4523   -0.0000
   740        0.0000             nan     0.4523   -0.0000
   760        0.0000             nan     0.4523   -0.0000
   780        0.0000             nan     0.4523   -0.0000
   800        0.0000             nan     0.4523   -0.0000
   820        0.0000             nan     0.4523   -0.0000
   840        0.0000             nan     0.4523   -0.0000
   860        0.0000             nan     0.4523   -0.0000
   880        0.0000             nan     0.4523   -0.0000
   900        0.0000             nan     0.4523   -0.0000
   920        0.0000             nan     0.4523   -0.0000
   940        0.0000             nan     0.4523   -0.0000
   960        0.0000             nan     0.4523   -0.0000
   980        0.0000             nan     0.4523   -0.0000
  1000        0.0000             nan     0.4523   -0.0000
  1020        0.0000             nan     0.4523   -0.0000
  1040        0.0000             nan     0.4523   -0.0000
  1060        0.0000             nan     0.4523   -0.0000
  1080        0.0000             nan     0.4523   -0.0000
  1100        0.0000             nan     0.4523   -0.0000
  1120        0.0000             nan     0.4523   -0.0000
  1140        0.0000             nan     0.4523   -0.0000
  1160        0.0000             nan     0.4523   -0.0000
  1180        0.0000             nan     0.4523   -0.0000
  1200        0.0000             nan     0.4523   -0.0000
  1220        0.0000             nan     0.4523   -0.0000
  1240        0.0000             nan     0.4523   -0.0000
  1260        0.0000             nan     0.4523   -0.0000
  1280        0.0000             nan     0.4523   -0.0000
  1300        0.0000             nan     0.4523   -0.0000
  1320        0.0000             nan     0.4523   -0.0000
  1340        0.0000             nan     0.4523   -0.0000
  1360        0.0000             nan     0.4523   -0.0000
  1380        0.0000             nan     0.4523   -0.0000
  1400        0.0000             nan     0.4523   -0.0000
  1420        0.0000             nan     0.4523   -0.0000
  1440        0.0000             nan     0.4523   -0.0000
  1460        0.0000             nan     0.4523   -0.0000
  1480        0.0000             nan     0.4523   -0.0000
  1500        0.0000             nan     0.4523   -0.0000
  1520        0.0000             nan     0.4523   -0.0000
  1540        0.0000             nan     0.4523   -0.0000
  1560        0.0000             nan     0.4523   -0.0000
  1580        0.0000             nan     0.4523   -0.0000
  1600        0.0000             nan     0.4523   -0.0000
  1620        0.0000             nan     0.4523   -0.0000
  1640        0.0000             nan     0.4523   -0.0000
  1660        0.0000             nan     0.4523   -0.0000
  1680        0.0000             nan     0.4523   -0.0000
  1700        0.0000             nan     0.4523   -0.0000
  1720        0.0000             nan     0.4523   -0.0000
  1740        0.0000             nan     0.4523   -0.0000
  1760        0.0000             nan     0.4523   -0.0000
  1780        0.0000             nan     0.4523   -0.0000
  1800        0.0000             nan     0.4523   -0.0000
  1820        0.0000             nan     0.4523   -0.0000
  1840        0.0000             nan     0.4523   -0.0000
  1860        0.0000             nan     0.4523   -0.0000
  1880        0.0000             nan     0.4523   -0.0000
  1900        0.0000             nan     0.4523   -0.0000
  1920        0.0000             nan     0.4523   -0.0000
  1940        0.0000             nan     0.4523   -0.0000
  1960        0.0000             nan     0.4523   -0.0000
  1980        0.0000             nan     0.4523   -0.0000
  2000        0.0000             nan     0.4523   -0.0000
  2020        0.0000             nan     0.4523   -0.0000
  2040        0.0000             nan     0.4523   -0.0000
  2043        0.0000             nan     0.4523   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9712             nan     0.5059   -0.0450
     2        0.9659             nan     0.5059   -0.0573
     3        0.9860             nan     0.5059   -0.0905
     4        0.9673             nan     0.5059   -0.0047
     5        0.9547             nan     0.5059   -0.0036
     6        0.9432             nan     0.5059   -0.0181
     7        0.9337             nan     0.5059   -0.0268
     8        0.9268             nan     0.5059   -0.0232
     9        0.9191             nan     0.5059   -0.0338
    10        0.9092             nan     0.5059   -0.0208
    20        0.8168             nan     0.5059   -0.0290
    40        0.7009             nan     0.5059   -0.0259
    60        0.6236             nan     0.5059   -0.0328
    80        0.5308             nan     0.5059   -0.0088
   100        0.4826             nan     0.5059   -0.0169
   120        0.4092             nan     0.5059   -0.0070
   140        0.3666             nan     0.5059    0.0007
   160        0.3245             nan     0.5059   -0.0120
   180        0.2952             nan     0.5059   -0.0106
   200        0.2755             nan     0.5059   -0.0114
   220        0.2507             nan     0.5059   -0.0080
   240        0.2228             nan     0.5059   -0.0035
   260        0.2055             nan     0.5059   -0.0053
   280        0.1833             nan     0.5059   -0.0048
   300        0.1680             nan     0.5059   -0.0068
   320        0.1513             nan     0.5059   -0.0009
   340        0.1364             nan     0.5059   -0.0047
   360        0.1240             nan     0.5059   -0.0061
   380        0.1155             nan     0.5059   -0.0027
   400        0.1067             nan     0.5059   -0.0049
   420        0.0972             nan     0.5059   -0.0013
   440        0.0892             nan     0.5059   -0.0028
   460        0.0833             nan     0.5059   -0.0008
   480        0.0749             nan     0.5059   -0.0017
   500        0.0679             nan     0.5059   -0.0025
   520        0.0588             nan     0.5059   -0.0006
   540        0.0528             nan     0.5059   -0.0023
   560        0.0481             nan     0.5059   -0.0026
   580        0.0451             nan     0.5059   -0.0017
   600        0.0419             nan     0.5059   -0.0009
   620        0.0388             nan     0.5059   -0.0006
   640        0.0371             nan     0.5059   -0.0013
   660        0.0345             nan     0.5059   -0.0019
   680        0.0323             nan     0.5059   -0.0013
   700        0.0290             nan     0.5059   -0.0008
   720        0.0265             nan     0.5059   -0.0010
   740        0.0241             nan     0.5059   -0.0005
   760        0.0224             nan     0.5059   -0.0007
   780        0.0202             nan     0.5059   -0.0004
   800        0.0190             nan     0.5059   -0.0010
   820        0.0177             nan     0.5059   -0.0005
   840        0.0163             nan     0.5059   -0.0005
   860        0.0151             nan     0.5059   -0.0010
   880        0.0135             nan     0.5059   -0.0004
   900        0.0121             nan     0.5059   -0.0003
   920        0.0112             nan     0.5059   -0.0003
   940        0.0102             nan     0.5059   -0.0004
   960        0.0097             nan     0.5059   -0.0002
   980        0.0088             nan     0.5059   -0.0002
  1000        0.0083             nan     0.5059   -0.0003
  1020        0.0076             nan     0.5059   -0.0002
  1040        0.0072             nan     0.5059   -0.0004
  1060        0.0067             nan     0.5059   -0.0000
  1080        0.0060             nan     0.5059   -0.0003
  1100        0.0055             nan     0.5059   -0.0002
  1120        0.0051             nan     0.5059   -0.0001
  1140        0.0047             nan     0.5059   -0.0001
  1160        0.0044             nan     0.5059   -0.0002
  1180        0.0040             nan     0.5059   -0.0001
  1200        0.0037             nan     0.5059   -0.0002
  1220        0.0035             nan     0.5059   -0.0001
  1240        0.0032             nan     0.5059   -0.0001
  1260        0.0029             nan     0.5059   -0.0001
  1280        0.0026             nan     0.5059   -0.0000
  1300        0.0024             nan     0.5059   -0.0000
  1320        0.0022             nan     0.5059   -0.0002
  1340        0.0020             nan     0.5059   -0.0000
  1360        0.0019             nan     0.5059   -0.0000
  1380        0.0017             nan     0.5059   -0.0000
  1400        0.0016             nan     0.5059   -0.0001
  1420        0.0015             nan     0.5059   -0.0000
  1440        0.0014             nan     0.5059   -0.0000
  1460        0.0013             nan     0.5059   -0.0000
  1480        0.0011             nan     0.5059   -0.0000
  1500        0.0010             nan     0.5059   -0.0000
  1520        0.0009             nan     0.5059   -0.0000
  1540        0.0009             nan     0.5059   -0.0000
  1560        0.0008             nan     0.5059   -0.0000
  1580        0.0007             nan     0.5059   -0.0000
  1600        0.0007             nan     0.5059   -0.0000
  1620        0.0006             nan     0.5059   -0.0000
  1640        0.0006             nan     0.5059   -0.0000
  1660        0.0005             nan     0.5059   -0.0000
  1680        0.0005             nan     0.5059   -0.0000
  1700        0.0005             nan     0.5059   -0.0000
  1720        0.0004             nan     0.5059   -0.0000
  1740        0.0004             nan     0.5059   -0.0000
  1760        0.0004             nan     0.5059   -0.0000
  1780        0.0003             nan     0.5059   -0.0000
  1800        0.0003             nan     0.5059   -0.0000
  1820        0.0003             nan     0.5059   -0.0000
  1840        0.0003             nan     0.5059   -0.0000
  1860        0.0002             nan     0.5059   -0.0000
  1880        0.0002             nan     0.5059   -0.0000
  1900        0.0002             nan     0.5059   -0.0000
  1920        0.0002             nan     0.5059   -0.0000
  1940        0.0002             nan     0.5059   -0.0000
  1960        0.0002             nan     0.5059   -0.0000
  1980        0.0001             nan     0.5059   -0.0000
  2000        0.0001             nan     0.5059   -0.0000
  2020        0.0001             nan     0.5059   -0.0000
  2040        0.0001             nan     0.5059   -0.0000
  2060        0.0001             nan     0.5059   -0.0000
  2080        0.0001             nan     0.5059   -0.0000
  2100        0.0001             nan     0.5059   -0.0000
  2120        0.0001             nan     0.5059   -0.0000
  2140        0.0001             nan     0.5059   -0.0000
  2160        0.0001             nan     0.5059   -0.0000
  2180        0.0001             nan     0.5059   -0.0000
  2200        0.0001             nan     0.5059   -0.0000
  2220        0.0001             nan     0.5059   -0.0000
  2240        0.0001             nan     0.5059   -0.0000
  2260        0.0001             nan     0.5059   -0.0000
  2280        0.0000             nan     0.5059   -0.0000
  2300        0.0000             nan     0.5059   -0.0000
  2320        0.0000             nan     0.5059   -0.0000
  2340        0.0000             nan     0.5059   -0.0000
  2360        0.0000             nan     0.5059   -0.0000
  2380        0.0000             nan     0.5059   -0.0000
  2400        0.0000             nan     0.5059   -0.0000
  2420        0.0000             nan     0.5059   -0.0000
  2440        0.0000             nan     0.5059   -0.0000
  2460        0.0000             nan     0.5059   -0.0000
  2480        0.0000             nan     0.5059   -0.0000
  2500        0.0000             nan     0.5059   -0.0000
  2520        0.0000             nan     0.5059   -0.0000
  2540        0.0000             nan     0.5059   -0.0000
  2560        0.0000             nan     0.5059   -0.0000
  2580        0.0000             nan     0.5059   -0.0000
  2600        0.0000             nan     0.5059   -0.0000
  2620        0.0000             nan     0.5059   -0.0000
  2640        0.0000             nan     0.5059   -0.0000
  2660        0.0000             nan     0.5059   -0.0000
  2680        0.0000             nan     0.5059   -0.0000
  2700        0.0000             nan     0.5059   -0.0000
  2720        0.0000             nan     0.5059   -0.0000
  2740        0.0000             nan     0.5059   -0.0000
  2760        0.0000             nan     0.5059   -0.0000
  2780        0.0000             nan     0.5059   -0.0000
  2800        0.0000             nan     0.5059   -0.0000
  2820        0.0000             nan     0.5059   -0.0000
  2840        0.0000             nan     0.5059   -0.0000
  2860        0.0000             nan     0.5059   -0.0000
  2880        0.0000             nan     0.5059   -0.0000
  2900        0.0000             nan     0.5059   -0.0000
  2920        0.0000             nan     0.5059   -0.0000
  2940        0.0000             nan     0.5059   -0.0000
  2960        0.0000             nan     0.5059   -0.0000
  2980        0.0000             nan     0.5059   -0.0000
  3000        0.0000             nan     0.5059   -0.0000
  3020        0.0000             nan     0.5059   -0.0000
  3040        0.0000             nan     0.5059   -0.0000
  3060        0.0000             nan     0.5059   -0.0000
  3080        0.0000             nan     0.5059   -0.0000
  3100        0.0000             nan     0.5059   -0.0000
  3120        0.0000             nan     0.5059   -0.0000
  3140        0.0000             nan     0.5059   -0.0000
  3160        0.0000             nan     0.5059   -0.0000
  3180        0.0000             nan     0.5059   -0.0000
  3200        0.0000             nan     0.5059   -0.0000
  3220        0.0000             nan     0.5059   -0.0000
  3240        0.0000             nan     0.5059   -0.0000
  3260        0.0000             nan     0.5059   -0.0000
  3280        0.0000             nan     0.5059   -0.0000
  3300        0.0000             nan     0.5059   -0.0000
  3320        0.0000             nan     0.5059   -0.0000
  3340        0.0000             nan     0.5059   -0.0000
  3360        0.0000             nan     0.5059   -0.0000
  3380        0.0000             nan     0.5059   -0.0000
  3400        0.0000             nan     0.5059   -0.0000
  3420        0.0000             nan     0.5059   -0.0000
  3440        0.0000             nan     0.5059   -0.0000
  3460        0.0000             nan     0.5059   -0.0000
  3480        0.0000             nan     0.5059   -0.0000
  3500        0.0000             nan     0.5059   -0.0000
  3520        0.0000             nan     0.5059   -0.0000
  3540        0.0000             nan     0.5059   -0.0000
  3560        0.0000             nan     0.5059   -0.0000
  3580        0.0000             nan     0.5059   -0.0000
  3600        0.0000             nan     0.5059   -0.0000
  3620        0.0000             nan     0.5059   -0.0000
  3640        0.0000             nan     0.5059   -0.0000
  3660        0.0000             nan     0.5059   -0.0000
  3680        0.0000             nan     0.5059   -0.0000
  3700        0.0000             nan     0.5059   -0.0000
  3720        0.0000             nan     0.5059   -0.0000
  3740        0.0000             nan     0.5059   -0.0000
  3760        0.0000             nan     0.5059   -0.0000
  3780        0.0000             nan     0.5059   -0.0000
  3800        0.0000             nan     0.5059   -0.0000
  3820        0.0000             nan     0.5059   -0.0000
  3840        0.0000             nan     0.5059   -0.0000
  3860        0.0000             nan     0.5059   -0.0000
  3880        0.0000             nan     0.5059   -0.0000
  3900        0.0000             nan     0.5059   -0.0000
  3920        0.0000             nan     0.5059   -0.0000
  3940        0.0000             nan     0.5059   -0.0000
  3960        0.0000             nan     0.5059   -0.0000
  3980        0.0000             nan     0.5059   -0.0000
  4000        0.0000             nan     0.5059   -0.0000
  4020        0.0000             nan     0.5059   -0.0000
  4040        0.0000             nan     0.5059   -0.0000
  4060        0.0000             nan     0.5059   -0.0000
  4080        0.0000             nan     0.5059   -0.0000
  4100        0.0000             nan     0.5059   -0.0000
  4120        0.0000             nan     0.5059   -0.0000
  4140        0.0000             nan     0.5059   -0.0000
  4160        0.0000             nan     0.5059   -0.0000
  4180        0.0000             nan     0.5059   -0.0000
  4200        0.0000             nan     0.5059   -0.0000
  4220        0.0000             nan     0.5059   -0.0000
  4240        0.0000             nan     0.5059   -0.0000
  4260        0.0000             nan     0.5059   -0.0000
  4280        0.0000             nan     0.5059   -0.0000
  4300        0.0000             nan     0.5059   -0.0000
  4320        0.0000             nan     0.5059   -0.0000
  4340        0.0000             nan     0.5059   -0.0000
  4360        0.0000             nan     0.5059   -0.0000
  4380        0.0000             nan     0.5059   -0.0000
  4400        0.0000             nan     0.5059   -0.0000
  4420        0.0000             nan     0.5059   -0.0000
  4440        0.0000             nan     0.5059   -0.0000
  4460        0.0000             nan     0.5059   -0.0000
  4480        0.0000             nan     0.5059   -0.0000
  4500        0.0000             nan     0.5059   -0.0000
  4520        0.0000             nan     0.5059   -0.0000
  4540        0.0000             nan     0.5059   -0.0000
  4560        0.0000             nan     0.5059   -0.0000
  4580        0.0000             nan     0.5059   -0.0000
  4600        0.0000             nan     0.5059   -0.0000
  4620        0.0000             nan     0.5059   -0.0000
  4640        0.0000             nan     0.5059   -0.0000
  4660        0.0000             nan     0.5059   -0.0000
  4680        0.0000             nan     0.5059   -0.0000
  4700        0.0000             nan     0.5059   -0.0000
  4720        0.0000             nan     0.5059   -0.0000
  4740        0.0000             nan     0.5059   -0.0000
  4760        0.0000             nan     0.5059   -0.0000
  4780        0.0000             nan     0.5059   -0.0000
  4800        0.0000             nan     0.5059   -0.0000
  4820        0.0000             nan     0.5059   -0.0000
  4840        0.0000             nan     0.5059   -0.0000
  4860        0.0000             nan     0.5059   -0.0000
  4880        0.0000             nan     0.5059   -0.0000
  4900        0.0000             nan     0.5059   -0.0000
  4920        0.0000             nan     0.5059   -0.0000
  4922        0.0000             nan     0.5059   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9445             nan     0.5986   -0.0459
     2        0.9058             nan     0.5986   -0.0564
     3        0.8839             nan     0.5986   -0.0424
     4        0.8763             nan     0.5986   -0.0805
     5        0.8139             nan     0.5986   -0.0149
     6        0.8045             nan     0.5986   -0.0657
     7        0.7788             nan     0.5986   -0.0255
     8        0.7689             nan     0.5986   -0.0527
     9        0.7542             nan     0.5986   -0.0722
    10        0.7545             nan     0.5986   -0.0674
    20        0.5778             nan     0.5986   -0.0573
    40        0.3792             nan     0.5986   -0.0024
    60        0.2539             nan     0.5986   -0.0194
    80        0.1672             nan     0.5986   -0.0145
   100        0.1131             nan     0.5986   -0.0104
   120        0.0809             nan     0.5986   -0.0079
   140        0.0562             nan     0.5986   -0.0042
   160        0.0383             nan     0.5986   -0.0026
   180        0.0256             nan     0.5986   -0.0010
   200        0.0168             nan     0.5986   -0.0013
   220        0.0118             nan     0.5986   -0.0007
   240        0.0074             nan     0.5986   -0.0004
   260        0.0049             nan     0.5986   -0.0004
   280        0.0033             nan     0.5986   -0.0001
   300        0.0024             nan     0.5986   -0.0001
   320        0.0016             nan     0.5986   -0.0000
   340        0.0012             nan     0.5986   -0.0001
   360        0.0008             nan     0.5986   -0.0001
   380        0.0006             nan     0.5986   -0.0000
   400        0.0004             nan     0.5986   -0.0001
   420        0.0003             nan     0.5986   -0.0000
   440        0.0002             nan     0.5986   -0.0000
   460        0.0002             nan     0.5986   -0.0000
   480        0.0001             nan     0.5986   -0.0000
   500        0.0001             nan     0.5986   -0.0000
   520        0.0001             nan     0.5986   -0.0000
   540        0.0000             nan     0.5986   -0.0000
   560        0.0000             nan     0.5986   -0.0000
   580        0.0000             nan     0.5986   -0.0000
   600        0.0000             nan     0.5986   -0.0000
   620        0.0000             nan     0.5986   -0.0000
   640        0.0000             nan     0.5986   -0.0000
   660        0.0000             nan     0.5986   -0.0000
   680        0.0000             nan     0.5986   -0.0000
   700        0.0000             nan     0.5986   -0.0000
   720        0.0000             nan     0.5986   -0.0000
   740        0.0000             nan     0.5986   -0.0000
   760        0.0000             nan     0.5986   -0.0000
   780        0.0000             nan     0.5986   -0.0000
   800        0.0000             nan     0.5986   -0.0000
   820        0.0000             nan     0.5986   -0.0000
   840        0.0000             nan     0.5986   -0.0000
   860        0.0000             nan     0.5986   -0.0000
   880        0.0000             nan     0.5986   -0.0000
   900        0.0000             nan     0.5986   -0.0000
   920        0.0000             nan     0.5986   -0.0000
   940        0.0000             nan     0.5986   -0.0000
   960        0.0000             nan     0.5986   -0.0000
   980        0.0000             nan     0.5986   -0.0000
  1000        0.0000             nan     0.5986   -0.0000
  1020        0.0000             nan     0.5986   -0.0000
  1040        0.0000             nan     0.5986   -0.0000
  1060        0.0000             nan     0.5986   -0.0000
  1080        0.0000             nan     0.5986   -0.0000
  1100        0.0000             nan     0.5986   -0.0000
  1120        0.0000             nan     0.5986   -0.0000
  1140        0.0000             nan     0.5986   -0.0000
  1160        0.0000             nan     0.5986   -0.0000
  1180        0.0000             nan     0.5986   -0.0000
  1200        0.0000             nan     0.5986   -0.0000
  1220        0.0000             nan     0.5986   -0.0000
  1240        0.0000             nan     0.5986   -0.0000
  1260        0.0000             nan     0.5986   -0.0000
  1280        0.0000             nan     0.5986   -0.0000
  1300        0.0000             nan     0.5986   -0.0000
  1320        0.0000             nan     0.5986   -0.0000
  1340        0.0000             nan     0.5986   -0.0000
  1360        0.0000             nan     0.5986   -0.0000
  1380        0.0000             nan     0.5986   -0.0000
  1400        0.0000             nan     0.5986   -0.0000
  1420        0.0000             nan     0.5986   -0.0000
  1440        0.0000             nan     0.5986   -0.0000
  1460        0.0000             nan     0.5986   -0.0000
  1480        0.0000             nan     0.5986   -0.0000
  1500        0.0000             nan     0.5986   -0.0000
  1520        0.0000             nan     0.5986   -0.0000
  1529        0.0000             nan     0.5986   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9958             nan     0.0142    0.0006
     2        0.9937             nan     0.0142   -0.0003
     3        0.9901             nan     0.0142    0.0008
     4        0.9876             nan     0.0142   -0.0009
     5        0.9849             nan     0.0142   -0.0006
     6        0.9829             nan     0.0142   -0.0007
     7        0.9797             nan     0.0142   -0.0002
     8        0.9760             nan     0.0142    0.0015
     9        0.9735             nan     0.0142    0.0002
    10        0.9708             nan     0.0142    0.0003
    20        0.9450             nan     0.0142    0.0001
    40        0.8959             nan     0.0142   -0.0005
    60        0.8539             nan     0.0142   -0.0001
    80        0.8167             nan     0.0142   -0.0012
   100        0.7847             nan     0.0142   -0.0008
   120        0.7534             nan     0.0142   -0.0010
   140        0.7282             nan     0.0142   -0.0012
   160        0.7010             nan     0.0142   -0.0011
   180        0.6738             nan     0.0142   -0.0012
   200        0.6489             nan     0.0142   -0.0006
   220        0.6258             nan     0.0142   -0.0005
   240        0.6017             nan     0.0142   -0.0006
   260        0.5817             nan     0.0142   -0.0011
   280        0.5630             nan     0.0142   -0.0009
   300        0.5447             nan     0.0142   -0.0008
   320        0.5252             nan     0.0142   -0.0004
   340        0.5081             nan     0.0142   -0.0009
   360        0.4931             nan     0.0142   -0.0004
   380        0.4791             nan     0.0142   -0.0006
   400        0.4651             nan     0.0142   -0.0004
   420        0.4514             nan     0.0142   -0.0006
   440        0.4389             nan     0.0142   -0.0002
   460        0.4248             nan     0.0142   -0.0004
   480        0.4119             nan     0.0142   -0.0007
   500        0.4001             nan     0.0142   -0.0003
   520        0.3885             nan     0.0142   -0.0004
   540        0.3778             nan     0.0142   -0.0003
   560        0.3669             nan     0.0142   -0.0003
   580        0.3572             nan     0.0142   -0.0010
   600        0.3478             nan     0.0142   -0.0010
   620        0.3387             nan     0.0142   -0.0005
   640        0.3298             nan     0.0142   -0.0005
   660        0.3203             nan     0.0142   -0.0005
   680        0.3116             nan     0.0142   -0.0007
   700        0.3028             nan     0.0142   -0.0008
   720        0.2945             nan     0.0142   -0.0003
   740        0.2866             nan     0.0142   -0.0003
   760        0.2783             nan     0.0142   -0.0004
   780        0.2715             nan     0.0142   -0.0006
   800        0.2643             nan     0.0142   -0.0006
   820        0.2573             nan     0.0142   -0.0006
   840        0.2509             nan     0.0142   -0.0005
   860        0.2443             nan     0.0142   -0.0006
   880        0.2381             nan     0.0142   -0.0004
   900        0.2322             nan     0.0142   -0.0003
   920        0.2262             nan     0.0142   -0.0005
   940        0.2206             nan     0.0142   -0.0004
   960        0.2153             nan     0.0142   -0.0005
   980        0.2098             nan     0.0142   -0.0004
  1000        0.2048             nan     0.0142   -0.0002
  1020        0.1994             nan     0.0142   -0.0003
  1040        0.1943             nan     0.0142   -0.0002
  1060        0.1895             nan     0.0142   -0.0004
  1080        0.1847             nan     0.0142   -0.0002
  1100        0.1804             nan     0.0142   -0.0003
  1120        0.1761             nan     0.0142   -0.0003
  1140        0.1720             nan     0.0142   -0.0003
  1160        0.1682             nan     0.0142   -0.0002
  1180        0.1643             nan     0.0142   -0.0002
  1200        0.1605             nan     0.0142   -0.0002
  1220        0.1567             nan     0.0142   -0.0004
  1240        0.1527             nan     0.0142   -0.0003
  1260        0.1489             nan     0.0142   -0.0002
  1280        0.1453             nan     0.0142   -0.0001
  1300        0.1417             nan     0.0142   -0.0005
  1320        0.1385             nan     0.0142   -0.0003
  1340        0.1351             nan     0.0142   -0.0002
  1360        0.1323             nan     0.0142   -0.0003
  1380        0.1294             nan     0.0142   -0.0003
  1400        0.1265             nan     0.0142   -0.0003
  1420        0.1235             nan     0.0142   -0.0003
  1440        0.1204             nan     0.0142   -0.0001
  1460        0.1178             nan     0.0142   -0.0002
  1480        0.1148             nan     0.0142   -0.0001
  1500        0.1123             nan     0.0142   -0.0002
  1520        0.1097             nan     0.0142   -0.0003
  1540        0.1073             nan     0.0142   -0.0003
  1560        0.1046             nan     0.0142   -0.0002
  1580        0.1022             nan     0.0142   -0.0001
  1600        0.0999             nan     0.0142   -0.0002
  1620        0.0975             nan     0.0142   -0.0002
  1640        0.0952             nan     0.0142   -0.0002
  1660        0.0930             nan     0.0142   -0.0002
  1680        0.0910             nan     0.0142   -0.0002
  1700        0.0891             nan     0.0142   -0.0001
  1720        0.0872             nan     0.0142   -0.0002
  1740        0.0852             nan     0.0142   -0.0000
  1760        0.0833             nan     0.0142   -0.0001
  1780        0.0814             nan     0.0142   -0.0001
  1800        0.0794             nan     0.0142   -0.0001
  1820        0.0775             nan     0.0142   -0.0001
  1840        0.0757             nan     0.0142   -0.0002
  1860        0.0742             nan     0.0142   -0.0002
  1880        0.0727             nan     0.0142   -0.0001
  1900        0.0711             nan     0.0142   -0.0001
  1920        0.0695             nan     0.0142   -0.0001
  1940        0.0678             nan     0.0142   -0.0001
  1960        0.0664             nan     0.0142   -0.0001
  1980        0.0649             nan     0.0142   -0.0001
  2000        0.0634             nan     0.0142   -0.0001
  2020        0.0621             nan     0.0142   -0.0001
  2040        0.0607             nan     0.0142   -0.0001
  2060        0.0592             nan     0.0142   -0.0001
  2080        0.0578             nan     0.0142   -0.0001
  2100        0.0564             nan     0.0142   -0.0001
  2120        0.0552             nan     0.0142   -0.0001
  2140        0.0539             nan     0.0142   -0.0001
  2160        0.0527             nan     0.0142   -0.0001
  2180        0.0515             nan     0.0142   -0.0001
  2200        0.0503             nan     0.0142   -0.0001
  2220        0.0491             nan     0.0142   -0.0001
  2240        0.0480             nan     0.0142   -0.0001
  2260        0.0470             nan     0.0142   -0.0001
  2280        0.0460             nan     0.0142   -0.0001
  2300        0.0450             nan     0.0142   -0.0001
  2320        0.0440             nan     0.0142   -0.0001
  2340        0.0430             nan     0.0142   -0.0001
  2360        0.0420             nan     0.0142   -0.0000
  2380        0.0410             nan     0.0142   -0.0001
  2400        0.0401             nan     0.0142   -0.0000
  2420        0.0393             nan     0.0142   -0.0001
  2440        0.0385             nan     0.0142   -0.0001
  2460        0.0376             nan     0.0142   -0.0001
  2480        0.0368             nan     0.0142   -0.0000
  2500        0.0359             nan     0.0142   -0.0000
  2520        0.0352             nan     0.0142   -0.0000
  2540        0.0344             nan     0.0142   -0.0000
  2560        0.0338             nan     0.0142   -0.0001
  2580        0.0329             nan     0.0142   -0.0000
  2600        0.0323             nan     0.0142   -0.0001
  2620        0.0316             nan     0.0142   -0.0000
  2640        0.0310             nan     0.0142   -0.0000
  2660        0.0304             nan     0.0142   -0.0000
  2680        0.0297             nan     0.0142   -0.0001
  2700        0.0290             nan     0.0142   -0.0001
  2720        0.0284             nan     0.0142   -0.0001
  2740        0.0278             nan     0.0142   -0.0001
  2760        0.0272             nan     0.0142   -0.0000
  2780        0.0266             nan     0.0142   -0.0001
  2800        0.0261             nan     0.0142    0.0000
  2820        0.0254             nan     0.0142   -0.0000
  2840        0.0249             nan     0.0142   -0.0000
  2860        0.0244             nan     0.0142   -0.0001
  2880        0.0239             nan     0.0142   -0.0000
  2900        0.0235             nan     0.0142   -0.0000
  2920        0.0229             nan     0.0142   -0.0001
  2940        0.0224             nan     0.0142   -0.0000
  2960        0.0220             nan     0.0142   -0.0000
  2980        0.0215             nan     0.0142   -0.0000
  3000        0.0211             nan     0.0142   -0.0000
  3020        0.0207             nan     0.0142   -0.0000
  3040        0.0202             nan     0.0142   -0.0000
  3047        0.0201             nan     0.0142   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9850             nan     0.1007   -0.0044
     2        0.9688             nan     0.1007    0.0022
     3        0.9477             nan     0.1007    0.0055
     4        0.9276             nan     0.1007   -0.0027
     5        0.9177             nan     0.1007   -0.0042
     6        0.9115             nan     0.1007   -0.0079
     7        0.8945             nan     0.1007   -0.0010
     8        0.8863             nan     0.1007   -0.0056
     9        0.8775             nan     0.1007   -0.0051
    10        0.8703             nan     0.1007   -0.0062
    20        0.7773             nan     0.1007    0.0011
    40        0.6408             nan     0.1007   -0.0041
    60        0.5507             nan     0.1007   -0.0052
    80        0.4804             nan     0.1007   -0.0032
   100        0.4193             nan     0.1007   -0.0042
   120        0.3640             nan     0.1007   -0.0033
   140        0.3218             nan     0.1007   -0.0046
   160        0.2898             nan     0.1007   -0.0039
   180        0.2581             nan     0.1007   -0.0017
   200        0.2319             nan     0.1007   -0.0023
   220        0.2062             nan     0.1007   -0.0035
   240        0.1846             nan     0.1007   -0.0018
   260        0.1647             nan     0.1007   -0.0005
   280        0.1479             nan     0.1007   -0.0025
   300        0.1325             nan     0.1007   -0.0016
   320        0.1190             nan     0.1007   -0.0013
   340        0.1074             nan     0.1007   -0.0009
   360        0.0964             nan     0.1007   -0.0012
   380        0.0885             nan     0.1007   -0.0012
   400        0.0806             nan     0.1007   -0.0015
   420        0.0736             nan     0.1007   -0.0007
   440        0.0674             nan     0.1007   -0.0010
   460        0.0612             nan     0.1007   -0.0007
   480        0.0551             nan     0.1007   -0.0004
   500        0.0498             nan     0.1007   -0.0006
   520        0.0452             nan     0.1007   -0.0008
   540        0.0410             nan     0.1007   -0.0008
   560        0.0369             nan     0.1007   -0.0004
   580        0.0335             nan     0.1007   -0.0005
   600        0.0308             nan     0.1007   -0.0004
   620        0.0282             nan     0.1007   -0.0006
   640        0.0257             nan     0.1007   -0.0005
   660        0.0234             nan     0.1007   -0.0003
   675        0.0218             nan     0.1007   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9796             nan     0.1139    0.0059
     2        0.9513             nan     0.1139    0.0029
     3        0.9379             nan     0.1139    0.0025
     4        0.9208             nan     0.1139    0.0054
     5        0.9078             nan     0.1139   -0.0023
     6        0.8985             nan     0.1139   -0.0068
     7        0.8849             nan     0.1139   -0.0120
     8        0.8723             nan     0.1139    0.0014
     9        0.8592             nan     0.1139   -0.0026
    10        0.8449             nan     0.1139    0.0024
    20        0.7642             nan     0.1139   -0.0069
    40        0.6383             nan     0.1139   -0.0043
    60        0.5529             nan     0.1139   -0.0076
    80        0.4720             nan     0.1139   -0.0059
   100        0.4099             nan     0.1139   -0.0053
   120        0.3549             nan     0.1139   -0.0054
   140        0.3066             nan     0.1139   -0.0045
   160        0.2681             nan     0.1139   -0.0036
   180        0.2336             nan     0.1139   -0.0019
   200        0.2069             nan     0.1139   -0.0031
   220        0.1823             nan     0.1139   -0.0037
   240        0.1652             nan     0.1139   -0.0027
   260        0.1492             nan     0.1139   -0.0015
   280        0.1337             nan     0.1139   -0.0018
   300        0.1198             nan     0.1139   -0.0022
   320        0.1086             nan     0.1139   -0.0016
   340        0.0960             nan     0.1139   -0.0009
   360        0.0858             nan     0.1139   -0.0010
   380        0.0779             nan     0.1139   -0.0009
   400        0.0694             nan     0.1139   -0.0009
   420        0.0628             nan     0.1139   -0.0007
   440        0.0568             nan     0.1139   -0.0010
   460        0.0506             nan     0.1139   -0.0005
   480        0.0455             nan     0.1139   -0.0007
   500        0.0409             nan     0.1139   -0.0007
   520        0.0364             nan     0.1139   -0.0005
   540        0.0326             nan     0.1139   -0.0003
   560        0.0296             nan     0.1139   -0.0002
   580        0.0268             nan     0.1139   -0.0003
   600        0.0244             nan     0.1139   -0.0002
   620        0.0222             nan     0.1139   -0.0002
   640        0.0200             nan     0.1139   -0.0002
   660        0.0182             nan     0.1139   -0.0002
   680        0.0165             nan     0.1139   -0.0003
   700        0.0149             nan     0.1139   -0.0002
   720        0.0135             nan     0.1139   -0.0002
   740        0.0124             nan     0.1139   -0.0001
   760        0.0114             nan     0.1139   -0.0002
   780        0.0104             nan     0.1139   -0.0002
   800        0.0094             nan     0.1139   -0.0001
   820        0.0084             nan     0.1139   -0.0001
   840        0.0077             nan     0.1139   -0.0001
   860        0.0068             nan     0.1139   -0.0001
   880        0.0062             nan     0.1139   -0.0001
   900        0.0057             nan     0.1139   -0.0001
   920        0.0051             nan     0.1139   -0.0001
   940        0.0046             nan     0.1139   -0.0001
   960        0.0043             nan     0.1139   -0.0001
   980        0.0039             nan     0.1139   -0.0000
  1000        0.0036             nan     0.1139   -0.0000
  1020        0.0033             nan     0.1139   -0.0001
  1040        0.0030             nan     0.1139   -0.0000
  1060        0.0027             nan     0.1139   -0.0000
  1080        0.0024             nan     0.1139   -0.0000
  1100        0.0022             nan     0.1139   -0.0000
  1120        0.0020             nan     0.1139   -0.0000
  1140        0.0018             nan     0.1139   -0.0000
  1151        0.0017             nan     0.1139   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9758             nan     0.1790   -0.0033
     2        0.9602             nan     0.1790   -0.0053
     3        0.9493             nan     0.1790   -0.0107
     4        0.9304             nan     0.1790   -0.0160
     5        0.9167             nan     0.1790   -0.0065
     6        0.9103             nan     0.1790   -0.0177
     7        0.8982             nan     0.1790   -0.0044
     8        0.8829             nan     0.1790   -0.0017
     9        0.8720             nan     0.1790   -0.0078
    10        0.8631             nan     0.1790   -0.0144
    20        0.7754             nan     0.1790   -0.0135
    40        0.6597             nan     0.1790   -0.0130
    60        0.5851             nan     0.1790   -0.0048
    80        0.5110             nan     0.1790   -0.0145
   100        0.4490             nan     0.1790   -0.0056
   120        0.3941             nan     0.1790   -0.0028
   140        0.3510             nan     0.1790   -0.0056
   160        0.3179             nan     0.1790   -0.0057
   180        0.2849             nan     0.1790   -0.0032
   200        0.2571             nan     0.1790   -0.0070
   220        0.2305             nan     0.1790   -0.0043
   240        0.2090             nan     0.1790   -0.0021
   260        0.1895             nan     0.1790   -0.0021
   280        0.1725             nan     0.1790   -0.0018
   300        0.1552             nan     0.1790   -0.0017
   320        0.1419             nan     0.1790   -0.0027
   340        0.1294             nan     0.1790   -0.0018
   360        0.1173             nan     0.1790   -0.0025
   380        0.1066             nan     0.1790   -0.0020
   400        0.0975             nan     0.1790   -0.0013
   420        0.0882             nan     0.1790   -0.0019
   440        0.0794             nan     0.1790   -0.0007
   460        0.0726             nan     0.1790   -0.0019
   480        0.0671             nan     0.1790   -0.0007
   500        0.0605             nan     0.1790   -0.0016
   520        0.0562             nan     0.1790   -0.0003
   540        0.0512             nan     0.1790   -0.0010
   560        0.0471             nan     0.1790   -0.0009
   580        0.0437             nan     0.1790   -0.0005
   600        0.0397             nan     0.1790   -0.0008
   620        0.0365             nan     0.1790   -0.0005
   640        0.0333             nan     0.1790   -0.0007
   660        0.0308             nan     0.1790   -0.0007
   680        0.0286             nan     0.1790   -0.0006
   700        0.0264             nan     0.1790   -0.0004
   720        0.0243             nan     0.1790   -0.0004
   740        0.0222             nan     0.1790   -0.0005
   760        0.0204             nan     0.1790   -0.0006
   780        0.0189             nan     0.1790   -0.0003
   800        0.0174             nan     0.1790   -0.0003
   820        0.0161             nan     0.1790   -0.0003
   840        0.0152             nan     0.1790   -0.0003
   860        0.0138             nan     0.1790   -0.0003
   880        0.0128             nan     0.1790   -0.0002
   900        0.0119             nan     0.1790   -0.0002
   920        0.0109             nan     0.1790   -0.0002
   940        0.0100             nan     0.1790   -0.0002
   960        0.0092             nan     0.1790   -0.0001
   980        0.0086             nan     0.1790   -0.0002
  1000        0.0079             nan     0.1790   -0.0001
  1020        0.0073             nan     0.1790   -0.0001
  1040        0.0067             nan     0.1790   -0.0001
  1060        0.0062             nan     0.1790   -0.0001
  1080        0.0057             nan     0.1790   -0.0000
  1100        0.0053             nan     0.1790   -0.0001
  1120        0.0050             nan     0.1790   -0.0001
  1140        0.0046             nan     0.1790   -0.0001
  1160        0.0042             nan     0.1790   -0.0001
  1180        0.0039             nan     0.1790   -0.0001
  1200        0.0036             nan     0.1790   -0.0001
  1220        0.0033             nan     0.1790   -0.0001
  1240        0.0031             nan     0.1790   -0.0000
  1260        0.0028             nan     0.1790   -0.0001
  1280        0.0027             nan     0.1790   -0.0000
  1300        0.0025             nan     0.1790   -0.0000
  1320        0.0023             nan     0.1790   -0.0000
  1340        0.0021             nan     0.1790   -0.0001
  1360        0.0020             nan     0.1790   -0.0000
  1380        0.0018             nan     0.1790   -0.0000
  1400        0.0017             nan     0.1790   -0.0000
  1420        0.0015             nan     0.1790   -0.0000
  1440        0.0015             nan     0.1790   -0.0000
  1460        0.0014             nan     0.1790   -0.0000
  1480        0.0013             nan     0.1790   -0.0000
  1500        0.0012             nan     0.1790   -0.0000
  1520        0.0011             nan     0.1790   -0.0000
  1540        0.0010             nan     0.1790   -0.0000
  1560        0.0010             nan     0.1790   -0.0000
  1580        0.0009             nan     0.1790   -0.0000
  1600        0.0008             nan     0.1790   -0.0000
  1620        0.0008             nan     0.1790   -0.0000
  1640        0.0007             nan     0.1790   -0.0000
  1660        0.0007             nan     0.1790   -0.0000
  1680        0.0006             nan     0.1790   -0.0000
  1700        0.0006             nan     0.1790   -0.0000
  1720        0.0005             nan     0.1790   -0.0000
  1740        0.0005             nan     0.1790   -0.0000
  1760        0.0005             nan     0.1790   -0.0000
  1780        0.0004             nan     0.1790   -0.0000
  1800        0.0004             nan     0.1790   -0.0000
  1820        0.0004             nan     0.1790   -0.0000
  1840        0.0003             nan     0.1790   -0.0000
  1860        0.0003             nan     0.1790   -0.0000
  1880        0.0003             nan     0.1790   -0.0000
  1900        0.0003             nan     0.1790   -0.0000
  1920        0.0003             nan     0.1790   -0.0000
  1940        0.0002             nan     0.1790   -0.0000
  1960        0.0002             nan     0.1790   -0.0000
  1980        0.0002             nan     0.1790   -0.0000
  2000        0.0002             nan     0.1790   -0.0000
  2020        0.0002             nan     0.1790   -0.0000
  2040        0.0002             nan     0.1790   -0.0000
  2060        0.0002             nan     0.1790   -0.0000
  2080        0.0001             nan     0.1790   -0.0000
  2100        0.0001             nan     0.1790   -0.0000
  2120        0.0001             nan     0.1790   -0.0000
  2140        0.0001             nan     0.1790   -0.0000
  2160        0.0001             nan     0.1790   -0.0000
  2180        0.0001             nan     0.1790   -0.0000
  2200        0.0001             nan     0.1790   -0.0000
  2220        0.0001             nan     0.1790   -0.0000
  2240        0.0001             nan     0.1790   -0.0000
  2260        0.0001             nan     0.1790   -0.0000
  2280        0.0001             nan     0.1790   -0.0000
  2300        0.0001             nan     0.1790   -0.0000
  2320        0.0001             nan     0.1790   -0.0000
  2340        0.0001             nan     0.1790   -0.0000
  2360        0.0001             nan     0.1790   -0.0000
  2380        0.0000             nan     0.1790   -0.0000
  2400        0.0000             nan     0.1790   -0.0000
  2420        0.0000             nan     0.1790   -0.0000
  2440        0.0000             nan     0.1790   -0.0000
  2460        0.0000             nan     0.1790   -0.0000
  2480        0.0000             nan     0.1790   -0.0000
  2500        0.0000             nan     0.1790   -0.0000
  2520        0.0000             nan     0.1790   -0.0000
  2540        0.0000             nan     0.1790   -0.0000
  2560        0.0000             nan     0.1790   -0.0000
  2580        0.0000             nan     0.1790   -0.0000
  2600        0.0000             nan     0.1790   -0.0000
  2601        0.0000             nan     0.1790   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9771             nan     0.1997   -0.0078
     2        0.9497             nan     0.1997   -0.0149
     3        0.9304             nan     0.1997   -0.0077
     4        0.9027             nan     0.1997   -0.0062
     5        0.8916             nan     0.1997   -0.0269
     6        0.8754             nan     0.1997   -0.0187
     7        0.8577             nan     0.1997   -0.0042
     8        0.8350             nan     0.1997    0.0085
     9        0.8214             nan     0.1997   -0.0120
    10        0.7987             nan     0.1997   -0.0075
    20        0.6659             nan     0.1997   -0.0076
    40        0.4883             nan     0.1997   -0.0143
    60        0.3565             nan     0.1997   -0.0078
    80        0.2709             nan     0.1997   -0.0029
   100        0.2163             nan     0.1997   -0.0040
   120        0.1781             nan     0.1997   -0.0046
   140        0.1461             nan     0.1997   -0.0017
   160        0.1157             nan     0.1997   -0.0050
   180        0.0930             nan     0.1997   -0.0025
   200        0.0746             nan     0.1997   -0.0022
   220        0.0603             nan     0.1997   -0.0015
   222        0.0590             nan     0.1997   -0.0016

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9861             nan     0.2168   -0.0066
     2        0.9688             nan     0.2168   -0.0040
     3        0.9602             nan     0.2168   -0.0138
     4        0.9505             nan     0.2168   -0.0141
     5        0.9256             nan     0.2168   -0.0006
     6        0.9083             nan     0.2168   -0.0066
     7        0.9060             nan     0.2168   -0.0164
     8        0.8981             nan     0.2168   -0.0078
     9        0.8941             nan     0.2168   -0.0147
    10        0.8784             nan     0.2168   -0.0085
    20        0.8220             nan     0.2168   -0.0163
    40        0.7111             nan     0.2168   -0.0139
    60        0.6211             nan     0.2168   -0.0108
    80        0.5519             nan     0.2168   -0.0096
   100        0.5078             nan     0.2168   -0.0143
   120        0.4597             nan     0.2168   -0.0046
   140        0.4246             nan     0.2168   -0.0055
   160        0.3881             nan     0.2168   -0.0073
   180        0.3504             nan     0.2168   -0.0068
   200        0.3208             nan     0.2168   -0.0045
   220        0.2962             nan     0.2168   -0.0052
   240        0.2677             nan     0.2168   -0.0045
   260        0.2462             nan     0.2168   -0.0035
   280        0.2274             nan     0.2168   -0.0032
   300        0.2103             nan     0.2168   -0.0018
   320        0.1938             nan     0.2168   -0.0021
   340        0.1797             nan     0.2168   -0.0043
   360        0.1666             nan     0.2168   -0.0029
   380        0.1550             nan     0.2168   -0.0022
   400        0.1430             nan     0.2168   -0.0028
   420        0.1323             nan     0.2168   -0.0031
   440        0.1234             nan     0.2168   -0.0015
   460        0.1156             nan     0.2168   -0.0024
   480        0.1059             nan     0.2168   -0.0026
   500        0.0992             nan     0.2168   -0.0021
   520        0.0916             nan     0.2168   -0.0017
   540        0.0853             nan     0.2168   -0.0009
   560        0.0792             nan     0.2168   -0.0018
   580        0.0733             nan     0.2168   -0.0019
   600        0.0683             nan     0.2168   -0.0012
   620        0.0646             nan     0.2168   -0.0008
   640        0.0605             nan     0.2168   -0.0010
   660        0.0559             nan     0.2168   -0.0012
   680        0.0518             nan     0.2168   -0.0008
   700        0.0480             nan     0.2168   -0.0013
   720        0.0449             nan     0.2168   -0.0009
   740        0.0423             nan     0.2168   -0.0005
   760        0.0393             nan     0.2168   -0.0006
   780        0.0369             nan     0.2168   -0.0006
   800        0.0353             nan     0.2168   -0.0011
   820        0.0326             nan     0.2168   -0.0007
   840        0.0309             nan     0.2168   -0.0004
   860        0.0287             nan     0.2168   -0.0004
   880        0.0270             nan     0.2168   -0.0007
   900        0.0252             nan     0.2168   -0.0003
   920        0.0234             nan     0.2168   -0.0003
   940        0.0216             nan     0.2168   -0.0003
   960        0.0203             nan     0.2168   -0.0003
   980        0.0190             nan     0.2168   -0.0005
  1000        0.0179             nan     0.2168   -0.0002
  1020        0.0167             nan     0.2168   -0.0002
  1040        0.0156             nan     0.2168   -0.0005
  1060        0.0148             nan     0.2168   -0.0003
  1080        0.0138             nan     0.2168   -0.0003
  1100        0.0129             nan     0.2168   -0.0002
  1120        0.0122             nan     0.2168   -0.0002
  1140        0.0115             nan     0.2168   -0.0002
  1160        0.0107             nan     0.2168   -0.0001
  1180        0.0101             nan     0.2168   -0.0003
  1200        0.0094             nan     0.2168   -0.0001
  1220        0.0090             nan     0.2168   -0.0002
  1240        0.0084             nan     0.2168   -0.0001
  1260        0.0078             nan     0.2168   -0.0002
  1280        0.0073             nan     0.2168   -0.0002
  1300        0.0070             nan     0.2168   -0.0001
  1320        0.0065             nan     0.2168   -0.0001
  1340        0.0062             nan     0.2168   -0.0002
  1360        0.0057             nan     0.2168   -0.0002
  1380        0.0053             nan     0.2168   -0.0001
  1400        0.0050             nan     0.2168   -0.0001
  1420        0.0047             nan     0.2168   -0.0001
  1440        0.0044             nan     0.2168   -0.0000
  1460        0.0041             nan     0.2168   -0.0001
  1480        0.0039             nan     0.2168   -0.0000
  1500        0.0037             nan     0.2168   -0.0001
  1520        0.0035             nan     0.2168   -0.0001
  1540        0.0033             nan     0.2168   -0.0001
  1560        0.0031             nan     0.2168   -0.0000
  1580        0.0029             nan     0.2168   -0.0000
  1600        0.0028             nan     0.2168   -0.0000
  1620        0.0026             nan     0.2168   -0.0000
  1640        0.0024             nan     0.2168   -0.0000
  1660        0.0023             nan     0.2168   -0.0000
  1680        0.0022             nan     0.2168   -0.0001
  1700        0.0021             nan     0.2168   -0.0000
  1720        0.0019             nan     0.2168   -0.0000
  1740        0.0018             nan     0.2168   -0.0000
  1760        0.0018             nan     0.2168   -0.0001
  1780        0.0016             nan     0.2168   -0.0000
  1800        0.0016             nan     0.2168   -0.0000
  1820        0.0015             nan     0.2168   -0.0000
  1840        0.0014             nan     0.2168   -0.0000
  1860        0.0013             nan     0.2168   -0.0000
  1880        0.0013             nan     0.2168   -0.0000
  1900        0.0012             nan     0.2168   -0.0000
  1920        0.0011             nan     0.2168   -0.0000
  1940        0.0010             nan     0.2168   -0.0000
  1960        0.0010             nan     0.2168   -0.0000
  1980        0.0009             nan     0.2168   -0.0000
  2000        0.0009             nan     0.2168   -0.0000
  2020        0.0008             nan     0.2168   -0.0000
  2040        0.0008             nan     0.2168   -0.0000
  2060        0.0007             nan     0.2168   -0.0000
  2080        0.0007             nan     0.2168   -0.0000
  2100        0.0006             nan     0.2168   -0.0000
  2120        0.0006             nan     0.2168   -0.0000
  2140        0.0006             nan     0.2168   -0.0000
  2160        0.0005             nan     0.2168   -0.0000
  2180        0.0005             nan     0.2168   -0.0000
  2200        0.0005             nan     0.2168   -0.0000
  2220        0.0005             nan     0.2168   -0.0000
  2240        0.0004             nan     0.2168   -0.0000
  2260        0.0004             nan     0.2168   -0.0000
  2280        0.0004             nan     0.2168   -0.0000
  2300        0.0004             nan     0.2168   -0.0000
  2320        0.0003             nan     0.2168   -0.0000
  2340        0.0003             nan     0.2168   -0.0000
  2360        0.0003             nan     0.2168   -0.0000
  2380        0.0003             nan     0.2168   -0.0000
  2400        0.0003             nan     0.2168   -0.0000
  2420        0.0003             nan     0.2168   -0.0000
  2440        0.0002             nan     0.2168   -0.0000
  2460        0.0002             nan     0.2168   -0.0000
  2480        0.0002             nan     0.2168   -0.0000
  2500        0.0002             nan     0.2168   -0.0000
  2520        0.0002             nan     0.2168   -0.0000
  2540        0.0002             nan     0.2168   -0.0000
  2560        0.0002             nan     0.2168   -0.0000
  2580        0.0002             nan     0.2168   -0.0000
  2600        0.0002             nan     0.2168   -0.0000
  2620        0.0001             nan     0.2168   -0.0000
  2640        0.0001             nan     0.2168   -0.0000
  2660        0.0001             nan     0.2168   -0.0000
  2680        0.0001             nan     0.2168   -0.0000
  2700        0.0001             nan     0.2168   -0.0000
  2720        0.0001             nan     0.2168   -0.0000
  2740        0.0001             nan     0.2168   -0.0000
  2760        0.0001             nan     0.2168   -0.0000
  2780        0.0001             nan     0.2168   -0.0000
  2800        0.0001             nan     0.2168   -0.0000
  2820        0.0001             nan     0.2168   -0.0000
  2840        0.0001             nan     0.2168   -0.0000
  2860        0.0001             nan     0.2168   -0.0000
  2880        0.0001             nan     0.2168   -0.0000
  2900        0.0001             nan     0.2168   -0.0000
  2920        0.0001             nan     0.2168   -0.0000
  2940        0.0001             nan     0.2168   -0.0000
  2960        0.0001             nan     0.2168   -0.0000
  2980        0.0001             nan     0.2168   -0.0000
  3000        0.0001             nan     0.2168   -0.0000
  3020        0.0000             nan     0.2168   -0.0000
  3040        0.0000             nan     0.2168   -0.0000
  3060        0.0000             nan     0.2168   -0.0000
  3080        0.0000             nan     0.2168   -0.0000
  3100        0.0000             nan     0.2168   -0.0000
  3120        0.0000             nan     0.2168   -0.0000
  3140        0.0000             nan     0.2168   -0.0000
  3160        0.0000             nan     0.2168   -0.0000
  3180        0.0000             nan     0.2168   -0.0000
  3200        0.0000             nan     0.2168   -0.0000
  3220        0.0000             nan     0.2168   -0.0000
  3240        0.0000             nan     0.2168   -0.0000
  3260        0.0000             nan     0.2168   -0.0000
  3280        0.0000             nan     0.2168   -0.0000
  3300        0.0000             nan     0.2168   -0.0000
  3320        0.0000             nan     0.2168   -0.0000
  3340        0.0000             nan     0.2168   -0.0000
  3360        0.0000             nan     0.2168   -0.0000
  3380        0.0000             nan     0.2168   -0.0000
  3400        0.0000             nan     0.2168   -0.0000
  3420        0.0000             nan     0.2168   -0.0000
  3440        0.0000             nan     0.2168   -0.0000
  3460        0.0000             nan     0.2168   -0.0000
  3480        0.0000             nan     0.2168   -0.0000
  3500        0.0000             nan     0.2168   -0.0000
  3520        0.0000             nan     0.2168   -0.0000
  3540        0.0000             nan     0.2168   -0.0000
  3560        0.0000             nan     0.2168   -0.0000
  3580        0.0000             nan     0.2168   -0.0000
  3600        0.0000             nan     0.2168   -0.0000
  3620        0.0000             nan     0.2168   -0.0000
  3640        0.0000             nan     0.2168   -0.0000
  3660        0.0000             nan     0.2168   -0.0000
  3680        0.0000             nan     0.2168   -0.0000
  3700        0.0000             nan     0.2168   -0.0000
  3720        0.0000             nan     0.2168   -0.0000
  3740        0.0000             nan     0.2168   -0.0000
  3760        0.0000             nan     0.2168   -0.0000
  3780        0.0000             nan     0.2168   -0.0000
  3800        0.0000             nan     0.2168   -0.0000
  3820        0.0000             nan     0.2168   -0.0000
  3840        0.0000             nan     0.2168   -0.0000
  3860        0.0000             nan     0.2168   -0.0000
  3880        0.0000             nan     0.2168   -0.0000
  3900        0.0000             nan     0.2168   -0.0000
  3920        0.0000             nan     0.2168   -0.0000
  3940        0.0000             nan     0.2168   -0.0000
  3960        0.0000             nan     0.2168   -0.0000
  3980        0.0000             nan     0.2168   -0.0000
  4000        0.0000             nan     0.2168   -0.0000
  4020        0.0000             nan     0.2168   -0.0000
  4040        0.0000             nan     0.2168   -0.0000
  4060        0.0000             nan     0.2168   -0.0000
  4080        0.0000             nan     0.2168   -0.0000
  4100        0.0000             nan     0.2168   -0.0000
  4120        0.0000             nan     0.2168   -0.0000
  4140        0.0000             nan     0.2168   -0.0000
  4160        0.0000             nan     0.2168   -0.0000
  4180        0.0000             nan     0.2168   -0.0000
  4200        0.0000             nan     0.2168   -0.0000
  4220        0.0000             nan     0.2168   -0.0000
  4240        0.0000             nan     0.2168   -0.0000
  4260        0.0000             nan     0.2168   -0.0000
  4280        0.0000             nan     0.2168   -0.0000
  4300        0.0000             nan     0.2168   -0.0000
  4320        0.0000             nan     0.2168   -0.0000
  4340        0.0000             nan     0.2168   -0.0000
  4360        0.0000             nan     0.2168   -0.0000
  4380        0.0000             nan     0.2168   -0.0000
  4400        0.0000             nan     0.2168   -0.0000
  4420        0.0000             nan     0.2168   -0.0000
  4440        0.0000             nan     0.2168   -0.0000
  4460        0.0000             nan     0.2168   -0.0000
  4480        0.0000             nan     0.2168   -0.0000
  4500        0.0000             nan     0.2168   -0.0000
  4520        0.0000             nan     0.2168   -0.0000
  4540        0.0000             nan     0.2168   -0.0000
  4560        0.0000             nan     0.2168   -0.0000
  4580        0.0000             nan     0.2168   -0.0000
  4600        0.0000             nan     0.2168   -0.0000
  4620        0.0000             nan     0.2168   -0.0000
  4640        0.0000             nan     0.2168   -0.0000
  4660        0.0000             nan     0.2168   -0.0000
  4680        0.0000             nan     0.2168   -0.0000
  4700        0.0000             nan     0.2168   -0.0000
  4720        0.0000             nan     0.2168   -0.0000
  4740        0.0000             nan     0.2168   -0.0000
  4760        0.0000             nan     0.2168   -0.0000
  4780        0.0000             nan     0.2168   -0.0000
  4800        0.0000             nan     0.2168   -0.0000
  4820        0.0000             nan     0.2168   -0.0000
  4840        0.0000             nan     0.2168   -0.0000
  4860        0.0000             nan     0.2168   -0.0000
  4880        0.0000             nan     0.2168   -0.0000
  4898        0.0000             nan     0.2168   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9637             nan     0.2757   -0.0002
     2        0.9282             nan     0.2757   -0.0071
     3        0.9075             nan     0.2757   -0.0162
     4        0.8853             nan     0.2757   -0.0253
     5        0.8587             nan     0.2757   -0.0027
     6        0.8293             nan     0.2757   -0.0174
     7        0.8040             nan     0.2757   -0.0291
     8        0.7896             nan     0.2757   -0.0118
     9        0.7818             nan     0.2757   -0.0296
    10        0.7717             nan     0.2757   -0.0218
    20        0.6435             nan     0.2757   -0.0133
    40        0.4835             nan     0.2757   -0.0112
    60        0.3689             nan     0.2757   -0.0141
    80        0.2761             nan     0.2757   -0.0073
   100        0.2214             nan     0.2757   -0.0089
   120        0.1733             nan     0.2757   -0.0049
   140        0.1332             nan     0.2757   -0.0034
   160        0.1009             nan     0.2757   -0.0050
   180        0.0785             nan     0.2757   -0.0013
   200        0.0608             nan     0.2757   -0.0023
   220        0.0483             nan     0.2757   -0.0013
   240        0.0371             nan     0.2757   -0.0004
   260        0.0288             nan     0.2757   -0.0005
   280        0.0227             nan     0.2757   -0.0004
   300        0.0185             nan     0.2757   -0.0005
   320        0.0147             nan     0.2757   -0.0005
   340        0.0115             nan     0.2757   -0.0006
   360        0.0093             nan     0.2757   -0.0005
   380        0.0077             nan     0.2757   -0.0002
   400        0.0059             nan     0.2757   -0.0002
   420        0.0048             nan     0.2757   -0.0002
   440        0.0039             nan     0.2757   -0.0001
   460        0.0030             nan     0.2757   -0.0001
   480        0.0025             nan     0.2757   -0.0001
   500        0.0019             nan     0.2757   -0.0001
   520        0.0015             nan     0.2757   -0.0000
   540        0.0012             nan     0.2757   -0.0000
   560        0.0009             nan     0.2757   -0.0000
   580        0.0007             nan     0.2757   -0.0000
   600        0.0006             nan     0.2757   -0.0000
   620        0.0005             nan     0.2757   -0.0000
   640        0.0004             nan     0.2757   -0.0000
   660        0.0003             nan     0.2757   -0.0000
   680        0.0003             nan     0.2757   -0.0000
   700        0.0002             nan     0.2757   -0.0000
   720        0.0002             nan     0.2757   -0.0000
   740        0.0001             nan     0.2757   -0.0000
   760        0.0001             nan     0.2757   -0.0000
   780        0.0001             nan     0.2757   -0.0000
   800        0.0001             nan     0.2757   -0.0000
   820        0.0000             nan     0.2757   -0.0000
   840        0.0000             nan     0.2757   -0.0000
   860        0.0000             nan     0.2757   -0.0000
   880        0.0000             nan     0.2757   -0.0000
   900        0.0000             nan     0.2757   -0.0000
   920        0.0000             nan     0.2757   -0.0000
   940        0.0000             nan     0.2757   -0.0000
   960        0.0000             nan     0.2757   -0.0000
   980        0.0000             nan     0.2757   -0.0000
  1000        0.0000             nan     0.2757   -0.0000
  1020        0.0000             nan     0.2757   -0.0000
  1040        0.0000             nan     0.2757   -0.0000
  1060        0.0000             nan     0.2757   -0.0000
  1080        0.0000             nan     0.2757   -0.0000
  1100        0.0000             nan     0.2757   -0.0000
  1120        0.0000             nan     0.2757   -0.0000
  1140        0.0000             nan     0.2757   -0.0000
  1160        0.0000             nan     0.2757   -0.0000
  1180        0.0000             nan     0.2757   -0.0000
  1200        0.0000             nan     0.2757   -0.0000
  1220        0.0000             nan     0.2757   -0.0000
  1240        0.0000             nan     0.2757   -0.0000
  1260        0.0000             nan     0.2757   -0.0000
  1280        0.0000             nan     0.2757   -0.0000
  1300        0.0000             nan     0.2757   -0.0000
  1320        0.0000             nan     0.2757   -0.0000
  1340        0.0000             nan     0.2757   -0.0000
  1360        0.0000             nan     0.2757   -0.0000
  1380        0.0000             nan     0.2757   -0.0000
  1400        0.0000             nan     0.2757   -0.0000
  1420        0.0000             nan     0.2757   -0.0000
  1440        0.0000             nan     0.2757   -0.0000
  1460        0.0000             nan     0.2757   -0.0000
  1480        0.0000             nan     0.2757   -0.0000
  1500        0.0000             nan     0.2757   -0.0000
  1520        0.0000             nan     0.2757   -0.0000
  1540        0.0000             nan     0.2757   -0.0000
  1560        0.0000             nan     0.2757   -0.0000
  1580        0.0000             nan     0.2757   -0.0000
  1600        0.0000             nan     0.2757   -0.0000
  1620        0.0000             nan     0.2757   -0.0000
  1640        0.0000             nan     0.2757   -0.0000
  1660        0.0000             nan     0.2757   -0.0000
  1680        0.0000             nan     0.2757   -0.0000
  1700        0.0000             nan     0.2757   -0.0000
  1720        0.0000             nan     0.2757   -0.0000
  1740        0.0000             nan     0.2757   -0.0000
  1760        0.0000             nan     0.2757   -0.0000
  1780        0.0000             nan     0.2757   -0.0000
  1800        0.0000             nan     0.2757   -0.0000
  1820        0.0000             nan     0.2757   -0.0000
  1840        0.0000             nan     0.2757   -0.0000
  1860        0.0000             nan     0.2757   -0.0000
  1880        0.0000             nan     0.2757   -0.0000
  1900        0.0000             nan     0.2757   -0.0000
  1920        0.0000             nan     0.2757   -0.0000
  1940        0.0000             nan     0.2757   -0.0000
  1960        0.0000             nan     0.2757   -0.0000
  1980        0.0000             nan     0.2757   -0.0000
  2000        0.0000             nan     0.2757   -0.0000
  2020        0.0000             nan     0.2757   -0.0000
  2040        0.0000             nan     0.2757   -0.0000
  2060        0.0000             nan     0.2757   -0.0000
  2080        0.0000             nan     0.2757   -0.0000
  2100        0.0000             nan     0.2757   -0.0000
  2120        0.0000             nan     0.2757   -0.0000
  2140        0.0000             nan     0.2757   -0.0000
  2160        0.0000             nan     0.2757   -0.0000
  2180        0.0000             nan     0.2757   -0.0000
  2200        0.0000             nan     0.2757   -0.0000
  2220        0.0000             nan     0.2757   -0.0000
  2240        0.0000             nan     0.2757   -0.0000
  2260        0.0000             nan     0.2757   -0.0000
  2280        0.0000             nan     0.2757   -0.0000
  2300        0.0000             nan     0.2757   -0.0000
  2320        0.0000             nan     0.2757   -0.0000
  2340        0.0000             nan     0.2757   -0.0000
  2360        0.0000             nan     0.2757   -0.0000
  2380        0.0000             nan     0.2757   -0.0000
  2400        0.0000             nan     0.2757   -0.0000
  2420        0.0000             nan     0.2757   -0.0000
  2440        0.0000             nan     0.2757   -0.0000
  2460        0.0000             nan     0.2757   -0.0000
  2480        0.0000             nan     0.2757   -0.0000
  2500        0.0000             nan     0.2757   -0.0000
  2520        0.0000             nan     0.2757   -0.0000
  2527        0.0000             nan     0.2757   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9601             nan     0.2956   -0.0306
     2        0.9292             nan     0.2956   -0.0012
     3        0.9113             nan     0.2956   -0.0243
     4        0.8884             nan     0.2956   -0.0068
     5        0.8619             nan     0.2956   -0.0150
     6        0.8471             nan     0.2956   -0.0383
     7        0.8227             nan     0.2956   -0.0015
     8        0.8167             nan     0.2956   -0.0364
     9        0.7969             nan     0.2956   -0.0257
    10        0.7717             nan     0.2956   -0.0048
    20        0.6330             nan     0.2956   -0.0245
    40        0.4597             nan     0.2956   -0.0112
    60        0.3403             nan     0.2956   -0.0116
    80        0.2530             nan     0.2956   -0.0100
   100        0.1904             nan     0.2956   -0.0123
   120        0.1488             nan     0.2956   -0.0069
   140        0.1149             nan     0.2956   -0.0047
   160        0.0865             nan     0.2956   -0.0011
   180        0.0682             nan     0.2956   -0.0028
   200        0.0538             nan     0.2956   -0.0011
   220        0.0423             nan     0.2956   -0.0011
   240        0.0339             nan     0.2956   -0.0011
   260        0.0266             nan     0.2956   -0.0010
   280        0.0214             nan     0.2956   -0.0012
   300        0.0165             nan     0.2956   -0.0008
   320        0.0128             nan     0.2956   -0.0005
   340        0.0105             nan     0.2956   -0.0004
   360        0.0083             nan     0.2956   -0.0004
   380        0.0064             nan     0.2956   -0.0003
   400        0.0051             nan     0.2956   -0.0002
   420        0.0042             nan     0.2956   -0.0001
   440        0.0032             nan     0.2956   -0.0001
   460        0.0026             nan     0.2956   -0.0001
   480        0.0021             nan     0.2956   -0.0000
   500        0.0017             nan     0.2956   -0.0001
   520        0.0013             nan     0.2956   -0.0000
   540        0.0011             nan     0.2956   -0.0000
   560        0.0009             nan     0.2956   -0.0000
   580        0.0007             nan     0.2956   -0.0000
   600        0.0006             nan     0.2956   -0.0000
   620        0.0004             nan     0.2956   -0.0000
   640        0.0004             nan     0.2956   -0.0000
   660        0.0003             nan     0.2956   -0.0000
   680        0.0002             nan     0.2956   -0.0000
   700        0.0002             nan     0.2956   -0.0000
   720        0.0002             nan     0.2956   -0.0000
   740        0.0001             nan     0.2956   -0.0000
   760        0.0001             nan     0.2956   -0.0000
   780        0.0001             nan     0.2956   -0.0000
   800        0.0001             nan     0.2956   -0.0000
   820        0.0001             nan     0.2956   -0.0000
   840        0.0000             nan     0.2956   -0.0000
   860        0.0000             nan     0.2956   -0.0000
   880        0.0000             nan     0.2956   -0.0000
   900        0.0000             nan     0.2956   -0.0000
   920        0.0000             nan     0.2956   -0.0000
   940        0.0000             nan     0.2956   -0.0000
   960        0.0000             nan     0.2956   -0.0000
   980        0.0000             nan     0.2956   -0.0000
  1000        0.0000             nan     0.2956   -0.0000
  1020        0.0000             nan     0.2956   -0.0000
  1040        0.0000             nan     0.2956   -0.0000
  1060        0.0000             nan     0.2956   -0.0000
  1080        0.0000             nan     0.2956   -0.0000
  1100        0.0000             nan     0.2956   -0.0000
  1120        0.0000             nan     0.2956   -0.0000
  1140        0.0000             nan     0.2956   -0.0000
  1160        0.0000             nan     0.2956   -0.0000
  1180        0.0000             nan     0.2956   -0.0000
  1200        0.0000             nan     0.2956   -0.0000
  1220        0.0000             nan     0.2956   -0.0000
  1240        0.0000             nan     0.2956   -0.0000
  1260        0.0000             nan     0.2956   -0.0000
  1280        0.0000             nan     0.2956   -0.0000
  1300        0.0000             nan     0.2956   -0.0000
  1320        0.0000             nan     0.2956   -0.0000
  1340        0.0000             nan     0.2956   -0.0000
  1360        0.0000             nan     0.2956   -0.0000
  1380        0.0000             nan     0.2956   -0.0000
  1400        0.0000             nan     0.2956   -0.0000
  1420        0.0000             nan     0.2956   -0.0000
  1440        0.0000             nan     0.2956   -0.0000
  1460        0.0000             nan     0.2956   -0.0000
  1480        0.0000             nan     0.2956   -0.0000
  1500        0.0000             nan     0.2956   -0.0000
  1520        0.0000             nan     0.2956   -0.0000
  1540        0.0000             nan     0.2956   -0.0000
  1560        0.0000             nan     0.2956   -0.0000
  1580        0.0000             nan     0.2956   -0.0000
  1600        0.0000             nan     0.2956   -0.0000
  1620        0.0000             nan     0.2956   -0.0000
  1640        0.0000             nan     0.2956   -0.0000
  1660        0.0000             nan     0.2956   -0.0000
  1680        0.0000             nan     0.2956   -0.0000
  1700        0.0000             nan     0.2956   -0.0000
  1720        0.0000             nan     0.2956   -0.0000
  1740        0.0000             nan     0.2956   -0.0000
  1760        0.0000             nan     0.2956   -0.0000
  1780        0.0000             nan     0.2956   -0.0000
  1800        0.0000             nan     0.2956   -0.0000
  1820        0.0000             nan     0.2956   -0.0000
  1840        0.0000             nan     0.2956   -0.0000
  1860        0.0000             nan     0.2956   -0.0000
  1880        0.0000             nan     0.2956   -0.0000
  1900        0.0000             nan     0.2956   -0.0000
  1920        0.0000             nan     0.2956   -0.0000
  1940        0.0000             nan     0.2956   -0.0000
  1960        0.0000             nan     0.2956   -0.0000
  1980        0.0000             nan     0.2956   -0.0000
  2000        0.0000             nan     0.2956   -0.0000
  2020        0.0000             nan     0.2956   -0.0000
  2040        0.0000             nan     0.2956   -0.0000
  2060        0.0000             nan     0.2956   -0.0000
  2080        0.0000             nan     0.2956   -0.0000
  2100        0.0000             nan     0.2956   -0.0000
  2120        0.0000             nan     0.2956   -0.0000
  2140        0.0000             nan     0.2956   -0.0000
  2160        0.0000             nan     0.2956   -0.0000
  2180        0.0000             nan     0.2956   -0.0000
  2200        0.0000             nan     0.2956   -0.0000
  2220        0.0000             nan     0.2956   -0.0000
  2240        0.0000             nan     0.2956   -0.0000
  2260        0.0000             nan     0.2956   -0.0000
  2280        0.0000             nan     0.2956   -0.0000
  2300        0.0000             nan     0.2956   -0.0000
  2320        0.0000             nan     0.2956   -0.0000
  2340        0.0000             nan     0.2956   -0.0000
  2360        0.0000             nan     0.2956   -0.0000
  2380        0.0000             nan     0.2956   -0.0000
  2400        0.0000             nan     0.2956   -0.0000
  2420        0.0000             nan     0.2956   -0.0000
  2440        0.0000             nan     0.2956   -0.0000
  2460        0.0000             nan     0.2956   -0.0000
  2480        0.0000             nan     0.2956   -0.0000
  2500        0.0000             nan     0.2956   -0.0000
  2520        0.0000             nan     0.2956   -0.0000
  2540        0.0000             nan     0.2956   -0.0000
  2560        0.0000             nan     0.2956   -0.0000
  2580        0.0000             nan     0.2956   -0.0000
  2600        0.0000             nan     0.2956   -0.0000
  2620        0.0000             nan     0.2956   -0.0000
  2640        0.0000             nan     0.2956   -0.0000
  2660        0.0000             nan     0.2956   -0.0000
  2680        0.0000             nan     0.2956   -0.0000
  2700        0.0000             nan     0.2956   -0.0000
  2720        0.0000             nan     0.2956   -0.0000
  2740        0.0000             nan     0.2956   -0.0000
  2760        0.0000             nan     0.2956   -0.0000
  2780        0.0000             nan     0.2956   -0.0000
  2800        0.0000             nan     0.2956   -0.0000
  2820        0.0000             nan     0.2956   -0.0000
  2840        0.0000             nan     0.2956   -0.0000
  2860        0.0000             nan     0.2956   -0.0000
  2880        0.0000             nan     0.2956   -0.0000
  2900        0.0000             nan     0.2956   -0.0000
  2920        0.0000             nan     0.2956   -0.0000
  2940        0.0000             nan     0.2956   -0.0000
  2960        0.0000             nan     0.2956   -0.0000
  2980        0.0000             nan     0.2956   -0.0000
  3000        0.0000             nan     0.2956   -0.0000
  3020        0.0000             nan     0.2956   -0.0000
  3040        0.0000             nan     0.2956   -0.0000
  3060        0.0000             nan     0.2956   -0.0000
  3080        0.0000             nan     0.2956   -0.0000
  3100        0.0000             nan     0.2956   -0.0000
  3120        0.0000             nan     0.2956   -0.0000
  3140        0.0000             nan     0.2956    0.0000
  3160        0.0000             nan     0.2956   -0.0000
  3180        0.0000             nan     0.2956   -0.0000
  3200        0.0000             nan     0.2956   -0.0000
  3220        0.0000             nan     0.2956   -0.0000
  3240        0.0000             nan     0.2956   -0.0000
  3260        0.0000             nan     0.2956   -0.0000
  3280        0.0000             nan     0.2956   -0.0000
  3300        0.0000             nan     0.2956   -0.0000
  3320        0.0000             nan     0.2956   -0.0000
  3340        0.0000             nan     0.2956   -0.0000
  3360        0.0000             nan     0.2956   -0.0000
  3380        0.0000             nan     0.2956   -0.0000
  3400        0.0000             nan     0.2956   -0.0000
  3420        0.0000             nan     0.2956   -0.0000
  3440        0.0000             nan     0.2956    0.0000
  3460        0.0000             nan     0.2956   -0.0000
  3480        0.0000             nan     0.2956   -0.0000
  3500        0.0000             nan     0.2956   -0.0000
  3520        0.0000             nan     0.2956   -0.0000
  3527        0.0000             nan     0.2956   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9671             nan     0.2958   -0.0157
     2        0.9408             nan     0.2958   -0.0254
     3        0.8887             nan     0.2958    0.0015
     4        0.8614             nan     0.2958   -0.0142
     5        0.8395             nan     0.2958   -0.0130
     6        0.8287             nan     0.2958   -0.0404
     7        0.8153             nan     0.2958   -0.0267
     8        0.7977             nan     0.2958   -0.0168
     9        0.7725             nan     0.2958   -0.0192
    10        0.7531             nan     0.2958   -0.0105
    20        0.6284             nan     0.2958   -0.0174
    40        0.4331             nan     0.2958   -0.0085
    60        0.3101             nan     0.2958   -0.0101
    80        0.2194             nan     0.2958   -0.0079
   100        0.1623             nan     0.2958   -0.0061
   120        0.1198             nan     0.2958   -0.0046
   140        0.0900             nan     0.2958   -0.0018
   160        0.0679             nan     0.2958   -0.0023
   180        0.0509             nan     0.2958   -0.0020
   200        0.0402             nan     0.2958   -0.0010
   220        0.0305             nan     0.2958   -0.0014
   240        0.0234             nan     0.2958   -0.0010
   260        0.0180             nan     0.2958   -0.0004
   280        0.0143             nan     0.2958   -0.0008
   300        0.0106             nan     0.2958   -0.0005
   320        0.0083             nan     0.2958   -0.0002
   340        0.0064             nan     0.2958   -0.0001
   360        0.0048             nan     0.2958   -0.0001
   380        0.0037             nan     0.2958   -0.0002
   400        0.0029             nan     0.2958   -0.0002
   420        0.0023             nan     0.2958   -0.0001
   440        0.0017             nan     0.2958   -0.0001
   460        0.0013             nan     0.2958   -0.0000
   480        0.0011             nan     0.2958   -0.0000
   500        0.0009             nan     0.2958   -0.0000
   520        0.0007             nan     0.2958   -0.0000
   540        0.0005             nan     0.2958   -0.0000
   560        0.0004             nan     0.2958   -0.0000
   580        0.0003             nan     0.2958   -0.0000
   600        0.0002             nan     0.2958   -0.0000
   620        0.0002             nan     0.2958   -0.0000
   640        0.0002             nan     0.2958   -0.0000
   660        0.0001             nan     0.2958   -0.0000
   680        0.0001             nan     0.2958   -0.0000
   700        0.0001             nan     0.2958   -0.0000
   720        0.0001             nan     0.2958   -0.0000
   740        0.0000             nan     0.2958   -0.0000
   760        0.0000             nan     0.2958   -0.0000
   780        0.0000             nan     0.2958   -0.0000
   800        0.0000             nan     0.2958   -0.0000
   820        0.0000             nan     0.2958   -0.0000
   840        0.0000             nan     0.2958   -0.0000
   860        0.0000             nan     0.2958   -0.0000
   880        0.0000             nan     0.2958   -0.0000
   900        0.0000             nan     0.2958   -0.0000
   920        0.0000             nan     0.2958   -0.0000
   940        0.0000             nan     0.2958   -0.0000
   960        0.0000             nan     0.2958   -0.0000
   980        0.0000             nan     0.2958   -0.0000
  1000        0.0000             nan     0.2958   -0.0000
  1020        0.0000             nan     0.2958   -0.0000
  1040        0.0000             nan     0.2958   -0.0000
  1060        0.0000             nan     0.2958   -0.0000
  1080        0.0000             nan     0.2958   -0.0000
  1100        0.0000             nan     0.2958   -0.0000
  1120        0.0000             nan     0.2958   -0.0000
  1140        0.0000             nan     0.2958   -0.0000
  1160        0.0000             nan     0.2958   -0.0000
  1180        0.0000             nan     0.2958   -0.0000
  1200        0.0000             nan     0.2958   -0.0000
  1220        0.0000             nan     0.2958   -0.0000
  1240        0.0000             nan     0.2958   -0.0000
  1260        0.0000             nan     0.2958   -0.0000
  1280        0.0000             nan     0.2958   -0.0000
  1300        0.0000             nan     0.2958   -0.0000
  1320        0.0000             nan     0.2958   -0.0000
  1340        0.0000             nan     0.2958   -0.0000
  1360        0.0000             nan     0.2958   -0.0000
  1380        0.0000             nan     0.2958   -0.0000
  1400        0.0000             nan     0.2958   -0.0000
  1420        0.0000             nan     0.2958   -0.0000
  1440        0.0000             nan     0.2958   -0.0000
  1460        0.0000             nan     0.2958   -0.0000
  1480        0.0000             nan     0.2958   -0.0000
  1500        0.0000             nan     0.2958   -0.0000
  1520        0.0000             nan     0.2958   -0.0000
  1540        0.0000             nan     0.2958   -0.0000
  1560        0.0000             nan     0.2958   -0.0000
  1580        0.0000             nan     0.2958   -0.0000
  1600        0.0000             nan     0.2958   -0.0000
  1620        0.0000             nan     0.2958   -0.0000
  1640        0.0000             nan     0.2958   -0.0000
  1660        0.0000             nan     0.2958   -0.0000
  1680        0.0000             nan     0.2958   -0.0000
  1700        0.0000             nan     0.2958   -0.0000
  1720        0.0000             nan     0.2958   -0.0000
  1740        0.0000             nan     0.2958   -0.0000
  1760        0.0000             nan     0.2958   -0.0000
  1780        0.0000             nan     0.2958   -0.0000
  1800        0.0000             nan     0.2958   -0.0000
  1820        0.0000             nan     0.2958   -0.0000
  1840        0.0000             nan     0.2958   -0.0000
  1860        0.0000             nan     0.2958   -0.0000
  1880        0.0000             nan     0.2958   -0.0000
  1900        0.0000             nan     0.2958   -0.0000
  1920        0.0000             nan     0.2958   -0.0000
  1940        0.0000             nan     0.2958   -0.0000
  1960        0.0000             nan     0.2958   -0.0000
  1980        0.0000             nan     0.2958   -0.0000
  1985        0.0000             nan     0.2958   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9251             nan     0.3117   -0.0060
     2        0.8883             nan     0.3117   -0.0214
     3        0.8562             nan     0.3117   -0.0349
     4        0.8261             nan     0.3117   -0.0202
     5        0.8097             nan     0.3117   -0.0449
     6        0.7911             nan     0.3117   -0.0355
     7        0.7702             nan     0.3117   -0.0209
     8        0.7366             nan     0.3117   -0.0069
     9        0.7100             nan     0.3117   -0.0241
    10        0.6883             nan     0.3117   -0.0277
    20        0.5162             nan     0.3117   -0.0209
    40        0.3062             nan     0.3117   -0.0115
    60        0.2007             nan     0.3117   -0.0085
    80        0.1315             nan     0.3117   -0.0045
   100        0.0862             nan     0.3117   -0.0067
   120        0.0585             nan     0.3117   -0.0018
   140        0.0395             nan     0.3117   -0.0017
   160        0.0269             nan     0.3117   -0.0013
   180        0.0185             nan     0.3117   -0.0007
   200        0.0129             nan     0.3117   -0.0008
   220        0.0083             nan     0.3117   -0.0002
   240        0.0054             nan     0.3117   -0.0001
   260        0.0035             nan     0.3117   -0.0003
   280        0.0024             nan     0.3117   -0.0001
   300        0.0016             nan     0.3117   -0.0000
   320        0.0011             nan     0.3117   -0.0001
   340        0.0008             nan     0.3117   -0.0000
   360        0.0006             nan     0.3117   -0.0000
   380        0.0004             nan     0.3117   -0.0000
   400        0.0003             nan     0.3117   -0.0000
   420        0.0002             nan     0.3117   -0.0000
   440        0.0001             nan     0.3117   -0.0000
   460        0.0001             nan     0.3117   -0.0000
   480        0.0001             nan     0.3117   -0.0000
   500        0.0000             nan     0.3117   -0.0000
   520        0.0000             nan     0.3117   -0.0000
   540        0.0000             nan     0.3117   -0.0000
   560        0.0000             nan     0.3117   -0.0000
   580        0.0000             nan     0.3117   -0.0000
   600        0.0000             nan     0.3117   -0.0000
   620        0.0000             nan     0.3117   -0.0000
   640        0.0000             nan     0.3117   -0.0000
   660        0.0000             nan     0.3117   -0.0000
   680        0.0000             nan     0.3117   -0.0000
   700        0.0000             nan     0.3117   -0.0000
   720        0.0000             nan     0.3117   -0.0000
   740        0.0000             nan     0.3117   -0.0000
   760        0.0000             nan     0.3117   -0.0000
   780        0.0000             nan     0.3117   -0.0000
   800        0.0000             nan     0.3117   -0.0000
   820        0.0000             nan     0.3117   -0.0000
   840        0.0000             nan     0.3117   -0.0000
   860        0.0000             nan     0.3117   -0.0000
   880        0.0000             nan     0.3117   -0.0000
   900        0.0000             nan     0.3117   -0.0000
   920        0.0000             nan     0.3117   -0.0000
   940        0.0000             nan     0.3117   -0.0000
   960        0.0000             nan     0.3117   -0.0000
   980        0.0000             nan     0.3117   -0.0000
  1000        0.0000             nan     0.3117   -0.0000
  1020        0.0000             nan     0.3117   -0.0000
  1040        0.0000             nan     0.3117   -0.0000
  1060        0.0000             nan     0.3117   -0.0000
  1080        0.0000             nan     0.3117   -0.0000
  1100        0.0000             nan     0.3117   -0.0000
  1120        0.0000             nan     0.3117   -0.0000
  1140        0.0000             nan     0.3117   -0.0000
  1160        0.0000             nan     0.3117   -0.0000
  1180        0.0000             nan     0.3117   -0.0000
  1200        0.0000             nan     0.3117   -0.0000
  1220        0.0000             nan     0.3117   -0.0000
  1240        0.0000             nan     0.3117   -0.0000
  1260        0.0000             nan     0.3117   -0.0000
  1280        0.0000             nan     0.3117   -0.0000
  1300        0.0000             nan     0.3117   -0.0000
  1320        0.0000             nan     0.3117   -0.0000
  1340        0.0000             nan     0.3117   -0.0000
  1360        0.0000             nan     0.3117   -0.0000
  1380        0.0000             nan     0.3117   -0.0000
  1400        0.0000             nan     0.3117   -0.0000
  1420        0.0000             nan     0.3117   -0.0000
  1440        0.0000             nan     0.3117   -0.0000
  1460        0.0000             nan     0.3117   -0.0000
  1480        0.0000             nan     0.3117   -0.0000
  1500        0.0000             nan     0.3117   -0.0000
  1520        0.0000             nan     0.3117   -0.0000
  1540        0.0000             nan     0.3117   -0.0000
  1560        0.0000             nan     0.3117   -0.0000
  1580        0.0000             nan     0.3117   -0.0000
  1600        0.0000             nan     0.3117    0.0000
  1620        0.0000             nan     0.3117   -0.0000
  1640        0.0000             nan     0.3117   -0.0000
  1660        0.0000             nan     0.3117   -0.0000
  1680        0.0000             nan     0.3117   -0.0000
  1700        0.0000             nan     0.3117   -0.0000
  1720        0.0000             nan     0.3117   -0.0000
  1740        0.0000             nan     0.3117   -0.0000
  1760        0.0000             nan     0.3117   -0.0000
  1780        0.0000             nan     0.3117   -0.0000
  1800        0.0000             nan     0.3117   -0.0000
  1820        0.0000             nan     0.3117   -0.0000
  1840        0.0000             nan     0.3117   -0.0000
  1860        0.0000             nan     0.3117   -0.0000
  1880        0.0000             nan     0.3117   -0.0000
  1900        0.0000             nan     0.3117   -0.0000
  1920        0.0000             nan     0.3117   -0.0000
  1940        0.0000             nan     0.3117   -0.0000
  1960        0.0000             nan     0.3117   -0.0000
  1980        0.0000             nan     0.3117   -0.0000
  2000        0.0000             nan     0.3117   -0.0000
  2020        0.0000             nan     0.3117   -0.0000
  2040        0.0000             nan     0.3117   -0.0000
  2060        0.0000             nan     0.3117   -0.0000
  2080        0.0000             nan     0.3117   -0.0000
  2100        0.0000             nan     0.3117   -0.0000
  2120        0.0000             nan     0.3117   -0.0000
  2140        0.0000             nan     0.3117   -0.0000
  2160        0.0000             nan     0.3117   -0.0000
  2180        0.0000             nan     0.3117   -0.0000
  2200        0.0000             nan     0.3117   -0.0000
  2220        0.0000             nan     0.3117   -0.0000
  2240        0.0000             nan     0.3117   -0.0000
  2260        0.0000             nan     0.3117   -0.0000
  2280        0.0000             nan     0.3117   -0.0000
  2300        0.0000             nan     0.3117   -0.0000
  2320        0.0000             nan     0.3117   -0.0000
  2340        0.0000             nan     0.3117   -0.0000
  2360        0.0000             nan     0.3117   -0.0000
  2380        0.0000             nan     0.3117   -0.0000
  2400        0.0000             nan     0.3117   -0.0000
  2420        0.0000             nan     0.3117   -0.0000
  2440        0.0000             nan     0.3117    0.0000
  2460        0.0000             nan     0.3117   -0.0000
  2480        0.0000             nan     0.3117   -0.0000
  2500        0.0000             nan     0.3117   -0.0000
  2520        0.0000             nan     0.3117   -0.0000
  2540        0.0000             nan     0.3117   -0.0000
  2560        0.0000             nan     0.3117   -0.0000
  2580        0.0000             nan     0.3117   -0.0000
  2600        0.0000             nan     0.3117   -0.0000
  2620        0.0000             nan     0.3117    0.0000
  2640        0.0000             nan     0.3117   -0.0000
  2642        0.0000             nan     0.3117   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9757             nan     0.3640   -0.0301
     2        0.9452             nan     0.3640   -0.0432
     3        0.9101             nan     0.3640   -0.0188
     4        0.8886             nan     0.3640   -0.0242
     5        0.8334             nan     0.3640    0.0173
     6        0.7997             nan     0.3640   -0.0163
     7        0.7777             nan     0.3640   -0.0185
     8        0.7615             nan     0.3640   -0.0154
     9        0.7437             nan     0.3640   -0.0349
    10        0.7223             nan     0.3640   -0.0296
    20        0.5545             nan     0.3640   -0.0173
    40        0.3457             nan     0.3640   -0.0134
    60        0.2301             nan     0.3640   -0.0145
    80        0.1621             nan     0.3640   -0.0126
   100        0.1007             nan     0.3640   -0.0040
   120        0.0702             nan     0.3640   -0.0034
   140        0.0471             nan     0.3640   -0.0017
   160        0.0329             nan     0.3640   -0.0016
   180        0.0220             nan     0.3640   -0.0004
   200        0.0153             nan     0.3640   -0.0009
   220        0.0109             nan     0.3640   -0.0005
   240        0.0078             nan     0.3640   -0.0003
   260        0.0053             nan     0.3640   -0.0003
   280        0.0037             nan     0.3640   -0.0002
   300        0.0025             nan     0.3640   -0.0001
   320        0.0018             nan     0.3640   -0.0000
   340        0.0013             nan     0.3640   -0.0000
   360        0.0009             nan     0.3640   -0.0001
   380        0.0006             nan     0.3640   -0.0000
   400        0.0004             nan     0.3640   -0.0000
   420        0.0003             nan     0.3640   -0.0000
   440        0.0002             nan     0.3640   -0.0000
   460        0.0001             nan     0.3640   -0.0000
   480        0.0001             nan     0.3640   -0.0000
   500        0.0001             nan     0.3640   -0.0000
   520        0.0001             nan     0.3640   -0.0000
   540        0.0000             nan     0.3640   -0.0000
   560        0.0000             nan     0.3640   -0.0000
   580        0.0000             nan     0.3640   -0.0000
   600        0.0000             nan     0.3640   -0.0000
   620        0.0000             nan     0.3640   -0.0000
   640        0.0000             nan     0.3640   -0.0000
   660        0.0000             nan     0.3640   -0.0000
   680        0.0000             nan     0.3640   -0.0000
   700        0.0000             nan     0.3640   -0.0000
   720        0.0000             nan     0.3640   -0.0000
   740        0.0000             nan     0.3640   -0.0000
   760        0.0000             nan     0.3640   -0.0000
   780        0.0000             nan     0.3640   -0.0000
   800        0.0000             nan     0.3640   -0.0000
   820        0.0000             nan     0.3640   -0.0000
   840        0.0000             nan     0.3640   -0.0000
   860        0.0000             nan     0.3640   -0.0000
   880        0.0000             nan     0.3640   -0.0000
   900        0.0000             nan     0.3640   -0.0000
   920        0.0000             nan     0.3640   -0.0000
   940        0.0000             nan     0.3640   -0.0000
   960        0.0000             nan     0.3640   -0.0000
   980        0.0000             nan     0.3640   -0.0000
  1000        0.0000             nan     0.3640   -0.0000
  1020        0.0000             nan     0.3640   -0.0000
  1040        0.0000             nan     0.3640   -0.0000
  1060        0.0000             nan     0.3640   -0.0000
  1080        0.0000             nan     0.3640   -0.0000
  1100        0.0000             nan     0.3640   -0.0000
  1120        0.0000             nan     0.3640   -0.0000
  1140        0.0000             nan     0.3640   -0.0000
  1160        0.0000             nan     0.3640   -0.0000
  1180        0.0000             nan     0.3640   -0.0000
  1200        0.0000             nan     0.3640   -0.0000
  1220        0.0000             nan     0.3640   -0.0000
  1240        0.0000             nan     0.3640   -0.0000
  1260        0.0000             nan     0.3640   -0.0000
  1280        0.0000             nan     0.3640   -0.0000
  1300        0.0000             nan     0.3640   -0.0000
  1320        0.0000             nan     0.3640   -0.0000
  1340        0.0000             nan     0.3640   -0.0000
  1360        0.0000             nan     0.3640   -0.0000
  1380        0.0000             nan     0.3640   -0.0000
  1400        0.0000             nan     0.3640   -0.0000
  1420        0.0000             nan     0.3640   -0.0000
  1440        0.0000             nan     0.3640   -0.0000
  1460        0.0000             nan     0.3640   -0.0000
  1480        0.0000             nan     0.3640   -0.0000
  1500        0.0000             nan     0.3640   -0.0000
  1520        0.0000             nan     0.3640   -0.0000
  1540        0.0000             nan     0.3640   -0.0000
  1560        0.0000             nan     0.3640   -0.0000
  1580        0.0000             nan     0.3640   -0.0000
  1587        0.0000             nan     0.3640   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9824             nan     0.3688    0.0004
     2        0.9727             nan     0.3688    0.0011
     3        0.9660             nan     0.3688    0.0006
     4        0.9623             nan     0.3688   -0.0163
     5        0.9578             nan     0.3688   -0.0091
     6        0.9520             nan     0.3688   -0.0025
     7        0.9452             nan     0.3688   -0.0033
     8        0.9426             nan     0.3688   -0.0110
     9        0.9354             nan     0.3688   -0.0139
    10        0.9307             nan     0.3688   -0.0068
    20        0.8991             nan     0.3688   -0.0134
    40        0.8640             nan     0.3688   -0.0081
    60        0.8222             nan     0.3688   -0.0041
    80        0.7824             nan     0.3688   -0.0109
   100        0.7525             nan     0.3688   -0.0053
   120        0.7182             nan     0.3688   -0.0075
   140        0.6952             nan     0.3688   -0.0123
   160        0.6741             nan     0.3688   -0.0202
   180        0.6563             nan     0.3688   -0.0121
   200        0.6379             nan     0.3688   -0.0076
   220        0.6178             nan     0.3688   -0.0125
   240        0.6014             nan     0.3688   -0.0102
   260        0.5842             nan     0.3688   -0.0106
   280        0.5719             nan     0.3688   -0.0095
   300        0.5499             nan     0.3688   -0.0070
   320        0.5353             nan     0.3688   -0.0146
   340        0.5179             nan     0.3688   -0.0092
   360        0.5014             nan     0.3688   -0.0003
   380        0.4905             nan     0.3688   -0.0091
   400        0.4800             nan     0.3688   -0.0022
   420        0.4727             nan     0.3688   -0.0056
   440        0.4651             nan     0.3688   -0.0110
   460        0.4442             nan     0.3688   -0.0071
   480        0.4325             nan     0.3688   -0.0045
   500        0.4294             nan     0.3688   -0.0098
   520        0.4174             nan     0.3688   -0.0080
   540        0.4094             nan     0.3688   -0.0062
   560        0.3980             nan     0.3688   -0.0051
   580        0.3917             nan     0.3688   -0.0071
   600        0.3841             nan     0.3688   -0.0021
   620        0.3777             nan     0.3688   -0.0053
   640        0.3711             nan     0.3688   -0.0089
   660        0.3668             nan     0.3688   -0.0102
   680        0.3558             nan     0.3688   -0.0032
   700        0.3481             nan     0.3688   -0.0065
   720        0.3390             nan     0.3688   -0.0036
   740        0.3327             nan     0.3688   -0.0072
   760        0.3238             nan     0.3688   -0.0056
   780        0.3196             nan     0.3688   -0.0035
   800        0.3142             nan     0.3688   -0.0082
   820        0.3063             nan     0.3688   -0.0029
   840        0.3005             nan     0.3688   -0.0056
   860        0.2943             nan     0.3688   -0.0043
   880        0.2893             nan     0.3688   -0.0027
   900        0.2831             nan     0.3688   -0.0028
   920        0.2781             nan     0.3688   -0.0030
   940        0.2719             nan     0.3688   -0.0004
   960        0.2663             nan     0.3688   -0.0024
   980        0.2637             nan     0.3688   -0.0080
  1000        0.2597             nan     0.3688   -0.0006
  1020        0.2521             nan     0.3688   -0.0036
  1040        0.2477             nan     0.3688   -0.0069
  1060        0.2428             nan     0.3688   -0.0013
  1080        0.2401             nan     0.3688   -0.0068
  1100        0.2346             nan     0.3688   -0.0034
  1120        0.2290             nan     0.3688   -0.0028
  1140        0.2215             nan     0.3688   -0.0039
  1160        0.2185             nan     0.3688   -0.0022
  1180        0.2153             nan     0.3688   -0.0012
  1200        0.2101             nan     0.3688   -0.0007
  1220        0.2056             nan     0.3688   -0.0016
  1240        0.2008             nan     0.3688   -0.0021
  1260        0.1954             nan     0.3688   -0.0009
  1280        0.1933             nan     0.3688   -0.0032
  1300        0.1880             nan     0.3688   -0.0015
  1320        0.1855             nan     0.3688   -0.0033
  1340        0.1839             nan     0.3688   -0.0010
  1360        0.1799             nan     0.3688   -0.0015
  1380        0.1753             nan     0.3688   -0.0043
  1400        0.1707             nan     0.3688   -0.0012
  1420        0.1693             nan     0.3688   -0.0048
  1440        0.1667             nan     0.3688   -0.0032
  1460        0.1641             nan     0.3688   -0.0024
  1480        0.1623             nan     0.3688   -0.0015
  1500        0.1590             nan     0.3688   -0.0027
  1520        0.1550             nan     0.3688   -0.0022
  1540        0.1529             nan     0.3688   -0.0021
  1560        0.1488             nan     0.3688   -0.0014
  1580        0.1477             nan     0.3688   -0.0028
  1600        0.1452             nan     0.3688   -0.0011
  1620        0.1420             nan     0.3688   -0.0007
  1640        0.1398             nan     0.3688   -0.0011
  1660        0.1377             nan     0.3688   -0.0020
  1680        0.1344             nan     0.3688   -0.0010
  1700        0.1321             nan     0.3688   -0.0025
  1720        0.1302             nan     0.3688   -0.0019
  1740        0.1305             nan     0.3688   -0.0028
  1760        0.1268             nan     0.3688   -0.0017
  1780        0.1251             nan     0.3688   -0.0012
  1800        0.1225             nan     0.3688   -0.0023
  1820        0.1204             nan     0.3688   -0.0030
  1840        0.1176             nan     0.3688   -0.0018
  1860        0.1167             nan     0.3688   -0.0018
  1880        0.1145             nan     0.3688   -0.0012
  1888        0.1148             nan     0.3688   -0.0011

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9811             nan     0.3918   -0.0092
     2        0.9723             nan     0.3918   -0.0064
     3        0.9622             nan     0.3918   -0.0261
     4        0.9370             nan     0.3918   -0.0069
     5        0.9207             nan     0.3918   -0.0074
     6        0.9130             nan     0.3918   -0.0192
     7        0.9104             nan     0.3918   -0.0158
     8        0.9051             nan     0.3918   -0.0205
     9        0.8928             nan     0.3918   -0.0184
    10        0.8828             nan     0.3918   -0.0124
    20        0.8402             nan     0.3918   -0.0646
    40        0.7246             nan     0.3918   -0.0242
    60        0.6428             nan     0.3918    0.0012
    80        0.5657             nan     0.3918   -0.0178
   100        0.5095             nan     0.3918   -0.0042
   120        0.4694             nan     0.3918   -0.0163
   140        0.4280             nan     0.3918   -0.0108
   160        0.3820             nan     0.3918   -0.0113
   180        0.3505             nan     0.3918   -0.0113
   200        0.3240             nan     0.3918   -0.0100
   220        0.2920             nan     0.3918   -0.0060
   240        0.2694             nan     0.3918   -0.0075
   260        0.2518             nan     0.3918   -0.0072
   280        0.2328             nan     0.3918   -0.0049
   300        0.2124             nan     0.3918   -0.0071
   320        0.1917             nan     0.3918   -0.0043
   340        0.1731             nan     0.3918   -0.0044
   360        0.1557             nan     0.3918   -0.0032
   380        0.1444             nan     0.3918   -0.0048
   400        0.1340             nan     0.3918   -0.0051
   420        0.1270             nan     0.3918   -0.0019
   440        0.1163             nan     0.3918   -0.0036
   460        0.1078             nan     0.3918   -0.0022
   480        0.0974             nan     0.3918   -0.0032
   500        0.0885             nan     0.3918   -0.0011
   520        0.0828             nan     0.3918   -0.0026
   540        0.0761             nan     0.3918   -0.0018
   560        0.0689             nan     0.3918   -0.0004
   580        0.0624             nan     0.3918   -0.0016
   600        0.0549             nan     0.3918   -0.0005
   620        0.0514             nan     0.3918   -0.0012
   640        0.0477             nan     0.3918   -0.0014
   660        0.0445             nan     0.3918   -0.0012
   680        0.0422             nan     0.3918   -0.0031
   700        0.0388             nan     0.3918   -0.0006
   720        0.0358             nan     0.3918   -0.0008
   740        0.0325             nan     0.3918   -0.0010
   760        0.0303             nan     0.3918   -0.0015
   780        0.0274             nan     0.3918   -0.0006
   800        0.0250             nan     0.3918   -0.0004
   820        0.0229             nan     0.3918   -0.0010
   840        0.0213             nan     0.3918   -0.0005
   860        0.0198             nan     0.3918   -0.0004
   880        0.0182             nan     0.3918   -0.0005
   881        0.0182             nan     0.3918   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9711             nan     0.4081   -0.0519
     2        0.9095             nan     0.4081    0.0072
     3        0.8798             nan     0.4081   -0.0464
     4        0.8544             nan     0.4081   -0.0269
     5        0.8100             nan     0.4081   -0.0221
     6        0.7739             nan     0.4081    0.0030
     7        0.7339             nan     0.4081   -0.0366
     8        0.7119             nan     0.4081   -0.0455
     9        0.6943             nan     0.4081   -0.0308
    10        0.6867             nan     0.4081   -0.0515
    20        0.5032             nan     0.4081   -0.0341
    40        0.3124             nan     0.4081   -0.0126
    60        0.1904             nan     0.4081   -0.0181
    80        0.1285             nan     0.4081   -0.0038
   100        0.0804             nan     0.4081   -0.0051
   120        0.0527             nan     0.4081   -0.0028
   140        0.0328             nan     0.4081   -0.0021
   160        0.0217             nan     0.4081   -0.0008
   180        0.0143             nan     0.4081   -0.0012
   200        0.0100             nan     0.4081   -0.0002
   220        0.0067             nan     0.4081   -0.0005
   240        0.0043             nan     0.4081   -0.0003
   260        0.0030             nan     0.4081   -0.0002
   280        0.0019             nan     0.4081   -0.0001
   300        0.0014             nan     0.4081   -0.0001
   320        0.0009             nan     0.4081   -0.0001
   340        0.0006             nan     0.4081   -0.0000
   360        0.0004             nan     0.4081   -0.0000
   380        0.0003             nan     0.4081   -0.0000
   400        0.0002             nan     0.4081   -0.0000
   420        0.0001             nan     0.4081   -0.0000
   440        0.0001             nan     0.4081   -0.0000
   460        0.0001             nan     0.4081   -0.0000
   480        0.0000             nan     0.4081   -0.0000
   500        0.0000             nan     0.4081   -0.0000
   520        0.0000             nan     0.4081   -0.0000
   540        0.0000             nan     0.4081   -0.0000
   560        0.0000             nan     0.4081   -0.0000
   580        0.0000             nan     0.4081   -0.0000
   600        0.0000             nan     0.4081   -0.0000
   620        0.0000             nan     0.4081   -0.0000
   640        0.0000             nan     0.4081   -0.0000
   660        0.0000             nan     0.4081   -0.0000
   680        0.0000             nan     0.4081   -0.0000
   700        0.0000             nan     0.4081   -0.0000
   720        0.0000             nan     0.4081   -0.0000
   740        0.0000             nan     0.4081   -0.0000
   760        0.0000             nan     0.4081   -0.0000
   780        0.0000             nan     0.4081   -0.0000
   800        0.0000             nan     0.4081   -0.0000
   820        0.0000             nan     0.4081   -0.0000
   840        0.0000             nan     0.4081   -0.0000
   860        0.0000             nan     0.4081   -0.0000
   880        0.0000             nan     0.4081   -0.0000
   900        0.0000             nan     0.4081   -0.0000
   920        0.0000             nan     0.4081   -0.0000
   940        0.0000             nan     0.4081   -0.0000
   960        0.0000             nan     0.4081   -0.0000
   980        0.0000             nan     0.4081   -0.0000
  1000        0.0000             nan     0.4081   -0.0000
  1020        0.0000             nan     0.4081   -0.0000
  1040        0.0000             nan     0.4081   -0.0000
  1060        0.0000             nan     0.4081   -0.0000
  1080        0.0000             nan     0.4081   -0.0000
  1100        0.0000             nan     0.4081   -0.0000
  1120        0.0000             nan     0.4081   -0.0000
  1140        0.0000             nan     0.4081   -0.0000
  1160        0.0000             nan     0.4081   -0.0000
  1180        0.0000             nan     0.4081   -0.0000
  1200        0.0000             nan     0.4081   -0.0000
  1220        0.0000             nan     0.4081   -0.0000
  1240        0.0000             nan     0.4081   -0.0000
  1260        0.0000             nan     0.4081   -0.0000
  1280        0.0000             nan     0.4081   -0.0000
  1300        0.0000             nan     0.4081   -0.0000
  1320        0.0000             nan     0.4081   -0.0000
  1340        0.0000             nan     0.4081   -0.0000
  1360        0.0000             nan     0.4081   -0.0000
  1380        0.0000             nan     0.4081   -0.0000
  1400        0.0000             nan     0.4081   -0.0000
  1420        0.0000             nan     0.4081   -0.0000
  1440        0.0000             nan     0.4081   -0.0000
  1460        0.0000             nan     0.4081   -0.0000
  1480        0.0000             nan     0.4081   -0.0000
  1500        0.0000             nan     0.4081   -0.0000
  1520        0.0000             nan     0.4081   -0.0000
  1540        0.0000             nan     0.4081   -0.0000
  1560        0.0000             nan     0.4081   -0.0000
  1580        0.0000             nan     0.4081   -0.0000
  1600        0.0000             nan     0.4081   -0.0000
  1620        0.0000             nan     0.4081   -0.0000
  1640        0.0000             nan     0.4081   -0.0000
  1660        0.0000             nan     0.4081   -0.0000
  1680        0.0000             nan     0.4081   -0.0000
  1700        0.0000             nan     0.4081   -0.0000
  1720        0.0000             nan     0.4081   -0.0000
  1740        0.0000             nan     0.4081   -0.0000
  1760        0.0000             nan     0.4081   -0.0000
  1780        0.0000             nan     0.4081   -0.0000
  1800        0.0000             nan     0.4081   -0.0000
  1820        0.0000             nan     0.4081   -0.0000
  1840        0.0000             nan     0.4081   -0.0000
  1860        0.0000             nan     0.4081   -0.0000
  1880        0.0000             nan     0.4081   -0.0000
  1900        0.0000             nan     0.4081   -0.0000
  1920        0.0000             nan     0.4081   -0.0000
  1940        0.0000             nan     0.4081   -0.0000
  1960        0.0000             nan     0.4081   -0.0000
  1980        0.0000             nan     0.4081   -0.0000
  2000        0.0000             nan     0.4081   -0.0000
  2020        0.0000             nan     0.4081   -0.0000
  2040        0.0000             nan     0.4081   -0.0000
  2060        0.0000             nan     0.4081   -0.0000
  2080        0.0000             nan     0.4081   -0.0000
  2100        0.0000             nan     0.4081   -0.0000
  2120        0.0000             nan     0.4081   -0.0000
  2140        0.0000             nan     0.4081   -0.0000
  2160        0.0000             nan     0.4081   -0.0000
  2180        0.0000             nan     0.4081   -0.0000
  2200        0.0000             nan     0.4081   -0.0000
  2220        0.0000             nan     0.4081   -0.0000
  2240        0.0000             nan     0.4081   -0.0000
  2260        0.0000             nan     0.4081   -0.0000
  2280        0.0000             nan     0.4081   -0.0000
  2300        0.0000             nan     0.4081   -0.0000
  2320        0.0000             nan     0.4081   -0.0000
  2340        0.0000             nan     0.4081   -0.0000
  2360        0.0000             nan     0.4081   -0.0000
  2380        0.0000             nan     0.4081   -0.0000
  2400        0.0000             nan     0.4081   -0.0000
  2420        0.0000             nan     0.4081   -0.0000
  2440        0.0000             nan     0.4081   -0.0000
  2460        0.0000             nan     0.4081   -0.0000
  2480        0.0000             nan     0.4081   -0.0000
  2500        0.0000             nan     0.4081   -0.0000
  2520        0.0000             nan     0.4081   -0.0000
  2540        0.0000             nan     0.4081   -0.0000
  2560        0.0000             nan     0.4081   -0.0000
  2580        0.0000             nan     0.4081   -0.0000
  2600        0.0000             nan     0.4081   -0.0000
  2620        0.0000             nan     0.4081   -0.0000
  2640        0.0000             nan     0.4081   -0.0000
  2660        0.0000             nan     0.4081   -0.0000
  2680        0.0000             nan     0.4081   -0.0000
  2700        0.0000             nan     0.4081   -0.0000
  2720        0.0000             nan     0.4081   -0.0000
  2740        0.0000             nan     0.4081   -0.0000
  2760        0.0000             nan     0.4081   -0.0000
  2780        0.0000             nan     0.4081   -0.0000
  2800        0.0000             nan     0.4081   -0.0000
  2820        0.0000             nan     0.4081   -0.0000
  2840        0.0000             nan     0.4081    0.0000
  2860        0.0000             nan     0.4081   -0.0000
  2880        0.0000             nan     0.4081   -0.0000
  2900        0.0000             nan     0.4081   -0.0000
  2920        0.0000             nan     0.4081   -0.0000
  2940        0.0000             nan     0.4081   -0.0000
  2960        0.0000             nan     0.4081   -0.0000
  2980        0.0000             nan     0.4081   -0.0000
  3000        0.0000             nan     0.4081   -0.0000
  3020        0.0000             nan     0.4081   -0.0000
  3040        0.0000             nan     0.4081   -0.0000
  3060        0.0000             nan     0.4081   -0.0000
  3080        0.0000             nan     0.4081   -0.0000
  3100        0.0000             nan     0.4081   -0.0000
  3120        0.0000             nan     0.4081   -0.0000
  3140        0.0000             nan     0.4081   -0.0000
  3160        0.0000             nan     0.4081   -0.0000
  3180        0.0000             nan     0.4081   -0.0000
  3200        0.0000             nan     0.4081   -0.0000
  3220        0.0000             nan     0.4081   -0.0000
  3240        0.0000             nan     0.4081   -0.0000
  3260        0.0000             nan     0.4081   -0.0000
  3280        0.0000             nan     0.4081   -0.0000
  3300        0.0000             nan     0.4081   -0.0000
  3320        0.0000             nan     0.4081   -0.0000
  3340        0.0000             nan     0.4081   -0.0000
  3360        0.0000             nan     0.4081   -0.0000
  3380        0.0000             nan     0.4081   -0.0000
  3400        0.0000             nan     0.4081   -0.0000
  3420        0.0000             nan     0.4081   -0.0000
  3440        0.0000             nan     0.4081   -0.0000
  3460        0.0000             nan     0.4081   -0.0000
  3480        0.0000             nan     0.4081   -0.0000
  3500        0.0000             nan     0.4081   -0.0000
  3520        0.0000             nan     0.4081   -0.0000
  3540        0.0000             nan     0.4081   -0.0000
  3560        0.0000             nan     0.4081   -0.0000
  3580        0.0000             nan     0.4081   -0.0000
  3600        0.0000             nan     0.4081   -0.0000
  3620        0.0000             nan     0.4081   -0.0000
  3640        0.0000             nan     0.4081   -0.0000
  3660        0.0000             nan     0.4081   -0.0000
  3680        0.0000             nan     0.4081   -0.0000
  3700        0.0000             nan     0.4081   -0.0000
  3720        0.0000             nan     0.4081   -0.0000
  3740        0.0000             nan     0.4081    0.0000
  3760        0.0000             nan     0.4081   -0.0000
  3780        0.0000             nan     0.4081   -0.0000
  3800        0.0000             nan     0.4081   -0.0000
  3820        0.0000             nan     0.4081    0.0000
  3835        0.0000             nan     0.4081   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9372             nan     0.4204    0.0239
     2        0.9075             nan     0.4204   -0.0519
     3        0.8758             nan     0.4204   -0.0293
     4        0.8599             nan     0.4204   -0.0609
     5        0.8422             nan     0.4204   -0.0517
     6        0.8247             nan     0.4204   -0.0468
     7        0.8236             nan     0.4204   -0.0759
     8        0.8123             nan     0.4204   -0.0365
     9        0.7909             nan     0.4204   -0.0275
    10        0.7862             nan     0.4204   -0.0584
    20        0.6032             nan     0.4204   -0.0214
    40        0.4168             nan     0.4204   -0.0232
    60        0.3003             nan     0.4204   -0.0285
    80        0.2048             nan     0.4204   -0.0045
   100        0.1528             nan     0.4204   -0.0054
   120        0.1057             nan     0.4204   -0.0037
   140        0.0726             nan     0.4204   -0.0035
   160        0.0539             nan     0.4204   -0.0009
   180        0.0402             nan     0.4204   -0.0019
   200        0.0297             nan     0.4204   -0.0013
   220        0.0208             nan     0.4204   -0.0010
   240        0.0147             nan     0.4204   -0.0008
   260        0.0102             nan     0.4204   -0.0003
   280        0.0075             nan     0.4204   -0.0008
   300        0.0053             nan     0.4204   -0.0002
   320        0.0038             nan     0.4204   -0.0002
   340        0.0027             nan     0.4204   -0.0002
   360        0.0020             nan     0.4204   -0.0002
   380        0.0013             nan     0.4204   -0.0000
   400        0.0010             nan     0.4204   -0.0001
   420        0.0007             nan     0.4204   -0.0001
   440        0.0005             nan     0.4204   -0.0000
   460        0.0004             nan     0.4204   -0.0000
   480        0.0003             nan     0.4204   -0.0000
   500        0.0002             nan     0.4204   -0.0000
   520        0.0001             nan     0.4204   -0.0000
   540        0.0001             nan     0.4204   -0.0000
   560        0.0001             nan     0.4204   -0.0000
   580        0.0001             nan     0.4204   -0.0000
   600        0.0000             nan     0.4204   -0.0000
   620        0.0000             nan     0.4204   -0.0000
   640        0.0000             nan     0.4204   -0.0000
   660        0.0000             nan     0.4204   -0.0000
   680        0.0000             nan     0.4204   -0.0000
   700        0.0000             nan     0.4204   -0.0000
   720        0.0000             nan     0.4204   -0.0000
   740        0.0000             nan     0.4204   -0.0000
   760        0.0000             nan     0.4204   -0.0000
   780        0.0000             nan     0.4204   -0.0000
   800        0.0000             nan     0.4204   -0.0000
   820        0.0000             nan     0.4204   -0.0000
   840        0.0000             nan     0.4204   -0.0000
   860        0.0000             nan     0.4204   -0.0000
   880        0.0000             nan     0.4204   -0.0000
   900        0.0000             nan     0.4204   -0.0000
   920        0.0000             nan     0.4204   -0.0000
   940        0.0000             nan     0.4204   -0.0000
   960        0.0000             nan     0.4204   -0.0000
   980        0.0000             nan     0.4204   -0.0000
  1000        0.0000             nan     0.4204   -0.0000
  1020        0.0000             nan     0.4204   -0.0000
  1040        0.0000             nan     0.4204   -0.0000
  1060        0.0000             nan     0.4204   -0.0000
  1080        0.0000             nan     0.4204   -0.0000
  1100        0.0000             nan     0.4204   -0.0000
  1120        0.0000             nan     0.4204   -0.0000
  1140        0.0000             nan     0.4204   -0.0000
  1160        0.0000             nan     0.4204   -0.0000
  1180        0.0000             nan     0.4204   -0.0000
  1200        0.0000             nan     0.4204   -0.0000
  1220        0.0000             nan     0.4204   -0.0000
  1240        0.0000             nan     0.4204   -0.0000
  1260        0.0000             nan     0.4204   -0.0000
  1280        0.0000             nan     0.4204   -0.0000
  1300        0.0000             nan     0.4204   -0.0000
  1320        0.0000             nan     0.4204   -0.0000
  1340        0.0000             nan     0.4204   -0.0000
  1360        0.0000             nan     0.4204   -0.0000
  1380        0.0000             nan     0.4204   -0.0000
  1400        0.0000             nan     0.4204   -0.0000
  1420        0.0000             nan     0.4204   -0.0000
  1440        0.0000             nan     0.4204   -0.0000
  1460        0.0000             nan     0.4204   -0.0000
  1480        0.0000             nan     0.4204   -0.0000
  1500        0.0000             nan     0.4204   -0.0000
  1520        0.0000             nan     0.4204   -0.0000
  1540        0.0000             nan     0.4204   -0.0000
  1560        0.0000             nan     0.4204   -0.0000
  1580        0.0000             nan     0.4204   -0.0000
  1600        0.0000             nan     0.4204   -0.0000
  1620        0.0000             nan     0.4204   -0.0000
  1640        0.0000             nan     0.4204   -0.0000
  1660        0.0000             nan     0.4204   -0.0000
  1680        0.0000             nan     0.4204   -0.0000
  1700        0.0000             nan     0.4204   -0.0000
  1720        0.0000             nan     0.4204   -0.0000
  1740        0.0000             nan     0.4204   -0.0000
  1760        0.0000             nan     0.4204   -0.0000
  1780        0.0000             nan     0.4204   -0.0000
  1800        0.0000             nan     0.4204   -0.0000
  1820        0.0000             nan     0.4204   -0.0000
  1840        0.0000             nan     0.4204   -0.0000
  1860        0.0000             nan     0.4204   -0.0000
  1880        0.0000             nan     0.4204   -0.0000
  1900        0.0000             nan     0.4204   -0.0000
  1920        0.0000             nan     0.4204   -0.0000
  1940        0.0000             nan     0.4204   -0.0000
  1960        0.0000             nan     0.4204   -0.0000
  1980        0.0000             nan     0.4204   -0.0000
  2000        0.0000             nan     0.4204   -0.0000
  2020        0.0000             nan     0.4204   -0.0000
  2040        0.0000             nan     0.4204   -0.0000
  2060        0.0000             nan     0.4204   -0.0000
  2080        0.0000             nan     0.4204   -0.0000
  2100        0.0000             nan     0.4204   -0.0000
  2120        0.0000             nan     0.4204   -0.0000
  2140        0.0000             nan     0.4204   -0.0000
  2160        0.0000             nan     0.4204   -0.0000
  2180        0.0000             nan     0.4204   -0.0000
  2200        0.0000             nan     0.4204   -0.0000
  2220        0.0000             nan     0.4204   -0.0000
  2240        0.0000             nan     0.4204   -0.0000
  2260        0.0000             nan     0.4204   -0.0000
  2280        0.0000             nan     0.4204   -0.0000
  2300        0.0000             nan     0.4204   -0.0000
  2320        0.0000             nan     0.4204   -0.0000
  2340        0.0000             nan     0.4204   -0.0000
  2360        0.0000             nan     0.4204   -0.0000
  2380        0.0000             nan     0.4204   -0.0000
  2400        0.0000             nan     0.4204   -0.0000
  2420        0.0000             nan     0.4204   -0.0000
  2440        0.0000             nan     0.4204   -0.0000
  2460        0.0000             nan     0.4204   -0.0000
  2480        0.0000             nan     0.4204   -0.0000
  2500        0.0000             nan     0.4204   -0.0000
  2520        0.0000             nan     0.4204   -0.0000
  2540        0.0000             nan     0.4204   -0.0000
  2560        0.0000             nan     0.4204   -0.0000
  2580        0.0000             nan     0.4204   -0.0000
  2600        0.0000             nan     0.4204   -0.0000
  2620        0.0000             nan     0.4204   -0.0000
  2640        0.0000             nan     0.4204   -0.0000
  2660        0.0000             nan     0.4204   -0.0000
  2680        0.0000             nan     0.4204   -0.0000
  2700        0.0000             nan     0.4204   -0.0000
  2720        0.0000             nan     0.4204   -0.0000
  2740        0.0000             nan     0.4204   -0.0000
  2760        0.0000             nan     0.4204   -0.0000
  2780        0.0000             nan     0.4204   -0.0000
  2800        0.0000             nan     0.4204   -0.0000
  2820        0.0000             nan     0.4204   -0.0000
  2840        0.0000             nan     0.4204   -0.0000
  2860        0.0000             nan     0.4204   -0.0000
  2880        0.0000             nan     0.4204   -0.0000
  2900        0.0000             nan     0.4204   -0.0000
  2920        0.0000             nan     0.4204   -0.0000
  2940        0.0000             nan     0.4204   -0.0000
  2960        0.0000             nan     0.4204   -0.0000
  2980        0.0000             nan     0.4204   -0.0000
  3000        0.0000             nan     0.4204   -0.0000
  3020        0.0000             nan     0.4204   -0.0000
  3040        0.0000             nan     0.4204   -0.0000
  3060        0.0000             nan     0.4204   -0.0000
  3080        0.0000             nan     0.4204   -0.0000
  3100        0.0000             nan     0.4204   -0.0000
  3120        0.0000             nan     0.4204   -0.0000
  3140        0.0000             nan     0.4204   -0.0000
  3160        0.0000             nan     0.4204   -0.0000
  3180        0.0000             nan     0.4204   -0.0000
  3200        0.0000             nan     0.4204   -0.0000
  3220        0.0000             nan     0.4204   -0.0000
  3240        0.0000             nan     0.4204   -0.0000
  3260        0.0000             nan     0.4204   -0.0000
  3280        0.0000             nan     0.4204   -0.0000
  3300        0.0000             nan     0.4204   -0.0000
  3320        0.0000             nan     0.4204   -0.0000
  3340        0.0000             nan     0.4204   -0.0000
  3360        0.0000             nan     0.4204   -0.0000
  3380        0.0000             nan     0.4204   -0.0000
  3400        0.0000             nan     0.4204   -0.0000
  3420        0.0000             nan     0.4204   -0.0000
  3440        0.0000             nan     0.4204   -0.0000
  3460        0.0000             nan     0.4204   -0.0000
  3480        0.0000             nan     0.4204   -0.0000
  3500        0.0000             nan     0.4204   -0.0000
  3520        0.0000             nan     0.4204   -0.0000
  3540        0.0000             nan     0.4204   -0.0000
  3560        0.0000             nan     0.4204   -0.0000
  3580        0.0000             nan     0.4204   -0.0000
  3600        0.0000             nan     0.4204   -0.0000
  3620        0.0000             nan     0.4204   -0.0000
  3640        0.0000             nan     0.4204   -0.0000
  3660        0.0000             nan     0.4204   -0.0000
  3680        0.0000             nan     0.4204   -0.0000
  3700        0.0000             nan     0.4204   -0.0000
  3720        0.0000             nan     0.4204   -0.0000
  3740        0.0000             nan     0.4204   -0.0000
  3760        0.0000             nan     0.4204   -0.0000
  3780        0.0000             nan     0.4204   -0.0000
  3800        0.0000             nan     0.4204   -0.0000
  3820        0.0000             nan     0.4204   -0.0000
  3840        0.0000             nan     0.4204   -0.0000
  3860        0.0000             nan     0.4204   -0.0000
  3880        0.0000             nan     0.4204   -0.0000
  3900        0.0000             nan     0.4204   -0.0000
  3920        0.0000             nan     0.4204   -0.0000
  3940        0.0000             nan     0.4204   -0.0000
  3960        0.0000             nan     0.4204   -0.0000
  3980        0.0000             nan     0.4204   -0.0000
  4000        0.0000             nan     0.4204   -0.0000
  4020        0.0000             nan     0.4204   -0.0000
  4040        0.0000             nan     0.4204   -0.0000
  4060        0.0000             nan     0.4204   -0.0000
  4080        0.0000             nan     0.4204   -0.0000
  4100        0.0000             nan     0.4204   -0.0000
  4120        0.0000             nan     0.4204   -0.0000
  4140        0.0000             nan     0.4204   -0.0000
  4160        0.0000             nan     0.4204   -0.0000
  4180        0.0000             nan     0.4204   -0.0000
  4200        0.0000             nan     0.4204   -0.0000
  4220        0.0000             nan     0.4204   -0.0000
  4240        0.0000             nan     0.4204   -0.0000
  4260        0.0000             nan     0.4204   -0.0000
  4280        0.0000             nan     0.4204   -0.0000
  4300        0.0000             nan     0.4204   -0.0000
  4320        0.0000             nan     0.4204   -0.0000
  4340        0.0000             nan     0.4204   -0.0000
  4360        0.0000             nan     0.4204   -0.0000
  4380        0.0000             nan     0.4204   -0.0000
  4400        0.0000             nan     0.4204   -0.0000
  4420        0.0000             nan     0.4204   -0.0000
  4440        0.0000             nan     0.4204   -0.0000
  4460        0.0000             nan     0.4204   -0.0000
  4480        0.0000             nan     0.4204   -0.0000
  4500        0.0000             nan     0.4204   -0.0000
  4520        0.0000             nan     0.4204   -0.0000
  4540        0.0000             nan     0.4204   -0.0000
  4560        0.0000             nan     0.4204   -0.0000
  4580        0.0000             nan     0.4204   -0.0000
  4600        0.0000             nan     0.4204   -0.0000
  4620        0.0000             nan     0.4204   -0.0000
  4640        0.0000             nan     0.4204   -0.0000
  4660        0.0000             nan     0.4204   -0.0000
  4680        0.0000             nan     0.4204   -0.0000
  4700        0.0000             nan     0.4204   -0.0000
  4720        0.0000             nan     0.4204   -0.0000
  4740        0.0000             nan     0.4204   -0.0000
  4760        0.0000             nan     0.4204   -0.0000
  4780        0.0000             nan     0.4204   -0.0000
  4800        0.0000             nan     0.4204   -0.0000
  4820        0.0000             nan     0.4204   -0.0000
  4840        0.0000             nan     0.4204   -0.0000
  4860        0.0000             nan     0.4204   -0.0000
  4880        0.0000             nan     0.4204   -0.0000
  4900        0.0000             nan     0.4204   -0.0000
  4920        0.0000             nan     0.4204   -0.0000
  4940        0.0000             nan     0.4204   -0.0000
  4960        0.0000             nan     0.4204   -0.0000
  4980        0.0000             nan     0.4204   -0.0000
  4996        0.0000             nan     0.4204   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9555             nan     0.4363   -0.0474
     2        0.8884             nan     0.4363    0.0073
     3        0.8553             nan     0.4363   -0.0384
     4        0.8276             nan     0.4363   -0.0370
     5        0.7991             nan     0.4363   -0.0626
     6        0.7709             nan     0.4363   -0.0560
     7        0.7483             nan     0.4363   -0.0379
     8        0.7318             nan     0.4363   -0.0879
     9        0.6884             nan     0.4363   -0.0098
    10        0.6575             nan     0.4363   -0.0221
    20        0.4696             nan     0.4363   -0.0232
    40        0.2808             nan     0.4363   -0.0182
    60        0.1760             nan     0.4363   -0.0145
    80        0.0920             nan     0.4363   -0.0054
   100        0.0566             nan     0.4363   -0.0035
   120        0.0319             nan     0.4363   -0.0016
   140        0.0188             nan     0.4363   -0.0009
   160        0.0111             nan     0.4363   -0.0010
   180        0.0072             nan     0.4363   -0.0007
   200        0.0044             nan     0.4363   -0.0002
   220        0.0028             nan     0.4363   -0.0002
   240        0.0017             nan     0.4363   -0.0002
   260        0.0010             nan     0.4363   -0.0001
   280        0.0006             nan     0.4363   -0.0000
   300        0.0004             nan     0.4363   -0.0000
   320        0.0003             nan     0.4363   -0.0000
   340        0.0002             nan     0.4363   -0.0000
   360        0.0001             nan     0.4363   -0.0000
   380        0.0001             nan     0.4363   -0.0000
   400        0.0000             nan     0.4363   -0.0000
   420        0.0000             nan     0.4363   -0.0000
   440        0.0000             nan     0.4363   -0.0000
   460        0.0000             nan     0.4363   -0.0000
   480        0.0000             nan     0.4363   -0.0000
   500        0.0000             nan     0.4363   -0.0000
   520        0.0000             nan     0.4363   -0.0000
   540        0.0000             nan     0.4363   -0.0000
   560        0.0000             nan     0.4363   -0.0000
   580        0.0000             nan     0.4363   -0.0000
   600        0.0000             nan     0.4363   -0.0000
   620        0.0000             nan     0.4363   -0.0000
   640        0.0000             nan     0.4363   -0.0000
   660        0.0000             nan     0.4363   -0.0000
   680        0.0000             nan     0.4363   -0.0000
   700        0.0000             nan     0.4363   -0.0000
   720        0.0000             nan     0.4363   -0.0000
   740        0.0000             nan     0.4363   -0.0000
   760        0.0000             nan     0.4363   -0.0000
   780        0.0000             nan     0.4363   -0.0000
   800        0.0000             nan     0.4363   -0.0000
   820        0.0000             nan     0.4363   -0.0000
   840        0.0000             nan     0.4363   -0.0000
   860        0.0000             nan     0.4363   -0.0000
   880        0.0000             nan     0.4363   -0.0000
   900        0.0000             nan     0.4363   -0.0000
   920        0.0000             nan     0.4363   -0.0000
   940        0.0000             nan     0.4363   -0.0000
   960        0.0000             nan     0.4363   -0.0000
   980        0.0000             nan     0.4363   -0.0000
  1000        0.0000             nan     0.4363   -0.0000
  1020        0.0000             nan     0.4363   -0.0000
  1040        0.0000             nan     0.4363   -0.0000
  1060        0.0000             nan     0.4363   -0.0000
  1080        0.0000             nan     0.4363   -0.0000
  1100        0.0000             nan     0.4363   -0.0000
  1120        0.0000             nan     0.4363   -0.0000
  1140        0.0000             nan     0.4363   -0.0000
  1160        0.0000             nan     0.4363   -0.0000
  1180        0.0000             nan     0.4363   -0.0000
  1200        0.0000             nan     0.4363   -0.0000
  1220        0.0000             nan     0.4363   -0.0000
  1240        0.0000             nan     0.4363   -0.0000
  1260        0.0000             nan     0.4363   -0.0000
  1280        0.0000             nan     0.4363   -0.0000
  1300        0.0000             nan     0.4363   -0.0000
  1320        0.0000             nan     0.4363   -0.0000
  1340        0.0000             nan     0.4363   -0.0000
  1360        0.0000             nan     0.4363    0.0000
  1380        0.0000             nan     0.4363   -0.0000
  1400        0.0000             nan     0.4363   -0.0000
  1420        0.0000             nan     0.4363   -0.0000
  1440        0.0000             nan     0.4363   -0.0000
  1460        0.0000             nan     0.4363   -0.0000
  1480        0.0000             nan     0.4363   -0.0000
  1500        0.0000             nan     0.4363   -0.0000
  1520        0.0000             nan     0.4363   -0.0000
  1540        0.0000             nan     0.4363   -0.0000
  1560        0.0000             nan     0.4363   -0.0000
  1580        0.0000             nan     0.4363   -0.0000
  1600        0.0000             nan     0.4363   -0.0000
  1620        0.0000             nan     0.4363   -0.0000
  1640        0.0000             nan     0.4363   -0.0000
  1660        0.0000             nan     0.4363   -0.0000
  1680        0.0000             nan     0.4363   -0.0000
  1700        0.0000             nan     0.4363   -0.0000
  1720        0.0000             nan     0.4363   -0.0000
  1740        0.0000             nan     0.4363   -0.0000
  1760        0.0000             nan     0.4363   -0.0000
  1780        0.0000             nan     0.4363    0.0000
  1800        0.0000             nan     0.4363   -0.0000
  1820        0.0000             nan     0.4363   -0.0000
  1840        0.0000             nan     0.4363   -0.0000
  1860        0.0000             nan     0.4363   -0.0000
  1880        0.0000             nan     0.4363   -0.0000
  1900        0.0000             nan     0.4363   -0.0000
  1920        0.0000             nan     0.4363   -0.0000
  1940        0.0000             nan     0.4363   -0.0000
  1960        0.0000             nan     0.4363   -0.0000
  1980        0.0000             nan     0.4363   -0.0000
  2000        0.0000             nan     0.4363   -0.0000
  2020        0.0000             nan     0.4363   -0.0000
  2040        0.0000             nan     0.4363   -0.0000
  2060        0.0000             nan     0.4363   -0.0000
  2080        0.0000             nan     0.4363   -0.0000
  2100        0.0000             nan     0.4363   -0.0000
  2120        0.0000             nan     0.4363   -0.0000
  2140        0.0000             nan     0.4363   -0.0000
  2160        0.0000             nan     0.4363   -0.0000
  2180        0.0000             nan     0.4363   -0.0000
  2200        0.0000             nan     0.4363   -0.0000
  2220        0.0000             nan     0.4363   -0.0000
  2240        0.0000             nan     0.4363   -0.0000
  2260        0.0000             nan     0.4363   -0.0000
  2280        0.0000             nan     0.4363   -0.0000
  2300        0.0000             nan     0.4363   -0.0000
  2320        0.0000             nan     0.4363    0.0000
  2340        0.0000             nan     0.4363   -0.0000
  2360        0.0000             nan     0.4363    0.0000
  2380        0.0000             nan     0.4363   -0.0000
  2400        0.0000             nan     0.4363   -0.0000
  2420        0.0000             nan     0.4363   -0.0000
  2440        0.0000             nan     0.4363   -0.0000
  2460        0.0000             nan     0.4363   -0.0000
  2480        0.0000             nan     0.4363   -0.0000
  2500        0.0000             nan     0.4363   -0.0000
  2520        0.0000             nan     0.4363   -0.0000
  2540        0.0000             nan     0.4363   -0.0000
  2560        0.0000             nan     0.4363   -0.0000
  2580        0.0000             nan     0.4363   -0.0000
  2594        0.0000             nan     0.4363   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9715             nan     0.4488   -0.0379
     2        0.9086             nan     0.4488    0.0070
     3        0.8992             nan     0.4488   -0.0559
     4        0.8866             nan     0.4488   -0.0672
     5        0.8561             nan     0.4488   -0.0249
     6        0.8325             nan     0.4488   -0.0114
     7        0.8089             nan     0.4488   -0.0360
     8        0.7822             nan     0.4488   -0.0222
     9        0.7592             nan     0.4488   -0.0342
    10        0.7505             nan     0.4488   -0.0270
    20        0.6372             nan     0.4488   -0.0454
    40        0.4474             nan     0.4488   -0.0247
    60        0.3106             nan     0.4488   -0.0206
    80        0.2349             nan     0.4488   -0.0086
   100        0.1643             nan     0.4488   -0.0043
   120        0.1204             nan     0.4488   -0.0049
   140        0.0887             nan     0.4488   -0.0025
   160        0.0674             nan     0.4488   -0.0030
   180        0.0525             nan     0.4488   -0.0022
   200        0.0396             nan     0.4488   -0.0021
   220        0.0302             nan     0.4488   -0.0009
   240        0.0230             nan     0.4488   -0.0012
   260        0.0181             nan     0.4488   -0.0008
   280        0.0135             nan     0.4488   -0.0007
   300        0.0109             nan     0.4488   -0.0005
   320        0.0086             nan     0.4488   -0.0002
   340        0.0070             nan     0.4488   -0.0004
   360        0.0053             nan     0.4488   -0.0004
   380        0.0039             nan     0.4488   -0.0001
   400        0.0031             nan     0.4488   -0.0001
   420        0.0024             nan     0.4488   -0.0001
   440        0.0019             nan     0.4488   -0.0001
   460        0.0014             nan     0.4488   -0.0001
   480        0.0011             nan     0.4488   -0.0001
   500        0.0008             nan     0.4488   -0.0000
   520        0.0006             nan     0.4488   -0.0000
   540        0.0005             nan     0.4488   -0.0000
   560        0.0004             nan     0.4488   -0.0000
   580        0.0003             nan     0.4488   -0.0000
   600        0.0002             nan     0.4488   -0.0000
   620        0.0002             nan     0.4488   -0.0000
   640        0.0001             nan     0.4488   -0.0000
   660        0.0001             nan     0.4488   -0.0000
   680        0.0001             nan     0.4488   -0.0000
   700        0.0001             nan     0.4488   -0.0000
   720        0.0000             nan     0.4488   -0.0000
   740        0.0000             nan     0.4488   -0.0000
   760        0.0000             nan     0.4488   -0.0000
   780        0.0000             nan     0.4488   -0.0000
   800        0.0000             nan     0.4488   -0.0000
   820        0.0000             nan     0.4488   -0.0000
   840        0.0000             nan     0.4488   -0.0000
   860        0.0000             nan     0.4488   -0.0000
   880        0.0000             nan     0.4488   -0.0000
   900        0.0000             nan     0.4488   -0.0000
   920        0.0000             nan     0.4488   -0.0000
   940        0.0000             nan     0.4488   -0.0000
   960        0.0000             nan     0.4488   -0.0000
   980        0.0000             nan     0.4488   -0.0000
  1000        0.0000             nan     0.4488   -0.0000
  1020        0.0000             nan     0.4488   -0.0000
  1040        0.0000             nan     0.4488   -0.0000
  1060        0.0000             nan     0.4488   -0.0000
  1080        0.0000             nan     0.4488   -0.0000
  1100        0.0000             nan     0.4488   -0.0000
  1120        0.0000             nan     0.4488   -0.0000
  1140        0.0000             nan     0.4488   -0.0000
  1160        0.0000             nan     0.4488   -0.0000
  1180        0.0000             nan     0.4488   -0.0000
  1200        0.0000             nan     0.4488   -0.0000
  1220        0.0000             nan     0.4488   -0.0000
  1240        0.0000             nan     0.4488   -0.0000
  1260        0.0000             nan     0.4488   -0.0000
  1280        0.0000             nan     0.4488   -0.0000
  1300        0.0000             nan     0.4488   -0.0000
  1320        0.0000             nan     0.4488   -0.0000
  1340        0.0000             nan     0.4488   -0.0000
  1360        0.0000             nan     0.4488   -0.0000
  1380        0.0000             nan     0.4488   -0.0000
  1400        0.0000             nan     0.4488   -0.0000
  1420        0.0000             nan     0.4488   -0.0000
  1440        0.0000             nan     0.4488   -0.0000
  1460        0.0000             nan     0.4488   -0.0000
  1480        0.0000             nan     0.4488   -0.0000
  1500        0.0000             nan     0.4488   -0.0000
  1520        0.0000             nan     0.4488   -0.0000
  1540        0.0000             nan     0.4488   -0.0000
  1560        0.0000             nan     0.4488   -0.0000
  1580        0.0000             nan     0.4488   -0.0000
  1600        0.0000             nan     0.4488   -0.0000
  1620        0.0000             nan     0.4488   -0.0000
  1640        0.0000             nan     0.4488   -0.0000
  1660        0.0000             nan     0.4488   -0.0000
  1680        0.0000             nan     0.4488   -0.0000
  1700        0.0000             nan     0.4488   -0.0000
  1720        0.0000             nan     0.4488   -0.0000
  1740        0.0000             nan     0.4488   -0.0000
  1760        0.0000             nan     0.4488   -0.0000
  1780        0.0000             nan     0.4488   -0.0000
  1800        0.0000             nan     0.4488   -0.0000
  1820        0.0000             nan     0.4488   -0.0000
  1840        0.0000             nan     0.4488   -0.0000
  1860        0.0000             nan     0.4488   -0.0000
  1880        0.0000             nan     0.4488   -0.0000
  1900        0.0000             nan     0.4488   -0.0000
  1920        0.0000             nan     0.4488   -0.0000
  1940        0.0000             nan     0.4488   -0.0000
  1960        0.0000             nan     0.4488   -0.0000
  1980        0.0000             nan     0.4488   -0.0000
  2000        0.0000             nan     0.4488   -0.0000
  2020        0.0000             nan     0.4488   -0.0000
  2040        0.0000             nan     0.4488   -0.0000
  2060        0.0000             nan     0.4488   -0.0000
  2080        0.0000             nan     0.4488   -0.0000
  2100        0.0000             nan     0.4488   -0.0000
  2120        0.0000             nan     0.4488   -0.0000
  2140        0.0000             nan     0.4488   -0.0000
  2160        0.0000             nan     0.4488   -0.0000
  2180        0.0000             nan     0.4488   -0.0000
  2200        0.0000             nan     0.4488   -0.0000
  2220        0.0000             nan     0.4488   -0.0000
  2240        0.0000             nan     0.4488   -0.0000
  2260        0.0000             nan     0.4488   -0.0000
  2280        0.0000             nan     0.4488   -0.0000
  2300        0.0000             nan     0.4488   -0.0000
  2320        0.0000             nan     0.4488   -0.0000
  2340        0.0000             nan     0.4488   -0.0000
  2360        0.0000             nan     0.4488   -0.0000
  2380        0.0000             nan     0.4488   -0.0000
  2400        0.0000             nan     0.4488   -0.0000
  2420        0.0000             nan     0.4488   -0.0000
  2440        0.0000             nan     0.4488   -0.0000
  2460        0.0000             nan     0.4488   -0.0000
  2480        0.0000             nan     0.4488   -0.0000
  2500        0.0000             nan     0.4488   -0.0000
  2520        0.0000             nan     0.4488   -0.0000
  2540        0.0000             nan     0.4488   -0.0000
  2560        0.0000             nan     0.4488   -0.0000
  2580        0.0000             nan     0.4488   -0.0000
  2600        0.0000             nan     0.4488   -0.0000
  2620        0.0000             nan     0.4488   -0.0000
  2640        0.0000             nan     0.4488   -0.0000
  2660        0.0000             nan     0.4488   -0.0000
  2680        0.0000             nan     0.4488   -0.0000
  2700        0.0000             nan     0.4488   -0.0000
  2720        0.0000             nan     0.4488   -0.0000
  2740        0.0000             nan     0.4488   -0.0000
  2760        0.0000             nan     0.4488   -0.0000
  2780        0.0000             nan     0.4488   -0.0000
  2800        0.0000             nan     0.4488   -0.0000
  2803        0.0000             nan     0.4488   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9440             nan     0.4523   -0.0023
     2        0.8868             nan     0.4523   -0.0203
     3        0.8650             nan     0.4523   -0.0666
     4        0.8200             nan     0.4523   -0.0231
     5        0.8053             nan     0.4523   -0.0580
     6        0.7947             nan     0.4523   -0.0599
     7        0.7700             nan     0.4523   -0.0209
     8        0.7511             nan     0.4523   -0.0262
     9        0.7172             nan     0.4523   -0.0252
    10        0.6922             nan     0.4523   -0.0191
    20        0.5388             nan     0.4523   -0.0367
    40        0.3280             nan     0.4523   -0.0094
    60        0.2238             nan     0.4523   -0.0145
    80        0.1502             nan     0.4523   -0.0132
   100        0.1036             nan     0.4523   -0.0050
   120        0.0708             nan     0.4523   -0.0030
   140        0.0465             nan     0.4523   -0.0006
   160        0.0327             nan     0.4523   -0.0018
   180        0.0222             nan     0.4523   -0.0011
   200        0.0153             nan     0.4523   -0.0015
   220        0.0105             nan     0.4523   -0.0007
   240        0.0075             nan     0.4523   -0.0004
   260        0.0052             nan     0.4523   -0.0003
   280        0.0036             nan     0.4523   -0.0003
   300        0.0027             nan     0.4523   -0.0002
   320        0.0019             nan     0.4523   -0.0001
   340        0.0014             nan     0.4523   -0.0001
   360        0.0009             nan     0.4523   -0.0000
   380        0.0006             nan     0.4523   -0.0000
   400        0.0004             nan     0.4523   -0.0000
   420        0.0003             nan     0.4523   -0.0000
   440        0.0002             nan     0.4523   -0.0000
   460        0.0002             nan     0.4523   -0.0000
   480        0.0001             nan     0.4523   -0.0000
   500        0.0001             nan     0.4523   -0.0000
   520        0.0001             nan     0.4523   -0.0000
   540        0.0000             nan     0.4523   -0.0000
   560        0.0000             nan     0.4523   -0.0000
   580        0.0000             nan     0.4523   -0.0000
   600        0.0000             nan     0.4523   -0.0000
   620        0.0000             nan     0.4523   -0.0000
   640        0.0000             nan     0.4523   -0.0000
   660        0.0000             nan     0.4523   -0.0000
   680        0.0000             nan     0.4523   -0.0000
   700        0.0000             nan     0.4523   -0.0000
   720        0.0000             nan     0.4523   -0.0000
   740        0.0000             nan     0.4523   -0.0000
   760        0.0000             nan     0.4523   -0.0000
   780        0.0000             nan     0.4523   -0.0000
   800        0.0000             nan     0.4523   -0.0000
   820        0.0000             nan     0.4523   -0.0000
   840        0.0000             nan     0.4523   -0.0000
   860        0.0000             nan     0.4523   -0.0000
   880        0.0000             nan     0.4523   -0.0000
   900        0.0000             nan     0.4523   -0.0000
   920        0.0000             nan     0.4523   -0.0000
   940        0.0000             nan     0.4523   -0.0000
   960        0.0000             nan     0.4523   -0.0000
   980        0.0000             nan     0.4523   -0.0000
  1000        0.0000             nan     0.4523   -0.0000
  1020        0.0000             nan     0.4523   -0.0000
  1040        0.0000             nan     0.4523   -0.0000
  1060        0.0000             nan     0.4523   -0.0000
  1080        0.0000             nan     0.4523   -0.0000
  1100        0.0000             nan     0.4523   -0.0000
  1120        0.0000             nan     0.4523   -0.0000
  1140        0.0000             nan     0.4523   -0.0000
  1160        0.0000             nan     0.4523   -0.0000
  1180        0.0000             nan     0.4523   -0.0000
  1200        0.0000             nan     0.4523   -0.0000
  1220        0.0000             nan     0.4523   -0.0000
  1240        0.0000             nan     0.4523   -0.0000
  1260        0.0000             nan     0.4523   -0.0000
  1280        0.0000             nan     0.4523   -0.0000
  1300        0.0000             nan     0.4523   -0.0000
  1320        0.0000             nan     0.4523   -0.0000
  1340        0.0000             nan     0.4523   -0.0000
  1360        0.0000             nan     0.4523   -0.0000
  1380        0.0000             nan     0.4523   -0.0000
  1400        0.0000             nan     0.4523   -0.0000
  1420        0.0000             nan     0.4523   -0.0000
  1440        0.0000             nan     0.4523   -0.0000
  1460        0.0000             nan     0.4523   -0.0000
  1480        0.0000             nan     0.4523   -0.0000
  1500        0.0000             nan     0.4523   -0.0000
  1520        0.0000             nan     0.4523   -0.0000
  1540        0.0000             nan     0.4523   -0.0000
  1560        0.0000             nan     0.4523   -0.0000
  1580        0.0000             nan     0.4523   -0.0000
  1600        0.0000             nan     0.4523   -0.0000
  1620        0.0000             nan     0.4523   -0.0000
  1640        0.0000             nan     0.4523   -0.0000
  1660        0.0000             nan     0.4523   -0.0000
  1680        0.0000             nan     0.4523   -0.0000
  1700        0.0000             nan     0.4523   -0.0000
  1720        0.0000             nan     0.4523   -0.0000
  1740        0.0000             nan     0.4523   -0.0000
  1760        0.0000             nan     0.4523   -0.0000
  1780        0.0000             nan     0.4523   -0.0000
  1800        0.0000             nan     0.4523   -0.0000
  1820        0.0000             nan     0.4523   -0.0000
  1840        0.0000             nan     0.4523   -0.0000
  1860        0.0000             nan     0.4523   -0.0000
  1880        0.0000             nan     0.4523   -0.0000
  1900        0.0000             nan     0.4523   -0.0000
  1920        0.0000             nan     0.4523   -0.0000
  1940        0.0000             nan     0.4523   -0.0000
  1960        0.0000             nan     0.4523   -0.0000
  1980        0.0000             nan     0.4523   -0.0000
  2000        0.0000             nan     0.4523   -0.0000
  2020        0.0000             nan     0.4523   -0.0000
  2040        0.0000             nan     0.4523   -0.0000
  2043        0.0000             nan     0.4523   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9890             nan     0.5059   -0.0318
     2        0.9666             nan     0.5059   -0.0118
     3        0.9433             nan     0.5059   -0.0022
     4        0.9431             nan     0.5059   -0.0416
     5        0.9517             nan     0.5059   -0.0847
     6        0.9384             nan     0.5059   -0.0424
     7        0.9397             nan     0.5059   -0.0362
     8        0.9368             nan     0.5059   -0.0250
     9        0.9310             nan     0.5059   -0.0299
    10        0.9153             nan     0.5059   -0.0193
    20        0.8288             nan     0.5059   -0.0253
    40        0.7647             nan     0.5059   -0.0426
    60        0.6643             nan     0.5059   -0.0409
    80        0.5839             nan     0.5059   -0.0051
   100        0.5116             nan     0.5059   -0.0245
   120        0.4505             nan     0.5059   -0.0139
   140        0.4142             nan     0.5059   -0.0094
   160        0.3605             nan     0.5059   -0.0118
   180        0.3234             nan     0.5059   -0.0028
   200        0.2870             nan     0.5059   -0.0048
   220        0.2554             nan     0.5059   -0.0137
   240        0.2302             nan     0.5059   -0.0123
   260        0.2062             nan     0.5059   -0.0059
   280        0.1865             nan     0.5059   -0.0084
   300        0.1736             nan     0.5059   -0.0078
   320        0.1598             nan     0.5059   -0.0088
   340        0.1437             nan     0.5059   -0.0019
   360        0.1334             nan     0.5059   -0.0054
   380        0.1136             nan     0.5059   -0.0060
   400        0.1047             nan     0.5059   -0.0045
   420        0.0972             nan     0.5059   -0.0021
   440        0.0891             nan     0.5059   -0.0028
   460        0.0812             nan     0.5059   -0.0022
   480        0.0756             nan     0.5059   -0.0031
   500        0.0704             nan     0.5059   -0.0015
   520        0.0644             nan     0.5059   -0.0013
   540        0.0583             nan     0.5059   -0.0012
   560        0.0543             nan     0.5059   -0.0025
   580        0.0503             nan     0.5059   -0.0018
   600        0.0442             nan     0.5059   -0.0013
   620        0.0404             nan     0.5059   -0.0017
   640        0.0363             nan     0.5059   -0.0016
   660        0.0339             nan     0.5059   -0.0009
   680        0.0314             nan     0.5059   -0.0016
   700        0.0291             nan     0.5059   -0.0010
   720        0.0265             nan     0.5059   -0.0005
   740        0.0238             nan     0.5059   -0.0002
   760        0.0218             nan     0.5059   -0.0008
   780        0.0197             nan     0.5059   -0.0006
   800        0.0178             nan     0.5059   -0.0002
   820        0.0164             nan     0.5059   -0.0002
   840        0.0154             nan     0.5059   -0.0002
   860        0.0143             nan     0.5059   -0.0003
   880        0.0130             nan     0.5059   -0.0002
   900        0.0121             nan     0.5059   -0.0005
   920        0.0114             nan     0.5059   -0.0005
   940        0.0106             nan     0.5059   -0.0001
   960        0.0094             nan     0.5059   -0.0002
   980        0.0086             nan     0.5059   -0.0004
  1000        0.0079             nan     0.5059   -0.0003
  1020        0.0074             nan     0.5059   -0.0002
  1040        0.0069             nan     0.5059   -0.0000
  1060        0.0063             nan     0.5059   -0.0002
  1080        0.0059             nan     0.5059   -0.0003
  1100        0.0053             nan     0.5059   -0.0001
  1120        0.0048             nan     0.5059   -0.0003
  1140        0.0046             nan     0.5059   -0.0001
  1160        0.0043             nan     0.5059   -0.0001
  1180        0.0041             nan     0.5059   -0.0001
  1200        0.0038             nan     0.5059   -0.0001
  1220        0.0034             nan     0.5059   -0.0000
  1240        0.0032             nan     0.5059   -0.0002
  1260        0.0030             nan     0.5059   -0.0002
  1280        0.0028             nan     0.5059   -0.0001
  1300        0.0025             nan     0.5059   -0.0001
  1320        0.0023             nan     0.5059   -0.0001
  1340        0.0022             nan     0.5059   -0.0001
  1360        0.0021             nan     0.5059   -0.0001
  1380        0.0019             nan     0.5059   -0.0001
  1400        0.0017             nan     0.5059   -0.0000
  1420        0.0016             nan     0.5059   -0.0001
  1440        0.0015             nan     0.5059   -0.0000
  1460        0.0014             nan     0.5059   -0.0000
  1480        0.0013             nan     0.5059   -0.0000
  1500        0.0012             nan     0.5059   -0.0000
  1520        0.0011             nan     0.5059   -0.0000
  1540        0.0010             nan     0.5059   -0.0000
  1560        0.0009             nan     0.5059   -0.0000
  1580        0.0008             nan     0.5059   -0.0000
  1600        0.0008             nan     0.5059   -0.0000
  1620        0.0007             nan     0.5059   -0.0000
  1640        0.0007             nan     0.5059   -0.0000
  1660        0.0006             nan     0.5059   -0.0000
  1680        0.0006             nan     0.5059   -0.0000
  1700        0.0006             nan     0.5059   -0.0000
  1720        0.0005             nan     0.5059   -0.0000
  1740        0.0005             nan     0.5059   -0.0000
  1760        0.0004             nan     0.5059   -0.0000
  1780        0.0004             nan     0.5059   -0.0000
  1800        0.0004             nan     0.5059   -0.0000
  1820        0.0003             nan     0.5059   -0.0000
  1840        0.0003             nan     0.5059   -0.0000
  1860        0.0003             nan     0.5059   -0.0000
  1880        0.0003             nan     0.5059   -0.0000
  1900        0.0002             nan     0.5059   -0.0000
  1920        0.0002             nan     0.5059   -0.0000
  1940        0.0002             nan     0.5059   -0.0000
  1960        0.0002             nan     0.5059    0.0000
  1980        0.0002             nan     0.5059   -0.0000
  2000        0.0002             nan     0.5059   -0.0000
  2020        0.0001             nan     0.5059   -0.0000
  2040        0.0001             nan     0.5059   -0.0000
  2060        0.0001             nan     0.5059   -0.0000
  2080        0.0001             nan     0.5059   -0.0000
  2100        0.0001             nan     0.5059   -0.0000
  2120        0.0001             nan     0.5059   -0.0000
  2140        0.0001             nan     0.5059   -0.0000
  2160        0.0001             nan     0.5059   -0.0000
  2180        0.0001             nan     0.5059   -0.0000
  2200        0.0001             nan     0.5059   -0.0000
  2220        0.0001             nan     0.5059   -0.0000
  2240        0.0001             nan     0.5059   -0.0000
  2260        0.0001             nan     0.5059   -0.0000
  2280        0.0001             nan     0.5059   -0.0000
  2300        0.0001             nan     0.5059   -0.0000
  2320        0.0000             nan     0.5059   -0.0000
  2340        0.0000             nan     0.5059   -0.0000
  2360        0.0000             nan     0.5059   -0.0000
  2380        0.0000             nan     0.5059   -0.0000
  2400        0.0000             nan     0.5059   -0.0000
  2420        0.0000             nan     0.5059   -0.0000
  2440        0.0000             nan     0.5059   -0.0000
  2460        0.0000             nan     0.5059   -0.0000
  2480        0.0000             nan     0.5059   -0.0000
  2500        0.0000             nan     0.5059   -0.0000
  2520        0.0000             nan     0.5059   -0.0000
  2540        0.0000             nan     0.5059   -0.0000
  2560        0.0000             nan     0.5059   -0.0000
  2580        0.0000             nan     0.5059   -0.0000
  2600        0.0000             nan     0.5059   -0.0000
  2620        0.0000             nan     0.5059   -0.0000
  2640        0.0000             nan     0.5059   -0.0000
  2660        0.0000             nan     0.5059   -0.0000
  2680        0.0000             nan     0.5059   -0.0000
  2700        0.0000             nan     0.5059   -0.0000
  2720        0.0000             nan     0.5059   -0.0000
  2740        0.0000             nan     0.5059   -0.0000
  2760        0.0000             nan     0.5059   -0.0000
  2780        0.0000             nan     0.5059   -0.0000
  2800        0.0000             nan     0.5059   -0.0000
  2820        0.0000             nan     0.5059   -0.0000
  2840        0.0000             nan     0.5059   -0.0000
  2860        0.0000             nan     0.5059   -0.0000
  2880        0.0000             nan     0.5059   -0.0000
  2900        0.0000             nan     0.5059   -0.0000
  2920        0.0000             nan     0.5059   -0.0000
  2940        0.0000             nan     0.5059   -0.0000
  2960        0.0000             nan     0.5059   -0.0000
  2980        0.0000             nan     0.5059   -0.0000
  3000        0.0000             nan     0.5059   -0.0000
  3020        0.0000             nan     0.5059   -0.0000
  3040        0.0000             nan     0.5059   -0.0000
  3060        0.0000             nan     0.5059   -0.0000
  3080        0.0000             nan     0.5059   -0.0000
  3100        0.0000             nan     0.5059   -0.0000
  3120        0.0000             nan     0.5059   -0.0000
  3140        0.0000             nan     0.5059   -0.0000
  3160        0.0000             nan     0.5059   -0.0000
  3180        0.0000             nan     0.5059   -0.0000
  3200        0.0000             nan     0.5059   -0.0000
  3220        0.0000             nan     0.5059   -0.0000
  3240        0.0000             nan     0.5059   -0.0000
  3260        0.0000             nan     0.5059   -0.0000
  3280        0.0000             nan     0.5059   -0.0000
  3300        0.0000             nan     0.5059   -0.0000
  3320        0.0000             nan     0.5059   -0.0000
  3340        0.0000             nan     0.5059   -0.0000
  3360        0.0000             nan     0.5059   -0.0000
  3380        0.0000             nan     0.5059   -0.0000
  3400        0.0000             nan     0.5059   -0.0000
  3420        0.0000             nan     0.5059   -0.0000
  3440        0.0000             nan     0.5059   -0.0000
  3460        0.0000             nan     0.5059   -0.0000
  3480        0.0000             nan     0.5059   -0.0000
  3500        0.0000             nan     0.5059   -0.0000
  3520        0.0000             nan     0.5059   -0.0000
  3540        0.0000             nan     0.5059   -0.0000
  3560        0.0000             nan     0.5059   -0.0000
  3580        0.0000             nan     0.5059   -0.0000
  3600        0.0000             nan     0.5059   -0.0000
  3620        0.0000             nan     0.5059   -0.0000
  3640        0.0000             nan     0.5059   -0.0000
  3660        0.0000             nan     0.5059   -0.0000
  3680        0.0000             nan     0.5059   -0.0000
  3700        0.0000             nan     0.5059   -0.0000
  3720        0.0000             nan     0.5059   -0.0000
  3740        0.0000             nan     0.5059   -0.0000
  3760        0.0000             nan     0.5059   -0.0000
  3780        0.0000             nan     0.5059   -0.0000
  3800        0.0000             nan     0.5059   -0.0000
  3820        0.0000             nan     0.5059   -0.0000
  3840        0.0000             nan     0.5059   -0.0000
  3860        0.0000             nan     0.5059   -0.0000
  3880        0.0000             nan     0.5059   -0.0000
  3900        0.0000             nan     0.5059   -0.0000
  3920        0.0000             nan     0.5059   -0.0000
  3940        0.0000             nan     0.5059   -0.0000
  3960        0.0000             nan     0.5059   -0.0000
  3980        0.0000             nan     0.5059   -0.0000
  4000        0.0000             nan     0.5059   -0.0000
  4020        0.0000             nan     0.5059   -0.0000
  4040        0.0000             nan     0.5059   -0.0000
  4060        0.0000             nan     0.5059   -0.0000
  4080        0.0000             nan     0.5059   -0.0000
  4100        0.0000             nan     0.5059   -0.0000
  4120        0.0000             nan     0.5059   -0.0000
  4140        0.0000             nan     0.5059   -0.0000
  4160        0.0000             nan     0.5059   -0.0000
  4180        0.0000             nan     0.5059   -0.0000
  4200        0.0000             nan     0.5059   -0.0000
  4220        0.0000             nan     0.5059   -0.0000
  4240        0.0000             nan     0.5059   -0.0000
  4260        0.0000             nan     0.5059   -0.0000
  4280        0.0000             nan     0.5059   -0.0000
  4300        0.0000             nan     0.5059   -0.0000
  4320        0.0000             nan     0.5059   -0.0000
  4340        0.0000             nan     0.5059   -0.0000
  4360        0.0000             nan     0.5059   -0.0000
  4380        0.0000             nan     0.5059   -0.0000
  4400        0.0000             nan     0.5059   -0.0000
  4420        0.0000             nan     0.5059   -0.0000
  4440        0.0000             nan     0.5059   -0.0000
  4460        0.0000             nan     0.5059   -0.0000
  4480        0.0000             nan     0.5059   -0.0000
  4500        0.0000             nan     0.5059   -0.0000
  4520        0.0000             nan     0.5059   -0.0000
  4540        0.0000             nan     0.5059   -0.0000
  4560        0.0000             nan     0.5059   -0.0000
  4580        0.0000             nan     0.5059   -0.0000
  4600        0.0000             nan     0.5059   -0.0000
  4620        0.0000             nan     0.5059   -0.0000
  4640        0.0000             nan     0.5059   -0.0000
  4660        0.0000             nan     0.5059   -0.0000
  4680        0.0000             nan     0.5059   -0.0000
  4700        0.0000             nan     0.5059   -0.0000
  4720        0.0000             nan     0.5059   -0.0000
  4740        0.0000             nan     0.5059   -0.0000
  4760        0.0000             nan     0.5059   -0.0000
  4780        0.0000             nan     0.5059   -0.0000
  4800        0.0000             nan     0.5059   -0.0000
  4820        0.0000             nan     0.5059   -0.0000
  4840        0.0000             nan     0.5059   -0.0000
  4860        0.0000             nan     0.5059   -0.0000
  4880        0.0000             nan     0.5059   -0.0000
  4900        0.0000             nan     0.5059   -0.0000
  4920        0.0000             nan     0.5059   -0.0000
  4922        0.0000             nan     0.5059   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9396             nan     0.5986   -0.0045
     2        0.9319             nan     0.5986   -0.1134
     3        0.9021             nan     0.5986   -0.0572
     4        0.8752             nan     0.5986   -0.0345
     5        0.8581             nan     0.5986   -0.0783
     6        0.8297             nan     0.5986   -0.0322
     7        0.8113             nan     0.5986   -0.0788
     8        0.8006             nan     0.5986   -0.0539
     9        0.7901             nan     0.5986   -0.0486
    10        0.7768             nan     0.5986   -0.0463
    20        0.6241             nan     0.5986   -0.0349
    40        0.3804             nan     0.5986   -0.0198
    60        0.2380             nan     0.5986   -0.0075
    80        0.1553             nan     0.5986   -0.0046
   100        0.1113             nan     0.5986   -0.0098
   120        0.0767             nan     0.5986   -0.0057
   140        0.0526             nan     0.5986   -0.0017
   160        0.0396             nan     0.5986   -0.0028
   180        0.0285             nan     0.5986   -0.0018
   200        0.0200             nan     0.5986   -0.0008
   220        0.0145             nan     0.5986   -0.0007
   240        0.0102             nan     0.5986   -0.0008
   260        0.0072             nan     0.5986   -0.0005
   280        0.0053             nan     0.5986   -0.0002
   300        0.0039             nan     0.5986   -0.0003
   320        0.0027             nan     0.5986   -0.0002
   340        0.0020             nan     0.5986   -0.0002
   360        0.0015             nan     0.5986   -0.0001
   380        0.0010             nan     0.5986   -0.0000
   400        0.0007             nan     0.5986   -0.0000
   420        0.0005             nan     0.5986   -0.0001
   440        0.0003             nan     0.5986   -0.0000
   460        0.0002             nan     0.5986   -0.0000
   480        0.0002             nan     0.5986   -0.0000
   500        0.0001             nan     0.5986   -0.0000
   520        0.0001             nan     0.5986   -0.0000
   540        0.0001             nan     0.5986   -0.0000
   560        0.0000             nan     0.5986   -0.0000
   580        0.0000             nan     0.5986   -0.0000
   600        0.0000             nan     0.5986   -0.0000
   620        0.0000             nan     0.5986   -0.0000
   640        0.0000             nan     0.5986   -0.0000
   660        0.0000             nan     0.5986   -0.0000
   680        0.0000             nan     0.5986   -0.0000
   700        0.0000             nan     0.5986   -0.0000
   720        0.0000             nan     0.5986   -0.0000
   740        0.0000             nan     0.5986   -0.0000
   760        0.0000             nan     0.5986   -0.0000
   780        0.0000             nan     0.5986   -0.0000
   800        0.0000             nan     0.5986   -0.0000
   820        0.0000             nan     0.5986   -0.0000
   840        0.0000             nan     0.5986   -0.0000
   860        0.0000             nan     0.5986   -0.0000
   880        0.0000             nan     0.5986   -0.0000
   900        0.0000             nan     0.5986   -0.0000
   920        0.0000             nan     0.5986   -0.0000
   940        0.0000             nan     0.5986   -0.0000
   960        0.0000             nan     0.5986   -0.0000
   980        0.0000             nan     0.5986   -0.0000
  1000        0.0000             nan     0.5986   -0.0000
  1020        0.0000             nan     0.5986   -0.0000
  1040        0.0000             nan     0.5986   -0.0000
  1060        0.0000             nan     0.5986   -0.0000
  1080        0.0000             nan     0.5986   -0.0000
  1100        0.0000             nan     0.5986   -0.0000
  1120        0.0000             nan     0.5986   -0.0000
  1140        0.0000             nan     0.5986   -0.0000
  1160        0.0000             nan     0.5986   -0.0000
  1180        0.0000             nan     0.5986   -0.0000
  1200        0.0000             nan     0.5986   -0.0000
  1220        0.0000             nan     0.5986   -0.0000
  1240        0.0000             nan     0.5986   -0.0000
  1260        0.0000             nan     0.5986   -0.0000
  1280        0.0000             nan     0.5986   -0.0000
  1300        0.0000             nan     0.5986   -0.0000
  1320        0.0000             nan     0.5986   -0.0000
  1340        0.0000             nan     0.5986   -0.0000
  1360        0.0000             nan     0.5986   -0.0000
  1380        0.0000             nan     0.5986   -0.0000
  1400        0.0000             nan     0.5986   -0.0000
  1420        0.0000             nan     0.5986   -0.0000
  1440        0.0000             nan     0.5986   -0.0000
  1460        0.0000             nan     0.5986   -0.0000
  1480        0.0000             nan     0.5986   -0.0000
  1500        0.0000             nan     0.5986   -0.0000
  1520        0.0000             nan     0.5986   -0.0000
  1529        0.0000             nan     0.5986   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0239             nan     0.0142    0.0001
     2        1.0207             nan     0.0142    0.0003
     3        1.0188             nan     0.0142   -0.0013
     4        1.0164             nan     0.0142   -0.0006
     5        1.0132             nan     0.0142    0.0007
     6        1.0103             nan     0.0142   -0.0005
     7        1.0075             nan     0.0142    0.0001
     8        1.0050             nan     0.0142    0.0001
     9        1.0022             nan     0.0142   -0.0005
    10        0.9991             nan     0.0142   -0.0005
    20        0.9705             nan     0.0142    0.0005
    40        0.9229             nan     0.0142   -0.0011
    60        0.8799             nan     0.0142    0.0001
    80        0.8361             nan     0.0142   -0.0003
   100        0.8005             nan     0.0142   -0.0008
   120        0.7660             nan     0.0142   -0.0006
   140        0.7358             nan     0.0142   -0.0007
   160        0.7077             nan     0.0142   -0.0010
   180        0.6814             nan     0.0142   -0.0010
   200        0.6570             nan     0.0142   -0.0005
   220        0.6341             nan     0.0142   -0.0002
   240        0.6105             nan     0.0142   -0.0000
   260        0.5908             nan     0.0142   -0.0009
   280        0.5715             nan     0.0142   -0.0011
   300        0.5529             nan     0.0142   -0.0001
   320        0.5346             nan     0.0142   -0.0007
   340        0.5179             nan     0.0142   -0.0008
   360        0.4992             nan     0.0142   -0.0004
   380        0.4824             nan     0.0142   -0.0002
   400        0.4675             nan     0.0142   -0.0006
   420        0.4525             nan     0.0142   -0.0010
   440        0.4388             nan     0.0142   -0.0004
   460        0.4258             nan     0.0142   -0.0002
   480        0.4125             nan     0.0142   -0.0005
   500        0.3996             nan     0.0142   -0.0003
   520        0.3872             nan     0.0142   -0.0005
   540        0.3761             nan     0.0142   -0.0005
   560        0.3657             nan     0.0142   -0.0003
   580        0.3564             nan     0.0142   -0.0004
   600        0.3459             nan     0.0142   -0.0006
   620        0.3365             nan     0.0142   -0.0003
   640        0.3268             nan     0.0142   -0.0004
   660        0.3174             nan     0.0142   -0.0004
   680        0.3080             nan     0.0142   -0.0008
   700        0.2991             nan     0.0142   -0.0006
   720        0.2911             nan     0.0142   -0.0003
   740        0.2822             nan     0.0142   -0.0003
   760        0.2741             nan     0.0142   -0.0006
   780        0.2664             nan     0.0142   -0.0005
   800        0.2591             nan     0.0142   -0.0001
   820        0.2520             nan     0.0142   -0.0002
   840        0.2448             nan     0.0142   -0.0006
   860        0.2379             nan     0.0142   -0.0003
   880        0.2319             nan     0.0142   -0.0004
   900        0.2259             nan     0.0142   -0.0006
   920        0.2202             nan     0.0142   -0.0002
   940        0.2144             nan     0.0142   -0.0003
   960        0.2084             nan     0.0142   -0.0005
   980        0.2029             nan     0.0142   -0.0001
  1000        0.1978             nan     0.0142   -0.0003
  1020        0.1932             nan     0.0142   -0.0002
  1040        0.1880             nan     0.0142   -0.0002
  1060        0.1832             nan     0.0142   -0.0002
  1080        0.1783             nan     0.0142   -0.0005
  1100        0.1740             nan     0.0142   -0.0004
  1120        0.1695             nan     0.0142   -0.0005
  1140        0.1649             nan     0.0142   -0.0003
  1160        0.1607             nan     0.0142   -0.0002
  1180        0.1565             nan     0.0142   -0.0002
  1200        0.1526             nan     0.0142   -0.0002
  1220        0.1485             nan     0.0142   -0.0002
  1240        0.1446             nan     0.0142   -0.0003
  1260        0.1411             nan     0.0142   -0.0001
  1280        0.1378             nan     0.0142   -0.0003
  1300        0.1343             nan     0.0142   -0.0003
  1320        0.1311             nan     0.0142   -0.0002
  1340        0.1279             nan     0.0142   -0.0002
  1360        0.1247             nan     0.0142   -0.0003
  1380        0.1214             nan     0.0142   -0.0003
  1400        0.1186             nan     0.0142   -0.0002
  1420        0.1157             nan     0.0142   -0.0001
  1440        0.1125             nan     0.0142   -0.0002
  1460        0.1099             nan     0.0142   -0.0002
  1480        0.1072             nan     0.0142   -0.0003
  1500        0.1045             nan     0.0142   -0.0001
  1520        0.1019             nan     0.0142   -0.0002
  1540        0.0995             nan     0.0142   -0.0002
  1560        0.0972             nan     0.0142   -0.0002
  1580        0.0949             nan     0.0142   -0.0002
  1600        0.0925             nan     0.0142   -0.0002
  1620        0.0905             nan     0.0142   -0.0001
  1640        0.0883             nan     0.0142   -0.0002
  1660        0.0863             nan     0.0142   -0.0002
  1680        0.0844             nan     0.0142   -0.0002
  1700        0.0826             nan     0.0142   -0.0002
  1720        0.0802             nan     0.0142   -0.0001
  1740        0.0784             nan     0.0142   -0.0002
  1760        0.0765             nan     0.0142   -0.0002
  1780        0.0747             nan     0.0142   -0.0001
  1800        0.0730             nan     0.0142   -0.0001
  1820        0.0714             nan     0.0142   -0.0001
  1840        0.0698             nan     0.0142   -0.0001
  1860        0.0680             nan     0.0142   -0.0001
  1880        0.0665             nan     0.0142   -0.0001
  1900        0.0651             nan     0.0142   -0.0001
  1920        0.0635             nan     0.0142   -0.0001
  1940        0.0621             nan     0.0142   -0.0001
  1960        0.0607             nan     0.0142   -0.0001
  1980        0.0592             nan     0.0142   -0.0001
  2000        0.0577             nan     0.0142   -0.0000
  2020        0.0565             nan     0.0142   -0.0001
  2040        0.0551             nan     0.0142   -0.0001
  2060        0.0538             nan     0.0142   -0.0001
  2080        0.0526             nan     0.0142   -0.0001
  2100        0.0513             nan     0.0142   -0.0001
  2120        0.0501             nan     0.0142   -0.0001
  2140        0.0488             nan     0.0142   -0.0001
  2160        0.0476             nan     0.0142   -0.0000
  2180        0.0466             nan     0.0142   -0.0001
  2200        0.0455             nan     0.0142   -0.0001
  2220        0.0445             nan     0.0142   -0.0001
  2240        0.0434             nan     0.0142   -0.0001
  2260        0.0425             nan     0.0142   -0.0001
  2280        0.0416             nan     0.0142   -0.0001
  2300        0.0407             nan     0.0142   -0.0001
  2320        0.0398             nan     0.0142   -0.0001
  2340        0.0388             nan     0.0142   -0.0001
  2360        0.0380             nan     0.0142   -0.0001
  2380        0.0371             nan     0.0142   -0.0000
  2400        0.0362             nan     0.0142   -0.0001
  2420        0.0353             nan     0.0142   -0.0001
  2440        0.0346             nan     0.0142   -0.0001
  2460        0.0337             nan     0.0142   -0.0000
  2480        0.0330             nan     0.0142   -0.0000
  2500        0.0322             nan     0.0142   -0.0000
  2520        0.0314             nan     0.0142   -0.0001
  2540        0.0307             nan     0.0142   -0.0001
  2560        0.0299             nan     0.0142   -0.0001
  2580        0.0293             nan     0.0142   -0.0000
  2600        0.0286             nan     0.0142   -0.0000
  2620        0.0280             nan     0.0142   -0.0001
  2640        0.0273             nan     0.0142   -0.0000
  2660        0.0267             nan     0.0142   -0.0000
  2680        0.0261             nan     0.0142   -0.0000
  2700        0.0255             nan     0.0142   -0.0001
  2720        0.0250             nan     0.0142   -0.0000
  2740        0.0244             nan     0.0142   -0.0001
  2760        0.0239             nan     0.0142   -0.0001
  2780        0.0234             nan     0.0142   -0.0001
  2800        0.0228             nan     0.0142   -0.0000
  2820        0.0223             nan     0.0142   -0.0000
  2840        0.0218             nan     0.0142   -0.0000
  2860        0.0213             nan     0.0142   -0.0001
  2880        0.0209             nan     0.0142   -0.0000
  2900        0.0204             nan     0.0142   -0.0001
  2920        0.0200             nan     0.0142   -0.0000
  2940        0.0196             nan     0.0142   -0.0000
  2960        0.0192             nan     0.0142   -0.0000
  2980        0.0187             nan     0.0142   -0.0000
  3000        0.0183             nan     0.0142   -0.0000
  3020        0.0179             nan     0.0142   -0.0000
  3040        0.0175             nan     0.0142   -0.0000
  3047        0.0174             nan     0.0142   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0064             nan     0.1007    0.0038
     2        0.9911             nan     0.1007   -0.0048
     3        0.9787             nan     0.1007   -0.0053
     4        0.9675             nan     0.1007   -0.0055
     5        0.9561             nan     0.1007   -0.0016
     6        0.9435             nan     0.1007   -0.0022
     7        0.9338             nan     0.1007   -0.0027
     8        0.9214             nan     0.1007   -0.0024
     9        0.9114             nan     0.1007   -0.0109
    10        0.9034             nan     0.1007   -0.0055
    20        0.8130             nan     0.1007   -0.0041
    40        0.6764             nan     0.1007   -0.0088
    60        0.5715             nan     0.1007   -0.0035
    80        0.4992             nan     0.1007   -0.0075
   100        0.4370             nan     0.1007   -0.0039
   120        0.3812             nan     0.1007   -0.0030
   140        0.3325             nan     0.1007   -0.0031
   160        0.2947             nan     0.1007   -0.0030
   180        0.2657             nan     0.1007   -0.0027
   200        0.2392             nan     0.1007   -0.0023
   220        0.2114             nan     0.1007   -0.0023
   240        0.1892             nan     0.1007   -0.0028
   260        0.1695             nan     0.1007   -0.0032
   280        0.1502             nan     0.1007   -0.0013
   300        0.1350             nan     0.1007   -0.0020
   320        0.1204             nan     0.1007   -0.0011
   340        0.1087             nan     0.1007   -0.0015
   360        0.0979             nan     0.1007   -0.0012
   380        0.0893             nan     0.1007   -0.0008
   400        0.0810             nan     0.1007   -0.0007
   420        0.0731             nan     0.1007   -0.0007
   440        0.0664             nan     0.1007   -0.0008
   460        0.0605             nan     0.1007   -0.0010
   480        0.0545             nan     0.1007   -0.0005
   500        0.0492             nan     0.1007   -0.0004
   520        0.0443             nan     0.1007   -0.0004
   540        0.0404             nan     0.1007   -0.0005
   560        0.0366             nan     0.1007   -0.0004
   580        0.0336             nan     0.1007   -0.0002
   600        0.0303             nan     0.1007   -0.0005
   620        0.0272             nan     0.1007   -0.0003
   640        0.0245             nan     0.1007   -0.0003
   660        0.0222             nan     0.1007   -0.0003
   675        0.0206             nan     0.1007   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0080             nan     0.1139    0.0009
     2        0.9915             nan     0.1139    0.0026
     3        0.9727             nan     0.1139   -0.0090
     4        0.9621             nan     0.1139   -0.0043
     5        0.9526             nan     0.1139   -0.0104
     6        0.9378             nan     0.1139   -0.0024
     7        0.9235             nan     0.1139   -0.0067
     8        0.9160             nan     0.1139   -0.0078
     9        0.9007             nan     0.1139    0.0000
    10        0.8867             nan     0.1139   -0.0067
    20        0.7840             nan     0.1139   -0.0035
    40        0.6482             nan     0.1139   -0.0111
    60        0.5438             nan     0.1139   -0.0078
    80        0.4688             nan     0.1139   -0.0030
   100        0.4032             nan     0.1139   -0.0034
   120        0.3481             nan     0.1139   -0.0066
   140        0.3061             nan     0.1139   -0.0037
   160        0.2660             nan     0.1139   -0.0047
   180        0.2339             nan     0.1139   -0.0046
   200        0.2042             nan     0.1139   -0.0020
   220        0.1807             nan     0.1139   -0.0019
   240        0.1599             nan     0.1139   -0.0019
   260        0.1413             nan     0.1139   -0.0026
   280        0.1267             nan     0.1139   -0.0016
   300        0.1137             nan     0.1139   -0.0015
   320        0.1007             nan     0.1139   -0.0010
   340        0.0899             nan     0.1139   -0.0009
   360        0.0803             nan     0.1139   -0.0012
   380        0.0715             nan     0.1139   -0.0006
   400        0.0643             nan     0.1139   -0.0009
   420        0.0574             nan     0.1139   -0.0008
   440        0.0510             nan     0.1139   -0.0012
   460        0.0453             nan     0.1139   -0.0005
   480        0.0412             nan     0.1139   -0.0007
   500        0.0368             nan     0.1139   -0.0004
   520        0.0330             nan     0.1139   -0.0004
   540        0.0301             nan     0.1139   -0.0002
   560        0.0270             nan     0.1139   -0.0003
   580        0.0244             nan     0.1139   -0.0002
   600        0.0218             nan     0.1139   -0.0004
   620        0.0197             nan     0.1139   -0.0003
   640        0.0180             nan     0.1139   -0.0003
   660        0.0162             nan     0.1139   -0.0001
   680        0.0146             nan     0.1139   -0.0002
   700        0.0132             nan     0.1139   -0.0003
   720        0.0121             nan     0.1139   -0.0002
   740        0.0109             nan     0.1139   -0.0002
   760        0.0099             nan     0.1139   -0.0001
   780        0.0089             nan     0.1139   -0.0001
   800        0.0081             nan     0.1139   -0.0001
   820        0.0074             nan     0.1139   -0.0001
   840        0.0067             nan     0.1139   -0.0001
   860        0.0062             nan     0.1139   -0.0001
   880        0.0056             nan     0.1139   -0.0001
   900        0.0050             nan     0.1139   -0.0001
   920        0.0045             nan     0.1139   -0.0001
   940        0.0041             nan     0.1139   -0.0000
   960        0.0037             nan     0.1139   -0.0000
   980        0.0034             nan     0.1139   -0.0001
  1000        0.0031             nan     0.1139   -0.0000
  1020        0.0027             nan     0.1139   -0.0000
  1040        0.0025             nan     0.1139   -0.0000
  1060        0.0023             nan     0.1139   -0.0001
  1080        0.0021             nan     0.1139   -0.0000
  1100        0.0019             nan     0.1139   -0.0000
  1120        0.0017             nan     0.1139   -0.0000
  1140        0.0015             nan     0.1139   -0.0000
  1151        0.0015             nan     0.1139   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0154             nan     0.1790   -0.0120
     2        1.0010             nan     0.1790   -0.0110
     3        0.9901             nan     0.1790   -0.0295
     4        0.9651             nan     0.1790   -0.0001
     5        0.9511             nan     0.1790    0.0028
     6        0.9374             nan     0.1790   -0.0057
     7        0.9280             nan     0.1790   -0.0171
     8        0.9149             nan     0.1790   -0.0055
     9        0.9051             nan     0.1790   -0.0125
    10        0.8977             nan     0.1790   -0.0217
    20        0.8027             nan     0.1790   -0.0099
    40        0.6839             nan     0.1790   -0.0138
    60        0.5904             nan     0.1790   -0.0103
    80        0.5131             nan     0.1790   -0.0078
   100        0.4594             nan     0.1790   -0.0059
   120        0.4130             nan     0.1790   -0.0078
   140        0.3649             nan     0.1790   -0.0069
   160        0.3289             nan     0.1790   -0.0057
   180        0.2941             nan     0.1790   -0.0032
   200        0.2679             nan     0.1790   -0.0037
   220        0.2401             nan     0.1790   -0.0023
   240        0.2196             nan     0.1790   -0.0027
   260        0.2000             nan     0.1790   -0.0019
   280        0.1824             nan     0.1790   -0.0025
   300        0.1655             nan     0.1790   -0.0040
   320        0.1516             nan     0.1790   -0.0025
   340        0.1354             nan     0.1790   -0.0018
   360        0.1240             nan     0.1790   -0.0021
   380        0.1122             nan     0.1790   -0.0023
   400        0.1036             nan     0.1790   -0.0028
   420        0.0943             nan     0.1790   -0.0018
   440        0.0875             nan     0.1790   -0.0013
   460        0.0794             nan     0.1790   -0.0008
   480        0.0736             nan     0.1790   -0.0012
   500        0.0675             nan     0.1790   -0.0009
   520        0.0609             nan     0.1790   -0.0013
   540        0.0561             nan     0.1790   -0.0011
   560        0.0508             nan     0.1790   -0.0010
   580        0.0465             nan     0.1790   -0.0009
   600        0.0426             nan     0.1790   -0.0007
   620        0.0390             nan     0.1790   -0.0006
   640        0.0358             nan     0.1790   -0.0004
   660        0.0331             nan     0.1790   -0.0009
   680        0.0303             nan     0.1790   -0.0004
   700        0.0277             nan     0.1790   -0.0004
   720        0.0255             nan     0.1790   -0.0006
   740        0.0233             nan     0.1790   -0.0004
   760        0.0211             nan     0.1790   -0.0004
   780        0.0192             nan     0.1790   -0.0004
   800        0.0178             nan     0.1790   -0.0004
   820        0.0164             nan     0.1790   -0.0003
   840        0.0151             nan     0.1790   -0.0003
   860        0.0142             nan     0.1790   -0.0002
   880        0.0131             nan     0.1790   -0.0002
   900        0.0121             nan     0.1790   -0.0002
   920        0.0113             nan     0.1790   -0.0002
   940        0.0104             nan     0.1790   -0.0002
   960        0.0096             nan     0.1790   -0.0001
   980        0.0090             nan     0.1790   -0.0002
  1000        0.0083             nan     0.1790   -0.0001
  1020        0.0077             nan     0.1790   -0.0001
  1040        0.0071             nan     0.1790   -0.0001
  1060        0.0065             nan     0.1790   -0.0002
  1080        0.0060             nan     0.1790   -0.0001
  1100        0.0055             nan     0.1790   -0.0001
  1120        0.0050             nan     0.1790   -0.0000
  1140        0.0047             nan     0.1790   -0.0001
  1160        0.0044             nan     0.1790   -0.0001
  1180        0.0040             nan     0.1790   -0.0001
  1200        0.0037             nan     0.1790   -0.0001
  1220        0.0034             nan     0.1790   -0.0001
  1240        0.0031             nan     0.1790   -0.0000
  1260        0.0029             nan     0.1790   -0.0001
  1280        0.0027             nan     0.1790   -0.0001
  1300        0.0025             nan     0.1790   -0.0001
  1320        0.0024             nan     0.1790   -0.0000
  1340        0.0022             nan     0.1790   -0.0000
  1360        0.0020             nan     0.1790   -0.0000
  1380        0.0019             nan     0.1790   -0.0000
  1400        0.0018             nan     0.1790   -0.0000
  1420        0.0016             nan     0.1790   -0.0000
  1440        0.0015             nan     0.1790   -0.0000
  1460        0.0014             nan     0.1790   -0.0000
  1480        0.0013             nan     0.1790   -0.0000
  1500        0.0012             nan     0.1790   -0.0000
  1520        0.0011             nan     0.1790   -0.0000
  1540        0.0010             nan     0.1790   -0.0000
  1560        0.0010             nan     0.1790   -0.0000
  1580        0.0009             nan     0.1790   -0.0000
  1600        0.0009             nan     0.1790   -0.0000
  1620        0.0008             nan     0.1790   -0.0000
  1640        0.0007             nan     0.1790   -0.0000
  1660        0.0007             nan     0.1790   -0.0000
  1680        0.0006             nan     0.1790   -0.0000
  1700        0.0006             nan     0.1790   -0.0000
  1720        0.0005             nan     0.1790   -0.0000
  1740        0.0005             nan     0.1790   -0.0000
  1760        0.0005             nan     0.1790   -0.0000
  1780        0.0004             nan     0.1790   -0.0000
  1800        0.0004             nan     0.1790   -0.0000
  1820        0.0004             nan     0.1790   -0.0000
  1840        0.0004             nan     0.1790   -0.0000
  1860        0.0003             nan     0.1790   -0.0000
  1880        0.0003             nan     0.1790   -0.0000
  1900        0.0003             nan     0.1790   -0.0000
  1920        0.0003             nan     0.1790   -0.0000
  1940        0.0003             nan     0.1790   -0.0000
  1960        0.0002             nan     0.1790   -0.0000
  1980        0.0002             nan     0.1790   -0.0000
  2000        0.0002             nan     0.1790   -0.0000
  2020        0.0002             nan     0.1790   -0.0000
  2040        0.0002             nan     0.1790   -0.0000
  2060        0.0002             nan     0.1790   -0.0000
  2080        0.0002             nan     0.1790   -0.0000
  2100        0.0001             nan     0.1790   -0.0000
  2120        0.0001             nan     0.1790   -0.0000
  2140        0.0001             nan     0.1790   -0.0000
  2160        0.0001             nan     0.1790   -0.0000
  2180        0.0001             nan     0.1790   -0.0000
  2200        0.0001             nan     0.1790   -0.0000
  2220        0.0001             nan     0.1790   -0.0000
  2240        0.0001             nan     0.1790   -0.0000
  2260        0.0001             nan     0.1790   -0.0000
  2280        0.0001             nan     0.1790   -0.0000
  2300        0.0001             nan     0.1790   -0.0000
  2320        0.0001             nan     0.1790   -0.0000
  2340        0.0001             nan     0.1790   -0.0000
  2360        0.0001             nan     0.1790   -0.0000
  2380        0.0001             nan     0.1790   -0.0000
  2400        0.0001             nan     0.1790   -0.0000
  2420        0.0000             nan     0.1790   -0.0000
  2440        0.0000             nan     0.1790   -0.0000
  2460        0.0000             nan     0.1790   -0.0000
  2480        0.0000             nan     0.1790   -0.0000
  2500        0.0000             nan     0.1790   -0.0000
  2520        0.0000             nan     0.1790   -0.0000
  2540        0.0000             nan     0.1790   -0.0000
  2560        0.0000             nan     0.1790   -0.0000
  2580        0.0000             nan     0.1790   -0.0000
  2600        0.0000             nan     0.1790   -0.0000
  2601        0.0000             nan     0.1790   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9958             nan     0.1997   -0.0020
     2        0.9698             nan     0.1997   -0.0018
     3        0.9521             nan     0.1997   -0.0266
     4        0.9326             nan     0.1997   -0.0042
     5        0.9117             nan     0.1997   -0.0119
     6        0.8860             nan     0.1997    0.0047
     7        0.8721             nan     0.1997   -0.0049
     8        0.8555             nan     0.1997   -0.0133
     9        0.8339             nan     0.1997   -0.0062
    10        0.8132             nan     0.1997   -0.0037
    20        0.6652             nan     0.1997   -0.0077
    40        0.4883             nan     0.1997   -0.0049
    60        0.3632             nan     0.1997   -0.0047
    80        0.2833             nan     0.1997   -0.0094
   100        0.2236             nan     0.1997   -0.0028
   120        0.1720             nan     0.1997   -0.0035
   140        0.1387             nan     0.1997   -0.0027
   160        0.1068             nan     0.1997   -0.0032
   180        0.0865             nan     0.1997   -0.0017
   200        0.0682             nan     0.1997   -0.0017
   220        0.0548             nan     0.1997   -0.0015
   222        0.0537             nan     0.1997   -0.0018

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0139             nan     0.2168   -0.0039
     2        1.0045             nan     0.2168   -0.0118
     3        1.0051             nan     0.2168   -0.0330
     4        0.9958             nan     0.2168   -0.0191
     5        0.9759             nan     0.2168    0.0001
     6        0.9641             nan     0.2168   -0.0096
     7        0.9488             nan     0.2168    0.0030
     8        0.9423             nan     0.2168   -0.0152
     9        0.9317             nan     0.2168   -0.0046
    10        0.9220             nan     0.2168   -0.0250
    20        0.8336             nan     0.2168   -0.0054
    40        0.7131             nan     0.2168   -0.0078
    60        0.6253             nan     0.2168   -0.0128
    80        0.5575             nan     0.2168   -0.0042
   100        0.5058             nan     0.2168   -0.0058
   120        0.4541             nan     0.2168   -0.0034
   140        0.4047             nan     0.2168   -0.0018
   160        0.3690             nan     0.2168   -0.0048
   180        0.3365             nan     0.2168   -0.0051
   200        0.3099             nan     0.2168   -0.0023
   220        0.2800             nan     0.2168   -0.0056
   240        0.2610             nan     0.2168   -0.0030
   260        0.2394             nan     0.2168   -0.0025
   280        0.2210             nan     0.2168   -0.0039
   300        0.1995             nan     0.2168   -0.0028
   320        0.1853             nan     0.2168   -0.0020
   340        0.1700             nan     0.2168   -0.0020
   360        0.1576             nan     0.2168   -0.0023
   380        0.1442             nan     0.2168   -0.0012
   400        0.1311             nan     0.2168   -0.0008
   420        0.1206             nan     0.2168   -0.0015
   440        0.1104             nan     0.2168   -0.0015
   460        0.1027             nan     0.2168   -0.0021
   480        0.0948             nan     0.2168   -0.0019
   500        0.0871             nan     0.2168   -0.0010
   520        0.0811             nan     0.2168   -0.0015
   540        0.0759             nan     0.2168   -0.0013
   560        0.0704             nan     0.2168   -0.0007
   580        0.0652             nan     0.2168   -0.0013
   600        0.0606             nan     0.2168   -0.0007
   620        0.0556             nan     0.2168   -0.0015
   640        0.0512             nan     0.2168   -0.0002
   660        0.0472             nan     0.2168   -0.0010
   680        0.0445             nan     0.2168   -0.0006
   700        0.0416             nan     0.2168   -0.0009
   720        0.0392             nan     0.2168   -0.0012
   740        0.0367             nan     0.2168   -0.0008
   760        0.0344             nan     0.2168   -0.0001
   780        0.0321             nan     0.2168   -0.0005
   800        0.0304             nan     0.2168   -0.0008
   820        0.0282             nan     0.2168   -0.0004
   840        0.0265             nan     0.2168   -0.0004
   860        0.0246             nan     0.2168   -0.0005
   880        0.0229             nan     0.2168   -0.0003
   900        0.0217             nan     0.2168   -0.0004
   920        0.0203             nan     0.2168   -0.0003
   940        0.0192             nan     0.2168   -0.0005
   960        0.0180             nan     0.2168   -0.0003
   980        0.0167             nan     0.2168   -0.0002
  1000        0.0156             nan     0.2168   -0.0001
  1020        0.0148             nan     0.2168   -0.0003
  1040        0.0139             nan     0.2168   -0.0002
  1060        0.0130             nan     0.2168   -0.0003
  1080        0.0122             nan     0.2168   -0.0002
  1100        0.0114             nan     0.2168   -0.0001
  1120        0.0106             nan     0.2168   -0.0002
  1140        0.0100             nan     0.2168   -0.0003
  1160        0.0093             nan     0.2168   -0.0001
  1180        0.0088             nan     0.2168   -0.0002
  1200        0.0082             nan     0.2168   -0.0002
  1220        0.0078             nan     0.2168   -0.0002
  1240        0.0073             nan     0.2168   -0.0000
  1260        0.0068             nan     0.2168   -0.0001
  1280        0.0064             nan     0.2168   -0.0001
  1300        0.0060             nan     0.2168   -0.0001
  1320        0.0056             nan     0.2168   -0.0001
  1340        0.0053             nan     0.2168   -0.0001
  1360        0.0050             nan     0.2168   -0.0001
  1380        0.0047             nan     0.2168   -0.0001
  1400        0.0044             nan     0.2168   -0.0001
  1420        0.0042             nan     0.2168   -0.0001
  1440        0.0039             nan     0.2168   -0.0000
  1460        0.0036             nan     0.2168   -0.0000
  1480        0.0034             nan     0.2168   -0.0001
  1500        0.0032             nan     0.2168   -0.0001
  1520        0.0030             nan     0.2168   -0.0001
  1540        0.0029             nan     0.2168   -0.0001
  1560        0.0027             nan     0.2168   -0.0000
  1580        0.0025             nan     0.2168   -0.0001
  1600        0.0024             nan     0.2168   -0.0000
  1620        0.0022             nan     0.2168   -0.0000
  1640        0.0021             nan     0.2168   -0.0000
  1660        0.0020             nan     0.2168   -0.0001
  1680        0.0019             nan     0.2168   -0.0000
  1700        0.0018             nan     0.2168   -0.0000
  1720        0.0017             nan     0.2168   -0.0000
  1740        0.0016             nan     0.2168   -0.0000
  1760        0.0015             nan     0.2168   -0.0000
  1780        0.0014             nan     0.2168   -0.0000
  1800        0.0013             nan     0.2168   -0.0000
  1820        0.0012             nan     0.2168   -0.0000
  1840        0.0012             nan     0.2168   -0.0000
  1860        0.0011             nan     0.2168   -0.0000
  1880        0.0010             nan     0.2168   -0.0000
  1900        0.0010             nan     0.2168   -0.0000
  1920        0.0009             nan     0.2168   -0.0000
  1940        0.0009             nan     0.2168   -0.0000
  1960        0.0008             nan     0.2168   -0.0000
  1980        0.0008             nan     0.2168   -0.0000
  2000        0.0007             nan     0.2168   -0.0000
  2020        0.0007             nan     0.2168   -0.0000
  2040        0.0006             nan     0.2168   -0.0000
  2060        0.0006             nan     0.2168   -0.0000
  2080        0.0006             nan     0.2168   -0.0000
  2100        0.0005             nan     0.2168   -0.0000
  2120        0.0005             nan     0.2168   -0.0000
  2140        0.0005             nan     0.2168   -0.0000
  2160        0.0004             nan     0.2168   -0.0000
  2180        0.0004             nan     0.2168   -0.0000
  2200        0.0004             nan     0.2168   -0.0000
  2220        0.0004             nan     0.2168   -0.0000
  2240        0.0004             nan     0.2168   -0.0000
  2260        0.0003             nan     0.2168   -0.0000
  2280        0.0003             nan     0.2168   -0.0000
  2300        0.0003             nan     0.2168   -0.0000
  2320        0.0003             nan     0.2168   -0.0000
  2340        0.0003             nan     0.2168   -0.0000
  2360        0.0003             nan     0.2168   -0.0000
  2380        0.0002             nan     0.2168   -0.0000
  2400        0.0002             nan     0.2168   -0.0000
  2420        0.0002             nan     0.2168   -0.0000
  2440        0.0002             nan     0.2168   -0.0000
  2460        0.0002             nan     0.2168   -0.0000
  2480        0.0002             nan     0.2168   -0.0000
  2500        0.0002             nan     0.2168   -0.0000
  2520        0.0002             nan     0.2168   -0.0000
  2540        0.0002             nan     0.2168   -0.0000
  2560        0.0001             nan     0.2168   -0.0000
  2580        0.0001             nan     0.2168   -0.0000
  2600        0.0001             nan     0.2168   -0.0000
  2620        0.0001             nan     0.2168   -0.0000
  2640        0.0001             nan     0.2168   -0.0000
  2660        0.0001             nan     0.2168   -0.0000
  2680        0.0001             nan     0.2168   -0.0000
  2700        0.0001             nan     0.2168   -0.0000
  2720        0.0001             nan     0.2168   -0.0000
  2740        0.0001             nan     0.2168   -0.0000
  2760        0.0001             nan     0.2168   -0.0000
  2780        0.0001             nan     0.2168   -0.0000
  2800        0.0001             nan     0.2168   -0.0000
  2820        0.0001             nan     0.2168   -0.0000
  2840        0.0001             nan     0.2168   -0.0000
  2860        0.0001             nan     0.2168   -0.0000
  2880        0.0001             nan     0.2168   -0.0000
  2900        0.0001             nan     0.2168   -0.0000
  2920        0.0001             nan     0.2168   -0.0000
  2940        0.0000             nan     0.2168   -0.0000
  2960        0.0000             nan     0.2168   -0.0000
  2980        0.0000             nan     0.2168   -0.0000
  3000        0.0000             nan     0.2168   -0.0000
  3020        0.0000             nan     0.2168   -0.0000
  3040        0.0000             nan     0.2168   -0.0000
  3060        0.0000             nan     0.2168   -0.0000
  3080        0.0000             nan     0.2168   -0.0000
  3100        0.0000             nan     0.2168   -0.0000
  3120        0.0000             nan     0.2168   -0.0000
  3140        0.0000             nan     0.2168   -0.0000
  3160        0.0000             nan     0.2168   -0.0000
  3180        0.0000             nan     0.2168   -0.0000
  3200        0.0000             nan     0.2168   -0.0000
  3220        0.0000             nan     0.2168   -0.0000
  3240        0.0000             nan     0.2168   -0.0000
  3260        0.0000             nan     0.2168   -0.0000
  3280        0.0000             nan     0.2168   -0.0000
  3300        0.0000             nan     0.2168   -0.0000
  3320        0.0000             nan     0.2168   -0.0000
  3340        0.0000             nan     0.2168   -0.0000
  3360        0.0000             nan     0.2168   -0.0000
  3380        0.0000             nan     0.2168   -0.0000
  3400        0.0000             nan     0.2168   -0.0000
  3420        0.0000             nan     0.2168   -0.0000
  3440        0.0000             nan     0.2168   -0.0000
  3460        0.0000             nan     0.2168   -0.0000
  3480        0.0000             nan     0.2168   -0.0000
  3500        0.0000             nan     0.2168   -0.0000
  3520        0.0000             nan     0.2168   -0.0000
  3540        0.0000             nan     0.2168   -0.0000
  3560        0.0000             nan     0.2168   -0.0000
  3580        0.0000             nan     0.2168   -0.0000
  3600        0.0000             nan     0.2168   -0.0000
  3620        0.0000             nan     0.2168   -0.0000
  3640        0.0000             nan     0.2168   -0.0000
  3660        0.0000             nan     0.2168   -0.0000
  3680        0.0000             nan     0.2168   -0.0000
  3700        0.0000             nan     0.2168   -0.0000
  3720        0.0000             nan     0.2168   -0.0000
  3740        0.0000             nan     0.2168   -0.0000
  3760        0.0000             nan     0.2168   -0.0000
  3780        0.0000             nan     0.2168   -0.0000
  3800        0.0000             nan     0.2168   -0.0000
  3820        0.0000             nan     0.2168   -0.0000
  3840        0.0000             nan     0.2168   -0.0000
  3860        0.0000             nan     0.2168   -0.0000
  3880        0.0000             nan     0.2168   -0.0000
  3900        0.0000             nan     0.2168   -0.0000
  3920        0.0000             nan     0.2168   -0.0000
  3940        0.0000             nan     0.2168   -0.0000
  3960        0.0000             nan     0.2168   -0.0000
  3980        0.0000             nan     0.2168   -0.0000
  4000        0.0000             nan     0.2168   -0.0000
  4020        0.0000             nan     0.2168   -0.0000
  4040        0.0000             nan     0.2168   -0.0000
  4060        0.0000             nan     0.2168   -0.0000
  4080        0.0000             nan     0.2168   -0.0000
  4100        0.0000             nan     0.2168   -0.0000
  4120        0.0000             nan     0.2168   -0.0000
  4140        0.0000             nan     0.2168   -0.0000
  4160        0.0000             nan     0.2168   -0.0000
  4180        0.0000             nan     0.2168   -0.0000
  4200        0.0000             nan     0.2168   -0.0000
  4220        0.0000             nan     0.2168   -0.0000
  4240        0.0000             nan     0.2168   -0.0000
  4260        0.0000             nan     0.2168   -0.0000
  4280        0.0000             nan     0.2168   -0.0000
  4300        0.0000             nan     0.2168   -0.0000
  4320        0.0000             nan     0.2168   -0.0000
  4340        0.0000             nan     0.2168   -0.0000
  4360        0.0000             nan     0.2168   -0.0000
  4380        0.0000             nan     0.2168   -0.0000
  4400        0.0000             nan     0.2168   -0.0000
  4420        0.0000             nan     0.2168   -0.0000
  4440        0.0000             nan     0.2168   -0.0000
  4460        0.0000             nan     0.2168   -0.0000
  4480        0.0000             nan     0.2168   -0.0000
  4500        0.0000             nan     0.2168   -0.0000
  4520        0.0000             nan     0.2168   -0.0000
  4540        0.0000             nan     0.2168   -0.0000
  4560        0.0000             nan     0.2168   -0.0000
  4580        0.0000             nan     0.2168   -0.0000
  4600        0.0000             nan     0.2168   -0.0000
  4620        0.0000             nan     0.2168   -0.0000
  4640        0.0000             nan     0.2168   -0.0000
  4660        0.0000             nan     0.2168   -0.0000
  4680        0.0000             nan     0.2168   -0.0000
  4700        0.0000             nan     0.2168   -0.0000
  4720        0.0000             nan     0.2168   -0.0000
  4740        0.0000             nan     0.2168   -0.0000
  4760        0.0000             nan     0.2168   -0.0000
  4780        0.0000             nan     0.2168   -0.0000
  4800        0.0000             nan     0.2168   -0.0000
  4820        0.0000             nan     0.2168   -0.0000
  4840        0.0000             nan     0.2168   -0.0000
  4860        0.0000             nan     0.2168   -0.0000
  4880        0.0000             nan     0.2168   -0.0000
  4898        0.0000             nan     0.2168   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9972             nan     0.2757   -0.0043
     2        0.9608             nan     0.2757   -0.0130
     3        0.9404             nan     0.2757   -0.0379
     4        0.9010             nan     0.2757   -0.0064
     5        0.8765             nan     0.2757   -0.0104
     6        0.8615             nan     0.2757   -0.0279
     7        0.8540             nan     0.2757   -0.0216
     8        0.8347             nan     0.2757   -0.0148
     9        0.8177             nan     0.2757   -0.0171
    10        0.8020             nan     0.2757   -0.0197
    20        0.6527             nan     0.2757   -0.0138
    40        0.4715             nan     0.2757   -0.0176
    60        0.3428             nan     0.2757   -0.0009
    80        0.2474             nan     0.2757   -0.0072
   100        0.1906             nan     0.2757   -0.0057
   120        0.1477             nan     0.2757   -0.0034
   140        0.1153             nan     0.2757   -0.0044
   160        0.0911             nan     0.2757   -0.0028
   180        0.0688             nan     0.2757   -0.0014
   200        0.0531             nan     0.2757   -0.0026
   220        0.0412             nan     0.2757   -0.0005
   240        0.0315             nan     0.2757   -0.0005
   260        0.0248             nan     0.2757   -0.0003
   280        0.0199             nan     0.2757   -0.0006
   300        0.0155             nan     0.2757   -0.0003
   320        0.0119             nan     0.2757   -0.0003
   340        0.0099             nan     0.2757   -0.0002
   360        0.0080             nan     0.2757   -0.0004
   380        0.0064             nan     0.2757   -0.0002
   400        0.0050             nan     0.2757   -0.0002
   420        0.0039             nan     0.2757   -0.0001
   440        0.0031             nan     0.2757   -0.0001
   460        0.0023             nan     0.2757   -0.0001
   480        0.0019             nan     0.2757   -0.0001
   500        0.0014             nan     0.2757   -0.0001
   520        0.0011             nan     0.2757   -0.0001
   540        0.0008             nan     0.2757   -0.0000
   560        0.0007             nan     0.2757   -0.0000
   580        0.0005             nan     0.2757   -0.0000
   600        0.0004             nan     0.2757   -0.0000
   620        0.0003             nan     0.2757   -0.0000
   640        0.0003             nan     0.2757   -0.0000
   660        0.0002             nan     0.2757   -0.0000
   680        0.0002             nan     0.2757   -0.0000
   700        0.0001             nan     0.2757   -0.0000
   720        0.0001             nan     0.2757   -0.0000
   740        0.0001             nan     0.2757   -0.0000
   760        0.0001             nan     0.2757   -0.0000
   780        0.0001             nan     0.2757   -0.0000
   800        0.0000             nan     0.2757   -0.0000
   820        0.0000             nan     0.2757   -0.0000
   840        0.0000             nan     0.2757   -0.0000
   860        0.0000             nan     0.2757   -0.0000
   880        0.0000             nan     0.2757   -0.0000
   900        0.0000             nan     0.2757   -0.0000
   920        0.0000             nan     0.2757   -0.0000
   940        0.0000             nan     0.2757   -0.0000
   960        0.0000             nan     0.2757   -0.0000
   980        0.0000             nan     0.2757   -0.0000
  1000        0.0000             nan     0.2757   -0.0000
  1020        0.0000             nan     0.2757   -0.0000
  1040        0.0000             nan     0.2757   -0.0000
  1060        0.0000             nan     0.2757   -0.0000
  1080        0.0000             nan     0.2757   -0.0000
  1100        0.0000             nan     0.2757   -0.0000
  1120        0.0000             nan     0.2757   -0.0000
  1140        0.0000             nan     0.2757   -0.0000
  1160        0.0000             nan     0.2757   -0.0000
  1180        0.0000             nan     0.2757   -0.0000
  1200        0.0000             nan     0.2757   -0.0000
  1220        0.0000             nan     0.2757   -0.0000
  1240        0.0000             nan     0.2757   -0.0000
  1260        0.0000             nan     0.2757   -0.0000
  1280        0.0000             nan     0.2757   -0.0000
  1300        0.0000             nan     0.2757   -0.0000
  1320        0.0000             nan     0.2757   -0.0000
  1340        0.0000             nan     0.2757   -0.0000
  1360        0.0000             nan     0.2757   -0.0000
  1380        0.0000             nan     0.2757   -0.0000
  1400        0.0000             nan     0.2757   -0.0000
  1420        0.0000             nan     0.2757   -0.0000
  1440        0.0000             nan     0.2757   -0.0000
  1460        0.0000             nan     0.2757   -0.0000
  1480        0.0000             nan     0.2757   -0.0000
  1500        0.0000             nan     0.2757   -0.0000
  1520        0.0000             nan     0.2757   -0.0000
  1540        0.0000             nan     0.2757   -0.0000
  1560        0.0000             nan     0.2757   -0.0000
  1580        0.0000             nan     0.2757   -0.0000
  1600        0.0000             nan     0.2757   -0.0000
  1620        0.0000             nan     0.2757   -0.0000
  1640        0.0000             nan     0.2757   -0.0000
  1660        0.0000             nan     0.2757   -0.0000
  1680        0.0000             nan     0.2757   -0.0000
  1700        0.0000             nan     0.2757   -0.0000
  1720        0.0000             nan     0.2757   -0.0000
  1740        0.0000             nan     0.2757   -0.0000
  1760        0.0000             nan     0.2757   -0.0000
  1780        0.0000             nan     0.2757   -0.0000
  1800        0.0000             nan     0.2757   -0.0000
  1820        0.0000             nan     0.2757   -0.0000
  1840        0.0000             nan     0.2757   -0.0000
  1860        0.0000             nan     0.2757   -0.0000
  1880        0.0000             nan     0.2757   -0.0000
  1900        0.0000             nan     0.2757   -0.0000
  1920        0.0000             nan     0.2757   -0.0000
  1940        0.0000             nan     0.2757   -0.0000
  1960        0.0000             nan     0.2757   -0.0000
  1980        0.0000             nan     0.2757   -0.0000
  2000        0.0000             nan     0.2757   -0.0000
  2020        0.0000             nan     0.2757   -0.0000
  2040        0.0000             nan     0.2757   -0.0000
  2060        0.0000             nan     0.2757   -0.0000
  2080        0.0000             nan     0.2757   -0.0000
  2100        0.0000             nan     0.2757   -0.0000
  2120        0.0000             nan     0.2757   -0.0000
  2140        0.0000             nan     0.2757   -0.0000
  2160        0.0000             nan     0.2757   -0.0000
  2180        0.0000             nan     0.2757   -0.0000
  2200        0.0000             nan     0.2757   -0.0000
  2220        0.0000             nan     0.2757   -0.0000
  2240        0.0000             nan     0.2757   -0.0000
  2260        0.0000             nan     0.2757   -0.0000
  2280        0.0000             nan     0.2757   -0.0000
  2300        0.0000             nan     0.2757   -0.0000
  2320        0.0000             nan     0.2757   -0.0000
  2340        0.0000             nan     0.2757   -0.0000
  2360        0.0000             nan     0.2757   -0.0000
  2380        0.0000             nan     0.2757   -0.0000
  2400        0.0000             nan     0.2757   -0.0000
  2420        0.0000             nan     0.2757   -0.0000
  2440        0.0000             nan     0.2757   -0.0000
  2460        0.0000             nan     0.2757   -0.0000
  2480        0.0000             nan     0.2757   -0.0000
  2500        0.0000             nan     0.2757   -0.0000
  2520        0.0000             nan     0.2757   -0.0000
  2527        0.0000             nan     0.2757   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9950             nan     0.2956   -0.0417
     2        0.9501             nan     0.2956   -0.0207
     3        0.9328             nan     0.2956   -0.0196
     4        0.9126             nan     0.2956   -0.0245
     5        0.8889             nan     0.2956   -0.0101
     6        0.8731             nan     0.2956   -0.0206
     7        0.8561             nan     0.2956   -0.0180
     8        0.8331             nan     0.2956   -0.0228
     9        0.8288             nan     0.2956   -0.0398
    10        0.8085             nan     0.2956   -0.0054
    20        0.6620             nan     0.2956   -0.0096
    40        0.4741             nan     0.2956   -0.0167
    60        0.3606             nan     0.2956   -0.0058
    80        0.2643             nan     0.2956   -0.0092
   100        0.1975             nan     0.2956   -0.0041
   120        0.1531             nan     0.2956   -0.0063
   140        0.1175             nan     0.2956   -0.0048
   160        0.0894             nan     0.2956   -0.0018
   180        0.0693             nan     0.2956   -0.0025
   200        0.0537             nan     0.2956   -0.0012
   220        0.0419             nan     0.2956   -0.0018
   240        0.0325             nan     0.2956   -0.0011
   260        0.0256             nan     0.2956   -0.0008
   280        0.0202             nan     0.2956   -0.0005
   300        0.0156             nan     0.2956   -0.0008
   320        0.0122             nan     0.2956   -0.0005
   340        0.0097             nan     0.2956   -0.0002
   360        0.0078             nan     0.2956   -0.0003
   380        0.0062             nan     0.2956   -0.0001
   400        0.0049             nan     0.2956   -0.0002
   420        0.0038             nan     0.2956   -0.0001
   440        0.0031             nan     0.2956   -0.0001
   460        0.0025             nan     0.2956   -0.0001
   480        0.0020             nan     0.2956   -0.0001
   500        0.0017             nan     0.2956   -0.0000
   520        0.0013             nan     0.2956   -0.0000
   540        0.0011             nan     0.2956   -0.0001
   560        0.0009             nan     0.2956   -0.0000
   580        0.0007             nan     0.2956   -0.0000
   600        0.0006             nan     0.2956   -0.0000
   620        0.0005             nan     0.2956   -0.0000
   640        0.0004             nan     0.2956   -0.0000
   660        0.0003             nan     0.2956   -0.0000
   680        0.0002             nan     0.2956   -0.0000
   700        0.0002             nan     0.2956   -0.0000
   720        0.0002             nan     0.2956   -0.0000
   740        0.0001             nan     0.2956   -0.0000
   760        0.0001             nan     0.2956   -0.0000
   780        0.0001             nan     0.2956   -0.0000
   800        0.0001             nan     0.2956   -0.0000
   820        0.0001             nan     0.2956   -0.0000
   840        0.0000             nan     0.2956   -0.0000
   860        0.0000             nan     0.2956   -0.0000
   880        0.0000             nan     0.2956   -0.0000
   900        0.0000             nan     0.2956   -0.0000
   920        0.0000             nan     0.2956   -0.0000
   940        0.0000             nan     0.2956   -0.0000
   960        0.0000             nan     0.2956   -0.0000
   980        0.0000             nan     0.2956   -0.0000
  1000        0.0000             nan     0.2956   -0.0000
  1020        0.0000             nan     0.2956   -0.0000
  1040        0.0000             nan     0.2956   -0.0000
  1060        0.0000             nan     0.2956   -0.0000
  1080        0.0000             nan     0.2956   -0.0000
  1100        0.0000             nan     0.2956   -0.0000
  1120        0.0000             nan     0.2956   -0.0000
  1140        0.0000             nan     0.2956   -0.0000
  1160        0.0000             nan     0.2956   -0.0000
  1180        0.0000             nan     0.2956   -0.0000
  1200        0.0000             nan     0.2956   -0.0000
  1220        0.0000             nan     0.2956   -0.0000
  1240        0.0000             nan     0.2956   -0.0000
  1260        0.0000             nan     0.2956   -0.0000
  1280        0.0000             nan     0.2956   -0.0000
  1300        0.0000             nan     0.2956   -0.0000
  1320        0.0000             nan     0.2956   -0.0000
  1340        0.0000             nan     0.2956   -0.0000
  1360        0.0000             nan     0.2956   -0.0000
  1380        0.0000             nan     0.2956   -0.0000
  1400        0.0000             nan     0.2956   -0.0000
  1420        0.0000             nan     0.2956   -0.0000
  1440        0.0000             nan     0.2956   -0.0000
  1460        0.0000             nan     0.2956   -0.0000
  1480        0.0000             nan     0.2956   -0.0000
  1500        0.0000             nan     0.2956   -0.0000
  1520        0.0000             nan     0.2956   -0.0000
  1540        0.0000             nan     0.2956   -0.0000
  1560        0.0000             nan     0.2956   -0.0000
  1580        0.0000             nan     0.2956   -0.0000
  1600        0.0000             nan     0.2956   -0.0000
  1620        0.0000             nan     0.2956   -0.0000
  1640        0.0000             nan     0.2956   -0.0000
  1660        0.0000             nan     0.2956   -0.0000
  1680        0.0000             nan     0.2956   -0.0000
  1700        0.0000             nan     0.2956   -0.0000
  1720        0.0000             nan     0.2956   -0.0000
  1740        0.0000             nan     0.2956   -0.0000
  1760        0.0000             nan     0.2956   -0.0000
  1780        0.0000             nan     0.2956   -0.0000
  1800        0.0000             nan     0.2956   -0.0000
  1820        0.0000             nan     0.2956   -0.0000
  1840        0.0000             nan     0.2956   -0.0000
  1860        0.0000             nan     0.2956   -0.0000
  1880        0.0000             nan     0.2956   -0.0000
  1900        0.0000             nan     0.2956   -0.0000
  1920        0.0000             nan     0.2956   -0.0000
  1940        0.0000             nan     0.2956   -0.0000
  1960        0.0000             nan     0.2956    0.0000
  1980        0.0000             nan     0.2956   -0.0000
  2000        0.0000             nan     0.2956   -0.0000
  2020        0.0000             nan     0.2956   -0.0000
  2040        0.0000             nan     0.2956   -0.0000
  2060        0.0000             nan     0.2956   -0.0000
  2080        0.0000             nan     0.2956   -0.0000
  2100        0.0000             nan     0.2956   -0.0000
  2120        0.0000             nan     0.2956   -0.0000
  2140        0.0000             nan     0.2956   -0.0000
  2160        0.0000             nan     0.2956   -0.0000
  2180        0.0000             nan     0.2956   -0.0000
  2200        0.0000             nan     0.2956   -0.0000
  2220        0.0000             nan     0.2956   -0.0000
  2240        0.0000             nan     0.2956   -0.0000
  2260        0.0000             nan     0.2956   -0.0000
  2280        0.0000             nan     0.2956   -0.0000
  2300        0.0000             nan     0.2956   -0.0000
  2320        0.0000             nan     0.2956   -0.0000
  2340        0.0000             nan     0.2956   -0.0000
  2360        0.0000             nan     0.2956   -0.0000
  2380        0.0000             nan     0.2956    0.0000
  2400        0.0000             nan     0.2956   -0.0000
  2420        0.0000             nan     0.2956   -0.0000
  2440        0.0000             nan     0.2956   -0.0000
  2460        0.0000             nan     0.2956   -0.0000
  2480        0.0000             nan     0.2956   -0.0000
  2500        0.0000             nan     0.2956   -0.0000
  2520        0.0000             nan     0.2956   -0.0000
  2540        0.0000             nan     0.2956   -0.0000
  2560        0.0000             nan     0.2956   -0.0000
  2580        0.0000             nan     0.2956   -0.0000
  2600        0.0000             nan     0.2956   -0.0000
  2620        0.0000             nan     0.2956   -0.0000
  2640        0.0000             nan     0.2956   -0.0000
  2660        0.0000             nan     0.2956   -0.0000
  2680        0.0000             nan     0.2956   -0.0000
  2700        0.0000             nan     0.2956   -0.0000
  2720        0.0000             nan     0.2956   -0.0000
  2740        0.0000             nan     0.2956   -0.0000
  2760        0.0000             nan     0.2956   -0.0000
  2780        0.0000             nan     0.2956   -0.0000
  2800        0.0000             nan     0.2956   -0.0000
  2820        0.0000             nan     0.2956   -0.0000
  2840        0.0000             nan     0.2956   -0.0000
  2860        0.0000             nan     0.2956   -0.0000
  2880        0.0000             nan     0.2956   -0.0000
  2900        0.0000             nan     0.2956   -0.0000
  2920        0.0000             nan     0.2956   -0.0000
  2940        0.0000             nan     0.2956   -0.0000
  2960        0.0000             nan     0.2956   -0.0000
  2980        0.0000             nan     0.2956   -0.0000
  3000        0.0000             nan     0.2956   -0.0000
  3020        0.0000             nan     0.2956   -0.0000
  3040        0.0000             nan     0.2956    0.0000
  3060        0.0000             nan     0.2956   -0.0000
  3080        0.0000             nan     0.2956   -0.0000
  3100        0.0000             nan     0.2956   -0.0000
  3120        0.0000             nan     0.2956   -0.0000
  3140        0.0000             nan     0.2956   -0.0000
  3160        0.0000             nan     0.2956   -0.0000
  3180        0.0000             nan     0.2956   -0.0000
  3200        0.0000             nan     0.2956   -0.0000
  3220        0.0000             nan     0.2956   -0.0000
  3240        0.0000             nan     0.2956   -0.0000
  3260        0.0000             nan     0.2956   -0.0000
  3280        0.0000             nan     0.2956   -0.0000
  3300        0.0000             nan     0.2956   -0.0000
  3320        0.0000             nan     0.2956   -0.0000
  3340        0.0000             nan     0.2956   -0.0000
  3360        0.0000             nan     0.2956   -0.0000
  3380        0.0000             nan     0.2956   -0.0000
  3400        0.0000             nan     0.2956   -0.0000
  3420        0.0000             nan     0.2956   -0.0000
  3440        0.0000             nan     0.2956   -0.0000
  3460        0.0000             nan     0.2956   -0.0000
  3480        0.0000             nan     0.2956   -0.0000
  3500        0.0000             nan     0.2956   -0.0000
  3520        0.0000             nan     0.2956   -0.0000
  3527        0.0000             nan     0.2956   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9965             nan     0.2958   -0.0261
     2        0.9688             nan     0.2958   -0.0194
     3        0.9395             nan     0.2958   -0.0126
     4        0.9057             nan     0.2958   -0.0164
     5        0.8732             nan     0.2958   -0.0255
     6        0.8484             nan     0.2958   -0.0014
     7        0.8265             nan     0.2958   -0.0251
     8        0.8059             nan     0.2958   -0.0276
     9        0.7893             nan     0.2958   -0.0379
    10        0.7756             nan     0.2958   -0.0121
    20        0.6271             nan     0.2958   -0.0211
    40        0.4336             nan     0.2958   -0.0264
    60        0.3118             nan     0.2958   -0.0152
    80        0.2287             nan     0.2958   -0.0120
   100        0.1678             nan     0.2958   -0.0046
   120        0.1229             nan     0.2958   -0.0034
   140        0.0927             nan     0.2958   -0.0039
   160        0.0674             nan     0.2958   -0.0033
   180        0.0499             nan     0.2958   -0.0022
   200        0.0369             nan     0.2958   -0.0019
   220        0.0287             nan     0.2958   -0.0010
   240        0.0208             nan     0.2958   -0.0004
   260        0.0162             nan     0.2958   -0.0007
   280        0.0123             nan     0.2958   -0.0004
   300        0.0091             nan     0.2958   -0.0006
   320        0.0068             nan     0.2958   -0.0003
   340        0.0053             nan     0.2958   -0.0002
   360        0.0042             nan     0.2958   -0.0002
   380        0.0033             nan     0.2958   -0.0001
   400        0.0026             nan     0.2958   -0.0001
   420        0.0020             nan     0.2958   -0.0001
   440        0.0015             nan     0.2958   -0.0000
   460        0.0012             nan     0.2958   -0.0001
   480        0.0009             nan     0.2958   -0.0000
   500        0.0008             nan     0.2958   -0.0000
   520        0.0006             nan     0.2958   -0.0000
   540        0.0005             nan     0.2958   -0.0000
   560        0.0004             nan     0.2958   -0.0000
   580        0.0003             nan     0.2958   -0.0000
   600        0.0002             nan     0.2958   -0.0000
   620        0.0002             nan     0.2958   -0.0000
   640        0.0001             nan     0.2958   -0.0000
   660        0.0001             nan     0.2958   -0.0000
   680        0.0001             nan     0.2958   -0.0000
   700        0.0001             nan     0.2958   -0.0000
   720        0.0001             nan     0.2958   -0.0000
   740        0.0000             nan     0.2958   -0.0000
   760        0.0000             nan     0.2958   -0.0000
   780        0.0000             nan     0.2958   -0.0000
   800        0.0000             nan     0.2958   -0.0000
   820        0.0000             nan     0.2958   -0.0000
   840        0.0000             nan     0.2958   -0.0000
   860        0.0000             nan     0.2958   -0.0000
   880        0.0000             nan     0.2958   -0.0000
   900        0.0000             nan     0.2958   -0.0000
   920        0.0000             nan     0.2958   -0.0000
   940        0.0000             nan     0.2958   -0.0000
   960        0.0000             nan     0.2958   -0.0000
   980        0.0000             nan     0.2958   -0.0000
  1000        0.0000             nan     0.2958   -0.0000
  1020        0.0000             nan     0.2958   -0.0000
  1040        0.0000             nan     0.2958   -0.0000
  1060        0.0000             nan     0.2958   -0.0000
  1080        0.0000             nan     0.2958   -0.0000
  1100        0.0000             nan     0.2958   -0.0000
  1120        0.0000             nan     0.2958   -0.0000
  1140        0.0000             nan     0.2958   -0.0000
  1160        0.0000             nan     0.2958   -0.0000
  1180        0.0000             nan     0.2958   -0.0000
  1200        0.0000             nan     0.2958   -0.0000
  1220        0.0000             nan     0.2958   -0.0000
  1240        0.0000             nan     0.2958   -0.0000
  1260        0.0000             nan     0.2958   -0.0000
  1280        0.0000             nan     0.2958   -0.0000
  1300        0.0000             nan     0.2958   -0.0000
  1320        0.0000             nan     0.2958   -0.0000
  1340        0.0000             nan     0.2958   -0.0000
  1360        0.0000             nan     0.2958   -0.0000
  1380        0.0000             nan     0.2958   -0.0000
  1400        0.0000             nan     0.2958   -0.0000
  1420        0.0000             nan     0.2958   -0.0000
  1440        0.0000             nan     0.2958   -0.0000
  1460        0.0000             nan     0.2958   -0.0000
  1480        0.0000             nan     0.2958   -0.0000
  1500        0.0000             nan     0.2958   -0.0000
  1520        0.0000             nan     0.2958   -0.0000
  1540        0.0000             nan     0.2958   -0.0000
  1560        0.0000             nan     0.2958   -0.0000
  1580        0.0000             nan     0.2958   -0.0000
  1600        0.0000             nan     0.2958   -0.0000
  1620        0.0000             nan     0.2958   -0.0000
  1640        0.0000             nan     0.2958   -0.0000
  1660        0.0000             nan     0.2958   -0.0000
  1680        0.0000             nan     0.2958   -0.0000
  1700        0.0000             nan     0.2958   -0.0000
  1720        0.0000             nan     0.2958   -0.0000
  1740        0.0000             nan     0.2958   -0.0000
  1760        0.0000             nan     0.2958   -0.0000
  1780        0.0000             nan     0.2958   -0.0000
  1800        0.0000             nan     0.2958   -0.0000
  1820        0.0000             nan     0.2958   -0.0000
  1840        0.0000             nan     0.2958   -0.0000
  1860        0.0000             nan     0.2958   -0.0000
  1880        0.0000             nan     0.2958   -0.0000
  1900        0.0000             nan     0.2958   -0.0000
  1920        0.0000             nan     0.2958   -0.0000
  1940        0.0000             nan     0.2958   -0.0000
  1960        0.0000             nan     0.2958   -0.0000
  1980        0.0000             nan     0.2958   -0.0000
  1985        0.0000             nan     0.2958   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9932             nan     0.3117   -0.0250
     2        0.9545             nan     0.3117   -0.0385
     3        0.9093             nan     0.3117   -0.0191
     4        0.8728             nan     0.3117   -0.0071
     5        0.8479             nan     0.3117   -0.0156
     6        0.8250             nan     0.3117   -0.0175
     7        0.7982             nan     0.3117   -0.0181
     8        0.7789             nan     0.3117   -0.0332
     9        0.7542             nan     0.3117   -0.0305
    10        0.7191             nan     0.3117   -0.0089
    20        0.5339             nan     0.3117   -0.0156
    40        0.3353             nan     0.3117   -0.0128
    60        0.2164             nan     0.3117   -0.0089
    80        0.1411             nan     0.3117   -0.0045
   100        0.0894             nan     0.3117   -0.0032
   120        0.0638             nan     0.3117   -0.0049
   140        0.0389             nan     0.3117   -0.0010
   160        0.0262             nan     0.3117   -0.0010
   180        0.0174             nan     0.3117   -0.0008
   200        0.0113             nan     0.3117   -0.0004
   220        0.0077             nan     0.3117   -0.0002
   240        0.0056             nan     0.3117   -0.0002
   260        0.0039             nan     0.3117   -0.0002
   280        0.0025             nan     0.3117   -0.0001
   300        0.0017             nan     0.3117   -0.0001
   320        0.0012             nan     0.3117   -0.0000
   340        0.0008             nan     0.3117   -0.0000
   360        0.0006             nan     0.3117   -0.0000
   380        0.0005             nan     0.3117   -0.0000
   400        0.0003             nan     0.3117   -0.0000
   420        0.0002             nan     0.3117   -0.0000
   440        0.0001             nan     0.3117   -0.0000
   460        0.0001             nan     0.3117   -0.0000
   480        0.0001             nan     0.3117   -0.0000
   500        0.0001             nan     0.3117   -0.0000
   520        0.0000             nan     0.3117   -0.0000
   540        0.0000             nan     0.3117   -0.0000
   560        0.0000             nan     0.3117   -0.0000
   580        0.0000             nan     0.3117   -0.0000
   600        0.0000             nan     0.3117   -0.0000
   620        0.0000             nan     0.3117   -0.0000
   640        0.0000             nan     0.3117   -0.0000
   660        0.0000             nan     0.3117   -0.0000
   680        0.0000             nan     0.3117   -0.0000
   700        0.0000             nan     0.3117   -0.0000
   720        0.0000             nan     0.3117   -0.0000
   740        0.0000             nan     0.3117   -0.0000
   760        0.0000             nan     0.3117   -0.0000
   780        0.0000             nan     0.3117   -0.0000
   800        0.0000             nan     0.3117   -0.0000
   820        0.0000             nan     0.3117   -0.0000
   840        0.0000             nan     0.3117   -0.0000
   860        0.0000             nan     0.3117   -0.0000
   880        0.0000             nan     0.3117   -0.0000
   900        0.0000             nan     0.3117   -0.0000
   920        0.0000             nan     0.3117   -0.0000
   940        0.0000             nan     0.3117   -0.0000
   960        0.0000             nan     0.3117   -0.0000
   980        0.0000             nan     0.3117   -0.0000
  1000        0.0000             nan     0.3117   -0.0000
  1020        0.0000             nan     0.3117   -0.0000
  1040        0.0000             nan     0.3117   -0.0000
  1060        0.0000             nan     0.3117   -0.0000
  1080        0.0000             nan     0.3117   -0.0000
  1100        0.0000             nan     0.3117   -0.0000
  1120        0.0000             nan     0.3117   -0.0000
  1140        0.0000             nan     0.3117   -0.0000
  1160        0.0000             nan     0.3117   -0.0000
  1180        0.0000             nan     0.3117   -0.0000
  1200        0.0000             nan     0.3117   -0.0000
  1220        0.0000             nan     0.3117   -0.0000
  1240        0.0000             nan     0.3117   -0.0000
  1260        0.0000             nan     0.3117   -0.0000
  1280        0.0000             nan     0.3117   -0.0000
  1300        0.0000             nan     0.3117   -0.0000
  1320        0.0000             nan     0.3117   -0.0000
  1340        0.0000             nan     0.3117   -0.0000
  1360        0.0000             nan     0.3117   -0.0000
  1380        0.0000             nan     0.3117   -0.0000
  1400        0.0000             nan     0.3117    0.0000
  1420        0.0000             nan     0.3117   -0.0000
  1440        0.0000             nan     0.3117   -0.0000
  1460        0.0000             nan     0.3117   -0.0000
  1480        0.0000             nan     0.3117   -0.0000
  1500        0.0000             nan     0.3117   -0.0000
  1520        0.0000             nan     0.3117   -0.0000
  1540        0.0000             nan     0.3117    0.0000
  1560        0.0000             nan     0.3117   -0.0000
  1580        0.0000             nan     0.3117   -0.0000
  1600        0.0000             nan     0.3117   -0.0000
  1620        0.0000             nan     0.3117   -0.0000
  1640        0.0000             nan     0.3117   -0.0000
  1660        0.0000             nan     0.3117   -0.0000
  1680        0.0000             nan     0.3117   -0.0000
  1700        0.0000             nan     0.3117   -0.0000
  1720        0.0000             nan     0.3117   -0.0000
  1740        0.0000             nan     0.3117   -0.0000
  1760        0.0000             nan     0.3117   -0.0000
  1780        0.0000             nan     0.3117   -0.0000
  1800        0.0000             nan     0.3117   -0.0000
  1820        0.0000             nan     0.3117   -0.0000
  1840        0.0000             nan     0.3117   -0.0000
  1860        0.0000             nan     0.3117   -0.0000
  1880        0.0000             nan     0.3117   -0.0000
  1900        0.0000             nan     0.3117   -0.0000
  1920        0.0000             nan     0.3117   -0.0000
  1940        0.0000             nan     0.3117   -0.0000
  1960        0.0000             nan     0.3117   -0.0000
  1980        0.0000             nan     0.3117   -0.0000
  2000        0.0000             nan     0.3117   -0.0000
  2020        0.0000             nan     0.3117   -0.0000
  2040        0.0000             nan     0.3117   -0.0000
  2060        0.0000             nan     0.3117   -0.0000
  2080        0.0000             nan     0.3117   -0.0000
  2100        0.0000             nan     0.3117   -0.0000
  2120        0.0000             nan     0.3117   -0.0000
  2140        0.0000             nan     0.3117   -0.0000
  2160        0.0000             nan     0.3117   -0.0000
  2180        0.0000             nan     0.3117   -0.0000
  2200        0.0000             nan     0.3117   -0.0000
  2220        0.0000             nan     0.3117   -0.0000
  2240        0.0000             nan     0.3117   -0.0000
  2260        0.0000             nan     0.3117   -0.0000
  2280        0.0000             nan     0.3117    0.0000
  2300        0.0000             nan     0.3117   -0.0000
  2320        0.0000             nan     0.3117   -0.0000
  2340        0.0000             nan     0.3117   -0.0000
  2360        0.0000             nan     0.3117    0.0000
  2380        0.0000             nan     0.3117   -0.0000
  2400        0.0000             nan     0.3117   -0.0000
  2420        0.0000             nan     0.3117   -0.0000
  2440        0.0000             nan     0.3117   -0.0000
  2460        0.0000             nan     0.3117   -0.0000
  2480        0.0000             nan     0.3117   -0.0000
  2500        0.0000             nan     0.3117   -0.0000
  2520        0.0000             nan     0.3117   -0.0000
  2540        0.0000             nan     0.3117   -0.0000
  2560        0.0000             nan     0.3117   -0.0000
  2580        0.0000             nan     0.3117   -0.0000
  2600        0.0000             nan     0.3117   -0.0000
  2620        0.0000             nan     0.3117   -0.0000
  2640        0.0000             nan     0.3117   -0.0000
  2642        0.0000             nan     0.3117   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9804             nan     0.3640   -0.0233
     2        0.9437             nan     0.3640   -0.0112
     3        0.9104             nan     0.3640   -0.0236
     4        0.8802             nan     0.3640   -0.0211
     5        0.8341             nan     0.3640   -0.0174
     6        0.8050             nan     0.3640   -0.0168
     7        0.7791             nan     0.3640   -0.0450
     8        0.7504             nan     0.3640   -0.0120
     9        0.7210             nan     0.3640   -0.0183
    10        0.6991             nan     0.3640   -0.0156
    20        0.5435             nan     0.3640   -0.0334
    40        0.3408             nan     0.3640   -0.0154
    60        0.2126             nan     0.3640   -0.0075
    80        0.1415             nan     0.3640   -0.0090
   100        0.0925             nan     0.3640   -0.0037
   120        0.0617             nan     0.3640   -0.0026
   140        0.0420             nan     0.3640   -0.0026
   160        0.0279             nan     0.3640   -0.0017
   180        0.0198             nan     0.3640   -0.0010
   200        0.0136             nan     0.3640   -0.0003
   220        0.0091             nan     0.3640   -0.0006
   240        0.0061             nan     0.3640   -0.0002
   260        0.0044             nan     0.3640   -0.0002
   280        0.0031             nan     0.3640   -0.0001
   300        0.0021             nan     0.3640   -0.0001
   320        0.0015             nan     0.3640   -0.0000
   340        0.0010             nan     0.3640   -0.0000
   360        0.0007             nan     0.3640   -0.0000
   380        0.0005             nan     0.3640   -0.0000
   400        0.0004             nan     0.3640   -0.0000
   420        0.0003             nan     0.3640   -0.0000
   440        0.0002             nan     0.3640   -0.0000
   460        0.0001             nan     0.3640   -0.0000
   480        0.0001             nan     0.3640   -0.0000
   500        0.0001             nan     0.3640   -0.0000
   520        0.0000             nan     0.3640   -0.0000
   540        0.0000             nan     0.3640   -0.0000
   560        0.0000             nan     0.3640   -0.0000
   580        0.0000             nan     0.3640   -0.0000
   600        0.0000             nan     0.3640   -0.0000
   620        0.0000             nan     0.3640   -0.0000
   640        0.0000             nan     0.3640   -0.0000
   660        0.0000             nan     0.3640   -0.0000
   680        0.0000             nan     0.3640   -0.0000
   700        0.0000             nan     0.3640   -0.0000
   720        0.0000             nan     0.3640   -0.0000
   740        0.0000             nan     0.3640   -0.0000
   760        0.0000             nan     0.3640   -0.0000
   780        0.0000             nan     0.3640   -0.0000
   800        0.0000             nan     0.3640   -0.0000
   820        0.0000             nan     0.3640   -0.0000
   840        0.0000             nan     0.3640   -0.0000
   860        0.0000             nan     0.3640   -0.0000
   880        0.0000             nan     0.3640   -0.0000
   900        0.0000             nan     0.3640   -0.0000
   920        0.0000             nan     0.3640   -0.0000
   940        0.0000             nan     0.3640   -0.0000
   960        0.0000             nan     0.3640   -0.0000
   980        0.0000             nan     0.3640   -0.0000
  1000        0.0000             nan     0.3640   -0.0000
  1020        0.0000             nan     0.3640   -0.0000
  1040        0.0000             nan     0.3640   -0.0000
  1060        0.0000             nan     0.3640   -0.0000
  1080        0.0000             nan     0.3640   -0.0000
  1100        0.0000             nan     0.3640   -0.0000
  1120        0.0000             nan     0.3640   -0.0000
  1140        0.0000             nan     0.3640   -0.0000
  1160        0.0000             nan     0.3640   -0.0000
  1180        0.0000             nan     0.3640   -0.0000
  1200        0.0000             nan     0.3640   -0.0000
  1220        0.0000             nan     0.3640   -0.0000
  1240        0.0000             nan     0.3640   -0.0000
  1260        0.0000             nan     0.3640   -0.0000
  1280        0.0000             nan     0.3640   -0.0000
  1300        0.0000             nan     0.3640   -0.0000
  1320        0.0000             nan     0.3640   -0.0000
  1340        0.0000             nan     0.3640   -0.0000
  1360        0.0000             nan     0.3640   -0.0000
  1380        0.0000             nan     0.3640   -0.0000
  1400        0.0000             nan     0.3640   -0.0000
  1420        0.0000             nan     0.3640   -0.0000
  1440        0.0000             nan     0.3640   -0.0000
  1460        0.0000             nan     0.3640   -0.0000
  1480        0.0000             nan     0.3640   -0.0000
  1500        0.0000             nan     0.3640   -0.0000
  1520        0.0000             nan     0.3640   -0.0000
  1540        0.0000             nan     0.3640   -0.0000
  1560        0.0000             nan     0.3640   -0.0000
  1580        0.0000             nan     0.3640   -0.0000
  1587        0.0000             nan     0.3640   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0168             nan     0.3688    0.0003
     2        1.0110             nan     0.3688   -0.0137
     3        1.0044             nan     0.3688   -0.0144
     4        1.0021             nan     0.3688   -0.0178
     5        0.9996             nan     0.3688   -0.0198
     6        0.9879             nan     0.3688   -0.0069
     7        0.9768             nan     0.3688    0.0000
     8        0.9694             nan     0.3688   -0.0076
     9        0.9536             nan     0.3688   -0.0084
    10        0.9480             nan     0.3688   -0.0013
    20        0.8994             nan     0.3688   -0.0143
    40        0.8535             nan     0.3688   -0.0136
    60        0.8147             nan     0.3688   -0.0152
    80        0.7769             nan     0.3688   -0.0178
   100        0.7387             nan     0.3688   -0.0086
   120        0.7292             nan     0.3688   -0.0107
   140        0.6994             nan     0.3688   -0.0073
   160        0.6695             nan     0.3688   -0.0120
   180        0.6488             nan     0.3688   -0.0142
   200        0.6224             nan     0.3688   -0.0069
   220        0.6046             nan     0.3688   -0.0049
   240        0.5851             nan     0.3688   -0.0014
   260        0.5762             nan     0.3688   -0.0063
   280        0.5552             nan     0.3688   -0.0089
   300        0.5370             nan     0.3688   -0.0058
   320        0.5158             nan     0.3688   -0.0036
   340        0.5014             nan     0.3688   -0.0116
   360        0.4860             nan     0.3688   -0.0130
   380        0.4710             nan     0.3688   -0.0109
   400        0.4606             nan     0.3688   -0.0092
   420        0.4501             nan     0.3688   -0.0025
   440        0.4394             nan     0.3688   -0.0078
   460        0.4317             nan     0.3688   -0.0071
   480        0.4209             nan     0.3688   -0.0059
   500        0.4182             nan     0.3688   -0.0089
   520        0.4097             nan     0.3688   -0.0106
   540        0.3937             nan     0.3688   -0.0031
   560        0.3868             nan     0.3688   -0.0046
   580        0.3831             nan     0.3688   -0.0053
   600        0.3715             nan     0.3688   -0.0053
   620        0.3651             nan     0.3688   -0.0018
   640        0.3566             nan     0.3688   -0.0056
   660        0.3506             nan     0.3688   -0.0021
   680        0.3454             nan     0.3688   -0.0078
   700        0.3399             nan     0.3688   -0.0017
   720        0.3369             nan     0.3688   -0.0043
   740        0.3319             nan     0.3688   -0.0063
   760        0.3210             nan     0.3688   -0.0049
   780        0.3157             nan     0.3688   -0.0052
   800        0.3086             nan     0.3688   -0.0027
   820        0.3008             nan     0.3688   -0.0050
   840        0.2947             nan     0.3688   -0.0088
   860        0.2837             nan     0.3688   -0.0064
   880        0.2807             nan     0.3688   -0.0040
   900        0.2732             nan     0.3688   -0.0039
   920        0.2631             nan     0.3688   -0.0022
   940        0.2607             nan     0.3688   -0.0066
   960        0.2557             nan     0.3688   -0.0029
   980        0.2510             nan     0.3688   -0.0044
  1000        0.2469             nan     0.3688   -0.0029
  1020        0.2436             nan     0.3688   -0.0034
  1040        0.2424             nan     0.3688   -0.0038
  1060        0.2365             nan     0.3688   -0.0029
  1080        0.2315             nan     0.3688   -0.0015
  1100        0.2285             nan     0.3688   -0.0036
  1120        0.2250             nan     0.3688   -0.0053
  1140        0.2198             nan     0.3688   -0.0035
  1160        0.2145             nan     0.3688   -0.0013
  1180        0.2106             nan     0.3688   -0.0016
  1200        0.2065             nan     0.3688   -0.0023
  1220        0.2011             nan     0.3688   -0.0020
  1240        0.1968             nan     0.3688   -0.0009
  1260        0.1937             nan     0.3688   -0.0020
  1280        0.1916             nan     0.3688   -0.0032
  1300        0.1874             nan     0.3688   -0.0025
  1320        0.1832             nan     0.3688   -0.0002
  1340        0.1800             nan     0.3688   -0.0031
  1360        0.1765             nan     0.3688   -0.0035
  1380        0.1738             nan     0.3688   -0.0029
  1400        0.1712             nan     0.3688   -0.0012
  1420        0.1667             nan     0.3688   -0.0028
  1440        0.1660             nan     0.3688   -0.0028
  1460        0.1618             nan     0.3688   -0.0013
  1480        0.1596             nan     0.3688   -0.0024
  1500        0.1560             nan     0.3688   -0.0008
  1520        0.1555             nan     0.3688   -0.0030
  1540        0.1537             nan     0.3688   -0.0028
  1560        0.1504             nan     0.3688   -0.0020
  1580        0.1492             nan     0.3688   -0.0020
  1600        0.1470             nan     0.3688   -0.0019
  1620        0.1448             nan     0.3688   -0.0029
  1640        0.1409             nan     0.3688   -0.0020
  1660        0.1388             nan     0.3688   -0.0012
  1680        0.1367             nan     0.3688   -0.0017
  1700        0.1358             nan     0.3688   -0.0019
  1720        0.1333             nan     0.3688   -0.0015
  1740        0.1312             nan     0.3688   -0.0021
  1760        0.1287             nan     0.3688   -0.0002
  1780        0.1273             nan     0.3688   -0.0006
  1800        0.1245             nan     0.3688   -0.0009
  1820        0.1225             nan     0.3688   -0.0015
  1840        0.1204             nan     0.3688   -0.0007
  1860        0.1190             nan     0.3688   -0.0011
  1880        0.1173             nan     0.3688   -0.0019
  1888        0.1156             nan     0.3688   -0.0018

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0110             nan     0.3918   -0.0259
     2        1.0009             nan     0.3918   -0.0198
     3        0.9758             nan     0.3918   -0.0031
     4        0.9592             nan     0.3918   -0.0004
     5        0.9477             nan     0.3918   -0.0222
     6        0.9344             nan     0.3918   -0.0019
     7        0.9278             nan     0.3918   -0.0122
     8        0.9207             nan     0.3918   -0.0205
     9        0.9154             nan     0.3918   -0.0255
    10        0.9041             nan     0.3918   -0.0103
    20        0.8233             nan     0.3918   -0.0138
    40        0.7071             nan     0.3918   -0.0058
    60        0.6066             nan     0.3918   -0.0091
    80        0.5520             nan     0.3918   -0.0186
   100        0.4766             nan     0.3918   -0.0089
   120        0.4360             nan     0.3918   -0.0113
   140        0.3931             nan     0.3918   -0.0116
   160        0.3541             nan     0.3918   -0.0045
   180        0.3167             nan     0.3918   -0.0078
   200        0.2956             nan     0.3918   -0.0063
   220        0.2682             nan     0.3918   -0.0028
   240        0.2468             nan     0.3918   -0.0060
   260        0.2259             nan     0.3918   -0.0120
   280        0.2051             nan     0.3918   -0.0047
   300        0.1871             nan     0.3918   -0.0057
   320        0.1692             nan     0.3918   -0.0047
   340        0.1561             nan     0.3918   -0.0026
   360        0.1400             nan     0.3918   -0.0043
   380        0.1305             nan     0.3918   -0.0036
   400        0.1217             nan     0.3918   -0.0038
   420        0.1135             nan     0.3918   -0.0006
   440        0.1060             nan     0.3918   -0.0027
   460        0.0951             nan     0.3918   -0.0005
   480        0.0895             nan     0.3918   -0.0030
   500        0.0834             nan     0.3918   -0.0014
   520        0.0775             nan     0.3918   -0.0014
   540        0.0709             nan     0.3918   -0.0011
   560        0.0653             nan     0.3918   -0.0015
   580        0.0607             nan     0.3918   -0.0012
   600        0.0556             nan     0.3918   -0.0021
   620        0.0518             nan     0.3918   -0.0011
   640        0.0482             nan     0.3918   -0.0013
   660        0.0435             nan     0.3918   -0.0014
   680        0.0405             nan     0.3918   -0.0009
   700        0.0381             nan     0.3918   -0.0015
   720        0.0358             nan     0.3918   -0.0003
   740        0.0332             nan     0.3918   -0.0011
   760        0.0310             nan     0.3918   -0.0006
   780        0.0291             nan     0.3918   -0.0010
   800        0.0262             nan     0.3918   -0.0003
   820        0.0244             nan     0.3918   -0.0003
   840        0.0227             nan     0.3918   -0.0004
   860        0.0209             nan     0.3918   -0.0005
   880        0.0196             nan     0.3918   -0.0006
   881        0.0195             nan     0.3918   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9913             nan     0.4081   -0.0333
     2        0.9514             nan     0.4081   -0.0379
     3        0.9157             nan     0.4081   -0.0203
     4        0.8860             nan     0.4081   -0.0536
     5        0.8568             nan     0.4081   -0.0462
     6        0.8159             nan     0.4081   -0.0071
     7        0.8023             nan     0.4081   -0.0769
     8        0.7810             nan     0.4081   -0.0324
     9        0.7544             nan     0.4081   -0.0433
    10        0.7444             nan     0.4081   -0.0743
    20        0.5294             nan     0.4081   -0.0263
    40        0.3297             nan     0.4081   -0.0169
    60        0.1945             nan     0.4081   -0.0131
    80        0.1287             nan     0.4081   -0.0077
   100        0.0824             nan     0.4081   -0.0054
   120        0.0519             nan     0.4081   -0.0018
   140        0.0325             nan     0.4081   -0.0019
   160        0.0220             nan     0.4081   -0.0017
   180        0.0144             nan     0.4081   -0.0009
   200        0.0095             nan     0.4081   -0.0005
   220        0.0059             nan     0.4081   -0.0002
   240        0.0038             nan     0.4081   -0.0003
   260        0.0027             nan     0.4081   -0.0001
   280        0.0018             nan     0.4081   -0.0001
   300        0.0012             nan     0.4081   -0.0000
   320        0.0008             nan     0.4081   -0.0000
   340        0.0005             nan     0.4081   -0.0000
   360        0.0004             nan     0.4081   -0.0000
   380        0.0003             nan     0.4081   -0.0000
   400        0.0002             nan     0.4081   -0.0000
   420        0.0001             nan     0.4081   -0.0000
   440        0.0001             nan     0.4081   -0.0000
   460        0.0001             nan     0.4081   -0.0000
   480        0.0000             nan     0.4081   -0.0000
   500        0.0000             nan     0.4081   -0.0000
   520        0.0000             nan     0.4081   -0.0000
   540        0.0000             nan     0.4081   -0.0000
   560        0.0000             nan     0.4081   -0.0000
   580        0.0000             nan     0.4081   -0.0000
   600        0.0000             nan     0.4081   -0.0000
   620        0.0000             nan     0.4081   -0.0000
   640        0.0000             nan     0.4081   -0.0000
   660        0.0000             nan     0.4081   -0.0000
   680        0.0000             nan     0.4081   -0.0000
   700        0.0000             nan     0.4081   -0.0000
   720        0.0000             nan     0.4081   -0.0000
   740        0.0000             nan     0.4081   -0.0000
   760        0.0000             nan     0.4081   -0.0000
   780        0.0000             nan     0.4081   -0.0000
   800        0.0000             nan     0.4081   -0.0000
   820        0.0000             nan     0.4081   -0.0000
   840        0.0000             nan     0.4081   -0.0000
   860        0.0000             nan     0.4081   -0.0000
   880        0.0000             nan     0.4081   -0.0000
   900        0.0000             nan     0.4081   -0.0000
   920        0.0000             nan     0.4081   -0.0000
   940        0.0000             nan     0.4081   -0.0000
   960        0.0000             nan     0.4081   -0.0000
   980        0.0000             nan     0.4081   -0.0000
  1000        0.0000             nan     0.4081   -0.0000
  1020        0.0000             nan     0.4081   -0.0000
  1040        0.0000             nan     0.4081   -0.0000
  1060        0.0000             nan     0.4081   -0.0000
  1080        0.0000             nan     0.4081   -0.0000
  1100        0.0000             nan     0.4081   -0.0000
  1120        0.0000             nan     0.4081   -0.0000
  1140        0.0000             nan     0.4081   -0.0000
  1160        0.0000             nan     0.4081   -0.0000
  1180        0.0000             nan     0.4081   -0.0000
  1200        0.0000             nan     0.4081   -0.0000
  1220        0.0000             nan     0.4081   -0.0000
  1240        0.0000             nan     0.4081   -0.0000
  1260        0.0000             nan     0.4081   -0.0000
  1280        0.0000             nan     0.4081   -0.0000
  1300        0.0000             nan     0.4081   -0.0000
  1320        0.0000             nan     0.4081   -0.0000
  1340        0.0000             nan     0.4081   -0.0000
  1360        0.0000             nan     0.4081   -0.0000
  1380        0.0000             nan     0.4081   -0.0000
  1400        0.0000             nan     0.4081   -0.0000
  1420        0.0000             nan     0.4081   -0.0000
  1440        0.0000             nan     0.4081   -0.0000
  1460        0.0000             nan     0.4081   -0.0000
  1480        0.0000             nan     0.4081   -0.0000
  1500        0.0000             nan     0.4081   -0.0000
  1520        0.0000             nan     0.4081   -0.0000
  1540        0.0000             nan     0.4081   -0.0000
  1560        0.0000             nan     0.4081   -0.0000
  1580        0.0000             nan     0.4081   -0.0000
  1600        0.0000             nan     0.4081   -0.0000
  1620        0.0000             nan     0.4081   -0.0000
  1640        0.0000             nan     0.4081   -0.0000
  1660        0.0000             nan     0.4081   -0.0000
  1680        0.0000             nan     0.4081   -0.0000
  1700        0.0000             nan     0.4081   -0.0000
  1720        0.0000             nan     0.4081   -0.0000
  1740        0.0000             nan     0.4081   -0.0000
  1760        0.0000             nan     0.4081   -0.0000
  1780        0.0000             nan     0.4081   -0.0000
  1800        0.0000             nan     0.4081   -0.0000
  1820        0.0000             nan     0.4081   -0.0000
  1840        0.0000             nan     0.4081   -0.0000
  1860        0.0000             nan     0.4081   -0.0000
  1880        0.0000             nan     0.4081   -0.0000
  1900        0.0000             nan     0.4081   -0.0000
  1920        0.0000             nan     0.4081   -0.0000
  1940        0.0000             nan     0.4081   -0.0000
  1960        0.0000             nan     0.4081   -0.0000
  1980        0.0000             nan     0.4081   -0.0000
  2000        0.0000             nan     0.4081   -0.0000
  2020        0.0000             nan     0.4081   -0.0000
  2040        0.0000             nan     0.4081   -0.0000
  2060        0.0000             nan     0.4081   -0.0000
  2080        0.0000             nan     0.4081   -0.0000
  2100        0.0000             nan     0.4081   -0.0000
  2120        0.0000             nan     0.4081   -0.0000
  2140        0.0000             nan     0.4081   -0.0000
  2160        0.0000             nan     0.4081   -0.0000
  2180        0.0000             nan     0.4081   -0.0000
  2200        0.0000             nan     0.4081   -0.0000
  2220        0.0000             nan     0.4081   -0.0000
  2240        0.0000             nan     0.4081   -0.0000
  2260        0.0000             nan     0.4081   -0.0000
  2280        0.0000             nan     0.4081   -0.0000
  2300        0.0000             nan     0.4081   -0.0000
  2320        0.0000             nan     0.4081   -0.0000
  2340        0.0000             nan     0.4081   -0.0000
  2360        0.0000             nan     0.4081   -0.0000
  2380        0.0000             nan     0.4081   -0.0000
  2400        0.0000             nan     0.4081   -0.0000
  2420        0.0000             nan     0.4081   -0.0000
  2440        0.0000             nan     0.4081   -0.0000
  2460        0.0000             nan     0.4081   -0.0000
  2480        0.0000             nan     0.4081   -0.0000
  2500        0.0000             nan     0.4081   -0.0000
  2520        0.0000             nan     0.4081   -0.0000
  2540        0.0000             nan     0.4081   -0.0000
  2560        0.0000             nan     0.4081   -0.0000
  2580        0.0000             nan     0.4081   -0.0000
  2600        0.0000             nan     0.4081   -0.0000
  2620        0.0000             nan     0.4081   -0.0000
  2640        0.0000             nan     0.4081   -0.0000
  2660        0.0000             nan     0.4081   -0.0000
  2680        0.0000             nan     0.4081   -0.0000
  2700        0.0000             nan     0.4081   -0.0000
  2720        0.0000             nan     0.4081   -0.0000
  2740        0.0000             nan     0.4081   -0.0000
  2760        0.0000             nan     0.4081   -0.0000
  2780        0.0000             nan     0.4081   -0.0000
  2800        0.0000             nan     0.4081   -0.0000
  2820        0.0000             nan     0.4081   -0.0000
  2840        0.0000             nan     0.4081   -0.0000
  2860        0.0000             nan     0.4081   -0.0000
  2880        0.0000             nan     0.4081   -0.0000
  2900        0.0000             nan     0.4081   -0.0000
  2920        0.0000             nan     0.4081   -0.0000
  2940        0.0000             nan     0.4081   -0.0000
  2960        0.0000             nan     0.4081   -0.0000
  2980        0.0000             nan     0.4081   -0.0000
  3000        0.0000             nan     0.4081   -0.0000
  3020        0.0000             nan     0.4081   -0.0000
  3040        0.0000             nan     0.4081   -0.0000
  3060        0.0000             nan     0.4081   -0.0000
  3080        0.0000             nan     0.4081   -0.0000
  3100        0.0000             nan     0.4081   -0.0000
  3120        0.0000             nan     0.4081   -0.0000
  3140        0.0000             nan     0.4081   -0.0000
  3160        0.0000             nan     0.4081   -0.0000
  3180        0.0000             nan     0.4081   -0.0000
  3200        0.0000             nan     0.4081   -0.0000
  3220        0.0000             nan     0.4081   -0.0000
  3240        0.0000             nan     0.4081   -0.0000
  3260        0.0000             nan     0.4081   -0.0000
  3280        0.0000             nan     0.4081   -0.0000
  3300        0.0000             nan     0.4081   -0.0000
  3320        0.0000             nan     0.4081   -0.0000
  3340        0.0000             nan     0.4081   -0.0000
  3360        0.0000             nan     0.4081   -0.0000
  3380        0.0000             nan     0.4081   -0.0000
  3400        0.0000             nan     0.4081   -0.0000
  3420        0.0000             nan     0.4081   -0.0000
  3440        0.0000             nan     0.4081   -0.0000
  3460        0.0000             nan     0.4081   -0.0000
  3480        0.0000             nan     0.4081   -0.0000
  3500        0.0000             nan     0.4081   -0.0000
  3520        0.0000             nan     0.4081   -0.0000
  3540        0.0000             nan     0.4081   -0.0000
  3560        0.0000             nan     0.4081   -0.0000
  3580        0.0000             nan     0.4081   -0.0000
  3600        0.0000             nan     0.4081   -0.0000
  3620        0.0000             nan     0.4081   -0.0000
  3640        0.0000             nan     0.4081   -0.0000
  3660        0.0000             nan     0.4081   -0.0000
  3680        0.0000             nan     0.4081   -0.0000
  3700        0.0000             nan     0.4081   -0.0000
  3720        0.0000             nan     0.4081   -0.0000
  3740        0.0000             nan     0.4081   -0.0000
  3760        0.0000             nan     0.4081   -0.0000
  3780        0.0000             nan     0.4081   -0.0000
  3800        0.0000             nan     0.4081   -0.0000
  3820        0.0000             nan     0.4081   -0.0000
  3835        0.0000             nan     0.4081   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9722             nan     0.4204   -0.0024
     2        0.9376             nan     0.4204   -0.0441
     3        0.9174             nan     0.4204   -0.0250
     4        0.8731             nan     0.4204    0.0061
     5        0.8401             nan     0.4204   -0.0113
     6        0.8162             nan     0.4204   -0.0183
     7        0.7965             nan     0.4204   -0.0349
     8        0.7726             nan     0.4204   -0.0190
     9        0.7691             nan     0.4204   -0.0455
    10        0.7522             nan     0.4204   -0.0261
    20        0.5770             nan     0.4204   -0.0328
    40        0.3832             nan     0.4204   -0.0137
    60        0.2514             nan     0.4204   -0.0091
    80        0.1684             nan     0.4204   -0.0126
   100        0.1157             nan     0.4204   -0.0024
   120        0.0844             nan     0.4204   -0.0039
   140        0.0632             nan     0.4204   -0.0044
   160        0.0476             nan     0.4204   -0.0007
   180        0.0326             nan     0.4204   -0.0023
   200        0.0225             nan     0.4204   -0.0014
   220        0.0158             nan     0.4204   -0.0012
   240        0.0114             nan     0.4204   -0.0007
   260        0.0083             nan     0.4204   -0.0003
   280        0.0058             nan     0.4204   -0.0002
   300        0.0042             nan     0.4204   -0.0001
   320        0.0030             nan     0.4204   -0.0001
   340        0.0022             nan     0.4204   -0.0001
   360        0.0016             nan     0.4204   -0.0000
   380        0.0012             nan     0.4204   -0.0000
   400        0.0008             nan     0.4204   -0.0000
   420        0.0007             nan     0.4204   -0.0000
   440        0.0005             nan     0.4204   -0.0000
   460        0.0003             nan     0.4204   -0.0000
   480        0.0003             nan     0.4204   -0.0000
   500        0.0002             nan     0.4204   -0.0000
   520        0.0001             nan     0.4204   -0.0000
   540        0.0001             nan     0.4204   -0.0000
   560        0.0001             nan     0.4204   -0.0000
   580        0.0001             nan     0.4204   -0.0000
   600        0.0000             nan     0.4204   -0.0000
   620        0.0000             nan     0.4204   -0.0000
   640        0.0000             nan     0.4204   -0.0000
   660        0.0000             nan     0.4204   -0.0000
   680        0.0000             nan     0.4204   -0.0000
   700        0.0000             nan     0.4204   -0.0000
   720        0.0000             nan     0.4204   -0.0000
   740        0.0000             nan     0.4204   -0.0000
   760        0.0000             nan     0.4204   -0.0000
   780        0.0000             nan     0.4204   -0.0000
   800        0.0000             nan     0.4204   -0.0000
   820        0.0000             nan     0.4204   -0.0000
   840        0.0000             nan     0.4204   -0.0000
   860        0.0000             nan     0.4204   -0.0000
   880        0.0000             nan     0.4204   -0.0000
   900        0.0000             nan     0.4204   -0.0000
   920        0.0000             nan     0.4204   -0.0000
   940        0.0000             nan     0.4204   -0.0000
   960        0.0000             nan     0.4204   -0.0000
   980        0.0000             nan     0.4204   -0.0000
  1000        0.0000             nan     0.4204   -0.0000
  1020        0.0000             nan     0.4204   -0.0000
  1040        0.0000             nan     0.4204   -0.0000
  1060        0.0000             nan     0.4204   -0.0000
  1080        0.0000             nan     0.4204   -0.0000
  1100        0.0000             nan     0.4204   -0.0000
  1120        0.0000             nan     0.4204   -0.0000
  1140        0.0000             nan     0.4204   -0.0000
  1160        0.0000             nan     0.4204   -0.0000
  1180        0.0000             nan     0.4204   -0.0000
  1200        0.0000             nan     0.4204   -0.0000
  1220        0.0000             nan     0.4204   -0.0000
  1240        0.0000             nan     0.4204   -0.0000
  1260        0.0000             nan     0.4204   -0.0000
  1280        0.0000             nan     0.4204   -0.0000
  1300        0.0000             nan     0.4204   -0.0000
  1320        0.0000             nan     0.4204   -0.0000
  1340        0.0000             nan     0.4204   -0.0000
  1360        0.0000             nan     0.4204   -0.0000
  1380        0.0000             nan     0.4204   -0.0000
  1400        0.0000             nan     0.4204   -0.0000
  1420        0.0000             nan     0.4204   -0.0000
  1440        0.0000             nan     0.4204   -0.0000
  1460        0.0000             nan     0.4204   -0.0000
  1480        0.0000             nan     0.4204   -0.0000
  1500        0.0000             nan     0.4204   -0.0000
  1520        0.0000             nan     0.4204   -0.0000
  1540        0.0000             nan     0.4204   -0.0000
  1560        0.0000             nan     0.4204   -0.0000
  1580        0.0000             nan     0.4204   -0.0000
  1600        0.0000             nan     0.4204   -0.0000
  1620        0.0000             nan     0.4204   -0.0000
  1640        0.0000             nan     0.4204   -0.0000
  1660        0.0000             nan     0.4204   -0.0000
  1680        0.0000             nan     0.4204   -0.0000
  1700        0.0000             nan     0.4204   -0.0000
  1720        0.0000             nan     0.4204   -0.0000
  1740        0.0000             nan     0.4204   -0.0000
  1760        0.0000             nan     0.4204   -0.0000
  1780        0.0000             nan     0.4204   -0.0000
  1800        0.0000             nan     0.4204   -0.0000
  1820        0.0000             nan     0.4204   -0.0000
  1840        0.0000             nan     0.4204   -0.0000
  1860        0.0000             nan     0.4204   -0.0000
  1880        0.0000             nan     0.4204   -0.0000
  1900        0.0000             nan     0.4204   -0.0000
  1920        0.0000             nan     0.4204   -0.0000
  1940        0.0000             nan     0.4204   -0.0000
  1960        0.0000             nan     0.4204   -0.0000
  1980        0.0000             nan     0.4204   -0.0000
  2000        0.0000             nan     0.4204   -0.0000
  2020        0.0000             nan     0.4204   -0.0000
  2040        0.0000             nan     0.4204   -0.0000
  2060        0.0000             nan     0.4204   -0.0000
  2080        0.0000             nan     0.4204   -0.0000
  2100        0.0000             nan     0.4204   -0.0000
  2120        0.0000             nan     0.4204   -0.0000
  2140        0.0000             nan     0.4204   -0.0000
  2160        0.0000             nan     0.4204   -0.0000
  2180        0.0000             nan     0.4204   -0.0000
  2200        0.0000             nan     0.4204   -0.0000
  2220        0.0000             nan     0.4204   -0.0000
  2240        0.0000             nan     0.4204   -0.0000
  2260        0.0000             nan     0.4204   -0.0000
  2280        0.0000             nan     0.4204   -0.0000
  2300        0.0000             nan     0.4204   -0.0000
  2320        0.0000             nan     0.4204   -0.0000
  2340        0.0000             nan     0.4204   -0.0000
  2360        0.0000             nan     0.4204   -0.0000
  2380        0.0000             nan     0.4204   -0.0000
  2400        0.0000             nan     0.4204   -0.0000
  2420        0.0000             nan     0.4204   -0.0000
  2440        0.0000             nan     0.4204   -0.0000
  2460        0.0000             nan     0.4204   -0.0000
  2480        0.0000             nan     0.4204   -0.0000
  2500        0.0000             nan     0.4204   -0.0000
  2520        0.0000             nan     0.4204   -0.0000
  2540        0.0000             nan     0.4204   -0.0000
  2560        0.0000             nan     0.4204   -0.0000
  2580        0.0000             nan     0.4204   -0.0000
  2600        0.0000             nan     0.4204   -0.0000
  2620        0.0000             nan     0.4204   -0.0000
  2640        0.0000             nan     0.4204   -0.0000
  2660        0.0000             nan     0.4204   -0.0000
  2680        0.0000             nan     0.4204   -0.0000
  2700        0.0000             nan     0.4204   -0.0000
  2720        0.0000             nan     0.4204   -0.0000
  2740        0.0000             nan     0.4204   -0.0000
  2760        0.0000             nan     0.4204   -0.0000
  2780        0.0000             nan     0.4204   -0.0000
  2800        0.0000             nan     0.4204   -0.0000
  2820        0.0000             nan     0.4204   -0.0000
  2840        0.0000             nan     0.4204   -0.0000
  2860        0.0000             nan     0.4204   -0.0000
  2880        0.0000             nan     0.4204   -0.0000
  2900        0.0000             nan     0.4204   -0.0000
  2920        0.0000             nan     0.4204   -0.0000
  2940        0.0000             nan     0.4204   -0.0000
  2960        0.0000             nan     0.4204   -0.0000
  2980        0.0000             nan     0.4204   -0.0000
  3000        0.0000             nan     0.4204   -0.0000
  3020        0.0000             nan     0.4204   -0.0000
  3040        0.0000             nan     0.4204   -0.0000
  3060        0.0000             nan     0.4204   -0.0000
  3080        0.0000             nan     0.4204   -0.0000
  3100        0.0000             nan     0.4204   -0.0000
  3120        0.0000             nan     0.4204   -0.0000
  3140        0.0000             nan     0.4204   -0.0000
  3160        0.0000             nan     0.4204   -0.0000
  3180        0.0000             nan     0.4204   -0.0000
  3200        0.0000             nan     0.4204   -0.0000
  3220        0.0000             nan     0.4204   -0.0000
  3240        0.0000             nan     0.4204   -0.0000
  3260        0.0000             nan     0.4204   -0.0000
  3280        0.0000             nan     0.4204   -0.0000
  3300        0.0000             nan     0.4204   -0.0000
  3320        0.0000             nan     0.4204   -0.0000
  3340        0.0000             nan     0.4204   -0.0000
  3360        0.0000             nan     0.4204   -0.0000
  3380        0.0000             nan     0.4204   -0.0000
  3400        0.0000             nan     0.4204   -0.0000
  3420        0.0000             nan     0.4204   -0.0000
  3440        0.0000             nan     0.4204   -0.0000
  3460        0.0000             nan     0.4204   -0.0000
  3480        0.0000             nan     0.4204   -0.0000
  3500        0.0000             nan     0.4204   -0.0000
  3520        0.0000             nan     0.4204   -0.0000
  3540        0.0000             nan     0.4204   -0.0000
  3560        0.0000             nan     0.4204   -0.0000
  3580        0.0000             nan     0.4204   -0.0000
  3600        0.0000             nan     0.4204   -0.0000
  3620        0.0000             nan     0.4204   -0.0000
  3640        0.0000             nan     0.4204   -0.0000
  3660        0.0000             nan     0.4204   -0.0000
  3680        0.0000             nan     0.4204   -0.0000
  3700        0.0000             nan     0.4204   -0.0000
  3720        0.0000             nan     0.4204   -0.0000
  3740        0.0000             nan     0.4204   -0.0000
  3760        0.0000             nan     0.4204   -0.0000
  3780        0.0000             nan     0.4204   -0.0000
  3800        0.0000             nan     0.4204   -0.0000
  3820        0.0000             nan     0.4204   -0.0000
  3840        0.0000             nan     0.4204   -0.0000
  3860        0.0000             nan     0.4204   -0.0000
  3880        0.0000             nan     0.4204   -0.0000
  3900        0.0000             nan     0.4204   -0.0000
  3920        0.0000             nan     0.4204   -0.0000
  3940        0.0000             nan     0.4204   -0.0000
  3960        0.0000             nan     0.4204   -0.0000
  3980        0.0000             nan     0.4204   -0.0000
  4000        0.0000             nan     0.4204   -0.0000
  4020        0.0000             nan     0.4204   -0.0000
  4040        0.0000             nan     0.4204   -0.0000
  4060        0.0000             nan     0.4204   -0.0000
  4080        0.0000             nan     0.4204   -0.0000
  4100        0.0000             nan     0.4204   -0.0000
  4120        0.0000             nan     0.4204   -0.0000
  4140        0.0000             nan     0.4204   -0.0000
  4160        0.0000             nan     0.4204   -0.0000
  4180        0.0000             nan     0.4204   -0.0000
  4200        0.0000             nan     0.4204   -0.0000
  4220        0.0000             nan     0.4204   -0.0000
  4240        0.0000             nan     0.4204   -0.0000
  4260        0.0000             nan     0.4204   -0.0000
  4280        0.0000             nan     0.4204   -0.0000
  4300        0.0000             nan     0.4204   -0.0000
  4320        0.0000             nan     0.4204   -0.0000
  4340        0.0000             nan     0.4204   -0.0000
  4360        0.0000             nan     0.4204   -0.0000
  4380        0.0000             nan     0.4204   -0.0000
  4400        0.0000             nan     0.4204   -0.0000
  4420        0.0000             nan     0.4204   -0.0000
  4440        0.0000             nan     0.4204   -0.0000
  4460        0.0000             nan     0.4204   -0.0000
  4480        0.0000             nan     0.4204   -0.0000
  4500        0.0000             nan     0.4204   -0.0000
  4520        0.0000             nan     0.4204   -0.0000
  4540        0.0000             nan     0.4204   -0.0000
  4560        0.0000             nan     0.4204   -0.0000
  4580        0.0000             nan     0.4204   -0.0000
  4600        0.0000             nan     0.4204   -0.0000
  4620        0.0000             nan     0.4204   -0.0000
  4640        0.0000             nan     0.4204   -0.0000
  4660        0.0000             nan     0.4204   -0.0000
  4680        0.0000             nan     0.4204   -0.0000
  4700        0.0000             nan     0.4204   -0.0000
  4720        0.0000             nan     0.4204   -0.0000
  4740        0.0000             nan     0.4204   -0.0000
  4760        0.0000             nan     0.4204   -0.0000
  4780        0.0000             nan     0.4204   -0.0000
  4800        0.0000             nan     0.4204   -0.0000
  4820        0.0000             nan     0.4204   -0.0000
  4840        0.0000             nan     0.4204   -0.0000
  4860        0.0000             nan     0.4204   -0.0000
  4880        0.0000             nan     0.4204   -0.0000
  4900        0.0000             nan     0.4204   -0.0000
  4920        0.0000             nan     0.4204   -0.0000
  4940        0.0000             nan     0.4204   -0.0000
  4960        0.0000             nan     0.4204   -0.0000
  4980        0.0000             nan     0.4204   -0.0000
  4996        0.0000             nan     0.4204   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9499             nan     0.4363   -0.0252
     2        0.9064             nan     0.4363   -0.0252
     3        0.8701             nan     0.4363   -0.0553
     4        0.8404             nan     0.4363   -0.0302
     5        0.8124             nan     0.4363   -0.0586
     6        0.7814             nan     0.4363   -0.0450
     7        0.7450             nan     0.4363   -0.0411
     8        0.7245             nan     0.4363   -0.0425
     9        0.6963             nan     0.4363   -0.0511
    10        0.6744             nan     0.4363   -0.0467
    20        0.4992             nan     0.4363   -0.0406
    40        0.2626             nan     0.4363   -0.0134
    60        0.1495             nan     0.4363   -0.0121
    80        0.0847             nan     0.4363   -0.0080
   100        0.0513             nan     0.4363   -0.0037
   120        0.0318             nan     0.4363   -0.0010
   140        0.0194             nan     0.4363   -0.0012
   160        0.0116             nan     0.4363   -0.0006
   180        0.0071             nan     0.4363   -0.0006
   200        0.0043             nan     0.4363   -0.0003
   220        0.0028             nan     0.4363   -0.0000
   240        0.0017             nan     0.4363   -0.0001
   260        0.0011             nan     0.4363   -0.0001
   280        0.0007             nan     0.4363   -0.0001
   300        0.0004             nan     0.4363   -0.0000
   320        0.0003             nan     0.4363   -0.0000
   340        0.0002             nan     0.4363   -0.0000
   360        0.0001             nan     0.4363   -0.0000
   380        0.0001             nan     0.4363   -0.0000
   400        0.0000             nan     0.4363   -0.0000
   420        0.0000             nan     0.4363   -0.0000
   440        0.0000             nan     0.4363   -0.0000
   460        0.0000             nan     0.4363   -0.0000
   480        0.0000             nan     0.4363   -0.0000
   500        0.0000             nan     0.4363   -0.0000
   520        0.0000             nan     0.4363   -0.0000
   540        0.0000             nan     0.4363   -0.0000
   560        0.0000             nan     0.4363   -0.0000
   580        0.0000             nan     0.4363   -0.0000
   600        0.0000             nan     0.4363   -0.0000
   620        0.0000             nan     0.4363   -0.0000
   640        0.0000             nan     0.4363   -0.0000
   660        0.0000             nan     0.4363   -0.0000
   680        0.0000             nan     0.4363   -0.0000
   700        0.0000             nan     0.4363   -0.0000
   720        0.0000             nan     0.4363   -0.0000
   740        0.0000             nan     0.4363   -0.0000
   760        0.0000             nan     0.4363   -0.0000
   780        0.0000             nan     0.4363   -0.0000
   800        0.0000             nan     0.4363   -0.0000
   820        0.0000             nan     0.4363   -0.0000
   840        0.0000             nan     0.4363   -0.0000
   860        0.0000             nan     0.4363   -0.0000
   880        0.0000             nan     0.4363   -0.0000
   900        0.0000             nan     0.4363   -0.0000
   920        0.0000             nan     0.4363   -0.0000
   940        0.0000             nan     0.4363   -0.0000
   960        0.0000             nan     0.4363   -0.0000
   980        0.0000             nan     0.4363   -0.0000
  1000        0.0000             nan     0.4363   -0.0000
  1020        0.0000             nan     0.4363   -0.0000
  1040        0.0000             nan     0.4363   -0.0000
  1060        0.0000             nan     0.4363   -0.0000
  1080        0.0000             nan     0.4363   -0.0000
  1100        0.0000             nan     0.4363   -0.0000
  1120        0.0000             nan     0.4363   -0.0000
  1140        0.0000             nan     0.4363   -0.0000
  1160        0.0000             nan     0.4363   -0.0000
  1180        0.0000             nan     0.4363   -0.0000
  1200        0.0000             nan     0.4363   -0.0000
  1220        0.0000             nan     0.4363   -0.0000
  1240        0.0000             nan     0.4363   -0.0000
  1260        0.0000             nan     0.4363   -0.0000
  1280        0.0000             nan     0.4363   -0.0000
  1300        0.0000             nan     0.4363   -0.0000
  1320        0.0000             nan     0.4363   -0.0000
  1340        0.0000             nan     0.4363   -0.0000
  1360        0.0000             nan     0.4363   -0.0000
  1380        0.0000             nan     0.4363   -0.0000
  1400        0.0000             nan     0.4363   -0.0000
  1420        0.0000             nan     0.4363   -0.0000
  1440        0.0000             nan     0.4363   -0.0000
  1460        0.0000             nan     0.4363   -0.0000
  1480        0.0000             nan     0.4363   -0.0000
  1500        0.0000             nan     0.4363   -0.0000
  1520        0.0000             nan     0.4363   -0.0000
  1540        0.0000             nan     0.4363   -0.0000
  1560        0.0000             nan     0.4363   -0.0000
  1580        0.0000             nan     0.4363   -0.0000
  1600        0.0000             nan     0.4363   -0.0000
  1620        0.0000             nan     0.4363   -0.0000
  1640        0.0000             nan     0.4363   -0.0000
  1660        0.0000             nan     0.4363   -0.0000
  1680        0.0000             nan     0.4363   -0.0000
  1700        0.0000             nan     0.4363    0.0000
  1720        0.0000             nan     0.4363   -0.0000
  1740        0.0000             nan     0.4363   -0.0000
  1760        0.0000             nan     0.4363   -0.0000
  1780        0.0000             nan     0.4363   -0.0000
  1800        0.0000             nan     0.4363   -0.0000
  1820        0.0000             nan     0.4363   -0.0000
  1840        0.0000             nan     0.4363   -0.0000
  1860        0.0000             nan     0.4363   -0.0000
  1880        0.0000             nan     0.4363   -0.0000
  1900        0.0000             nan     0.4363   -0.0000
  1920        0.0000             nan     0.4363   -0.0000
  1940        0.0000             nan     0.4363   -0.0000
  1960        0.0000             nan     0.4363   -0.0000
  1980        0.0000             nan     0.4363   -0.0000
  2000        0.0000             nan     0.4363   -0.0000
  2020        0.0000             nan     0.4363   -0.0000
  2040        0.0000             nan     0.4363   -0.0000
  2060        0.0000             nan     0.4363   -0.0000
  2080        0.0000             nan     0.4363   -0.0000
  2100        0.0000             nan     0.4363   -0.0000
  2120        0.0000             nan     0.4363   -0.0000
  2140        0.0000             nan     0.4363   -0.0000
  2160        0.0000             nan     0.4363   -0.0000
  2180        0.0000             nan     0.4363   -0.0000
  2200        0.0000             nan     0.4363   -0.0000
  2220        0.0000             nan     0.4363   -0.0000
  2240        0.0000             nan     0.4363   -0.0000
  2260        0.0000             nan     0.4363   -0.0000
  2280        0.0000             nan     0.4363   -0.0000
  2300        0.0000             nan     0.4363   -0.0000
  2320        0.0000             nan     0.4363   -0.0000
  2340        0.0000             nan     0.4363   -0.0000
  2360        0.0000             nan     0.4363   -0.0000
  2380        0.0000             nan     0.4363   -0.0000
  2400        0.0000             nan     0.4363   -0.0000
  2420        0.0000             nan     0.4363   -0.0000
  2440        0.0000             nan     0.4363   -0.0000
  2460        0.0000             nan     0.4363   -0.0000
  2480        0.0000             nan     0.4363   -0.0000
  2500        0.0000             nan     0.4363   -0.0000
  2520        0.0000             nan     0.4363   -0.0000
  2540        0.0000             nan     0.4363   -0.0000
  2560        0.0000             nan     0.4363    0.0000
  2580        0.0000             nan     0.4363   -0.0000
  2594        0.0000             nan     0.4363   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9938             nan     0.4488   -0.0318
     2        0.9499             nan     0.4488    0.0045
     3        0.9166             nan     0.4488   -0.0147
     4        0.8860             nan     0.4488   -0.0204
     5        0.8694             nan     0.4488   -0.0248
     6        0.8503             nan     0.4488   -0.0340
     7        0.8363             nan     0.4488   -0.0521
     8        0.7992             nan     0.4488    0.0104
     9        0.7812             nan     0.4488   -0.0240
    10        0.7676             nan     0.4488   -0.0396
    20        0.6381             nan     0.4488   -0.0292
    40        0.4634             nan     0.4488   -0.0323
    60        0.3214             nan     0.4488   -0.0077
    80        0.2342             nan     0.4488   -0.0091
   100        0.1751             nan     0.4488   -0.0064
   120        0.1316             nan     0.4488   -0.0041
   140        0.0991             nan     0.4488   -0.0034
   160        0.0770             nan     0.4488   -0.0014
   180        0.0581             nan     0.4488   -0.0015
   200        0.0433             nan     0.4488   -0.0020
   220        0.0318             nan     0.4488   -0.0022
   240        0.0232             nan     0.4488   -0.0009
   260        0.0189             nan     0.4488   -0.0007
   280        0.0137             nan     0.4488   -0.0007
   300        0.0103             nan     0.4488   -0.0005
   320        0.0079             nan     0.4488   -0.0002
   340        0.0061             nan     0.4488   -0.0002
   360        0.0044             nan     0.4488   -0.0003
   380        0.0034             nan     0.4488   -0.0001
   400        0.0026             nan     0.4488   -0.0001
   420        0.0020             nan     0.4488   -0.0001
   440        0.0015             nan     0.4488   -0.0000
   460        0.0011             nan     0.4488   -0.0001
   480        0.0009             nan     0.4488   -0.0001
   500        0.0007             nan     0.4488   -0.0000
   520        0.0006             nan     0.4488   -0.0000
   540        0.0004             nan     0.4488   -0.0000
   560        0.0003             nan     0.4488   -0.0000
   580        0.0003             nan     0.4488   -0.0000
   600        0.0002             nan     0.4488   -0.0000
   620        0.0002             nan     0.4488   -0.0000
   640        0.0001             nan     0.4488   -0.0000
   660        0.0001             nan     0.4488   -0.0000
   680        0.0001             nan     0.4488   -0.0000
   700        0.0001             nan     0.4488   -0.0000
   720        0.0000             nan     0.4488   -0.0000
   740        0.0000             nan     0.4488   -0.0000
   760        0.0000             nan     0.4488   -0.0000
   780        0.0000             nan     0.4488   -0.0000
   800        0.0000             nan     0.4488   -0.0000
   820        0.0000             nan     0.4488   -0.0000
   840        0.0000             nan     0.4488   -0.0000
   860        0.0000             nan     0.4488   -0.0000
   880        0.0000             nan     0.4488   -0.0000
   900        0.0000             nan     0.4488   -0.0000
   920        0.0000             nan     0.4488   -0.0000
   940        0.0000             nan     0.4488   -0.0000
   960        0.0000             nan     0.4488   -0.0000
   980        0.0000             nan     0.4488   -0.0000
  1000        0.0000             nan     0.4488   -0.0000
  1020        0.0000             nan     0.4488   -0.0000
  1040        0.0000             nan     0.4488   -0.0000
  1060        0.0000             nan     0.4488   -0.0000
  1080        0.0000             nan     0.4488   -0.0000
  1100        0.0000             nan     0.4488   -0.0000
  1120        0.0000             nan     0.4488   -0.0000
  1140        0.0000             nan     0.4488   -0.0000
  1160        0.0000             nan     0.4488   -0.0000
  1180        0.0000             nan     0.4488   -0.0000
  1200        0.0000             nan     0.4488   -0.0000
  1220        0.0000             nan     0.4488   -0.0000
  1240        0.0000             nan     0.4488   -0.0000
  1260        0.0000             nan     0.4488   -0.0000
  1280        0.0000             nan     0.4488   -0.0000
  1300        0.0000             nan     0.4488   -0.0000
  1320        0.0000             nan     0.4488   -0.0000
  1340        0.0000             nan     0.4488   -0.0000
  1360        0.0000             nan     0.4488   -0.0000
  1380        0.0000             nan     0.4488   -0.0000
  1400        0.0000             nan     0.4488   -0.0000
  1420        0.0000             nan     0.4488   -0.0000
  1440        0.0000             nan     0.4488   -0.0000
  1460        0.0000             nan     0.4488   -0.0000
  1480        0.0000             nan     0.4488   -0.0000
  1500        0.0000             nan     0.4488   -0.0000
  1520        0.0000             nan     0.4488   -0.0000
  1540        0.0000             nan     0.4488   -0.0000
  1560        0.0000             nan     0.4488   -0.0000
  1580        0.0000             nan     0.4488   -0.0000
  1600        0.0000             nan     0.4488   -0.0000
  1620        0.0000             nan     0.4488   -0.0000
  1640        0.0000             nan     0.4488   -0.0000
  1660        0.0000             nan     0.4488   -0.0000
  1680        0.0000             nan     0.4488   -0.0000
  1700        0.0000             nan     0.4488   -0.0000
  1720        0.0000             nan     0.4488   -0.0000
  1740        0.0000             nan     0.4488   -0.0000
  1760        0.0000             nan     0.4488   -0.0000
  1780        0.0000             nan     0.4488   -0.0000
  1800        0.0000             nan     0.4488   -0.0000
  1820        0.0000             nan     0.4488   -0.0000
  1840        0.0000             nan     0.4488   -0.0000
  1860        0.0000             nan     0.4488   -0.0000
  1880        0.0000             nan     0.4488   -0.0000
  1900        0.0000             nan     0.4488   -0.0000
  1920        0.0000             nan     0.4488   -0.0000
  1940        0.0000             nan     0.4488   -0.0000
  1960        0.0000             nan     0.4488   -0.0000
  1980        0.0000             nan     0.4488   -0.0000
  2000        0.0000             nan     0.4488   -0.0000
  2020        0.0000             nan     0.4488   -0.0000
  2040        0.0000             nan     0.4488   -0.0000
  2060        0.0000             nan     0.4488   -0.0000
  2080        0.0000             nan     0.4488   -0.0000
  2100        0.0000             nan     0.4488   -0.0000
  2120        0.0000             nan     0.4488   -0.0000
  2140        0.0000             nan     0.4488   -0.0000
  2160        0.0000             nan     0.4488   -0.0000
  2180        0.0000             nan     0.4488   -0.0000
  2200        0.0000             nan     0.4488   -0.0000
  2220        0.0000             nan     0.4488   -0.0000
  2240        0.0000             nan     0.4488   -0.0000
  2260        0.0000             nan     0.4488   -0.0000
  2280        0.0000             nan     0.4488   -0.0000
  2300        0.0000             nan     0.4488   -0.0000
  2320        0.0000             nan     0.4488   -0.0000
  2340        0.0000             nan     0.4488   -0.0000
  2360        0.0000             nan     0.4488   -0.0000
  2380        0.0000             nan     0.4488   -0.0000
  2400        0.0000             nan     0.4488   -0.0000
  2420        0.0000             nan     0.4488   -0.0000
  2440        0.0000             nan     0.4488   -0.0000
  2460        0.0000             nan     0.4488   -0.0000
  2480        0.0000             nan     0.4488   -0.0000
  2500        0.0000             nan     0.4488   -0.0000
  2520        0.0000             nan     0.4488   -0.0000
  2540        0.0000             nan     0.4488   -0.0000
  2560        0.0000             nan     0.4488   -0.0000
  2580        0.0000             nan     0.4488   -0.0000
  2600        0.0000             nan     0.4488   -0.0000
  2620        0.0000             nan     0.4488   -0.0000
  2640        0.0000             nan     0.4488   -0.0000
  2660        0.0000             nan     0.4488   -0.0000
  2680        0.0000             nan     0.4488   -0.0000
  2700        0.0000             nan     0.4488   -0.0000
  2720        0.0000             nan     0.4488   -0.0000
  2740        0.0000             nan     0.4488   -0.0000
  2760        0.0000             nan     0.4488   -0.0000
  2780        0.0000             nan     0.4488   -0.0000
  2800        0.0000             nan     0.4488   -0.0000
  2803        0.0000             nan     0.4488   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9904             nan     0.4523   -0.0373
     2        0.9568             nan     0.4523   -0.0663
     3        0.9389             nan     0.4523   -0.0516
     4        0.9236             nan     0.4523   -0.0557
     5        0.9013             nan     0.4523   -0.0461
     6        0.8736             nan     0.4523   -0.0484
     7        0.8419             nan     0.4523   -0.0215
     8        0.8162             nan     0.4523   -0.0651
     9        0.7927             nan     0.4523   -0.0249
    10        0.7742             nan     0.4523   -0.0782
    20        0.6377             nan     0.4523   -0.0373
    40        0.3720             nan     0.4523   -0.0128
    60        0.2306             nan     0.4523   -0.0105
    80        0.1565             nan     0.4523   -0.0038
   100        0.1041             nan     0.4523   -0.0070
   120        0.0681             nan     0.4523   -0.0045
   140        0.0473             nan     0.4523   -0.0018
   160        0.0347             nan     0.4523   -0.0025
   180        0.0234             nan     0.4523   -0.0010
   200        0.0167             nan     0.4523   -0.0009
   220        0.0121             nan     0.4523   -0.0005
   240        0.0081             nan     0.4523   -0.0001
   260        0.0060             nan     0.4523   -0.0004
   280        0.0042             nan     0.4523   -0.0003
   300        0.0030             nan     0.4523   -0.0003
   320        0.0020             nan     0.4523   -0.0001
   340        0.0014             nan     0.4523   -0.0001
   360        0.0010             nan     0.4523   -0.0001
   380        0.0007             nan     0.4523   -0.0001
   400        0.0005             nan     0.4523   -0.0000
   420        0.0004             nan     0.4523   -0.0000
   440        0.0003             nan     0.4523   -0.0000
   460        0.0002             nan     0.4523   -0.0000
   480        0.0001             nan     0.4523   -0.0000
   500        0.0001             nan     0.4523   -0.0000
   520        0.0001             nan     0.4523   -0.0000
   540        0.0001             nan     0.4523   -0.0000
   560        0.0000             nan     0.4523   -0.0000
   580        0.0000             nan     0.4523   -0.0000
   600        0.0000             nan     0.4523   -0.0000
   620        0.0000             nan     0.4523   -0.0000
   640        0.0000             nan     0.4523   -0.0000
   660        0.0000             nan     0.4523   -0.0000
   680        0.0000             nan     0.4523   -0.0000
   700        0.0000             nan     0.4523   -0.0000
   720        0.0000             nan     0.4523   -0.0000
   740        0.0000             nan     0.4523   -0.0000
   760        0.0000             nan     0.4523   -0.0000
   780        0.0000             nan     0.4523   -0.0000
   800        0.0000             nan     0.4523   -0.0000
   820        0.0000             nan     0.4523   -0.0000
   840        0.0000             nan     0.4523   -0.0000
   860        0.0000             nan     0.4523   -0.0000
   880        0.0000             nan     0.4523   -0.0000
   900        0.0000             nan     0.4523   -0.0000
   920        0.0000             nan     0.4523   -0.0000
   940        0.0000             nan     0.4523   -0.0000
   960        0.0000             nan     0.4523   -0.0000
   980        0.0000             nan     0.4523   -0.0000
  1000        0.0000             nan     0.4523   -0.0000
  1020        0.0000             nan     0.4523   -0.0000
  1040        0.0000             nan     0.4523   -0.0000
  1060        0.0000             nan     0.4523   -0.0000
  1080        0.0000             nan     0.4523   -0.0000
  1100        0.0000             nan     0.4523   -0.0000
  1120        0.0000             nan     0.4523   -0.0000
  1140        0.0000             nan     0.4523   -0.0000
  1160        0.0000             nan     0.4523   -0.0000
  1180        0.0000             nan     0.4523   -0.0000
  1200        0.0000             nan     0.4523   -0.0000
  1220        0.0000             nan     0.4523   -0.0000
  1240        0.0000             nan     0.4523   -0.0000
  1260        0.0000             nan     0.4523   -0.0000
  1280        0.0000             nan     0.4523   -0.0000
  1300        0.0000             nan     0.4523   -0.0000
  1320        0.0000             nan     0.4523   -0.0000
  1340        0.0000             nan     0.4523   -0.0000
  1360        0.0000             nan     0.4523   -0.0000
  1380        0.0000             nan     0.4523   -0.0000
  1400        0.0000             nan     0.4523   -0.0000
  1420        0.0000             nan     0.4523   -0.0000
  1440        0.0000             nan     0.4523   -0.0000
  1460        0.0000             nan     0.4523   -0.0000
  1480        0.0000             nan     0.4523   -0.0000
  1500        0.0000             nan     0.4523   -0.0000
  1520        0.0000             nan     0.4523   -0.0000
  1540        0.0000             nan     0.4523   -0.0000
  1560        0.0000             nan     0.4523   -0.0000
  1580        0.0000             nan     0.4523   -0.0000
  1600        0.0000             nan     0.4523   -0.0000
  1620        0.0000             nan     0.4523   -0.0000
  1640        0.0000             nan     0.4523   -0.0000
  1660        0.0000             nan     0.4523   -0.0000
  1680        0.0000             nan     0.4523   -0.0000
  1700        0.0000             nan     0.4523   -0.0000
  1720        0.0000             nan     0.4523   -0.0000
  1740        0.0000             nan     0.4523   -0.0000
  1760        0.0000             nan     0.4523   -0.0000
  1780        0.0000             nan     0.4523   -0.0000
  1800        0.0000             nan     0.4523   -0.0000
  1820        0.0000             nan     0.4523   -0.0000
  1840        0.0000             nan     0.4523   -0.0000
  1860        0.0000             nan     0.4523   -0.0000
  1880        0.0000             nan     0.4523   -0.0000
  1900        0.0000             nan     0.4523   -0.0000
  1920        0.0000             nan     0.4523   -0.0000
  1940        0.0000             nan     0.4523   -0.0000
  1960        0.0000             nan     0.4523   -0.0000
  1980        0.0000             nan     0.4523   -0.0000
  2000        0.0000             nan     0.4523   -0.0000
  2020        0.0000             nan     0.4523   -0.0000
  2040        0.0000             nan     0.4523   -0.0000
  2043        0.0000             nan     0.4523   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0051             nan     0.5059   -0.0369
     2        0.9773             nan     0.5059    0.0023
     3        0.9600             nan     0.5059   -0.0198
     4        0.9506             nan     0.5059   -0.0271
     5        0.9282             nan     0.5059   -0.0185
     6        0.9196             nan     0.5059   -0.0256
     7        0.9134             nan     0.5059   -0.0353
     8        0.9137             nan     0.5059   -0.0437
     9        0.9016             nan     0.5059   -0.0079
    10        0.8815             nan     0.5059    0.0045
    20        0.7824             nan     0.5059    0.0024
    40        0.6925             nan     0.5059   -0.0089
    60        0.6064             nan     0.5059   -0.0162
    80        0.5479             nan     0.5059   -0.0155
   100        0.4926             nan     0.5059   -0.0154
   120        0.4423             nan     0.5059   -0.0116
   140        0.4027             nan     0.5059   -0.0199
   160        0.3586             nan     0.5059   -0.0184
   180        0.3228             nan     0.5059   -0.0101
   200        0.2859             nan     0.5059   -0.0062
   220        0.2594             nan     0.5059   -0.0016
   240        0.2325             nan     0.5059   -0.0050
   260        0.2086             nan     0.5059   -0.0040
   280        0.1920             nan     0.5059   -0.0002
   300        0.1702             nan     0.5059   -0.0102
   320        0.1484             nan     0.5059   -0.0021
   340        0.1301             nan     0.5059   -0.0022
   360        0.1206             nan     0.5059   -0.0075
   380        0.1066             nan     0.5059   -0.0029
   400        0.0994             nan     0.5059   -0.0042
   420        0.0898             nan     0.5059   -0.0013
   440        0.0814             nan     0.5059   -0.0033
   460        0.0765             nan     0.5059   -0.0040
   480        0.0685             nan     0.5059   -0.0009
   500        0.0609             nan     0.5059   -0.0017
   520        0.0566             nan     0.5059   -0.0023
   540        0.0505             nan     0.5059   -0.0021
   560        0.0473             nan     0.5059   -0.0014
   580        0.0432             nan     0.5059   -0.0012
   600        0.0397             nan     0.5059   -0.0009
   620        0.0363             nan     0.5059   -0.0013
   640        0.0328             nan     0.5059   -0.0009
   660        0.0309             nan     0.5059   -0.0013
   680        0.0283             nan     0.5059   -0.0007
   700        0.0262             nan     0.5059   -0.0011
   720        0.0246             nan     0.5059   -0.0007
   740        0.0224             nan     0.5059   -0.0006
   760        0.0205             nan     0.5059   -0.0006
   780        0.0184             nan     0.5059   -0.0005
   800        0.0171             nan     0.5059   -0.0007
   820        0.0160             nan     0.5059   -0.0004
   840        0.0149             nan     0.5059   -0.0005
   860        0.0138             nan     0.5059   -0.0003
   880        0.0129             nan     0.5059   -0.0006
   900        0.0119             nan     0.5059   -0.0006
   920        0.0107             nan     0.5059   -0.0001
   940        0.0096             nan     0.5059   -0.0005
   960        0.0087             nan     0.5059   -0.0002
   980        0.0079             nan     0.5059   -0.0003
  1000        0.0074             nan     0.5059   -0.0004
  1020        0.0068             nan     0.5059   -0.0001
  1040        0.0060             nan     0.5059   -0.0002
  1060        0.0055             nan     0.5059   -0.0001
  1080        0.0051             nan     0.5059   -0.0001
  1100        0.0046             nan     0.5059   -0.0001
  1120        0.0042             nan     0.5059   -0.0001
  1140        0.0040             nan     0.5059   -0.0002
  1160        0.0037             nan     0.5059   -0.0001
  1180        0.0034             nan     0.5059   -0.0001
  1200        0.0031             nan     0.5059   -0.0001
  1220        0.0029             nan     0.5059   -0.0002
  1240        0.0026             nan     0.5059   -0.0001
  1260        0.0024             nan     0.5059   -0.0001
  1280        0.0023             nan     0.5059   -0.0001
  1300        0.0021             nan     0.5059   -0.0001
  1320        0.0019             nan     0.5059   -0.0001
  1340        0.0017             nan     0.5059   -0.0001
  1360        0.0016             nan     0.5059   -0.0001
  1380        0.0015             nan     0.5059   -0.0001
  1400        0.0014             nan     0.5059   -0.0000
  1420        0.0012             nan     0.5059   -0.0000
  1440        0.0012             nan     0.5059   -0.0000
  1460        0.0011             nan     0.5059   -0.0000
  1480        0.0010             nan     0.5059   -0.0000
  1500        0.0009             nan     0.5059   -0.0000
  1520        0.0009             nan     0.5059   -0.0001
  1540        0.0008             nan     0.5059   -0.0000
  1560        0.0007             nan     0.5059   -0.0000
  1580        0.0007             nan     0.5059   -0.0000
  1600        0.0006             nan     0.5059   -0.0000
  1620        0.0006             nan     0.5059   -0.0000
  1640        0.0005             nan     0.5059   -0.0000
  1660        0.0005             nan     0.5059    0.0000
  1680        0.0004             nan     0.5059   -0.0000
  1700        0.0004             nan     0.5059   -0.0000
  1720        0.0004             nan     0.5059   -0.0000
  1740        0.0003             nan     0.5059   -0.0000
  1760        0.0003             nan     0.5059   -0.0000
  1780        0.0003             nan     0.5059   -0.0000
  1800        0.0003             nan     0.5059   -0.0000
  1820        0.0002             nan     0.5059   -0.0000
  1840        0.0002             nan     0.5059   -0.0000
  1860        0.0002             nan     0.5059   -0.0000
  1880        0.0002             nan     0.5059   -0.0000
  1900        0.0002             nan     0.5059   -0.0000
  1920        0.0001             nan     0.5059   -0.0000
  1940        0.0001             nan     0.5059   -0.0000
  1960        0.0001             nan     0.5059   -0.0000
  1980        0.0001             nan     0.5059   -0.0000
  2000        0.0001             nan     0.5059   -0.0000
  2020        0.0001             nan     0.5059   -0.0000
  2040        0.0001             nan     0.5059   -0.0000
  2060        0.0001             nan     0.5059   -0.0000
  2080        0.0001             nan     0.5059   -0.0000
  2100        0.0001             nan     0.5059   -0.0000
  2120        0.0001             nan     0.5059   -0.0000
  2140        0.0001             nan     0.5059   -0.0000
  2160        0.0001             nan     0.5059   -0.0000
  2180        0.0001             nan     0.5059   -0.0000
  2200        0.0000             nan     0.5059   -0.0000
  2220        0.0000             nan     0.5059   -0.0000
  2240        0.0000             nan     0.5059   -0.0000
  2260        0.0000             nan     0.5059   -0.0000
  2280        0.0000             nan     0.5059   -0.0000
  2300        0.0000             nan     0.5059   -0.0000
  2320        0.0000             nan     0.5059   -0.0000
  2340        0.0000             nan     0.5059   -0.0000
  2360        0.0000             nan     0.5059   -0.0000
  2380        0.0000             nan     0.5059   -0.0000
  2400        0.0000             nan     0.5059   -0.0000
  2420        0.0000             nan     0.5059   -0.0000
  2440        0.0000             nan     0.5059   -0.0000
  2460        0.0000             nan     0.5059   -0.0000
  2480        0.0000             nan     0.5059   -0.0000
  2500        0.0000             nan     0.5059   -0.0000
  2520        0.0000             nan     0.5059   -0.0000
  2540        0.0000             nan     0.5059   -0.0000
  2560        0.0000             nan     0.5059   -0.0000
  2580        0.0000             nan     0.5059   -0.0000
  2600        0.0000             nan     0.5059   -0.0000
  2620        0.0000             nan     0.5059   -0.0000
  2640        0.0000             nan     0.5059   -0.0000
  2660        0.0000             nan     0.5059   -0.0000
  2680        0.0000             nan     0.5059   -0.0000
  2700        0.0000             nan     0.5059   -0.0000
  2720        0.0000             nan     0.5059   -0.0000
  2740        0.0000             nan     0.5059   -0.0000
  2760        0.0000             nan     0.5059   -0.0000
  2780        0.0000             nan     0.5059   -0.0000
  2800        0.0000             nan     0.5059   -0.0000
  2820        0.0000             nan     0.5059   -0.0000
  2840        0.0000             nan     0.5059   -0.0000
  2860        0.0000             nan     0.5059   -0.0000
  2880        0.0000             nan     0.5059   -0.0000
  2900        0.0000             nan     0.5059   -0.0000
  2920        0.0000             nan     0.5059   -0.0000
  2940        0.0000             nan     0.5059   -0.0000
  2960        0.0000             nan     0.5059   -0.0000
  2980        0.0000             nan     0.5059   -0.0000
  3000        0.0000             nan     0.5059   -0.0000
  3020        0.0000             nan     0.5059   -0.0000
  3040        0.0000             nan     0.5059   -0.0000
  3060        0.0000             nan     0.5059   -0.0000
  3080        0.0000             nan     0.5059   -0.0000
  3100        0.0000             nan     0.5059   -0.0000
  3120        0.0000             nan     0.5059   -0.0000
  3140        0.0000             nan     0.5059   -0.0000
  3160        0.0000             nan     0.5059   -0.0000
  3180        0.0000             nan     0.5059   -0.0000
  3200        0.0000             nan     0.5059   -0.0000
  3220        0.0000             nan     0.5059   -0.0000
  3240        0.0000             nan     0.5059   -0.0000
  3260        0.0000             nan     0.5059   -0.0000
  3280        0.0000             nan     0.5059   -0.0000
  3300        0.0000             nan     0.5059   -0.0000
  3320        0.0000             nan     0.5059   -0.0000
  3340        0.0000             nan     0.5059   -0.0000
  3360        0.0000             nan     0.5059   -0.0000
  3380        0.0000             nan     0.5059   -0.0000
  3400        0.0000             nan     0.5059   -0.0000
  3420        0.0000             nan     0.5059   -0.0000
  3440        0.0000             nan     0.5059   -0.0000
  3460        0.0000             nan     0.5059   -0.0000
  3480        0.0000             nan     0.5059   -0.0000
  3500        0.0000             nan     0.5059   -0.0000
  3520        0.0000             nan     0.5059   -0.0000
  3540        0.0000             nan     0.5059   -0.0000
  3560        0.0000             nan     0.5059   -0.0000
  3580        0.0000             nan     0.5059   -0.0000
  3600        0.0000             nan     0.5059   -0.0000
  3620        0.0000             nan     0.5059   -0.0000
  3640        0.0000             nan     0.5059   -0.0000
  3660        0.0000             nan     0.5059   -0.0000
  3680        0.0000             nan     0.5059   -0.0000
  3700        0.0000             nan     0.5059   -0.0000
  3720        0.0000             nan     0.5059   -0.0000
  3740        0.0000             nan     0.5059   -0.0000
  3760        0.0000             nan     0.5059   -0.0000
  3780        0.0000             nan     0.5059   -0.0000
  3800        0.0000             nan     0.5059   -0.0000
  3820        0.0000             nan     0.5059   -0.0000
  3840        0.0000             nan     0.5059   -0.0000
  3860        0.0000             nan     0.5059   -0.0000
  3880        0.0000             nan     0.5059   -0.0000
  3900        0.0000             nan     0.5059   -0.0000
  3920        0.0000             nan     0.5059   -0.0000
  3940        0.0000             nan     0.5059   -0.0000
  3960        0.0000             nan     0.5059   -0.0000
  3980        0.0000             nan     0.5059   -0.0000
  4000        0.0000             nan     0.5059   -0.0000
  4020        0.0000             nan     0.5059   -0.0000
  4040        0.0000             nan     0.5059   -0.0000
  4060        0.0000             nan     0.5059   -0.0000
  4080        0.0000             nan     0.5059   -0.0000
  4100        0.0000             nan     0.5059   -0.0000
  4120        0.0000             nan     0.5059   -0.0000
  4140        0.0000             nan     0.5059   -0.0000
  4160        0.0000             nan     0.5059   -0.0000
  4180        0.0000             nan     0.5059   -0.0000
  4200        0.0000             nan     0.5059   -0.0000
  4220        0.0000             nan     0.5059   -0.0000
  4240        0.0000             nan     0.5059   -0.0000
  4260        0.0000             nan     0.5059   -0.0000
  4280        0.0000             nan     0.5059   -0.0000
  4300        0.0000             nan     0.5059   -0.0000
  4320        0.0000             nan     0.5059   -0.0000
  4340        0.0000             nan     0.5059   -0.0000
  4360        0.0000             nan     0.5059   -0.0000
  4380        0.0000             nan     0.5059   -0.0000
  4400        0.0000             nan     0.5059   -0.0000
  4420        0.0000             nan     0.5059   -0.0000
  4440        0.0000             nan     0.5059   -0.0000
  4460        0.0000             nan     0.5059   -0.0000
  4480        0.0000             nan     0.5059   -0.0000
  4500        0.0000             nan     0.5059   -0.0000
  4520        0.0000             nan     0.5059   -0.0000
  4540        0.0000             nan     0.5059   -0.0000
  4560        0.0000             nan     0.5059   -0.0000
  4580        0.0000             nan     0.5059   -0.0000
  4600        0.0000             nan     0.5059   -0.0000
  4620        0.0000             nan     0.5059   -0.0000
  4640        0.0000             nan     0.5059   -0.0000
  4660        0.0000             nan     0.5059   -0.0000
  4680        0.0000             nan     0.5059   -0.0000
  4700        0.0000             nan     0.5059   -0.0000
  4720        0.0000             nan     0.5059   -0.0000
  4740        0.0000             nan     0.5059   -0.0000
  4760        0.0000             nan     0.5059   -0.0000
  4780        0.0000             nan     0.5059   -0.0000
  4800        0.0000             nan     0.5059   -0.0000
  4820        0.0000             nan     0.5059   -0.0000
  4840        0.0000             nan     0.5059   -0.0000
  4860        0.0000             nan     0.5059   -0.0000
  4880        0.0000             nan     0.5059   -0.0000
  4900        0.0000             nan     0.5059   -0.0000
  4920        0.0000             nan     0.5059   -0.0000
  4922        0.0000             nan     0.5059   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0068             nan     0.5986   -0.0967
     2        0.9636             nan     0.5986   -0.0352
     3        0.9145             nan     0.5986   -0.0300
     4        0.8807             nan     0.5986   -0.0291
     5        0.8338             nan     0.5986    0.0054
     6        0.8026             nan     0.5986   -0.0255
     7        0.8042             nan     0.5986   -0.0951
     8        0.7716             nan     0.5986   -0.0133
     9        0.7357             nan     0.5986   -0.0652
    10        0.7315             nan     0.5986   -0.0520
    20        0.5830             nan     0.5986   -0.0433
    40        0.3888             nan     0.5986   -0.0128
    60        0.2430             nan     0.5986   -0.0059
    80        0.1701             nan     0.5986   -0.0092
   100        0.1171             nan     0.5986   -0.0081
   120        0.0745             nan     0.5986   -0.0019
   140        0.0518             nan     0.5986   -0.0015
   160        0.0338             nan     0.5986   -0.0022
   180        0.0230             nan     0.5986   -0.0006
   200        0.0163             nan     0.5986   -0.0006
   220        0.0104             nan     0.5986   -0.0004
   240        0.0069             nan     0.5986   -0.0002
   260        0.0050             nan     0.5986   -0.0004
   280        0.0036             nan     0.5986   -0.0003
   300        0.0026             nan     0.5986   -0.0002
   320        0.0018             nan     0.5986   -0.0002
   340        0.0012             nan     0.5986   -0.0001
   360        0.0008             nan     0.5986   -0.0000
   380        0.0006             nan     0.5986   -0.0001
   400        0.0004             nan     0.5986   -0.0000
   420        0.0003             nan     0.5986   -0.0000
   440        0.0002             nan     0.5986   -0.0000
   460        0.0001             nan     0.5986   -0.0000
   480        0.0001             nan     0.5986   -0.0000
   500        0.0001             nan     0.5986   -0.0000
   520        0.0000             nan     0.5986   -0.0000
   540        0.0000             nan     0.5986   -0.0000
   560        0.0000             nan     0.5986   -0.0000
   580        0.0000             nan     0.5986   -0.0000
   600        0.0000             nan     0.5986   -0.0000
   620        0.0000             nan     0.5986   -0.0000
   640        0.0000             nan     0.5986   -0.0000
   660        0.0000             nan     0.5986   -0.0000
   680        0.0000             nan     0.5986   -0.0000
   700        0.0000             nan     0.5986   -0.0000
   720        0.0000             nan     0.5986   -0.0000
   740        0.0000             nan     0.5986   -0.0000
   760        0.0000             nan     0.5986   -0.0000
   780        0.0000             nan     0.5986   -0.0000
   800        0.0000             nan     0.5986   -0.0000
   820        0.0000             nan     0.5986   -0.0000
   840        0.0000             nan     0.5986   -0.0000
   860        0.0000             nan     0.5986   -0.0000
   880        0.0000             nan     0.5986   -0.0000
   900        0.0000             nan     0.5986   -0.0000
   920        0.0000             nan     0.5986   -0.0000
   940        0.0000             nan     0.5986   -0.0000
   960        0.0000             nan     0.5986   -0.0000
   980        0.0000             nan     0.5986   -0.0000
  1000        0.0000             nan     0.5986   -0.0000
  1020        0.0000             nan     0.5986   -0.0000
  1040        0.0000             nan     0.5986   -0.0000
  1060        0.0000             nan     0.5986   -0.0000
  1080        0.0000             nan     0.5986   -0.0000
  1100        0.0000             nan     0.5986   -0.0000
  1120        0.0000             nan     0.5986   -0.0000
  1140        0.0000             nan     0.5986   -0.0000
  1160        0.0000             nan     0.5986   -0.0000
  1180        0.0000             nan     0.5986   -0.0000
  1200        0.0000             nan     0.5986   -0.0000
  1220        0.0000             nan     0.5986   -0.0000
  1240        0.0000             nan     0.5986   -0.0000
  1260        0.0000             nan     0.5986   -0.0000
  1280        0.0000             nan     0.5986   -0.0000
  1300        0.0000             nan     0.5986   -0.0000
  1320        0.0000             nan     0.5986   -0.0000
  1340        0.0000             nan     0.5986   -0.0000
  1360        0.0000             nan     0.5986   -0.0000
  1380        0.0000             nan     0.5986   -0.0000
  1400        0.0000             nan     0.5986   -0.0000
  1420        0.0000             nan     0.5986   -0.0000
  1440        0.0000             nan     0.5986   -0.0000
  1460        0.0000             nan     0.5986   -0.0000
  1480        0.0000             nan     0.5986   -0.0000
  1500        0.0000             nan     0.5986   -0.0000
  1520        0.0000             nan     0.5986   -0.0000
  1529        0.0000             nan     0.5986   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9974             nan     0.0142    0.0001
     2        0.9958             nan     0.0142   -0.0009
     3        0.9936             nan     0.0142    0.0001
     4        0.9917             nan     0.0142   -0.0003
     5        0.9895             nan     0.0142   -0.0006
     6        0.9881             nan     0.0142   -0.0004
     7        0.9865             nan     0.0142    0.0000
     8        0.9846             nan     0.0142   -0.0003
     9        0.9824             nan     0.0142   -0.0008
    10        0.9809             nan     0.0142   -0.0001
    20        0.9634             nan     0.0142    0.0001
    40        0.9311             nan     0.0142   -0.0006
    60        0.9023             nan     0.0142   -0.0003
    80        0.8787             nan     0.0142   -0.0001
   100        0.8546             nan     0.0142   -0.0004
   120        0.8319             nan     0.0142   -0.0003
   140        0.8101             nan     0.0142   -0.0006
   160        0.7903             nan     0.0142   -0.0013
   180        0.7697             nan     0.0142   -0.0000
   200        0.7506             nan     0.0142   -0.0012
   220        0.7321             nan     0.0142   -0.0005
   240        0.7149             nan     0.0142   -0.0006
   260        0.6978             nan     0.0142   -0.0000
   280        0.6815             nan     0.0142   -0.0008
   300        0.6651             nan     0.0142   -0.0007
   320        0.6485             nan     0.0142   -0.0009
   340        0.6335             nan     0.0142   -0.0008
   360        0.6196             nan     0.0142   -0.0008
   380        0.6069             nan     0.0142   -0.0003
   400        0.5937             nan     0.0142   -0.0003
   420        0.5809             nan     0.0142   -0.0007
   440        0.5691             nan     0.0142   -0.0006
   460        0.5549             nan     0.0142   -0.0010
   480        0.5427             nan     0.0142   -0.0003
   500        0.5313             nan     0.0142   -0.0003
   520        0.5204             nan     0.0142   -0.0008
   540        0.5098             nan     0.0142   -0.0006
   560        0.5001             nan     0.0142   -0.0005
   580        0.4907             nan     0.0142   -0.0008
   600        0.4811             nan     0.0142   -0.0009
   620        0.4713             nan     0.0142   -0.0007
   640        0.4618             nan     0.0142   -0.0004
   660        0.4528             nan     0.0142   -0.0003
   680        0.4434             nan     0.0142   -0.0003
   700        0.4353             nan     0.0142   -0.0008
   720        0.4267             nan     0.0142   -0.0005
   740        0.4182             nan     0.0142   -0.0006
   760        0.4111             nan     0.0142   -0.0007
   780        0.4030             nan     0.0142   -0.0004
   800        0.3943             nan     0.0142   -0.0006
   820        0.3865             nan     0.0142   -0.0002
   840        0.3791             nan     0.0142   -0.0002
   860        0.3724             nan     0.0142   -0.0003
   880        0.3656             nan     0.0142   -0.0005
   900        0.3593             nan     0.0142   -0.0003
   920        0.3529             nan     0.0142   -0.0003
   940        0.3464             nan     0.0142   -0.0004
   960        0.3400             nan     0.0142   -0.0002
   980        0.3342             nan     0.0142   -0.0003
  1000        0.3283             nan     0.0142   -0.0004
  1020        0.3219             nan     0.0142   -0.0004
  1040        0.3163             nan     0.0142   -0.0004
  1060        0.3103             nan     0.0142   -0.0004
  1080        0.3039             nan     0.0142   -0.0001
  1100        0.2988             nan     0.0142   -0.0006
  1120        0.2935             nan     0.0142   -0.0006
  1140        0.2884             nan     0.0142   -0.0004
  1160        0.2832             nan     0.0142   -0.0006
  1180        0.2780             nan     0.0142   -0.0002
  1200        0.2730             nan     0.0142   -0.0002
  1220        0.2681             nan     0.0142   -0.0002
  1240        0.2636             nan     0.0142   -0.0004
  1260        0.2594             nan     0.0142   -0.0004
  1280        0.2549             nan     0.0142   -0.0003
  1300        0.2502             nan     0.0142   -0.0003
  1320        0.2457             nan     0.0142   -0.0001
  1340        0.2416             nan     0.0142   -0.0003
  1360        0.2372             nan     0.0142   -0.0004
  1380        0.2334             nan     0.0142   -0.0002
  1400        0.2294             nan     0.0142   -0.0003
  1420        0.2252             nan     0.0142   -0.0002
  1440        0.2216             nan     0.0142   -0.0002
  1460        0.2181             nan     0.0142   -0.0001
  1480        0.2141             nan     0.0142   -0.0002
  1500        0.2104             nan     0.0142   -0.0003
  1520        0.2071             nan     0.0142   -0.0003
  1540        0.2035             nan     0.0142   -0.0002
  1560        0.2002             nan     0.0142   -0.0002
  1580        0.1970             nan     0.0142   -0.0002
  1600        0.1937             nan     0.0142   -0.0002
  1620        0.1906             nan     0.0142   -0.0001
  1640        0.1873             nan     0.0142   -0.0003
  1660        0.1844             nan     0.0142   -0.0002
  1680        0.1811             nan     0.0142   -0.0002
  1700        0.1781             nan     0.0142   -0.0002
  1720        0.1752             nan     0.0142   -0.0002
  1740        0.1726             nan     0.0142   -0.0003
  1760        0.1696             nan     0.0142   -0.0003
  1780        0.1670             nan     0.0142   -0.0003
  1800        0.1643             nan     0.0142   -0.0002
  1820        0.1617             nan     0.0142   -0.0002
  1840        0.1590             nan     0.0142   -0.0002
  1860        0.1565             nan     0.0142   -0.0001
  1880        0.1538             nan     0.0142   -0.0001
  1900        0.1512             nan     0.0142   -0.0001
  1920        0.1488             nan     0.0142   -0.0002
  1940        0.1463             nan     0.0142   -0.0002
  1960        0.1441             nan     0.0142   -0.0001
  1980        0.1417             nan     0.0142   -0.0001
  2000        0.1393             nan     0.0142   -0.0002
  2020        0.1371             nan     0.0142   -0.0001
  2040        0.1349             nan     0.0142   -0.0001
  2060        0.1328             nan     0.0142   -0.0002
  2080        0.1307             nan     0.0142   -0.0002
  2100        0.1286             nan     0.0142   -0.0001
  2120        0.1266             nan     0.0142   -0.0002
  2140        0.1246             nan     0.0142   -0.0002
  2160        0.1226             nan     0.0142   -0.0002
  2180        0.1206             nan     0.0142   -0.0002
  2200        0.1187             nan     0.0142   -0.0003
  2220        0.1166             nan     0.0142   -0.0001
  2240        0.1148             nan     0.0142   -0.0001
  2260        0.1132             nan     0.0142   -0.0002
  2280        0.1114             nan     0.0142   -0.0002
  2300        0.1097             nan     0.0142   -0.0001
  2320        0.1078             nan     0.0142   -0.0001
  2340        0.1060             nan     0.0142   -0.0002
  2360        0.1044             nan     0.0142   -0.0001
  2380        0.1027             nan     0.0142   -0.0001
  2400        0.1011             nan     0.0142   -0.0001
  2420        0.0994             nan     0.0142   -0.0001
  2440        0.0977             nan     0.0142   -0.0001
  2460        0.0960             nan     0.0142   -0.0001
  2480        0.0946             nan     0.0142   -0.0001
  2500        0.0931             nan     0.0142   -0.0001
  2520        0.0915             nan     0.0142   -0.0001
  2540        0.0902             nan     0.0142   -0.0001
  2560        0.0887             nan     0.0142   -0.0001
  2580        0.0873             nan     0.0142   -0.0001
  2600        0.0860             nan     0.0142   -0.0001
  2620        0.0847             nan     0.0142   -0.0001
  2640        0.0833             nan     0.0142   -0.0001
  2660        0.0820             nan     0.0142   -0.0001
  2680        0.0806             nan     0.0142   -0.0001
  2700        0.0794             nan     0.0142   -0.0001
  2720        0.0781             nan     0.0142   -0.0001
  2740        0.0768             nan     0.0142   -0.0002
  2760        0.0758             nan     0.0142   -0.0001
  2780        0.0746             nan     0.0142   -0.0001
  2800        0.0734             nan     0.0142   -0.0001
  2820        0.0724             nan     0.0142   -0.0001
  2840        0.0713             nan     0.0142   -0.0001
  2860        0.0701             nan     0.0142   -0.0001
  2880        0.0690             nan     0.0142   -0.0001
  2900        0.0680             nan     0.0142   -0.0001
  2920        0.0669             nan     0.0142   -0.0001
  2940        0.0660             nan     0.0142   -0.0001
  2960        0.0649             nan     0.0142   -0.0001
  2980        0.0639             nan     0.0142   -0.0001
  3000        0.0630             nan     0.0142   -0.0000
  3020        0.0620             nan     0.0142   -0.0001
  3040        0.0611             nan     0.0142   -0.0001
  3047        0.0607             nan     0.0142   -0.0001

Stochastic Gradient Boosting 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  shrinkage   interaction.depth  n.minobsinnode  n.trees  RMSE      Rsquared   
  0.01420352   7                  7              3047     1.178250  0.007434716
  0.10072945   7                 23               675     1.201091  0.004998406
  0.11391158   6                 18              1151     1.244391  0.004673614
  0.17897697   4                 24              2601     1.254763  0.006116927
  0.19974261   6                 12               222     1.237713  0.008124969
  0.21683632   3                 23              4898     1.271054  0.002206848
  0.27570603   5                  7              2527     1.307789  0.010668942
  0.29564586   9                 25              3527     1.289153  0.004806349
  0.29583449  10                 23              1985     1.274212  0.004241002
  0.31173212   9                 18              2642     1.316821  0.008206147
  0.36403679   6                  9              1587     1.293711  0.005902052
  0.36876456   1                  5              1888     1.277333  0.005733434
  0.39178262   2                  9               881     1.307305  0.003782627
  0.40814694   8                 20              3835     1.305487  0.002106425
  0.42043969   5                  9              4996     1.342211  0.002438376
  0.43631712  10                 19              2594     1.318256  0.001790278
  0.44881821   4                  6              2803     1.421518  0.008129100
  0.45231844   7                 23              2043     1.349669  0.006008473
  0.50592976   2                 12              4922     1.411768  0.004392527
  0.59855077   6                 25              1529     1.416350  0.002361626
  MAE        Selected
  0.9366033  *       
  0.9485407          
  0.9898682          
  1.0083172          
  0.9755138          
  1.0193309          
  1.0438542          
  1.0361660          
  1.0173321          
  1.0632286          
  1.0250915          
  1.0264940          
  1.0286718          
  1.0538288          
  1.0664774          
  1.0450700          
  1.1385363          
  1.0739449          
  1.1218221          
  1.1348396          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were n.trees = 3047, interaction.depth =
 7, shrinkage = 0.01420352 and n.minobsinnode = 7.
[1] "Mon Mar 05 09:10:27 2018"
Error in relative.influence(object, n.trees = numTrees) : 
  could not find function "relative.influence"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: There were 25 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9     NA's   :9    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:13:27 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "gbm_h2o"                 
Multivariate Adaptive Regression Splines 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE      Rsquared      MAE      
  1.018668  0.0001414516  0.8083371

Tuning parameter 'degree' was held constant at a value of 1
[1] "Mon Mar 05 09:13:39 2018"
Generalized Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE      Rsquared    MAE     
  1.010177  0.00139138  0.798653

[1] "Mon Mar 05 09:13:51 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3     NA's   :3    
Error : Stopping
In addition: Warning messages:
1: model fit failed for Fold1: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
2: model fit failed for Fold1: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
3: model fit failed for Fold1: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
4: model fit failed for Fold2: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
5: model fit failed for Fold2: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
6: model fit failed for Fold2: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
7: model fit failed for Fold3: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
8: model fit failed for Fold3: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
9: model fit failed for Fold3: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
10: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3     NA's   :3    
Error : Stopping
In addition: Warning messages:
1: model fit failed for Fold1: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
2: model fit failed for Fold1: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
3: model fit failed for Fold1: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
4: model fit failed for Fold2: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
5: model fit failed for Fold2: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
6: model fit failed for Fold2: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
7: model fit failed for Fold3: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
8: model fit failed for Fold3: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
9: model fit failed for Fold3: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
10: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3     NA's   :3    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:14:07 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "glm.nb"                  
Boosted Generalized Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  mstop  prune  RMSE      Rsquared     MAE        Selected
    45   no     1.004926  0.002081920  0.7937110          
   135   no     1.008327  0.001483032  0.7968932          
   177   yes    1.003031  0.003033347  0.7924411  *       
   231   no     1.009566  0.001423571  0.7980651          
   306   no     1.009926  0.001403184  0.7984132          
   318   no     1.009953  0.001400277  0.7984426          
   378   yes    1.003031  0.003033347  0.7924411          
   397   no     1.010090  0.001394939  0.7985706          
   409   no     1.010103  0.001394467  0.7985823          
   506   yes    1.003031  0.003033347  0.7924411          
   519   no     1.010157  0.001392430  0.7986341          
   521   yes    1.003031  0.003033347  0.7924411          
   529   no     1.010160  0.001392355  0.7986366          
   561   yes    1.003031  0.003033347  0.7924411          
   610   no     1.010171  0.001391757  0.7986467          
   706   no     1.010175  0.001391472  0.7986509          
   768   no     1.010176  0.001391419  0.7986520          
   980   yes    1.003031  0.003033347  0.7924411          
   985   yes    1.003031  0.003033347  0.7924411          
  1000   yes    1.003031  0.003033347  0.7924411          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mstop = 177 and prune = yes.
[1] "Mon Mar 05 09:14:28 2018"
glmnet 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  alpha       lambda       RMSE       Rsquared     MAE        Selected
  0.04423375  0.130176485  1.0066900  0.001474909  0.7955227          
  0.13484489  0.365362973  1.0007641  0.004067766  0.7915547          
  0.17607728  0.003828452  1.0098879  0.001400890  0.7983769          
  0.23010151  0.121758659  1.0031021  0.002484668  0.7925990          
  0.30582363  0.111439979  1.0023263  0.003070644  0.7921403          
  0.31743816  0.111009795  1.0022042  0.003187396  0.7920813          
  0.37748590  0.002155545  1.0098753  0.001403038  0.7983661          
  0.39695999  4.055208420  0.9995283          NaN  0.7913185          
  0.40861725  0.304781633  0.9995283          NaN  0.7913185          
  0.50541101  0.062301092  1.0028813  0.002823051  0.7924323          
  0.51879696  4.205236449  0.9995283          NaN  0.7913185  *       
  0.52011220  0.014933399  1.0076703  0.001519470  0.7963103          
  0.52839347  2.529914787  0.9995283          NaN  0.7913185          
  0.56068793  0.027877581  1.0056323  0.001717809  0.7944923          
  0.60951029  0.483084832  0.9995283          NaN  0.7913185          
  0.70553546  1.732147713  0.9995283          NaN  0.7913185          
  0.76703082  1.274958249  0.9995283          NaN  0.7913185          
  0.97967031  0.010391172  1.0071142  0.001575123  0.7958185          
  0.98457705  0.003951573  1.0089061  0.001450375  0.7974255          
  0.99928846  0.048409483  1.0014024  0.004073563  0.7917730          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were alpha = 0.518797 and lambda = 4.205236.
[1] "Mon Mar 05 09:14:43 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: There were 25 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9     NA's   :9    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:17:42 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "glmnet_h2o"              
Start:  AIC=1424.77
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V5    1   480.64 1422.8
- V8    1   480.66 1422.8
- V9    1   480.68 1422.8
- V6    1   480.87 1423.0
- V10   1   481.40 1423.6
- V7    1   481.46 1423.6
- V2    1   481.52 1423.7
- V4    1   482.01 1424.2
<none>      480.63 1424.8
- V3    1   483.48 1425.8

Step:  AIC=1422.78
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V8    1   480.67 1420.8
- V9    1   480.69 1420.8
- V6    1   480.88 1421.0
- V10   1   481.40 1421.6
- V7    1   481.46 1421.7
- V2    1   481.53 1421.7
- V4    1   482.02 1422.2
<none>      480.64 1422.8
- V3    1   483.53 1423.8

Step:  AIC=1420.82
.outcome ~ V2 + V3 + V4 + V6 + V7 + V9 + V10

       Df Deviance    AIC
- V9    1   480.72 1418.9
- V6    1   480.91 1419.1
- V10   1   481.43 1419.6
- V7    1   481.49 1419.7
- V2    1   481.54 1419.7
- V4    1   482.12 1420.3
<none>      480.67 1420.8
- V3    1   483.53 1421.8

Step:  AIC=1418.87
.outcome ~ V2 + V3 + V4 + V6 + V7 + V10

       Df Deviance    AIC
- V6    1   480.96 1417.1
- V10   1   481.48 1417.7
- V7    1   481.55 1417.7
- V2    1   481.63 1417.8
- V4    1   482.21 1418.4
<none>      480.72 1418.9
- V3    1   483.71 1420.0

Step:  AIC=1417.13
.outcome ~ V2 + V3 + V4 + V7 + V10

       Df Deviance    AIC
- V10   1   481.73 1415.9
- V7    1   481.82 1416.0
- V2    1   481.88 1416.1
- V4    1   482.48 1416.7
<none>      480.96 1417.1
- V3    1   483.90 1418.2

Step:  AIC=1415.93
.outcome ~ V2 + V3 + V4 + V7

       Df Deviance    AIC
- V2    1   482.62 1414.8
- V7    1   482.63 1414.9
- V4    1   483.45 1415.7
<none>      481.73 1415.9
- V3    1   484.50 1416.8

Step:  AIC=1414.85
.outcome ~ V3 + V4 + V7

       Df Deviance    AIC
- V7    1   483.52 1413.8
- V4    1   484.24 1414.5
<none>      482.62 1414.8
- V3    1   485.22 1415.5

Step:  AIC=1413.78
.outcome ~ V3 + V4

       Df Deviance    AIC
- V4    1   485.22 1413.5
<none>      483.52 1413.8
- V3    1   486.06 1414.4

Step:  AIC=1413.55
.outcome ~ V3

       Df Deviance    AIC
<none>      485.22 1413.5
- V3    1   487.91 1414.3
Start:  AIC=1435.61
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V5    1   491.17 1433.7
- V2    1   491.20 1433.7
- V9    1   491.24 1433.7
- V8    1   491.24 1433.7
- V6    1   491.41 1433.9
- V3    1   492.11 1434.6
- V7    1   492.75 1435.3
<none>      491.11 1435.6
- V10   1   494.85 1437.4
- V4    1   494.87 1437.4

Step:  AIC=1433.66
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V2    1   491.26 1431.8
- V9    1   491.29 1431.8
- V8    1   491.31 1431.8
- V6    1   491.47 1432.0
- V3    1   492.21 1432.7
- V7    1   492.84 1433.4
<none>      491.17 1433.7
- V4    1   494.95 1435.5
- V10   1   494.95 1435.5

Step:  AIC=1431.76
.outcome ~ V3 + V4 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V9    1   491.39 1429.9
- V8    1   491.40 1429.9
- V6    1   491.56 1430.1
- V3    1   492.29 1430.8
- V7    1   492.91 1431.4
<none>      491.26 1431.8
- V4    1   495.01 1433.6
- V10   1   495.05 1433.6

Step:  AIC=1429.89
.outcome ~ V3 + V4 + V6 + V7 + V8 + V10

       Df Deviance    AIC
- V8    1   491.52 1428.0
- V6    1   491.71 1428.2
- V3    1   492.35 1428.9
- V7    1   493.01 1429.5
<none>      491.39 1429.9
- V4    1   495.16 1431.7
- V10   1   495.24 1431.8

Step:  AIC=1428.02
.outcome ~ V3 + V4 + V6 + V7 + V10

       Df Deviance    AIC
- V6    1   491.84 1426.3
- V3    1   492.51 1427.0
- V7    1   493.17 1427.7
<none>      491.52 1428.0
- V4    1   495.40 1430.0
- V10   1   495.45 1430.0

Step:  AIC=1426.35
.outcome ~ V3 + V4 + V7 + V10

       Df Deviance    AIC
- V3    1   492.89 1425.4
- V7    1   493.60 1426.2
<none>      491.84 1426.3
- V4    1   495.74 1428.3
- V10   1   495.74 1428.3

Step:  AIC=1425.42
.outcome ~ V4 + V7 + V10

       Df Deviance    AIC
- V7    1   494.61 1425.2
<none>      492.89 1425.4
- V4    1   496.65 1427.2
- V10   1   496.87 1427.5

Step:  AIC=1425.17
.outcome ~ V4 + V10

       Df Deviance    AIC
<none>      494.61 1425.2
- V4    1   498.25 1426.8
- V10   1   498.48 1427.1
Start:  AIC=1448.78
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V9    1   508.01 1446.9
- V8    1   508.09 1447.0
- V10   1   508.13 1447.0
- V5    1   508.14 1447.0
- V2    1   508.18 1447.0
- V4    1   508.22 1447.1
- V7    1   508.41 1447.3
- V3    1   509.24 1448.1
<none>      507.90 1448.8
- V6    1   510.10 1448.9

Step:  AIC=1446.89
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V10

       Df Deviance    AIC
- V8    1   508.21 1445.1
- V10   1   508.24 1445.1
- V5    1   508.24 1445.1
- V2    1   508.31 1445.2
- V4    1   508.34 1445.2
- V7    1   508.50 1445.4
- V3    1   509.48 1446.3
<none>      508.01 1446.9
- V6    1   510.18 1447.0

Step:  AIC=1445.08
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V10

       Df Deviance    AIC
- V5    1   508.41 1443.3
- V10   1   508.44 1443.3
- V2    1   508.50 1443.4
- V4    1   508.60 1443.5
- V7    1   508.68 1443.5
- V3    1   509.71 1444.5
<none>      508.21 1445.1
- V6    1   510.36 1445.2

Step:  AIC=1443.28
.outcome ~ V2 + V3 + V4 + V6 + V7 + V10

       Df Deviance    AIC
- V10   1   508.66 1441.5
- V2    1   508.72 1441.6
- V4    1   508.80 1441.7
- V7    1   508.86 1441.7
- V3    1   509.87 1442.7
<none>      508.41 1443.3
- V6    1   510.45 1443.3

Step:  AIC=1441.53
.outcome ~ V2 + V3 + V4 + V6 + V7

       Df Deviance    AIC
- V2    1   508.96 1439.8
- V4    1   509.09 1439.9
- V7    1   509.11 1440.0
- V3    1   510.07 1440.9
<none>      508.66 1441.5
- V6    1   510.82 1441.7

Step:  AIC=1439.82
.outcome ~ V3 + V4 + V6 + V7

       Df Deviance    AIC
- V4    1   509.36 1438.2
- V7    1   509.47 1438.3
- V3    1   510.31 1439.1
<none>      508.96 1439.8
- V6    1   511.19 1440.0

Step:  AIC=1438.21
.outcome ~ V3 + V6 + V7

       Df Deviance    AIC
- V7    1   509.92 1436.8
- V3    1   510.63 1437.5
<none>      509.36 1438.2
- V6    1   511.59 1438.4

Step:  AIC=1436.76
.outcome ~ V3 + V6

       Df Deviance    AIC
- V3    1   511.20 1436.0
<none>      509.92 1436.8
- V6    1   512.07 1436.9

Step:  AIC=1436.01
.outcome ~ V6

       Df Deviance    AIC
<none>      511.20 1436.0
- V6    1   513.42 1436.2
Start:  AIC=2148.43
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V5    1   744.39 2146.4
- V9    1   744.39 2146.4
- V10   1   744.43 2146.5
- V8    1   744.51 2146.6
- V7    1   744.81 2146.9
- V2    1   745.00 2147.1
- V6    1   745.45 2147.5
<none>      744.39 2148.4
- V4    1   746.70 2148.8
- V3    1   746.83 2148.9

Step:  AIC=2146.43
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V9    1   744.39 2144.4
- V10   1   744.43 2144.5
- V8    1   744.51 2144.6
- V7    1   744.81 2144.9
- V2    1   745.00 2145.1
- V6    1   745.45 2145.5
<none>      744.39 2146.4
- V4    1   746.70 2146.8
- V3    1   746.84 2146.9

Step:  AIC=2144.43
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V10

       Df Deviance    AIC
- V10   1   744.43 2142.5
- V8    1   744.51 2142.6
- V7    1   744.82 2142.9
- V2    1   745.01 2143.1
- V6    1   745.46 2143.5
<none>      744.39 2144.4
- V4    1   746.71 2144.8
- V3    1   746.91 2145.0

Step:  AIC=2142.48
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8

       Df Deviance    AIC
- V8    1   744.56 2140.6
- V7    1   744.85 2140.9
- V2    1   745.06 2141.1
- V6    1   745.48 2141.5
<none>      744.43 2142.5
- V4    1   746.72 2142.8
- V3    1   746.98 2143.1

Step:  AIC=2140.61
.outcome ~ V2 + V3 + V4 + V6 + V7

       Df Deviance    AIC
- V7    1   744.99 2139.0
- V2    1   745.17 2139.2
- V6    1   745.61 2139.7
<none>      744.56 2140.6
- V4    1   746.97 2141.0
- V3    1   747.12 2141.2

Step:  AIC=2139.04
.outcome ~ V2 + V3 + V4 + V6

       Df Deviance    AIC
- V2    1   745.56 2137.6
- V6    1   746.10 2138.2
<none>      744.99 2139.0
- V4    1   747.36 2139.4
- V3    1   747.51 2139.6

Step:  AIC=2137.62
.outcome ~ V3 + V4 + V6

       Df Deviance    AIC
- V6    1   746.70 2136.8
<none>      745.56 2137.6
- V4    1   747.86 2137.9
- V3    1   748.00 2138.1

Step:  AIC=2136.76
.outcome ~ V3 + V4

       Df Deviance    AIC
<none>      746.70 2136.8
- V4    1   749.02 2137.1
- V3    1   749.17 2137.2
Generalized Linear Model with Stepwise Feature Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.007435  0.003210255  0.7948808

[1] "Mon Mar 05 09:17:56 2018"
Independent Component Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  n.comp  RMSE       Rsquared      MAE        Selected
  1       0.9982042  0.0034689751  0.7899288  *       
  2       0.9982160  0.0030020850  0.7903117          
  3       1.0013995  0.0004851821  0.7930403          
  4       1.0036534  0.0004720845  0.7948240          
  5       1.0045092  0.0007197163  0.7947385          
  6       1.0057125  0.0014224114  0.7956186          
  7       1.0067098  0.0015947128  0.7970348          
  9       1.0101772  0.0013913804  0.7986530          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was n.comp = 1.
[1] "Mon Mar 05 09:18:14 2018"
Partial Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  ncomp  RMSE      Rsquared     MAE        Selected
  1      1.009065  0.001206158  0.7976930  *       
  2      1.010216  0.001459825  0.7987389          
  3      1.010160  0.001386382  0.7986385          
  4      1.010176  0.001391366  0.7986530          
  5      1.010177  0.001391364  0.7986529          
  6      1.010177  0.001391376  0.7986530          
  7      1.010177  0.001391380  0.7986530          
  9      1.010177  0.001391380  0.7986530          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 1.
[1] "Mon Mar 05 09:18:27 2018"
Error in MSEP(object) : could not find function "MSEP"
k-Nearest Neighbors 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  kmax  distance   kernel        RMSE      Rsquared      MAE        Selected
   12   1.6288940  epanechnikov  1.070806  0.0013004283  0.8520765          
   34   1.9724775  triangular    1.027996  0.0014808663  0.8155423          
   45   0.4548408  cos           1.021859  0.0028934704  0.8146619          
   58   1.6066376  triangular    1.015476  0.0005828620  0.8059803          
   77   1.5771551  gaussian      1.009659  0.0001299000  0.8011861          
   80   1.5758674  triweight     1.032568  0.0015535407  0.8206787          
   95   0.2636005  triweight     1.021991  0.0027777276  0.8176009          
  100   2.7737945  biweight      1.014475  0.0003120171  0.8041740          
  103   1.9121187  inv           1.003353  0.0008178956  0.7965658          
  127   1.3835541  biweight      1.012004  0.0006895702  0.8036808          
  130   2.7858893  cos           1.005734  0.0003129319  0.7978218          
  131   0.9080045  epanechnikov  1.007724  0.0008323671  0.8003169          
  133   2.6167128  triweight     1.016829  0.0004257899  0.8060926          
  141   1.1158267  cos           1.006859  0.0005538582  0.7996115          
  153   2.0654650  rectangular   1.001794  0.0014268966  0.7959396  *       
  177   2.4905912  biweight      1.006855  0.0001620314  0.7985465          
  192   2.3885654  cos           1.002671  0.0004968877  0.7955180          
  245   0.7872697  epanechnikov  1.003505  0.0010199028  0.7965789          
  247   0.4653791  inv           1.004167  0.0017261027  0.7965510          
  250   1.2995616  cos           1.002095  0.0004021187  0.7955461          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were kmax = 153, distance = 2.065465
 and kernel = rectangular.
[1] "Mon Mar 05 09:22:35 2018"
k-Nearest Neighbors 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  k    RMSE       Rsquared      MAE        Selected
   12  1.0413670  0.0023928643  0.8287172          
   34  1.0151574  0.0005651742  0.8013034          
   45  1.0092873  0.0000762549  0.8010837          
   58  1.0061642  0.0010507597  0.7982759          
   77  1.0046314  0.0011326119  0.7961602          
   80  1.0041859  0.0011037530  0.7963958          
   95  1.0037903  0.0004688058  0.7970957          
  100  1.0032310  0.0005426254  0.7974026          
  103  1.0022235  0.0011554649  0.7965745          
  127  1.0027795  0.0008809911  0.7959611          
  130  1.0016646  0.0010120997  0.7946596          
  131  1.0013239  0.0010137711  0.7945787          
  133  1.0012041  0.0019251623  0.7942288          
  141  1.0002882  0.0018762951  0.7936635          
  153  1.0000512  0.0017652575  0.7936088          
  177  1.0000880  0.0008379852  0.7934195          
  192  1.0008863  0.0005956433  0.7945336          
  245  1.0001714  0.0011622718  0.7932359          
  247  1.0001497  0.0010597426  0.7932084          
  250  0.9999053  0.0007754197  0.7929592  *       

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was k = 250.
[1] "Mon Mar 05 09:22:51 2018"
Polynomial Kernel Regularized Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  lambda        degree  RMSE          Rsquared      MAE           Selected
  1.664059e-05  2       58470.984589  0.0006882379  46504.639494          
  4.723071e-05  2       20600.825454  0.0006882386  16384.779075          
  7.592528e-05  1       25270.499404  0.0017442208  20377.018153          
  1.414189e-04  2        6880.202017  0.0006882408   5472.143012          
  3.381568e-04  2        2877.331683  0.0006882455   2288.478049          
  3.865368e-04  2        2517.196431  0.0006882467   2002.046079          
  7.716663e-04  1        2486.372837  0.0017442159   2004.890891          
  9.656060e-04  3         234.938573  0.0014671006    188.645473          
  1.104298e-03  2         881.088357  0.0006882638    700.774600          
  3.365542e-03  2         289.098066  0.0006883177    229.937202          
  3.926312e-03  3          57.787644  0.0014668354     46.385897          
  3.986218e-03  1         481.299108  0.0017441933    388.088481          
  4.384978e-03  3          51.745096  0.0014667945     41.533212          
  6.359744e-03  2         152.987867  0.0006883890    121.683506          
  1.115710e-02  3          20.358242  0.0014661930     16.326703          
  3.370368e-02  3           6.805801  0.0014642367      5.459670          
  6.841543e-02  3           3.464489  0.0014613643      2.796839          
  7.913189e-01  1           2.601771  0.0017386969      2.085767          
  8.373081e-01  1           2.479550  0.0017383774      1.986269          
  9.918415e-01  2           1.395732  0.0007116378      1.120840  *       

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 0.9918415 and degree = 2.
[1] "Mon Mar 05 09:25:35 2018"

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
-0.0357474203 -0.0619656177 -0.0474640200  0.0003973557 -0.0175229114 
           V7            V8            V9           V10 
-0.0346446784  0.0066901538  0.0119449442  0.0337743054 

 Quartiles of Marginal Effects:
 
             V2          V3          V4            V5          V6          V7
25% -0.04224093 -0.06826048 -0.05269751 -0.0032965247 -0.02033537 -0.03936883
50% -0.03654668 -0.06258920 -0.04809099  0.0002995724 -0.01725853 -0.03459448
75% -0.03038184 -0.05604691 -0.04262093  0.0039189902 -0.01441004 -0.02989912
             V8          V9        V10
25% 0.003183188 0.007057463 0.02811469
50% 0.006716311 0.012232413 0.03405973
75% 0.010677167 0.017226520 0.03982117

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.051394874 -0.063330493 -0.058795254 -0.013724327 -0.029702353 -0.050225124 
          V8           V9          V10 
 0.009250605  0.025492130  0.075708751 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.21065736 -0.19640034 -0.16122958 -0.11561916 -0.08819322 -0.17553997
50% -0.05498248 -0.06276141 -0.07273861 -0.01312290 -0.02578459 -0.04735623
75%  0.10877243  0.08994889  0.02823335  0.08750238  0.03955504  0.08190407
              V8          V9         V10
25% -0.087660195 -0.09502225 -0.04162775
50%  0.007609674  0.03345279  0.07180962
75%  0.114831973  0.15686125  0.20685629

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.017951097 -0.020847227 -0.019088445 -0.001391255  0.008831752 -0.028091579 
          V8           V9          V10 
 0.043198826  0.005624168  0.010849903 

 Quartiles of Marginal Effects:
 
              V2          V3          V4          V5           V6          V7
25% -0.174520931 -0.17204531 -0.15427959 -0.11932570 -0.132721910 -0.16273287
50%  0.004265447 -0.01232558 -0.01251022 -0.01520535  0.003487516 -0.02103286
75%  0.158474604  0.11502556  0.12172458  0.11799272  0.132540891  0.10760853
             V8           V9        V10
25% -0.11220765 -0.138787067 -0.1290632
50%  0.02244403 -0.006868107  0.0202238
75%  0.18303523  0.134498794  0.1538321

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.053687400 -0.069586265 -0.057372912 -0.002630742 -0.024944171 -0.052844487 
          V8           V9          V10 
 0.013197092  0.023751612  0.069089155 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5          V6          V7
25% -0.16799450 -0.17761146 -0.13956756 -0.075527352 -0.06430708 -0.15334790
50% -0.05600228 -0.07356238 -0.06004668 -0.005002219 -0.02424121 -0.05068837
75%  0.06051694  0.04264459  0.01914252  0.066421644  0.01544157  0.04806766
             V8          V9         V10
25% -0.05512462 -0.06414326 -0.03222094
50%  0.01489772  0.01901828  0.06417068
75%  0.08231818  0.11677242  0.17209972

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.040809249 -0.038704550 -0.033323361  0.002686539 -0.003716947 -0.045604312 
          V8           V9          V10 
 0.036846515 -0.007396588  0.073455171 

 Quartiles of Marginal Effects:
 
               V2          V3          V4            V5           V6
25% -0.4180104838 -0.37929164 -0.36018071 -0.2602567399 -0.300407513
50%  0.0009845855 -0.04433224 -0.04436943 -0.0005779084 -0.009129943
75%  0.3682429185  0.29938518  0.26671595  0.2519062353  0.360239490
             V7         V8          V9        V10
25% -0.34013038 -0.3130533 -0.29680291 -0.3064987
50% -0.04885302  0.0219357 -0.03052728  0.0875176
75%  0.24869052  0.3693382  0.29637665  0.4298394

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.050495689 -0.072131987 -0.056147085 -0.001995898 -0.023181812 -0.049640420 
          V8           V9          V10 
 0.011950534  0.020084092  0.058278654 

 Quartiles of Marginal Effects:
 
             V2            V3           V4           V5           V6
25% -0.12711927 -0.1447207703 -0.111130527 -0.049694887 -0.052306922
50% -0.05221327 -0.0744464074 -0.059592347 -0.004138712 -0.022370786
75%  0.02470477  0.0001678523 -0.003020014  0.042015628  0.007334762
             V7          V8          V9          V10
25% -0.10713756 -0.03271737 -0.03867224 -0.009343943
50% -0.05036743  0.01285153  0.01822163  0.056220244
75%  0.01029472  0.05690554  0.08114365  0.126624136

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.023917372 -0.042848088 -0.033894003  0.001973433 -0.012453413 -0.023791433 
          V8           V9          V10 
 0.003582311  0.010155615  0.022623273 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.02435765 -0.04328450 -0.03427694 0.001740009 -0.01262414 -0.02411964
50% -0.02401101 -0.04292275 -0.03398503 0.001967947 -0.01244507 -0.02380646
75% -0.02361807 -0.04241138 -0.03361671 0.002227446 -0.01225177 -0.02344694
             V8          V9        V10
25% 0.003346879 0.009832711 0.02226833
50% 0.003584767 0.010209193 0.02265165
75% 0.003841659 0.010483032 0.02300988

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.088701602 -0.032799817 -0.085170193  0.043176900 -0.017683546 -0.075882312 
          V8           V9          V10 
 0.009042224  0.013483584  0.152137059 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5          V6          V7
25% -0.54555428 -0.49602349 -0.47750632 -0.2832978 -0.36263801 -0.42413990
50%  0.01118328 -0.04836046 -0.07386551 -0.0238714 -0.01434642 -0.09175284
75%  0.43009678  0.45853477  0.30362898  0.3435004  0.33221360  0.26690596
             V8          V9        V10
25% -0.35806169 -0.40212593 -0.2625134
50%  0.02316672 -0.06047698  0.1569105
75%  0.36464707  0.40621390  0.5976931

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.094765514  0.014097966 -0.096876226  0.079806510 -0.023152320 -0.081159150 
          V8           V9          V10 
-0.008564279  0.017882707  0.210462890 

 Quartiles of Marginal Effects:
 
               V2          V3          V4          V5          V6         V7
25% -0.7259584704 -0.63764849 -0.63969881 -0.41091901 -0.49890335 -0.5500816
50% -0.0002081617 -0.02741171 -0.06137495 -0.02591601 -0.02805058 -0.1002984
75%  0.6078421494  0.66875598  0.44514255  0.53067302  0.45106706  0.3851995
             V8          V9        V10
25% -0.54067691 -0.53662783 -0.3962325
50%  0.04335741 -0.05989149  0.2102754
75%  0.48989083  0.59512374  0.8357831

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
-0.0190726737 -0.0214835376 -0.0203162069 -0.0009615734  0.0083315291 
           V7            V8            V9           V10 
-0.0296776316  0.0444906375  0.0062597429  0.0125880171 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5           V6          V7
25% -0.18597052 -0.18268897 -0.16285997 -0.12661909 -0.142719301 -0.17718402
50%  0.00357482 -0.01365493 -0.01379476 -0.01576623  0.004077259 -0.02339767
75%  0.16632624  0.12367137  0.13539735  0.12794309  0.144895982  0.11924484
             V8           V9         V10
25% -0.11848947 -0.143574753 -0.13329217
50%  0.02472704 -0.007308384  0.02190539
75%  0.19576454  0.142267515  0.16862032

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.09156625 -0.05066343 -0.08834580  0.04804089 -0.03190489 -0.08535546 
         V8          V9         V10 
 0.01477441  0.03130933  0.13321578 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5           V6         V7
25% -0.46616103 -0.46166640 -0.44890912 -0.22803298 -0.328970725 -0.3870142
50% -0.01874905 -0.07825052 -0.08515373 -0.03208617 -0.008816121 -0.1048514
75%  0.33423432  0.33956904  0.24872815  0.28762119  0.255216844  0.2037905
               V8          V9        V10
25% -0.2937417780 -0.33866055 -0.1871732
50%  0.0008279682 -0.01788916  0.1564407
75%  0.2749379759  0.36342216  0.4849140

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.073193233 -0.051624176 -0.071715801  0.012474892 -0.017908126 -0.069175079 
          V8           V9          V10 
 0.012399155  0.007187472  0.116574851 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.43751443 -0.43177085 -0.38449819 -0.23211916 -0.27589113 -0.34739708
50% -0.03262148 -0.05801183 -0.06926917 -0.02970581 -0.01361827 -0.06596016
75%  0.32658122  0.31553415  0.22726692  0.21663371  0.25423009  0.21631349
             V8          V9        V10
25% -0.25463237 -0.30118492 -0.1930564
50%  0.02803418 -0.03653435  0.1461284
75%  0.25032097  0.31101571  0.4542794

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.051876369 -0.070003739 -0.057063917 -0.004162206 -0.024383210 -0.051960082 
          V8           V9          V10 
 0.012524003  0.022716865  0.065341271 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5          V6          V7
25% -0.15543762 -0.16652654 -0.12923425 -0.069681957 -0.06075886 -0.13436398
50% -0.05329394 -0.07530619 -0.06107405 -0.007299682 -0.02174679 -0.05197811
75%  0.05291613  0.03040635  0.01112752  0.055412915  0.01494866  0.03526192
             V8          V9         V10
25% -0.04723727 -0.05816377 -0.02384576
50%  0.01350951  0.02075492  0.06117560
75%  0.07385084  0.10322647  0.16114156

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.05593131  0.02504935 -0.08999853  0.11176484  0.03021954 -0.07998062 
         V8          V9         V10 
-0.07723769 -0.08141619  0.25880894 

 Quartiles of Marginal Effects:
 
             V2          V3         V4          V5          V6          V7
25% -1.06054918 -0.93046619 -0.9867815 -0.60823152 -0.80222477 -0.86110077
50%  0.05274791 -0.05439237 -0.1118446  0.05770918  0.03602012 -0.06552889
75%  1.04194347  1.03650738  0.7701917  0.81152872  0.82002252  0.79085987
             V8          V9        V10
25% -0.98577171 -0.94667138 -0.6467184
50%  0.02439456 -0.01391469  0.1804244
75%  0.91771781  0.79885480  1.1313584

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.07257778 -0.06511445 -0.08139710  0.02178743 -0.04246916 -0.06999156 
         V8          V9         V10 
 0.01157106  0.02887403  0.10944018 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.38507367 -0.35462121 -0.34303951 -0.20642338 -0.25447069 -0.29481902
50% -0.02367776 -0.07322101 -0.08499205 -0.03189224 -0.01832596 -0.08631737
75%  0.26873285  0.23143798  0.16253977  0.20795087  0.18630426  0.15794397
              V8          V9        V10
25% -0.190656719 -0.25268940 -0.1273546
50% -0.005011897  0.01709345  0.1484290
75%  0.218439007  0.27062331  0.3995221

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.07465457 -0.06436019 -0.08246698  0.02495501 -0.04169014 -0.07211869 
         V8          V9         V10 
 0.01212105  0.02930310  0.11158936 

 Quartiles of Marginal Effects:
 
             V2         V3          V4          V5          V6          V7
25% -0.38548955 -0.3663274 -0.35405191 -0.21187574 -0.26103735 -0.29282491
50% -0.01530236 -0.0707177 -0.09575893 -0.02873647 -0.01795906 -0.09640171
75%  0.27003513  0.2398204  0.16900731  0.21673093  0.19252271  0.16310436
              V8          V9        V10
25% -0.194675417 -0.25965155 -0.1265458
50% -0.004143167  0.01079324  0.1571610
75%  0.225662239  0.28258572  0.4014098

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.045286842 -0.045843848 -0.039896237 -0.009339174 -0.009679096 -0.050825384 
          V8           V9          V10 
 0.025923634 -0.008654240  0.089135610 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5          V6          V7
25% -0.38306363 -0.36250638 -0.30474473 -0.225101597 -0.26090609 -0.32259329
50% -0.03555816 -0.06948614 -0.06471545  0.002228972 -0.02678411 -0.03139097
75%  0.33592620  0.28154750  0.23022225  0.221834860  0.29014017  0.18459468
              V8          V9        V10
25% -0.258731417 -0.28896702 -0.2262858
50%  0.006301086 -0.04084452  0.1095959
75%  0.302131232  0.25490701  0.3707320

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.045913263 -0.075041482 -0.054944983  0.002717607 -0.021486214 -0.042217020 
          V8           V9          V10 
 0.008839997  0.012579951  0.042453002 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5          V6          V7
25% -0.06058059 -0.08897070 -0.06671539 -0.005972138 -0.02806416 -0.05274539
50% -0.04609702 -0.07456227 -0.05566522  0.002549976 -0.02125898 -0.04237918
75% -0.03186522 -0.06158117 -0.04310703  0.011353100 -0.01443816 -0.03051668
              V8          V9        V10
25% 0.0006327996 0.001376809 0.02884068
50% 0.0086792546 0.012645145 0.04229759
75% 0.0174844265 0.023837072 0.05566340

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.033311997 -0.031208900 -0.034721711  0.007253718  0.001149858 -0.043590177 
          V8           V9          V10 
 0.048991724  0.007193663  0.042139169 

 Quartiles of Marginal Effects:
 
              V2          V3          V4          V5          V6         V7
25% -0.334163614 -0.32654600 -0.31058215 -0.21601810 -0.24431860 -0.2930108
50%  0.003856773 -0.03156957 -0.04491967 -0.01972435  0.01076845 -0.0441983
75%  0.313713274  0.25432225  0.23233437  0.20033891  0.29250782  0.2191824
            V8           V9         V10
25% -0.2498391 -0.252833708 -0.25287657
50%  0.0223612 -0.009009082  0.05309418
75%  0.3311409  0.252072925  0.35351270

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.013045210 -0.024167654 -0.019917578  0.001261131 -0.007162273 -0.013695654 
          V8           V9          V10 
 0.001716137  0.007091756  0.012883347 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5           V6          V7
25% -0.01310604 -0.02423893 -0.01997844 0.001225529 -0.007189749 -0.01374818
50% -0.01306145 -0.02417945 -0.01993442 0.001260272 -0.007164978 -0.01370306
75% -0.01300888 -0.02410881 -0.01987690 0.001298674 -0.007134805 -0.01364801
             V8          V9        V10
25% 0.001681335 0.007047567 0.01283370
50% 0.001718164 0.007100207 0.01289203
75% 0.001752053 0.007138671 0.01293971

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.010981242 -0.036971057 -0.074729278  0.007673409 -0.021017646 -0.049006711 
          V8           V9          V10 
 0.015986244 -0.013064691 -0.070854593 

 Quartiles of Marginal Effects:
 
              V2          V3          V4          V5          V6          V7
25% -0.015574977 -0.04147329 -0.07991017 0.002875227 -0.02518134 -0.05496949
50% -0.011511516 -0.03739946 -0.07516434 0.008113753 -0.02106818 -0.04953177
75% -0.006509772 -0.03311202 -0.06976175 0.012904573 -0.01719396 -0.04359915
            V8           V9         V10
25% 0.01210362 -0.016982155 -0.07583462
50% 0.01638246 -0.013168933 -0.07116687
75% 0.02026916 -0.009181964 -0.06665978

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.02317297 -0.04150431 -0.08513035 -0.00204083 -0.02914953 -0.06015048 
         V8          V9         V10 
 0.03840657 -0.02588659 -0.08250006 

 Quartiles of Marginal Effects:
 
             V2         V3          V4           V5          V6          V7
25% -0.13014836 -0.1436310 -0.18514893 -0.107444240 -0.11671563 -0.17606106
50% -0.03372538 -0.0407981 -0.08380575  0.004057679 -0.03279729 -0.05634207
75%  0.09063960  0.0599038  0.01887167  0.108140316  0.06209274  0.06482392
             V8          V9         V10
25% -0.06291489 -0.12542064 -0.19393816
50%  0.02805694 -0.03135857 -0.06720648
75%  0.13837784  0.08734763  0.03222075

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0141838562 -0.0214746673 -0.0339936934 -0.0429653083  0.0124300946 
           V7            V8            V9           V10 
-0.0326025233 -0.0008622832 -0.0200244669 -0.0503821889 

 Quartiles of Marginal Effects:
 
              V2          V3          V4          V5           V6           V7
25% -0.122928835 -0.14002588 -0.17267702 -0.18621433 -0.132350310 -0.160904856
50%  0.008330264 -0.00680879 -0.01089361 -0.01927476 -0.003487854 -0.007244974
75%  0.132362768  0.11115434  0.10565156  0.10003345  0.131886638  0.109005780
            V8          V9         V10
25% -0.1569365 -0.14692934 -0.19156126
50%  0.0109815 -0.01103475 -0.02344144
75%  0.1480046  0.12128724  0.09911071

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.026347607 -0.047897075 -0.083490610  0.005410433 -0.033031521 -0.070022451 
          V8           V9          V10 
 0.028793940 -0.021292318 -0.084620243 

 Quartiles of Marginal Effects:
 
             V2          V3           V4           V5          V6          V7
25% -0.10668602 -0.12093613 -0.166768058 -0.072009818 -0.08889945 -0.15869172
50% -0.03059027 -0.04953137 -0.084077081  0.008634862 -0.03847625 -0.07288932
75%  0.05589564  0.01813950  0.003953289  0.084387041  0.02747631  0.01420095
             V8          V9          V10
25% -0.04263443 -0.09612911 -0.169666254
50%  0.03247886 -0.02396891 -0.073566949
75%  0.09963130  0.06010267 -0.009331827

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0506381489 -0.0188133990 -0.0391498866 -0.0425005054  0.0009364588 
           V7            V8            V9           V10 
-0.0504944675  0.0379188565 -0.0453367587 -0.1436543327 

 Quartiles of Marginal Effects:
 
             V2           V3           V4          V5           V6          V7
25% -0.25809163 -0.279067217 -0.409508715 -0.35298340 -0.257442419 -0.39722322
50%  0.02512809 -0.004148154 -0.005292849 -0.05160699 -0.009092284 -0.06353549
75%  0.35055053  0.260792269  0.308693536  0.29058119  0.271988160  0.29983574
             V8          V9        V10
25% -0.33028202 -0.33290485 -0.4869734
50%  0.02857875 -0.02514586 -0.1290151
75%  0.44494498  0.26909551  0.2049314

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.022789567 -0.046187102 -0.087132674  0.006593238 -0.029839867 -0.066189843 
          V8           V9          V10 
 0.024388968 -0.019802295 -0.086114818 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5           V6           V7
25% -0.07599750 -0.093192929 -0.14178744 -0.04935539 -0.068958919 -0.126993996
50% -0.02568279 -0.048145615 -0.08819938  0.01191316 -0.032081038 -0.069542602
75%  0.03151185 -0.001223447 -0.02951935  0.06145161  0.008359778 -0.008195688
             V8          V9         V10
25% -0.02163894 -0.06679814 -0.14027991
50%  0.02593869 -0.02007753 -0.08032052
75%  0.06746314  0.03173461 -0.03566177

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.006970302 -0.025064682 -0.049760884  0.008412620 -0.015194166 -0.033570152 
          V8           V9          V10 
 0.012772626 -0.008406160 -0.048367273 

 Quartiles of Marginal Effects:
 
              V2          V3          V4          V5          V6          V7
25% -0.007271690 -0.02537276 -0.05017041 0.008126988 -0.01546730 -0.03398696
50% -0.007007243 -0.02510866 -0.04979522 0.008448173 -0.01520389 -0.03365295
75% -0.006678368 -0.02482371 -0.04941050 0.008775081 -0.01493927 -0.03324314
            V8           V9         V10
25% 0.01254675 -0.008664034 -0.04875325
50% 0.01281824 -0.008421316 -0.04846137
75% 0.01306353 -0.008159689 -0.04806061

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0768869826  0.0145166663 -0.0571520767 -0.0196952905 -0.0006815192 
           V7            V8            V9           V10 
-0.0185698787  0.1131110710 -0.0389766841 -0.2030297580 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5           V6          V7
25% -0.33559663 -0.31635088 -0.51130443 -0.43510663 -0.314746924 -0.42813446
50%  0.04234925  0.01430385 -0.06675532 -0.05100615 -0.002747214 -0.07811183
75%  0.51001182  0.36644456  0.39754332  0.35288740  0.350169846  0.33643589
            V8           V9        V10
25% -0.4199154 -0.417311336 -0.6325274
50%  0.1014235 -0.003032118 -0.1681618
75%  0.5764271  0.333170827  0.2825239

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.146678517  0.025497028 -0.039909214 -0.035505021 -0.003191011  0.007390831 
          V8           V9          V10 
 0.122333076 -0.050712419 -0.321394299 

 Quartiles of Marginal Effects:
 
            V2          V3          V4          V5          V6          V7
25% -0.4337382 -0.43621772 -0.68119510 -0.59533478 -0.46969823 -0.61576163
50%  0.0965231  0.07325403 -0.09390078 -0.09279798  0.02656265 -0.07531213
75%  0.7234029  0.52580593  0.55920607  0.42483029  0.49463312  0.57474689
             V8          V9        V10
25% -0.61744023 -0.54681352 -0.9673530
50%  0.06154784  0.01351746 -0.2454615
75%  0.75442497  0.48889830  0.4257083

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0155355930 -0.0219044536 -0.0345699899 -0.0439684888  0.0127005403 
           V7            V8            V9           V10 
-0.0345782514 -0.0005397671 -0.0210268695 -0.0535108297 

 Quartiles of Marginal Effects:
 
              V2           V3          V4          V5           V6           V7
25% -0.131199662 -0.146712046 -0.18347057 -0.19737925 -0.138116756 -0.174202442
50%  0.009649029 -0.009109927 -0.01137413 -0.02158414 -0.002405535 -0.007651038
75%  0.139241799  0.120154990  0.11341224  0.10603301  0.140381290  0.114779868
             V8          V9         V10
25% -0.16757516 -0.14931807 -0.20492880
50%  0.01374921 -0.01218658 -0.02642037
75%  0.15763670  0.12761818  0.10747292

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.032466333  0.023464811 -0.067566759  0.007736825  0.015281285 -0.006588959 
          V8           V9          V10 
 0.095993213 -0.016891287 -0.135169132 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5           V6          V7
25% -0.31604973 -0.23385342 -0.40234792 -0.3384339 -0.278183512 -0.32189243
50%  0.01002762 -0.01532946 -0.06700113 -0.0267508 -0.003936705 -0.02109293
75%  0.37414152  0.29608472  0.31031165  0.3476820  0.297555158  0.28162152
             V8          V9        V10
25% -0.30215509 -0.29148407 -0.4426105
50%  0.06376268 -0.01375681 -0.1314346
75%  0.49517801  0.27942214  0.2331250

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
 0.03748546 -0.00262143 -0.06959314 -0.01586310 -0.01030791 -0.03108700 
         V8          V9         V10 
 0.09443459 -0.03635503 -0.14474581 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.27790062 -0.25308231 -0.41230598 -0.32303765 -0.25763439 -0.33206151
50%  0.01365887 -0.01101176 -0.08591393 -0.03087362 -0.02686142 -0.05453135
75%  0.35056478  0.24506545  0.28937053  0.29671470  0.26413293  0.24145363
             V8          V9        V10
25% -0.28172657 -0.31011487 -0.4712608
50%  0.08651249 -0.02346702 -0.1289847
75%  0.46336204  0.26156915  0.1882469

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.024798525 -0.046991343 -0.085798164  0.004826169 -0.031758441 -0.067833076 
          V8           V9          V10 
 0.027615347 -0.021332583 -0.084694659 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6           V7
25% -0.09673824 -0.10958995 -0.15790592 -0.06699911 -0.08325645 -0.148848714
50% -0.02887889 -0.04867310 -0.08594052  0.01022002 -0.03636333 -0.070637917
75%  0.05106043  0.01252042 -0.01026181  0.07714926  0.02268978  0.009947411
             V8          V9         V10
25% -0.03546020 -0.08687434 -0.15768908
50%  0.03087305 -0.02241642 -0.07474605
75%  0.08706918  0.05176651 -0.01655819

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.228067593  0.042452474 -0.005449672  0.011029304 -0.013400291  0.052592135 
          V8           V9          V10 
 0.031769168 -0.138275288 -0.487566234 

 Quartiles of Marginal Effects:
 
            V2         V3          V4          V5          V6          V7
25% -0.7309806 -0.7161485 -0.92091885 -0.81071470 -0.70110246 -0.92670476
50%  0.1546125  0.1849453 -0.04206165 -0.07863925  0.02247563 -0.05201739
75%  1.0748459  0.8605701  0.92475475  0.73698306  0.73256642  0.96638611
             V8          V9        V10
25% -1.09296006 -0.85434984 -1.4637958
50%  0.05030814 -0.02520012 -0.4250705
75%  1.05890377  0.70086314  0.6210876

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.001140502  0.008511362 -0.077102080  0.007992718  0.004559235 -0.004624213 
          V8           V9          V10 
 0.076287686 -0.020150376 -0.099869065 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6           V7
25% -0.27294714 -0.19828161 -0.35080793 -0.25861031 -0.25978473 -0.260462958
50% -0.01330514 -0.02460737 -0.09133383 -0.01153721 -0.03156809  0.001073703
75%  0.25656044  0.20434993  0.21767089  0.26690263  0.22649730  0.235143474
             V8          V9         V10
25% -0.21251249 -0.25516298 -0.33717255
50%  0.05110303 -0.02134103 -0.09212714
75%  0.39297239  0.22964099  0.14756326

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.001464401  0.010799864 -0.076008619  0.008818231  0.006386510 -0.003833537 
          V8           V9          V10 
 0.078054386 -0.019422681 -0.102114740 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6            V7
25% -0.28140320 -0.20774821 -0.35523761 -0.26525085 -0.26472644 -2.626090e-01
50% -0.01347868 -0.02041912 -0.09329121 -0.01130222 -0.02494766  4.397488e-05
75%  0.26825212  0.21318911  0.22541237  0.28106461  0.23599473  2.402081e-01
             V8          V9         V10
25% -0.23244052 -0.26323295 -0.35044072
50%  0.05410355 -0.02051646 -0.09569829
75%  0.40276180  0.22977075  0.15292059

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
 0.03913478 -0.02004523 -0.05442715 -0.03612440 -0.01320870 -0.04848544 
         V8          V9         V10 
 0.06353215 -0.04402394 -0.13239236 

 Quartiles of Marginal Effects:
 
             V2         V3          V4          V5         V6          V7
25% -0.24968658 -0.2533408 -0.37666586 -0.32204892 -0.2442016 -0.35698850
50%  0.01996224 -0.0237167 -0.06341102 -0.05636317 -0.0219492 -0.07288045
75%  0.30813190  0.2399823  0.26070748  0.25728477  0.2329526  0.25534348
             V8          V9        V10
25% -0.25991081 -0.30492213 -0.4355667
50%  0.05164899 -0.02342173 -0.1438760
75%  0.42751570  0.21857691  0.1813851

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.015910326 -0.044359484 -0.089727962  0.009348362 -0.024882365 -0.060799638 
          V8           V9          V10 
 0.017909581 -0.016526122 -0.086956488 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5          V6          V7
25% -0.02646261 -0.05381706 -0.10083537 -0.001838946 -0.03420244 -0.07419131
50% -0.01614816 -0.04456189 -0.08964577  0.009816342 -0.02500604 -0.06144957
75% -0.00543842 -0.03530676 -0.07769125  0.020801930 -0.01632801 -0.04815640
             V8           V9         V10
25% 0.008438283 -0.025268009 -0.09696110
50% 0.018062378 -0.016385081 -0.08657227
75% 0.027236107 -0.006926784 -0.07698063

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.039336808 -0.020443469 -0.036270716 -0.045639768  0.012764822 -0.051334909 
          V8           V9          V10 
 0.008808912 -0.035790018 -0.107818328 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5            V6         V7
25% -0.23528019 -0.259201100 -0.31323673 -0.31465028 -0.2192680666 -0.3411245
50%  0.02858694 -0.005613491 -0.02177777 -0.05153919 -0.0007739234 -0.0374518
75%  0.28103701  0.240704402  0.24409349  0.23485013  0.2375553967  0.2308186
             V8          V9         V10
25% -0.30292741 -0.26372046 -0.37703581
50%  0.03745824 -0.02196316 -0.09734553
75%  0.32281708  0.22448420  0.18156032

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.003661801 -0.014141833 -0.027338659  0.005927147 -0.009130601 -0.018928614 
          V8           V9          V10 
 0.008326729 -0.004447948 -0.026931148 

 Quartiles of Marginal Effects:
 
              V2          V3          V4          V5           V6          V7
25% -0.003705674 -0.01418994 -0.02740507 0.005888418 -0.009173386 -0.01899370
50% -0.003665336 -0.01415077 -0.02734597 0.005933330 -0.009133999 -0.01894323
75% -0.003625105 -0.01410564 -0.02728448 0.005978047 -0.009096247 -0.01888590
             V8           V9         V10
25% 0.008298224 -0.004486258 -0.02699311
50% 0.008336152 -0.004452264 -0.02694930
75% 0.008369689 -0.004414038 -0.02688700

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.01984272 -0.04194263 -0.02162002 -0.01992110 -0.05289396  0.02781643 
         V8          V9         V10 
 0.01599520  0.01326817  0.01802318 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6         V7
25% -0.02539633 -0.04835207 -0.02397298 -0.02506900 -0.05757120 0.02123773
50% -0.01965582 -0.04312292 -0.02165850 -0.01986746 -0.05267068 0.02828425
75% -0.01376293 -0.03602781 -0.01929644 -0.01531759 -0.04773262 0.03363855
            V8          V9        V10
25% 0.01324136 0.007984333 0.01414188
50% 0.01600681 0.012879237 0.01835355
75% 0.01913210 0.019000318 0.02198140

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.026472202 -0.049920087 -0.019402743 -0.044072089 -0.063921857  0.034522830 
          V8           V9          V10 
 0.005385249  0.024517087  0.002995950 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.14170358 -0.24274716 -0.09522302 -0.16400965 -0.18779174 -0.10949722
50% -0.01941125 -0.03695704 -0.01407027 -0.06099590 -0.05988521  0.03351477
75%  0.10397337  0.13546785  0.06327852  0.06137651  0.06166089  0.16997123
              V8           V9          V10
25% -0.091128937 -0.148008994 -0.076923846
50%  0.007353303  0.008097974  0.002360863
75%  0.092984473  0.192789802  0.086278201

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.019920192 -0.015598441 -0.034678194 -0.058063372 -0.016195468  0.018600667 
          V8           V9          V10 
 0.005955286  0.004721934 -0.031002642 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.15219507 -0.15686219 -0.18163114 -0.16745783 -0.12889798 -0.13564133
50% -0.01231551 -0.01350785 -0.01824128 -0.02350272 -0.01089563  0.02039811
75%  0.11396195  0.12868647  0.09569645  0.09543240  0.12842515  0.17425817
              V8            V9           V10
25% -0.135368333 -0.1277785105 -0.1313243035
50%  0.005933029 -0.0003164751  0.0005619897
75%  0.141447683  0.1523826034  0.1133194889

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.033763543 -0.059520766 -0.020907681 -0.028696038 -0.062867931  0.038327396 
          V8           V9          V10 
-0.001434375  0.015060961  0.013120523 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.12340551 -0.19820251 -0.06815908 -0.12999992 -0.14246783 -0.07688740
50% -0.02985974 -0.06357432 -0.02395961 -0.02228979 -0.06282274  0.04028684
75%  0.06276920  0.06647995  0.02738245  0.06071661  0.03634480  0.14713822
               V8         V9         V10
25% -0.0584255653 -0.1131709 -0.05065073
50% -0.0005470226  0.0055723  0.01374257
75%  0.0551483466  0.1421512  0.08131048

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.031418752 -0.020708007 -0.044634921 -0.099987167 -0.015296010  0.059793762 
          V8           V9          V10 
 0.012811820  0.016061129 -0.001573605 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5            V6          V7
25% -0.33352206 -0.30458080 -0.38339132 -0.3973809 -0.3074526591 -0.31809702
50% -0.02229547 -0.02902349 -0.05608977 -0.1020257  0.0002467471  0.08771896
75%  0.26542908  0.31386621  0.21824430  0.2188327  0.2992131288  0.42132604
             V8          V9          V10
25% -0.28546764 -0.32420181 -0.263725656
50%  0.01114957  0.03521439  0.001584769
75%  0.30063022  0.35311356  0.274658070

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.029397036 -0.055888064 -0.022350898 -0.026749393 -0.063033257  0.035534279 
          V8           V9          V10 
 0.006651787  0.015014238  0.014870395 

 Quartiles of Marginal Effects:
 
             V2          V3           V4          V5            V6          V7
25% -0.09100606 -0.14175123 -0.052250901 -0.09195394 -0.1174842780 -0.04200393
50% -0.02606186 -0.05976456 -0.022382037 -0.02479642 -0.0616539219  0.03948166
75%  0.03647549  0.02122499  0.006743147  0.03044883 -0.0008629288  0.10549202
              V8           V9         V10
25% -0.030083450 -0.061901342 -0.02699557
50%  0.006936215  0.008190335  0.01532666
75%  0.042436790  0.092295529  0.06174716

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.01419580 -0.02940437 -0.01535477 -0.01065094 -0.03738537  0.01944029 
         V8          V9         V10 
 0.01153341  0.01009076  0.01390533 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6         V7
25% -0.01456917 -0.02981505 -0.01553286 -0.01095730 -0.03773100 0.01905656
50% -0.01418267 -0.02950080 -0.01538265 -0.01066205 -0.03741367 0.01947062
75% -0.01380948 -0.02907539 -0.01518094 -0.01036533 -0.03704838 0.01981695
            V8          V9        V10
25% 0.01135758 0.009761277 0.01366487
50% 0.01156974 0.010071688 0.01392650
75% 0.01174497 0.010452043 0.01418370

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.004733377 -0.023412415 -0.018726509 -0.060455511 -0.032389267  0.154488271 
          V8           V9          V10 
 0.010491088  0.071966504  0.021513805 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5          V6         V7
25% -0.42131369 -0.42165437 -0.47100908 -0.5193309 -0.40220334 -0.3009708
50% -0.03333557  0.01365331 -0.06343211 -0.1595866  0.02305403  0.1390655
75%  0.40825650  0.34754681  0.36746694  0.3376484  0.39035212  0.6262399
               V8          V9          V10
25% -0.3726120937 -0.39692567 -0.347482036
50%  0.0004346104  0.02461899 -0.001219119
75%  0.4181331719  0.50853596  0.377786244

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.01319986 -0.04147935 -0.01527850 -0.07729746 -0.02451542  0.22448786 
         V8          V9         V10 
 0.01295611  0.11210252  0.02917885 

 Quartiles of Marginal Effects:
 
            V2           V3          V4         V5          V6         V7
25% -0.5618641 -0.558028485 -0.61646420 -0.6616582 -0.48637613 -0.3436987
50% -0.0716707  0.005416651 -0.05143095 -0.2238964  0.04623091  0.1475239
75%  0.5393137  0.440353789  0.53214566  0.4630772  0.51893521  0.8412736
             V8          V9        V10
25% -0.48731507 -0.52975128 -0.4776884
50%  0.04937953  0.02240691 -0.0202505
75%  0.51749686  0.68428208  0.4873922

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.020739496 -0.016959124 -0.036364550 -0.060413887 -0.017406727  0.019992245 
          V8           V9          V10 
 0.006122861  0.004998731 -0.031603953 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5          V6          V7
25% -0.16205432 -0.16596181 -0.19199780 -0.1779427 -0.14106620 -0.14096120
50% -0.01176453 -0.01463031 -0.02234839 -0.0265770 -0.01041246  0.02208986
75%  0.12205425  0.13581218  0.10695997  0.1011301  0.13644688  0.18554718
              V8           V9           V10
25% -0.143384911 -0.137355930 -0.1345631810
50%  0.006702694  0.001743324  0.0009142217
75%  0.151252844  0.159010132  0.1230409103

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.028416449 -0.006623402 -0.007307868 -0.040565078 -0.059654972  0.133072929 
          V8           V9          V10 
 0.012713188  0.081144791 -0.006834534 

 Quartiles of Marginal Effects:
 
              V2           V3          V4          V5           V6          V7
25% -0.306384329 -0.385566683 -0.39528088 -0.43381244 -0.399756374 -0.23859729
50% -0.000135034  0.009742896 -0.03496583 -0.09635335  0.006496144  0.09457579
75%  0.327940184  0.336914214  0.34904518  0.27305665  0.330293475  0.49686996
             V8          V9         V10
25% -0.28763285 -0.37082152 -0.29413454
50%  0.02062223  0.05420879 -0.01150253
75%  0.33817215  0.47788895  0.28932129

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.003172236 -0.018754080 -0.020085077 -0.059856283 -0.039866133  0.100173686 
          V8           V9          V10 
 0.014426579  0.047447048  0.012416701 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5          V6         V7
25% -0.32895619 -0.36582142 -0.37519024 -0.4108014 -0.34669425 -0.2687422
50% -0.02840294  0.01004404 -0.03915905 -0.1232617  0.01086467  0.1058425
75%  0.32962798  0.31551301  0.30183639  0.2234310  0.29710896  0.4611566
             V8          V9          V10
25% -0.28058729 -0.33988109 -0.265268628
50%  0.01651363  0.04390451  0.008093051
75%  0.33013298  0.40683458  0.295479236

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.031687182 -0.057188242 -0.021365363 -0.029971204 -0.062684432  0.036606119 
          V8           V9          V10 
 0.002320595  0.015487332  0.013014438 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.11353664 -0.18180808 -0.06576105 -0.11858388 -0.13381603 -0.06714506
50% -0.02827128 -0.06242177 -0.02251296 -0.02654575 -0.05977354  0.03918911
75%  0.05716731  0.05371649  0.02240726  0.04905913  0.02419327  0.13370146
              V8           V9         V10
25% -0.050021137 -0.094646541 -0.04370302
50%  0.002972253  0.005488566  0.01268203
75%  0.050641832  0.128439580  0.07303134

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.028895164 -0.005558885 -0.073130267 -0.194353696 -0.011781018  0.193319770 
          V8           V9          V10 
 0.106968758  0.118464708  0.028515422 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5          V6         V7
25% -0.74015834 -0.77365345 -0.90860884 -1.0773466 -0.87336254 -0.7181914
50% -0.06165772 -0.01763714 -0.08264298 -0.1984833  0.05956901  0.1761428
75%  0.62076059  0.78757327  0.72116392  0.6518399  0.76418062  1.0041650
            V8          V9         V10
25% -0.6579417 -0.70786410 -0.86870027
50%  0.1385586  0.06578163 -0.09190262
75%  0.8534399  0.93209725  0.82348795

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.028074146 -0.009849697 -0.006981421 -0.039085871 -0.071724354  0.079866804 
          V8           V9          V10 
 0.017568025  0.068374866 -0.021373596 

 Quartiles of Marginal Effects:
 
               V2           V3          V4         V5          V6          V7
25% -0.2565692191 -0.324118719 -0.31033538 -0.3373661 -0.35324700 -0.19475919
50%  0.0005096549 -0.002267359 -0.02174285 -0.0923945 -0.04103425  0.08819299
75%  0.3025094234  0.312396527  0.28287825  0.1987264  0.23401997  0.36718948
             V8          V9         V10
25% -0.24967230 -0.27459470 -0.25815103
50%  0.04233846  0.04015892 -0.01206077
75%  0.29446826  0.39389875  0.21731402

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.029337725 -0.008719386 -0.006643770 -0.038599857 -0.070974125  0.085058503 
          V8           V9          V10 
 0.017015683  0.069971255 -0.020731823 

 Quartiles of Marginal Effects:
 
              V2          V3          V4          V5          V6          V7
25% -0.260683642 -0.32981406 -0.32232640 -0.35744763 -0.35968044 -0.20297997
50% -0.001047083  0.00115383 -0.02030229 -0.08929221 -0.03908808  0.08817892
75%  0.304694563  0.31614862  0.29215491  0.21482563  0.24502429  0.37770589
             V8          V9         V10
25% -0.25560633 -0.28688099 -0.26680433
50%  0.04575998  0.04819067 -0.01463291
75%  0.30601619  0.40660275  0.22402590

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.02416741 -0.01938676 -0.03238003 -0.08573851 -0.02374450  0.06525068 
         V8          V9         V10 
 0.01354900  0.01601662  0.01285129 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6         V7
25% -0.32966090 -0.30947728 -0.32878108 -0.39161796 -0.29398920 -0.2481317
50% -0.02114446 -0.01404766 -0.03400949 -0.09917978  0.01271196  0.0978223
75%  0.26241735  0.25208982  0.22688593  0.19304604  0.27519970  0.3701262
             V8          V9          V10
25% -0.27076161 -0.30468776 -0.238896726
50% -0.01075566  0.04304515  0.002755398
75%  0.29995969  0.34146753  0.256577121

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.02439303 -0.05193943 -0.02502306 -0.02239982 -0.06438243  0.03409008 
         V8          V9         V10 
 0.01721486  0.01478678  0.02024286 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6         V7
25% -0.03724903 -0.06744484 -0.03067795 -0.03482424 -0.07561998 0.01916845
50% -0.02383667 -0.05247575 -0.02512499 -0.02166828 -0.06342460 0.03432003
75% -0.01044002 -0.03772272 -0.01967837 -0.01160327 -0.05327327 0.04770098
            V8          V9        V10
25% 0.01094491 0.001793059 0.01128926
50% 0.01713164 0.013578010 0.02024659
75% 0.02375944 0.027361322 0.02873856

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.03167169 -0.02714015 -0.05215806 -0.09114228 -0.02445552  0.04402068 
         V8          V9         V10 
 0.00670013  0.01105056 -0.02711838 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.27797864 -0.31059508 -0.32543440 -0.33195901 -0.25551228 -0.27495296
50% -0.02746087 -0.02963103 -0.04610948 -0.05465257 -0.01009909  0.05743625
75%  0.20988993  0.25477304  0.20110588  0.17984360  0.24568627  0.33371302
             V8          V9         V10
25% -0.24641632 -0.26276832 -0.21563155
50%  0.01045502  0.01037397 -0.01069368
75%  0.25324138  0.28341166  0.22841567

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.008266755 -0.016738106 -0.008866498 -0.005080421 -0.021315374  0.010977379 
          V8           V9          V10 
 0.006623708  0.006251689  0.008331426 

 Quartiles of Marginal Effects:
 
              V2          V3           V4           V5          V6         V7
25% -0.008318608 -0.01680034 -0.008895667 -0.005123479 -0.02137246 0.01092396
50% -0.008268126 -0.01675571 -0.008871689 -0.005083166 -0.02132222 0.01098036
75% -0.008216306 -0.01669747 -0.008840306 -0.005040249 -0.02126559 0.01103043
             V8          V9         V10
25% 0.006597869 0.006204478 0.008297671
50% 0.006631672 0.006254199 0.008333730
75% 0.006654995 0.006301500 0.008374065

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.011212391 -0.023591328 -0.024003245  0.001164771 -0.016073779 -0.010170540 
          V8           V9          V10 
 0.006718737  0.003351231 -0.002394273 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.01126704 -0.02366955 -0.02406389 0.001127201 -0.01612919 -0.01023532
50% -0.01122160 -0.02360500 -0.02401792 0.001169487 -0.01607780 -0.01017889
75% -0.01116433 -0.02352828 -0.02395677 0.001211342 -0.01602035 -0.01011191
             V8          V9          V10
25% 0.006687317 0.003304713 -0.002452954
50% 0.006726701 0.003358411 -0.002398899
75% 0.006759068 0.003397819 -0.002340270
Radial Basis Function Kernel Regularized Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  lambda        sigma        RMSE      Rsquared      MAE        Selected
  1.664059e-05    67.319565  2.314403  0.0117275357  1.5866870          
  4.723071e-05    23.443910  2.839628  0.0086942826  1.9743926          
  7.592528e-05  2474.831282  1.053215  0.0003297272  0.8348471          
  1.414189e-04    72.080290  1.653630  0.0117229911  1.2205240          
  3.381568e-04    78.908997  1.481071  0.0110248606  1.1241009          
  3.865368e-04    79.221565  1.460345  0.0108649872  1.1116200          
  7.716663e-04  4451.770028  1.010902  0.0009291518  0.7996202          
  9.656060e-04     2.002661  1.068484  0.0007994799  0.8482425          
  1.104298e-03    28.216838  1.682167  0.0108561297  1.2541602          
  3.365542e-03   142.975345  1.102098  0.0017066361  0.8702272          
  3.926312e-03     1.929661  1.063083  0.0007812590  0.8441514          
  3.986218e-03   615.640638  1.028291  0.0002453237  0.8154114          
  4.384978e-03     3.243767  1.164228  0.0013184725  0.9240718          
  6.359744e-03   325.260272  1.044305  0.0002795593  0.8277340          
  1.115710e-02    17.621652  1.391838  0.0091636133  1.0839192          
  3.370368e-02     4.777621  1.224913  0.0025081457  0.9753294          
  6.841543e-02     6.535008  1.219150  0.0039460310  0.9713848          
  7.913189e-01   891.881246  1.003677  0.0013230582  0.7934380          
  8.373081e-01  2396.042449  1.001240  0.0013001613  0.7919736  *       
  9.918415e-01   185.033871  1.007290  0.0011310537  0.7963529          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 0.8373081 and sigma
 = 2396.042.
[1] "Mon Mar 05 09:35:56 2018"
Least Angle Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  fraction    RMSE       Rsquared     MAE        Selected
  0.04423375  0.9999893  0.004394509  0.7912986  *       
  0.13484489  1.0006419  0.003914077  0.7911088          
  0.17607728  1.0009823  0.004186102  0.7911840          
  0.23010151  1.0018116  0.003990703  0.7917652          
  0.30582363  1.0025733  0.003330721  0.7922046          
  0.31743816  1.0026910  0.003229622  0.7922677          
  0.37748590  1.0033435  0.002793505  0.7926108          
  0.39695999  1.0035692  0.002678019  0.7927446          
  0.40861725  1.0037072  0.002613907  0.7928273          
  0.50541101  1.0047735  0.002119048  0.7935466          
  0.51879696  1.0049104  0.002063061  0.7936674          
  0.52011220  1.0049241  0.002057708  0.7936794          
  0.52839347  1.0050104  0.002024593  0.7937550          
  0.56068793  1.0053576  0.001904612  0.7940701          
  0.60951029  1.0058768  0.001765790  0.7946079          
  0.70553546  1.0069258  0.001619950  0.7956202          
  0.76703082  1.0075625  0.001560433  0.7961930          
  0.97967031  1.0099296  0.001404124  0.7984124          
  0.98457705  1.0099890  0.001401020  0.7984705          
  0.99928846  1.0101685  0.001391821  0.7986446          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was fraction = 0.04423375.
[1] "Mon Mar 05 09:36:10 2018"
Least Angle Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  step  RMSE       Rsquared     MAE        Selected
  1     0.9995283          NaN  0.7913185  *       
  2     0.9996996  0.007337152  0.7912060          
  3     1.0006095  0.004024629  0.7909430          
  4     1.0018715  0.004192980  0.7918283          
  5     1.0033121  0.002849998  0.7925583          
  6     1.0047143  0.001942126  0.7936636          
  7     1.0057361  0.001691052  0.7947116          
  9     1.0066016  0.001672831  0.7955738          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was step = 1.
[1] "Mon Mar 05 09:36:23 2018"
The lasso 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  fraction    RMSE       Rsquared     MAE        Selected
  0.04423375  0.9999893  0.004394509  0.7912986  *       
  0.13484489  1.0006419  0.003914077  0.7911088          
  0.17607728  1.0009823  0.004186102  0.7911840          
  0.23010151  1.0018116  0.003990703  0.7917652          
  0.30582363  1.0025733  0.003330721  0.7922046          
  0.31743816  1.0026910  0.003229622  0.7922677          
  0.37748590  1.0033435  0.002793505  0.7926108          
  0.39695999  1.0035692  0.002678019  0.7927446          
  0.40861725  1.0037072  0.002613907  0.7928273          
  0.50541101  1.0047735  0.002119048  0.7935466          
  0.51879696  1.0049104  0.002063061  0.7936674          
  0.52011220  1.0049241  0.002057708  0.7936794          
  0.52839347  1.0050104  0.002024593  0.7937550          
  0.56068793  1.0053576  0.001904612  0.7940701          
  0.60951029  1.0058768  0.001765790  0.7946079          
  0.70553546  1.0069258  0.001619950  0.7956202          
  0.76703082  1.0075625  0.001560433  0.7961930          
  0.97967031  1.0099296  0.001404124  0.7984124          
  0.98457705  1.0099890  0.001401020  0.7984705          
  0.99928846  1.0101685  0.001391821  0.7986446          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was fraction = 0.04423375.
[1] "Mon Mar 05 09:36:36 2018"
Linear Regression with Backwards Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  nvmax  RMSE      Rsquared     MAE        Selected
  2      1.006272  0.004003851  0.7939403  *       
  3      1.009923  0.004106708  0.7977179          
  4      1.008410  0.002026982  0.7963585          
  5      1.009122  0.001359197  0.7977459          
  6      1.009332  0.001258555  0.7983959          
  7      1.010089  0.001464628  0.7987098          
  8      1.009914  0.001274734  0.7987952          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was nvmax = 2.
[1] "Mon Mar 05 09:36:50 2018"
Linear Regression with Forward Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  nvmax  RMSE      Rsquared     MAE        Selected
  2      1.006272  0.004003851  0.7939403  *       
  3      1.009923  0.004106708  0.7977179          
  4      1.008410  0.002026982  0.7963585          
  5      1.009122  0.001359197  0.7977459          
  6      1.009332  0.001258555  0.7983959          
  7      1.010089  0.001464628  0.7987098          
  8      1.009914  0.001274734  0.7987952          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was nvmax = 2.
[1] "Mon Mar 05 09:37:02 2018"
Linear Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE      Rsquared    MAE     
  1.010177  0.00139138  0.798653

Tuning parameter 'intercept' was held constant at a value of TRUE
[1] "Mon Mar 05 09:37:15 2018"
Start:  AIC=-1.84
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V5    1   0.00938 480.64 -3.8298
- V8    1   0.02865 480.66 -3.8097
- V9    1   0.05306 480.68 -3.7842
- V6    1   0.24411 480.87 -3.5847
- V10   1   0.77418 481.40 -3.0316
- V7    1   0.82917 481.46 -2.9743
- V2    1   0.89630 481.52 -2.9043
- V4    1   1.38337 482.01 -2.3968
<none>              480.63 -1.8396
- V3    1   2.85264 483.48 -0.8689

Step:  AIC=-3.83
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V8    1   0.03124 480.67 -5.7972
- V9    1   0.05446 480.69 -5.7729
- V6    1   0.24554 480.88 -5.5734
- V10   1   0.76648 481.40 -5.0299
- V7    1   0.82656 481.46 -4.9672
- V2    1   0.88932 481.53 -4.9018
- V4    1   1.37881 482.02 -4.3918
<none>              480.64 -3.8298
- V3    1   2.88802 483.53 -2.8224

Step:  AIC=-5.8
.outcome ~ V2 + V3 + V4 + V6 + V7 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V9    1   0.05363 480.72 -7.7412
- V6    1   0.24036 480.91 -7.5462
- V10   1   0.75603 481.43 -7.0082
- V7    1   0.81597 481.49 -6.9457
- V2    1   0.87355 481.54 -6.8857
- V4    1   1.44878 482.12 -6.2864
<none>              480.67 -5.7972
- V3    1   2.86059 483.53 -4.8185

Step:  AIC=-7.74
.outcome ~ V2 + V3 + V4 + V6 + V7 + V10

       Df Sum of Sq    RSS     AIC
- V6    1   0.24190 480.96 -9.4886
- V10   1   0.75958 481.48 -8.9486
- V7    1   0.82613 481.55 -8.8792
- V2    1   0.91035 481.63 -8.7914
- V4    1   1.48796 482.21 -8.1897
<none>              480.72 -7.7412
- V3    1   2.99205 483.71 -6.6264

Step:  AIC=-9.49
.outcome ~ V2 + V3 + V4 + V7 + V10

       Df Sum of Sq    RSS      AIC
- V10   1   0.76934 481.73 -10.6863
- V7    1   0.85777 481.82 -10.5941
- V2    1   0.91182 481.88 -10.5378
- V4    1   1.51762 482.48  -9.9071
<none>              480.96  -9.4886
- V3    1   2.93455 483.90  -8.4350

Step:  AIC=-10.69
.outcome ~ V2 + V3 + V4 + V7

       Df Sum of Sq    RSS      AIC
- V2    1   0.88409 482.62 -11.7658
- V7    1   0.89833 482.63 -11.7510
- V4    1   1.71611 483.45 -10.9011
<none>              481.73 -10.6863
- V3    1   2.76120 484.50  -9.8171

Step:  AIC=-11.77
.outcome ~ V3 + V4 + V7

       Df Sum of Sq    RSS     AIC
- V7    1   0.89799 483.52 -12.833
- V4    1   1.62040 484.24 -12.083
<none>              482.62 -11.766
- V3    1   2.60206 485.22 -11.066

Step:  AIC=-12.83
.outcome ~ V3 + V4

       Df Sum of Sq    RSS     AIC
- V4    1    1.7037 485.22 -13.067
<none>              483.52 -12.833
- V3    1    2.5388 486.06 -12.204

Step:  AIC=-13.07
.outcome ~ V3

       Df Sum of Sq    RSS     AIC
<none>              485.22 -13.067
- V3    1    2.6901 487.91 -12.291
Start:  AIC=8.99
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V5    1    0.0551 491.17  7.0479
- V2    1    0.0928 491.20  7.0865
- V9    1    0.1250 491.24  7.1194
- V8    1    0.1298 491.24  7.1243
- V6    1    0.3002 491.41  7.2983
- V3    1    0.9976 492.11  8.0103
- V7    1    1.6422 492.75  8.6674
<none>              491.11  8.9916
- V10   1    3.7435 494.85 10.8036
- V4    1    3.7576 494.87 10.8179

Step:  AIC=7.05
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS    AIC
- V2    1    0.0917 491.26 5.1416
- V9    1    0.1260 491.29 5.1767
- V8    1    0.1403 491.31 5.1912
- V6    1    0.3074 491.47 5.3620
- V3    1    1.0423 492.21 6.1120
- V7    1    1.6733 492.84 6.7552
<none>              491.17 7.0479
- V4    1    3.7815 494.95 8.8980
- V10   1    3.7825 494.95 8.8990

Step:  AIC=5.14
.outcome ~ V3 + V4 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS    AIC
- V9    1    0.1316 491.39 3.2761
- V8    1    0.1465 491.40 3.2913
- V6    1    0.3021 491.56 3.4502
- V3    1    1.0312 492.29 4.1943
- V7    1    1.6522 492.91 4.8271
<none>              491.26 5.1416
- V4    1    3.7476 495.01 6.9566
- V10   1    3.7886 495.05 6.9982

Step:  AIC=3.28
.outcome ~ V3 + V4 + V6 + V7 + V8 + V10

       Df Sum of Sq    RSS    AIC
- V8    1    0.1297 491.52 1.4085
- V6    1    0.3177 491.71 1.6005
- V3    1    0.9558 492.35 2.2515
- V7    1    1.6211 493.01 2.9295
<none>              491.39 3.2761
- V4    1    3.7657 495.16 5.1084
- V10   1    3.8506 495.24 5.1945

Step:  AIC=1.41
.outcome ~ V3 + V4 + V6 + V7 + V10

       Df Sum of Sq    RSS     AIC
- V6    1    0.3211 491.84 -0.2636
- V3    1    0.9911 492.51  0.4197
- V7    1    1.6457 493.17  1.0865
<none>              491.52  1.4085
- V4    1    3.8759 495.40  3.3515
- V10   1    3.9353 495.45  3.4117

Step:  AIC=-0.26
.outcome ~ V3 + V4 + V7 + V10

       Df Sum of Sq    RSS      AIC
- V3    1    1.0495 492.89 -1.19363
- V7    1    1.7613 493.60 -0.46913
<none>              491.84 -0.26364
- V4    1    3.8981 495.74  1.69933
- V10   1    3.8984 495.74  1.69962

Step:  AIC=-1.19
.outcome ~ V4 + V7 + V10

       Df Sum of Sq    RSS      AIC
- V7    1    1.7208 494.61 -1.44405
<none>              492.89 -1.19363
- V4    1    3.7584 496.65  0.61972
- V10   1    3.9818 496.87  0.84547

Step:  AIC=-1.44
.outcome ~ V4 + V10

       Df Sum of Sq    RSS      AIC
<none>              494.61 -1.44405
- V4    1    3.6343 498.25  0.23110
- V10   1    3.8740 498.48  0.47245
Start:  AIC=27.84
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS    AIC
- V9    1   0.10991 508.01 25.947
- V8    1   0.19256 508.09 26.028
- V10   1   0.22601 508.13 26.061
- V5    1   0.23830 508.14 26.073
- V2    1   0.27868 508.18 26.113
- V4    1   0.31867 508.22 26.152
- V7    1   0.50869 508.41 26.339
- V3    1   1.34073 509.24 27.157
<none>              507.90 27.839
- V6    1   2.19500 510.10 27.995

Step:  AIC=25.95
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V10

       Df Sum of Sq    RSS    AIC
- V8    1   0.19984 508.21 24.143
- V10   1   0.22972 508.24 24.173
- V5    1   0.22989 508.24 24.173
- V2    1   0.30060 508.31 24.243
- V4    1   0.33105 508.34 24.273
- V7    1   0.48978 508.50 24.429
- V3    1   1.46942 509.48 25.391
<none>              508.01 25.947
- V6    1   2.17041 510.18 26.078

Step:  AIC=24.14
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V10

       Df Sum of Sq    RSS    AIC
- V5    1   0.20334 508.41 22.343
- V10   1   0.22721 508.44 22.367
- V2    1   0.29376 508.50 22.433
- V4    1   0.39422 508.60 22.531
- V7    1   0.46694 508.68 22.603
- V3    1   1.49902 509.71 23.616
<none>              508.21 24.143
- V6    1   2.14798 510.36 24.252

Step:  AIC=22.34
.outcome ~ V2 + V3 + V4 + V6 + V7 + V10

       Df Sum of Sq    RSS    AIC
- V10   1   0.24869 508.66 20.588
- V2    1   0.30625 508.72 20.645
- V4    1   0.38800 508.80 20.725
- V7    1   0.44856 508.86 20.785
- V3    1   1.45965 509.87 21.777
<none>              508.41 22.343
- V6    1   2.03781 510.45 22.344

Step:  AIC=20.59
.outcome ~ V2 + V3 + V4 + V6 + V7

       Df Sum of Sq    RSS    AIC
- V2    1   0.29501 508.96 18.878
- V4    1   0.42449 509.09 19.005
- V7    1   0.44733 509.11 19.028
- V3    1   1.41198 510.07 19.974
<none>              508.66 20.588
- V6    1   2.15979 510.82 20.707

Step:  AIC=18.88
.outcome ~ V3 + V4 + V6 + V7

       Df Sum of Sq    RSS    AIC
- V4    1   0.39789 509.36 17.269
- V7    1   0.50984 509.47 17.379
- V3    1   1.35174 510.31 18.204
<none>              508.96 18.878
- V6    1   2.23577 511.19 19.070

Step:  AIC=17.27
.outcome ~ V3 + V6 + V7

       Df Sum of Sq    RSS    AIC
- V7    1   0.56826 509.92 15.826
- V3    1   1.27749 510.63 16.521
<none>              509.36 17.269
- V6    1   2.23320 511.59 17.456

Step:  AIC=15.83
.outcome ~ V3 + V6

       Df Sum of Sq    RSS    AIC
- V3    1    1.2762 511.20 15.076
<none>              509.92 15.826
- V6    1    2.1437 512.07 15.924

Step:  AIC=15.08
.outcome ~ V6

       Df Sum of Sq    RSS    AIC
<none>              511.20 15.076
- V6    1    2.2201 513.42 15.243
Start:  AIC=12.35
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS    AIC
- V5    1   0.00014 744.39 10.347
- V9    1   0.00366 744.39 10.351
- V10   1   0.04235 744.43 10.390
- V8    1   0.12226 744.51 10.470
- V7    1   0.42316 744.81 10.774
- V2    1   0.61486 745.00 10.968
- V6    1   1.06715 745.45 11.424
<none>              744.39 12.347
- V4    1   2.31486 746.70 12.682
- V3    1   2.44923 746.83 12.817

Step:  AIC=10.35
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V9    1   0.00364 744.39  8.3507
- V10   1   0.04222 744.43  8.3896
- V8    1   0.12224 744.51  8.4705
- V7    1   0.42320 744.81  8.7744
- V2    1   0.61566 745.00  8.9687
- V6    1   1.06841 745.45  9.4256
<none>              744.39 10.3470
- V4    1   2.31476 746.70 10.6818
- V3    1   2.45578 746.84 10.8238

Step:  AIC=8.35
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V10

       Df Sum of Sq    RSS    AIC
- V10   1   0.04176 744.43 6.3929
- V8    1   0.12345 744.51 6.4754
- V7    1   0.42635 744.82 6.7813
- V2    1   0.61990 745.01 6.9766
- V6    1   1.06658 745.46 7.4274
<none>              744.39 8.3507
- V4    1   2.32102 746.71 8.6918
- V3    1   2.51922 746.91 8.8914

Step:  AIC=6.39
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8

       Df Sum of Sq    RSS    AIC
- V8    1   0.12838 744.56 4.5225
- V7    1   0.42225 744.85 4.8193
- V2    1   0.62399 745.06 5.0229
- V6    1   1.05328 745.48 5.4561
<none>              744.43 6.3929
- V4    1   2.28539 746.72 6.6980
- V3    1   2.54957 746.98 6.9639

Step:  AIC=4.52
.outcome ~ V2 + V3 + V4 + V6 + V7

       Df Sum of Sq    RSS    AIC
- V7    1   0.42574 744.99 2.9524
- V2    1   0.61512 745.17 3.1435
- V6    1   1.04611 745.61 3.5784
<none>              744.56 4.5225
- V4    1   2.40781 746.97 4.9505
- V3    1   2.55591 747.12 5.0996

Step:  AIC=2.95
.outcome ~ V2 + V3 + V4 + V6

       Df Sum of Sq    RSS    AIC
- V2    1   0.57913 745.56 1.5368
- V6    1   1.11700 746.10 2.0791
<none>              744.99 2.9524
- V4    1   2.37221 747.36 3.3432
- V3    1   2.52796 747.51 3.4998

Step:  AIC=1.54
.outcome ~ V3 + V4 + V6

       Df Sum of Sq    RSS     AIC
- V6    1    1.1321 746.70 0.67774
<none>              745.56 1.53676
- V4    1    2.2909 747.86 1.84393
- V3    1    2.4338 748.00 1.98755

Step:  AIC=0.68
.outcome ~ V3 + V4

       Df Sum of Sq    RSS     AIC
<none>              746.70 0.67774
- V4    1    2.3207 749.02 1.01131
- V3    1    2.4719 749.17 1.16312
Linear Regression with Stepwise Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.007435  0.003210255  0.7948808

[1] "Mon Mar 05 09:37:28 2018"
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/src/contrib:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/src/contrib/PACKAGES'
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4/PACKAGES'
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: There were 25 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9     NA's   :9    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:38:01 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "logreg"                  
Error : package RWeka is required
Error : package RWeka is required
Error : package RWeka is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:38:13 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "M5"                      
Error : package RWeka is required
Error : package RWeka is required
Error : package RWeka is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:38:26 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "M5Rules"                 
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:38:39 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "mlpKerasDecay"           
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:38:52 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "mlpKerasDropout"         
Timing stopped at: 0.06 0 0.06
Error in (function (x, y, family = c("gaussian", "binomial", "poisson",  : 
  Null model produced by the full fit (all coefficients are zero).
           Please try a different parameter setting.
In addition: There were 43 warnings (use warnings() to see them)
Timing stopped at: 0.06 0 0.06
Error in (function (x, y, family = c("gaussian", "binomial", "poisson",  : 
  Null model produced by the full fit (all coefficients are zero).
           Please try a different parameter setting.
In addition: There were 17 warnings (use warnings() to see them)
Timing stopped at: 0.05 0 0.06
Error in (function (x, y, family = c("gaussian", "binomial", "poisson",  : 
  Null model produced by the full fit (all coefficients are zero).
           Please try a different parameter setting.
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 09:41:13 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "msaenet"                 
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/src/contrib:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/src/contrib/PACKAGES'
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4/PACKAGES'
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/src/contrib:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/src/contrib/PACKAGES'
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4/PACKAGES'
# weights:  221
initial  value 659.164176 
iter  10 value 487.135973
iter  20 value 451.790805
iter  30 value 434.885220
iter  40 value 417.189552
iter  50 value 406.825586
iter  60 value 398.934261
iter  70 value 389.421242
iter  80 value 384.946860
iter  90 value 374.821277
iter 100 value 367.033704
final  value 367.033704 
stopped after 100 iterations
# weights:  122
initial  value 608.518290 
iter  10 value 483.952449
iter  20 value 454.006640
iter  30 value 418.540473
iter  40 value 408.139743
iter  50 value 400.312510
iter  60 value 394.602868
iter  70 value 391.926312
iter  80 value 387.560010
iter  90 value 386.216907
iter 100 value 382.954069
final  value 382.954069 
stopped after 100 iterations
# weights:  122
initial  value 836.805445 
iter  10 value 493.698520
iter  20 value 493.597658
final  value 493.597639 
converged
# weights:  45
initial  value 596.248270 
iter  10 value 489.114557
iter  20 value 488.896441
iter  30 value 458.363436
iter  40 value 439.545454
iter  50 value 438.072070
iter  60 value 437.523919
iter  70 value 437.264742
iter  80 value 436.782499
iter  90 value 436.714594
iter 100 value 436.629827
final  value 436.629827 
stopped after 100 iterations
# weights:  166
initial  value 601.591259 
iter  10 value 489.239247
iter  20 value 488.117699
iter  30 value 488.085121
final  value 488.084811 
converged
# weights:  122
initial  value 564.493373 
iter  10 value 489.992421
iter  20 value 489.026018
iter  30 value 489.016331
iter  40 value 488.879541
iter  50 value 451.145025
iter  60 value 433.168999
iter  70 value 430.449721
iter  80 value 429.337049
iter  90 value 428.388385
iter 100 value 425.578722
final  value 425.578722 
stopped after 100 iterations
# weights:  221
initial  value 592.006183 
iter  10 value 490.300041
iter  20 value 489.031987
iter  30 value 473.583748
iter  40 value 456.807359
iter  50 value 446.855608
iter  60 value 439.606337
iter  70 value 437.562309
iter  80 value 436.295444
iter  90 value 434.286210
iter 100 value 429.853529
final  value 429.853529 
stopped after 100 iterations
# weights:  100
initial  value 699.597271 
iter  10 value 485.630272
iter  20 value 454.135959
iter  30 value 442.303383
iter  40 value 436.146831
iter  50 value 427.479983
iter  60 value 422.989837
iter  70 value 419.951437
iter  80 value 417.186481
iter  90 value 414.915816
iter 100 value 412.106072
final  value 412.106072 
stopped after 100 iterations
# weights:  12
initial  value 594.269139 
iter  10 value 489.541016
iter  20 value 486.609984
iter  30 value 474.037925
iter  40 value 472.425962
iter  50 value 472.417040
final  value 472.416435 
converged
# weights:  89
initial  value 558.418018 
iter  10 value 494.399594
iter  20 value 494.331535
final  value 494.331525 
converged
# weights:  56
initial  value 664.094802 
iter  10 value 479.216999
iter  20 value 443.489385
iter  30 value 436.075729
iter  40 value 433.409374
iter  50 value 431.590266
iter  60 value 430.707741
iter  70 value 430.077278
iter  80 value 429.716257
iter  90 value 429.493382
iter 100 value 429.455044
final  value 429.455044 
stopped after 100 iterations
# weights:  144
initial  value 547.199100 
iter  10 value 485.841050
iter  20 value 468.393116
iter  30 value 459.117057
iter  40 value 452.050195
iter  50 value 447.745495
iter  60 value 443.946757
iter  70 value 440.577093
iter  80 value 434.295257
iter  90 value 429.848420
iter 100 value 426.382394
final  value 426.382394 
stopped after 100 iterations
# weights:  133
initial  value 681.870228 
iter  10 value 489.765804
iter  20 value 488.887539
iter  30 value 456.121407
iter  40 value 428.695775
iter  50 value 417.766725
iter  60 value 407.851615
iter  70 value 401.029883
iter  80 value 397.054740
iter  90 value 393.888205
iter 100 value 390.411694
final  value 390.411694 
stopped after 100 iterations
# weights:  34
initial  value 531.388978 
iter  10 value 481.225963
iter  20 value 460.188861
iter  30 value 457.924553
iter  40 value 457.407844
iter  50 value 454.409856
iter  60 value 453.174470
iter  70 value 453.157121
final  value 453.157113 
converged
# weights:  78
initial  value 621.007887 
iter  10 value 486.224193
iter  20 value 452.922709
iter  30 value 440.471060
iter  40 value 428.489007
iter  50 value 420.256121
iter  60 value 415.384511
iter  70 value 411.860289
iter  80 value 409.369078
iter  90 value 401.124442
iter 100 value 394.154149
final  value 394.154149 
stopped after 100 iterations
# weights:  78
initial  value 611.631172 
iter  10 value 487.237595
iter  20 value 458.586004
iter  30 value 436.269319
iter  40 value 430.032914
iter  50 value 424.925846
iter  60 value 422.371565
iter  70 value 420.581158
iter  80 value 419.065385
iter  90 value 418.788366
iter 100 value 418.683970
final  value 418.683970 
stopped after 100 iterations
# weights:  177
initial  value 650.106207 
iter  10 value 493.258465
iter  20 value 485.887298
iter  30 value 484.624840
iter  40 value 484.427953
iter  50 value 484.355917
iter  60 value 484.353398
iter  70 value 484.341597
iter  80 value 484.310445
final  value 484.310249 
converged
# weights:  89
initial  value 583.359364 
iter  10 value 489.064383
final  value 489.019182 
converged
# weights:  122
initial  value 707.447258 
iter  10 value 490.735531
iter  20 value 490.298763
final  value 490.295825 
converged
# weights:  221
initial  value 828.035683 
iter  10 value 489.202163
iter  20 value 489.018237
iter  30 value 489.018087
iter  40 value 489.017905
iter  50 value 489.017678
iter  60 value 489.017386
iter  70 value 489.016991
iter  80 value 489.016426
iter  90 value 489.015547
iter 100 value 489.013984
final  value 489.013984 
stopped after 100 iterations
# weights:  221
initial  value 611.164982 
iter  10 value 501.972867
iter  20 value 448.853512
iter  30 value 420.388613
iter  40 value 402.968359
iter  50 value 391.410483
iter  60 value 387.708383
iter  70 value 381.186311
iter  80 value 375.090826
iter  90 value 367.711819
iter 100 value 362.599967
final  value 362.599967 
stopped after 100 iterations
# weights:  122
initial  value 536.262911 
iter  10 value 499.206457
iter  20 value 462.460419
iter  30 value 441.195042
iter  40 value 429.955384
iter  50 value 421.585737
iter  60 value 415.682998
iter  70 value 413.141352
iter  80 value 409.955472
iter  90 value 407.064621
iter 100 value 406.551001
final  value 406.551001 
stopped after 100 iterations
# weights:  122
initial  value 727.100569 
iter  10 value 509.142609
iter  20 value 507.384174
iter  20 value 507.384173
iter  20 value 507.384173
final  value 507.384173 
converged
# weights:  45
initial  value 751.992921 
iter  10 value 502.276671
iter  20 value 502.151303
iter  30 value 502.150730
iter  40 value 502.149988
iter  50 value 502.148911
iter  60 value 502.147090
iter  70 value 502.143234
iter  80 value 502.131023
iter  90 value 502.036767
iter 100 value 489.893398
final  value 489.893398 
stopped after 100 iterations
# weights:  166
initial  value 641.142552 
iter  10 value 507.425542
iter  20 value 500.471709
iter  30 value 500.222719
iter  40 value 500.220154
final  value 500.220119 
converged
# weights:  122
initial  value 768.731398 
iter  10 value 503.837016
iter  20 value 502.163833
iter  30 value 502.161237
iter  40 value 502.155934
iter  50 value 502.132925
iter  60 value 490.838338
iter  70 value 463.812307
iter  80 value 461.839500
iter  90 value 461.232321
iter 100 value 461.039018
final  value 461.039018 
stopped after 100 iterations
# weights:  221
initial  value 568.607012 
iter  10 value 502.839064
iter  20 value 502.153194
iter  30 value 502.152746
iter  40 value 502.152165
iter  50 value 502.151353
iter  60 value 502.150086
iter  70 value 502.147706
iter  80 value 502.141185
iter  90 value 502.066439
iter 100 value 490.757366
final  value 490.757366 
stopped after 100 iterations
# weights:  100
initial  value 689.942706 
iter  10 value 483.774027
iter  20 value 459.842352
iter  30 value 447.219862
iter  40 value 437.923005
iter  50 value 431.839448
iter  60 value 429.834749
iter  70 value 427.556378
iter  80 value 426.650177
iter  90 value 426.257860
iter 100 value 426.084421
final  value 426.084421 
stopped after 100 iterations
# weights:  12
initial  value 555.359922 
iter  10 value 502.225649
iter  20 value 494.009181
iter  30 value 492.017074
iter  40 value 491.516033
iter  50 value 491.017608
iter  60 value 489.458598
iter  70 value 489.335989
final  value 489.335983 
converged
# weights:  89
initial  value 622.088761 
iter  10 value 508.242723
iter  20 value 508.120420
final  value 508.119794 
converged
# weights:  56
initial  value 648.535033 
iter  10 value 498.789991
iter  20 value 469.202143
iter  30 value 456.510940
iter  40 value 453.636929
iter  50 value 451.876030
iter  60 value 450.725708
iter  70 value 450.272496
iter  80 value 449.080244
iter  90 value 444.390836
iter 100 value 441.664045
final  value 441.664045 
stopped after 100 iterations
# weights:  144
initial  value 699.514100 
iter  10 value 498.742231
iter  20 value 479.400108
iter  30 value 470.307940
iter  40 value 459.278833
iter  50 value 453.565513
iter  60 value 448.853528
iter  70 value 447.492215
iter  80 value 446.392417
iter  90 value 444.600265
iter 100 value 442.760514
final  value 442.760514 
stopped after 100 iterations
# weights:  133
initial  value 670.900348 
iter  10 value 502.799550
iter  20 value 501.990225
iter  30 value 469.020576
iter  40 value 438.589719
iter  50 value 428.672656
iter  60 value 426.750600
iter  70 value 422.831519
iter  80 value 419.404319
iter  90 value 418.319951
iter 100 value 412.478074
final  value 412.478074 
stopped after 100 iterations
# weights:  34
initial  value 560.212384 
iter  10 value 496.337751
iter  20 value 478.569685
iter  30 value 476.337181
iter  40 value 470.189794
iter  50 value 468.772823
iter  60 value 468.643167
final  value 468.642242 
converged
# weights:  78
initial  value 557.441304 
iter  10 value 499.250978
iter  20 value 458.844494
iter  30 value 449.118568
iter  40 value 444.238757
iter  50 value 440.854911
iter  60 value 437.521825
iter  70 value 434.561714
iter  80 value 431.802528
iter  90 value 430.711587
iter 100 value 429.959177
final  value 429.959177 
stopped after 100 iterations
# weights:  78
initial  value 589.933021 
iter  10 value 477.638353
iter  20 value 457.491224
iter  30 value 442.967305
iter  40 value 437.284055
iter  50 value 434.078066
iter  60 value 430.625801
iter  70 value 428.096375
iter  80 value 426.476234
iter  90 value 425.761933
iter 100 value 422.734141
final  value 422.734141 
stopped after 100 iterations
# weights:  177
initial  value 688.040310 
iter  10 value 506.174726
iter  20 value 497.998586
iter  30 value 496.520464
iter  40 value 496.092415
iter  50 value 496.074292
iter  50 value 496.074287
iter  50 value 496.074286
final  value 496.074286 
converged
# weights:  89
initial  value 594.164034 
iter  10 value 502.197114
iter  20 value 502.130711
iter  30 value 496.001757
iter  40 value 466.409307
iter  50 value 456.556480
iter  60 value 453.945860
iter  70 value 452.382738
iter  80 value 452.046058
iter  90 value 451.895447
iter 100 value 451.327867
final  value 451.327867 
stopped after 100 iterations
# weights:  122
initial  value 671.903648 
iter  10 value 504.626985
iter  20 value 503.725128
final  value 503.723572 
converged
# weights:  221
initial  value 537.361508 
iter  10 value 502.210511
iter  20 value 502.128915
iter  30 value 494.101579
iter  40 value 455.646601
iter  50 value 439.283550
iter  60 value 437.157069
iter  70 value 435.989603
iter  80 value 435.704107
iter  90 value 432.858473
iter 100 value 430.681710
final  value 430.681710 
stopped after 100 iterations
# weights:  221
initial  value 606.000863 
iter  10 value 512.509393
iter  20 value 459.747816
iter  30 value 434.723134
iter  40 value 416.795352
iter  50 value 405.094525
iter  60 value 395.805466
iter  70 value 382.246944
iter  80 value 369.036374
iter  90 value 362.169132
iter 100 value 359.361025
final  value 359.361025 
stopped after 100 iterations
# weights:  122
initial  value 592.386668 
iter  10 value 512.562938
iter  20 value 476.017582
iter  30 value 449.526768
iter  40 value 434.816080
iter  50 value 426.783362
iter  60 value 420.526278
iter  70 value 418.541891
iter  80 value 416.349753
iter  90 value 415.402271
iter 100 value 415.224829
final  value 415.224829 
stopped after 100 iterations
# weights:  122
initial  value 882.783291 
iter  10 value 518.897070
iter  20 value 518.802243
iter  20 value 518.802238
iter  20 value 518.802235
final  value 518.802235 
converged
# weights:  45
initial  value 581.289597 
iter  10 value 514.982897
iter  20 value 514.924240
iter  30 value 514.923348
iter  40 value 514.921767
iter  50 value 514.918175
iter  60 value 514.904279
iter  70 value 514.526796
iter  80 value 488.740926
iter  90 value 472.526369
iter 100 value 466.664694
final  value 466.664694 
stopped after 100 iterations
# weights:  166
initial  value 552.083956 
iter  10 value 513.375883
iter  20 value 513.057390
iter  30 value 513.046725
final  value 513.046698 
converged
# weights:  122
initial  value 788.992976 
iter  10 value 516.316225
iter  20 value 514.544106
iter  30 value 493.763773
iter  40 value 474.221465
iter  50 value 469.310598
iter  60 value 467.415400
iter  70 value 463.885108
iter  80 value 461.859139
iter  90 value 459.283997
iter 100 value 454.585394
final  value 454.585394 
stopped after 100 iterations
# weights:  221
initial  value 555.750198 
iter  10 value 515.300576
iter  20 value 514.909576
iter  30 value 513.104995
iter  40 value 480.855265
iter  50 value 453.965859
iter  60 value 435.692549
iter  70 value 422.070319
iter  80 value 409.562423
iter  90 value 404.925165
iter 100 value 402.011326
final  value 402.011326 
stopped after 100 iterations
# weights:  100
initial  value 545.063711 
iter  10 value 507.831462
iter  20 value 490.702564
iter  30 value 480.659794
iter  40 value 474.792918
iter  50 value 467.006105
iter  60 value 462.557727
iter  70 value 457.377869
iter  80 value 454.104676
iter  90 value 452.197125
iter 100 value 451.340247
final  value 451.340247 
stopped after 100 iterations
# weights:  12
initial  value 655.444089 
iter  10 value 515.300489
iter  20 value 499.103334
iter  30 value 496.839150
iter  40 value 496.756862
final  value 496.756756 
converged
# weights:  89
initial  value 580.944358 
iter  10 value 519.541854
final  value 519.514480 
converged
# weights:  56
initial  value 669.995206 
iter  10 value 505.245348
iter  20 value 480.581640
iter  30 value 473.296057
iter  40 value 464.786828
iter  50 value 461.669646
iter  60 value 458.449988
iter  70 value 457.311599
iter  80 value 456.866316
iter  90 value 456.267203
iter 100 value 454.302825
final  value 454.302825 
stopped after 100 iterations
# weights:  144
initial  value 640.438633 
iter  10 value 514.008320
iter  20 value 497.483079
iter  30 value 485.766849
iter  40 value 472.360929
iter  50 value 469.501465
iter  60 value 467.436385
iter  70 value 465.198346
iter  80 value 463.409141
iter  90 value 459.614526
iter 100 value 456.434012
final  value 456.434012 
stopped after 100 iterations
# weights:  133
initial  value 616.738801 
iter  10 value 518.288584
iter  20 value 514.948168
iter  30 value 514.915917
iter  40 value 504.840002
iter  50 value 475.722688
iter  60 value 468.531404
iter  70 value 465.173911
iter  80 value 463.957001
iter  90 value 463.166608
iter 100 value 459.708612
final  value 459.708612 
stopped after 100 iterations
# weights:  34
initial  value 580.424050 
iter  10 value 512.957690
iter  20 value 496.031537
iter  30 value 491.171270
iter  40 value 490.570483
iter  50 value 489.888075
final  value 489.867738 
converged
# weights:  78
initial  value 715.075978 
iter  10 value 516.387031
iter  20 value 479.992361
iter  30 value 451.273907
iter  40 value 440.725559
iter  50 value 423.403346
iter  60 value 421.515790
iter  70 value 421.003906
iter  80 value 420.831623
iter  90 value 417.693506
iter 100 value 416.310185
final  value 416.310185 
stopped after 100 iterations
# weights:  78
initial  value 544.041584 
iter  10 value 510.691737
iter  20 value 473.030726
iter  30 value 462.051274
iter  40 value 458.810955
iter  50 value 457.813436
iter  60 value 456.186506
iter  70 value 454.171094
iter  80 value 452.799499
iter  90 value 452.294985
iter 100 value 452.180402
final  value 452.180402 
stopped after 100 iterations
# weights:  177
initial  value 738.585812 
iter  10 value 512.993107
iter  20 value 510.905940
iter  30 value 509.667557
iter  40 value 509.503305
iter  50 value 509.490332
final  value 509.490223 
converged
# weights:  89
initial  value 721.989425 
iter  10 value 514.993987
final  value 514.923771 
converged
# weights:  122
initial  value 708.239812 
iter  10 value 516.081489
iter  20 value 515.659389
iter  30 value 515.655902
iter  30 value 515.655897
iter  30 value 515.655897
final  value 515.655897 
converged
# weights:  221
initial  value 845.687861 
iter  10 value 515.110149
iter  20 value 514.923186
iter  30 value 514.922995
iter  40 value 514.922752
iter  50 value 514.922435
iter  60 value 514.921998
iter  70 value 514.921352
iter  80 value 514.920299
iter  90 value 514.918268
iter 100 value 514.912811
final  value 514.912811 
stopped after 100 iterations
# weights:  122
initial  value 1134.995726 
iter  10 value 754.435338
iter  20 value 753.416160
final  value 753.415469 
converged
Neural Network 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  size  decay         RMSE      Rsquared      MAE        Selected
   1    1.810456e-02  1.011601  0.0019878781  0.7998097          
   3    8.809574e-02  1.011800  0.0049689642  0.8030333          
   4    8.122348e-05  1.020944  0.0082851330  0.8054623          
   5    1.634087e-02  1.028317  0.0075596598  0.8105390          
   7    1.418191e-02  1.048611  0.0034325536  0.8302428          
   7    1.426626e-02  1.048873  0.0011055239  0.8280088          
   8    3.366673e-05  1.003981  0.0030097937  0.7985625          
   8    3.528491e+00  1.001158  0.0009190357  0.7903273          
   9    6.671715e-02  1.058269  0.0092276063  0.8394359          
  11    6.546499e-04  1.016267  0.0129034541  0.8070564          
  11    5.849359e-03  1.053716  0.0010421374  0.8306293          
  11    1.711692e+00  1.000243  0.0010036627  0.7904009  *       
  11    3.730599e+00  1.000880  0.0009047857  0.7903097          
  12    1.704722e-03  1.020312  0.0140428743  0.8082892          
  13    1.351855e-01  1.027431  0.0074554988  0.8088840          
  15    9.575963e-01  1.000863  0.0014952979  0.7909897          
  16    5.985918e-01  1.003446  0.0015698991  0.7931472          
  20    8.526253e-05  1.010330  0.0011847629  0.8023155          
  20    3.754391e-04  1.041176  0.0006315401  0.8220650          
  20    3.973042e-03  1.067750  0.0092119750  0.8471891          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 11 and decay = 1.711692.
[1] "Mon Mar 05 09:42:09 2018"
Non-Negative Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.005255  0.006218413  0.7984068

[1] "Mon Mar 05 09:42:21 2018"
Non-Informative Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE       Rsquared  MAE      
  0.9995283  NaN       0.7913185

[1] "Mon Mar 05 09:42:34 2018"
Parallel Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  mtry  RMSE      Rsquared     MAE        Selected
  1     1.026011  0.005223604  0.8145250  *       
  2     1.035957  0.008343822  0.8228766          
  3     1.040950  0.009325596  0.8266950          
  4     1.046275  0.009066403  0.8306744          
  5     1.049389  0.010743053  0.8327270          
  6     1.049474  0.009270861  0.8331477          
  7     1.052118  0.010832187  0.8352940          
  9     1.051966  0.009549242  0.8345748          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 1.
[1] "Mon Mar 05 09:43:53 2018"
Error in varImp[, "%IncMSE"] : subscript out of bounds
In addition: Warning messages:
1: package 'mxnet' is not available (for R version 3.4.3) 
2: package 'mxnet' is not available (for R version 3.4.3) 
3: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
# weights:  221
initial  value 653.392555 
iter  10 value 486.677064
iter  20 value 444.399761
iter  30 value 426.035221
iter  40 value 417.458920
iter  50 value 409.524899
iter  60 value 402.170090
iter  70 value 387.443589
iter  80 value 382.338929
iter  90 value 379.187580
iter 100 value 374.163781
final  value 374.163781 
stopped after 100 iterations
# weights:  122
initial  value 604.783984 
iter  10 value 490.195180
iter  20 value 475.541184
iter  30 value 456.042583
iter  40 value 441.806293
iter  50 value 428.463966
iter  60 value 410.711689
iter  70 value 394.152339
iter  80 value 386.842295
iter  90 value 380.594988
iter 100 value 374.632431
final  value 374.632431 
stopped after 100 iterations
# weights:  122
initial  value 833.584714 
iter  10 value 493.719733
iter  20 value 493.604406
final  value 493.604380 
converged
# weights:  45
initial  value 596.497821 
iter  10 value 489.113618
iter  20 value 488.772071
iter  30 value 477.918731
iter  40 value 462.714603
iter  50 value 459.204319
iter  60 value 458.211984
iter  70 value 456.845576
iter  80 value 456.153964
iter  90 value 455.964421
iter 100 value 454.424029
final  value 454.424029 
stopped after 100 iterations
# weights:  166
initial  value 595.463994 
iter  10 value 488.646463
iter  20 value 488.012362
iter  30 value 487.996489
final  value 487.996388 
converged
# weights:  122
initial  value 562.292091 
iter  10 value 489.999440
iter  20 value 489.028170
iter  30 value 489.022417
iter  40 value 488.996829
iter  50 value 480.762411
iter  60 value 437.876955
iter  70 value 433.011732
iter  80 value 432.077447
iter  90 value 431.256325
iter 100 value 430.837739
final  value 430.837739 
stopped after 100 iterations
# weights:  221
initial  value 590.370624 
iter  10 value 490.291414
iter  20 value 489.031887
iter  30 value 473.061978
iter  40 value 451.771734
iter  50 value 423.359115
iter  60 value 415.408555
iter  70 value 412.155705
iter  80 value 410.034586
iter  90 value 408.647322
iter 100 value 406.494409
final  value 406.494409 
stopped after 100 iterations
# weights:  100
initial  value 704.666919 
iter  10 value 487.862373
iter  20 value 461.511597
iter  30 value 446.712695
iter  40 value 434.135663
iter  50 value 425.162771
iter  60 value 421.672149
iter  70 value 419.711624
iter  80 value 418.694338
iter  90 value 417.992996
iter 100 value 417.809002
final  value 417.809002 
stopped after 100 iterations
# weights:  12
initial  value 596.228707 
iter  10 value 488.826140
iter  20 value 480.149710
iter  30 value 475.396652
iter  40 value 473.096683
iter  50 value 471.154905
iter  60 value 470.559891
iter  70 value 470.515731
iter  80 value 470.502789
iter  80 value 470.502787
iter  80 value 470.502787
final  value 470.502787 
converged
# weights:  89
initial  value 558.018098 
iter  10 value 494.524218
iter  20 value 494.341109
final  value 494.341100 
converged
# weights:  56
initial  value 669.074783 
iter  10 value 486.472670
iter  20 value 451.669689
iter  30 value 434.953321
iter  40 value 429.304549
iter  50 value 421.640964
iter  60 value 418.762455
iter  70 value 416.033636
iter  80 value 414.748471
iter  90 value 414.067676
iter 100 value 413.974298
final  value 413.974298 
stopped after 100 iterations
# weights:  144
initial  value 557.209748 
iter  10 value 485.665612
iter  20 value 467.362788
iter  30 value 458.935358
iter  40 value 452.969567
iter  50 value 446.871422
iter  60 value 440.516171
iter  70 value 431.917519
iter  80 value 428.916970
iter  90 value 426.661030
iter 100 value 425.380874
final  value 425.380874 
stopped after 100 iterations
# weights:  133
initial  value 690.610186 
iter  10 value 489.741786
iter  20 value 489.069948
iter  30 value 479.976124
iter  40 value 433.745100
iter  50 value 423.288892
iter  60 value 419.138721
iter  70 value 413.934985
iter  80 value 410.616374
iter  90 value 404.947745
iter 100 value 403.993753
final  value 403.993753 
stopped after 100 iterations
# weights:  34
initial  value 533.592476 
iter  10 value 482.680579
iter  20 value 473.736333
iter  30 value 464.530373
iter  40 value 460.245976
iter  50 value 458.948763
iter  60 value 458.090101
iter  70 value 458.076883
iter  70 value 458.076879
final  value 458.076879 
converged
# weights:  78
initial  value 619.645926 
iter  10 value 487.243546
iter  20 value 441.391160
iter  30 value 422.674130
iter  40 value 414.373860
iter  50 value 407.865737
iter  60 value 406.532665
iter  70 value 405.498475
iter  80 value 403.865040
iter  90 value 401.325147
iter 100 value 399.885377
final  value 399.885377 
stopped after 100 iterations
# weights:  78
initial  value 611.453783 
iter  10 value 470.570461
iter  20 value 446.205435
iter  30 value 424.897472
iter  40 value 418.137862
iter  50 value 415.103751
iter  60 value 412.846478
iter  70 value 406.040545
iter  80 value 405.047113
iter  90 value 404.853978
iter 100 value 404.804247
final  value 404.804247 
stopped after 100 iterations
# weights:  177
initial  value 667.292487 
iter  10 value 493.147006
iter  20 value 485.751755
iter  30 value 484.572074
iter  40 value 484.314974
iter  50 value 484.243196
final  value 484.242606 
converged
# weights:  89
initial  value 584.355374 
iter  10 value 489.065941
iter  20 value 488.958904
iter  30 value 464.413095
iter  40 value 430.393969
iter  50 value 427.169096
iter  60 value 426.545943
iter  70 value 426.462392
iter  80 value 426.320786
iter  90 value 425.622902
iter 100 value 425.503065
final  value 425.503065 
stopped after 100 iterations
# weights:  122
initial  value 704.700591 
iter  10 value 490.778444
iter  20 value 490.294722
iter  30 value 490.292628
final  value 490.292600 
converged
# weights:  221
initial  value 826.610012 
iter  10 value 489.199039
iter  20 value 489.018109
iter  30 value 489.017920
iter  40 value 489.017683
iter  50 value 489.017376
iter  60 value 489.016957
iter  70 value 489.016347
iter  80 value 489.015372
iter  90 value 489.013556
iter 100 value 489.009037
final  value 489.009037 
stopped after 100 iterations
# weights:  221
initial  value 606.353505 
iter  10 value 503.259233
iter  20 value 470.641841
iter  30 value 453.025772
iter  40 value 442.655445
iter  50 value 435.814694
iter  60 value 430.372554
iter  70 value 422.933354
iter  80 value 420.514004
iter  90 value 416.014460
iter 100 value 412.713769
final  value 412.713769 
stopped after 100 iterations
# weights:  122
initial  value 530.777947 
iter  10 value 490.993706
iter  20 value 443.237374
iter  30 value 420.874365
iter  40 value 407.352189
iter  50 value 401.515044
iter  60 value 397.332693
iter  70 value 394.607448
iter  80 value 391.069053
iter  90 value 387.003779
iter 100 value 381.806360
final  value 381.806360 
stopped after 100 iterations
# weights:  122
initial  value 725.146870 
iter  10 value 508.525912
iter  20 value 507.367176
final  value 507.367007 
converged
# weights:  45
initial  value 753.138499 
iter  10 value 502.277769
iter  20 value 502.151214
iter  30 value 502.150641
iter  40 value 502.149899
iter  50 value 502.148829
iter  60 value 502.147055
iter  70 value 502.143412
iter  80 value 502.132320
iter  90 value 502.044756
iter 100 value 483.580731
final  value 483.580731 
stopped after 100 iterations
# weights:  166
initial  value 633.013442 
iter  10 value 507.719569
iter  20 value 500.988284
iter  30 value 500.222784
iter  40 value 500.167803
final  value 500.166770 
converged
# weights:  122
initial  value 764.638733 
iter  10 value 503.887590
iter  20 value 502.164247
iter  30 value 502.162034
iter  40 value 502.157959
iter  50 value 502.145510
iter  60 value 501.332030
iter  70 value 469.953019
iter  80 value 456.862559
iter  90 value 452.238977
iter 100 value 447.087556
final  value 447.087556 
stopped after 100 iterations
# weights:  221
initial  value 581.089580 
iter  10 value 502.947069
iter  20 value 502.155302
iter  30 value 502.147860
iter  40 value 502.141996
iter  50 value 502.089507
iter  60 value 487.807892
iter  70 value 453.772756
iter  80 value 447.528345
iter  90 value 441.199882
iter 100 value 440.558570
final  value 440.558570 
stopped after 100 iterations
# weights:  100
initial  value 694.914046 
iter  10 value 491.231541
iter  20 value 473.106036
iter  30 value 461.723196
iter  40 value 453.940455
iter  50 value 444.678879
iter  60 value 432.759997
iter  70 value 430.787650
iter  80 value 430.523479
iter  90 value 430.200012
iter 100 value 429.762057
final  value 429.762057 
stopped after 100 iterations
# weights:  12
initial  value 556.429310 
iter  10 value 501.690726
iter  20 value 491.830997
iter  30 value 487.930074
iter  40 value 487.002377
iter  50 value 486.960703
final  value 486.960192 
converged
# weights:  89
initial  value 626.808319 
iter  10 value 508.285793
iter  20 value 508.098415
final  value 508.098024 
converged
# weights:  56
initial  value 646.373334 
iter  10 value 491.926621
iter  20 value 462.496379
iter  30 value 449.109087
iter  40 value 444.548648
iter  50 value 440.564972
iter  60 value 434.238665
iter  70 value 431.896363
iter  80 value 431.645981
iter  90 value 431.602543
iter 100 value 431.592097
final  value 431.592097 
stopped after 100 iterations
# weights:  144
initial  value 694.416758 
iter  10 value 498.034296
iter  20 value 480.105808
iter  30 value 469.183833
iter  40 value 463.264493
iter  50 value 458.770858
iter  60 value 453.713989
iter  70 value 447.895611
iter  80 value 445.067064
iter  90 value 444.103177
iter 100 value 443.468859
final  value 443.468859 
stopped after 100 iterations
# weights:  133
initial  value 667.220176 
iter  10 value 502.820415
iter  20 value 502.174958
iter  30 value 482.755021
iter  40 value 461.239042
iter  50 value 452.179229
iter  60 value 443.671506
iter  70 value 440.398580
iter  80 value 436.821716
iter  90 value 427.128970
iter 100 value 422.310872
final  value 422.310872 
stopped after 100 iterations
# weights:  34
initial  value 560.309916 
iter  10 value 497.182319
iter  20 value 482.923868
iter  30 value 477.381850
iter  40 value 473.452530
iter  50 value 469.025402
iter  60 value 468.529672
iter  70 value 468.273978
iter  80 value 467.585384
iter  90 value 467.395853
final  value 467.395196 
converged
# weights:  78
initial  value 562.227573 
iter  10 value 496.768615
iter  20 value 468.359340
iter  30 value 446.883312
iter  40 value 437.624524
iter  50 value 428.530266
iter  60 value 421.859867
iter  70 value 414.852574
iter  80 value 412.238751
iter  90 value 411.572719
iter 100 value 410.642762
final  value 410.642762 
stopped after 100 iterations
# weights:  78
initial  value 594.186659 
iter  10 value 500.166886
iter  20 value 467.683955
iter  30 value 442.166747
iter  40 value 433.675631
iter  50 value 422.989866
iter  60 value 418.074584
iter  70 value 417.210893
iter  80 value 417.091120
iter  90 value 417.042535
iter 100 value 416.873585
final  value 416.873585 
stopped after 100 iterations
# weights:  177
initial  value 691.683079 
iter  10 value 506.159688
iter  20 value 497.958564
iter  30 value 497.209317
iter  40 value 496.247417
iter  50 value 496.111619
iter  60 value 496.089798
final  value 496.089582 
converged
# weights:  89
initial  value 588.293899 
iter  10 value 502.200265
iter  20 value 502.144711
iter  30 value 502.142414
iter  40 value 502.136032
iter  50 value 502.067059
iter  60 value 476.809378
iter  70 value 456.139324
iter  80 value 449.644797
iter  90 value 445.619761
iter 100 value 444.097671
final  value 444.097671 
stopped after 100 iterations
# weights:  122
initial  value 675.568604 
iter  10 value 504.523525
iter  20 value 503.699417
iter  30 value 503.691917
iter  30 value 503.691916
iter  30 value 503.691916
final  value 503.691916 
converged
# weights:  221
initial  value 531.728855 
iter  10 value 502.207327
iter  20 value 500.720096
iter  30 value 471.781300
iter  40 value 444.633134
iter  50 value 442.141013
iter  60 value 440.408185
iter  70 value 437.846943
iter  80 value 431.274676
iter  90 value 425.344770
iter 100 value 420.000101
final  value 420.000101 
stopped after 100 iterations
# weights:  221
initial  value 614.828737 
iter  10 value 512.541163
iter  20 value 474.481940
iter  30 value 455.597259
iter  40 value 438.848691
iter  50 value 427.372094
iter  60 value 419.677738
iter  70 value 409.694048
iter  80 value 404.086603
iter  90 value 402.251250
iter 100 value 399.987737
final  value 399.987737 
stopped after 100 iterations
# weights:  122
initial  value 592.249539 
iter  10 value 516.050936
iter  20 value 506.859329
iter  30 value 479.698201
iter  40 value 454.873762
iter  50 value 444.768035
iter  60 value 438.202034
iter  70 value 428.183364
iter  80 value 415.452717
iter  90 value 411.441575
iter 100 value 407.653656
final  value 407.653656 
stopped after 100 iterations
# weights:  122
initial  value 881.549422 
iter  10 value 518.925638
iter  20 value 518.821705
iter  20 value 518.821701
iter  20 value 518.821699
final  value 518.821699 
converged
# weights:  45
initial  value 581.662267 
iter  10 value 514.984125
iter  20 value 514.924821
iter  30 value 514.924199
iter  40 value 514.923222
iter  50 value 514.921431
iter  60 value 514.917125
iter  70 value 514.897953
iter  80 value 513.791028
iter  90 value 488.992602
iter 100 value 471.480561
final  value 471.480561 
stopped after 100 iterations
# weights:  166
initial  value 554.711249 
iter  10 value 513.526965
iter  20 value 513.226310
iter  30 value 513.221335
final  value 513.221322 
converged
# weights:  122
initial  value 790.577420 
iter  10 value 516.340597
iter  20 value 514.776125
iter  30 value 498.583794
iter  40 value 468.359443
iter  50 value 456.356532
iter  60 value 453.179074
iter  70 value 450.401504
iter  80 value 448.055019
iter  90 value 446.365494
iter 100 value 441.420020
final  value 441.420020 
stopped after 100 iterations
# weights:  221
initial  value 557.814067 
iter  10 value 515.299917
iter  20 value 514.910849
iter  30 value 512.291451
iter  40 value 496.950697
iter  50 value 477.243510
iter  60 value 470.953877
iter  70 value 469.839905
iter  80 value 465.597643
iter  90 value 462.927424
iter 100 value 460.416764
final  value 460.416764 
stopped after 100 iterations
# weights:  100
initial  value 547.452601 
iter  10 value 508.898109
iter  20 value 494.592712
iter  30 value 480.781514
iter  40 value 465.905620
iter  50 value 454.275051
iter  60 value 451.783903
iter  70 value 450.766796
iter  80 value 450.636343
iter  90 value 449.934639
iter 100 value 448.868208
final  value 448.868208 
stopped after 100 iterations
# weights:  12
initial  value 655.571135 
iter  10 value 515.663939
iter  20 value 510.164173
iter  30 value 500.161777
iter  40 value 499.203076
final  value 499.203035 
converged
# weights:  89
initial  value 580.494139 
iter  10 value 519.568762
final  value 519.540411 
converged
# weights:  56
initial  value 669.279498 
iter  10 value 500.043383
iter  20 value 464.725884
iter  30 value 458.280264
iter  40 value 455.976942
iter  50 value 454.491456
iter  60 value 452.369593
iter  70 value 449.700549
iter  80 value 449.526418
iter  90 value 449.508969
final  value 449.507988 
converged
# weights:  144
initial  value 640.718520 
iter  10 value 513.872496
iter  20 value 496.045506
iter  30 value 482.992213
iter  40 value 473.372726
iter  50 value 470.909364
iter  60 value 469.331738
iter  70 value 467.118887
iter  80 value 465.592470
iter  90 value 461.266598
iter 100 value 454.788498
final  value 454.788498 
stopped after 100 iterations
# weights:  133
initial  value 616.807421 
iter  10 value 518.267344
iter  20 value 514.946650
iter  30 value 514.906431
iter  40 value 500.773962
iter  50 value 472.621811
iter  60 value 460.598164
iter  70 value 456.083474
iter  80 value 448.564842
iter  90 value 442.517577
iter 100 value 436.914626
final  value 436.914626 
stopped after 100 iterations
# weights:  34
initial  value 578.950126 
iter  10 value 509.498824
iter  20 value 490.887909
iter  30 value 485.871269
iter  40 value 485.064226
iter  50 value 483.917618
iter  60 value 482.898100
iter  70 value 482.856975
final  value 482.856960 
converged
# weights:  78
initial  value 714.846613 
iter  10 value 504.558162
iter  20 value 462.603511
iter  30 value 439.255746
iter  40 value 430.052906
iter  50 value 424.659177
iter  60 value 420.907158
iter  70 value 418.062145
iter  80 value 417.428393
iter  90 value 417.153289
iter 100 value 417.117116
final  value 417.117116 
stopped after 100 iterations
# weights:  78
initial  value 546.897965 
iter  10 value 509.856537
iter  20 value 470.586066
iter  30 value 456.308167
iter  40 value 443.140439
iter  50 value 435.167475
iter  60 value 428.968524
iter  70 value 424.157955
iter  80 value 422.698669
iter  90 value 422.254959
iter 100 value 421.904743
final  value 421.904743 
stopped after 100 iterations
# weights:  177
initial  value 731.921674 
iter  10 value 515.036604
iter  20 value 510.633007
iter  30 value 509.750920
final  value 509.730515 
converged
# weights:  89
initial  value 723.255644 
iter  10 value 514.993296
iter  20 value 514.923451
iter  30 value 514.923369
iter  40 value 514.923275
iter  50 value 514.923167
iter  60 value 514.923041
iter  70 value 514.922889
iter  80 value 514.922702
iter  90 value 514.922464
iter 100 value 514.922149
final  value 514.922149 
stopped after 100 iterations
# weights:  122
initial  value 707.522107 
iter  10 value 516.039008
iter  20 value 515.695674
final  value 515.695193 
converged
# weights:  221
initial  value 846.242547 
iter  10 value 515.105460
iter  20 value 514.922354
iter  30 value 514.921883
iter  40 value 514.921181
iter  50 value 514.920012
iter  60 value 514.917670
iter  70 value 514.910755
iter  80 value 514.811310
iter  90 value 491.064702
iter 100 value 466.223088
final  value 466.223088 
stopped after 100 iterations
# weights:  122
initial  value 1144.894759 
iter  10 value 754.250819
iter  20 value 753.444166
final  value 753.442048 
converged
Neural Networks with Feature Extraction 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  size  decay         RMSE      Rsquared     MAE        Selected
   1    1.810456e-02  1.014218  0.005216873  0.8019791          
   3    8.809574e-02  1.015261  0.005487878  0.8018455          
   4    8.122348e-05  1.021000  0.003404352  0.8136015          
   5    1.634087e-02  1.038953  0.002889525  0.8247472          
   7    1.418191e-02  1.054840  0.002683272  0.8378784          
   7    1.426626e-02  1.059257  0.003645625  0.8358006          
   8    3.366673e-05  1.017838  0.002014290  0.8068986          
   8    3.528491e+00  1.001205  0.001067019  0.7903631          
   9    6.671715e-02  1.045064  0.013845365  0.8285066          
  11    6.546499e-04  1.031481  0.001459300  0.8120599          
  11    5.849359e-03  1.063132  0.010221230  0.8399164          
  11    1.711692e+00  1.000295  0.001017841  0.7904515  *       
  11    3.730599e+00  1.000918  0.001084817  0.7903386          
  12    1.704722e-03  1.036826  0.007058408  0.8244559          
  13    1.351855e-01  1.045285  0.001480158  0.8215750          
  15    9.575963e-01  1.000993  0.001372667  0.7911477          
  16    5.985918e-01  1.003243  0.001738593  0.7931471          
  20    8.526253e-05  1.020826  0.005278516  0.8068151          
  20    3.754391e-04  1.033618  0.002593655  0.8183143          
  20    3.973042e-03  1.069408  0.007862943  0.8482365          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 11 and decay = 1.711692.
[1] "Mon Mar 05 09:44:23 2018"
Principal Component Analysis 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  ncomp  RMSE       Rsquared      MAE        Selected
  1      0.9987044  0.0024898648  0.7905377  *       
  2      0.9999785  0.0014605252  0.7922812          
  3      1.0021398  0.0008300835  0.7935468          
  4      1.0027084  0.0006070383  0.7936270          
  5      1.0032252  0.0001703438  0.7940968          
  6      1.0043846  0.0005528045  0.7950784          
  7      1.0057227  0.0011162182  0.7958960          
  8      1.0055364  0.0011125554  0.7956769          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 1.
[1] "Mon Mar 05 09:44:36 2018"
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/src/contrib:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/src/contrib/PACKAGES'
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4/PACKAGES'
Loading required package: plsRglm
____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0866374383214861) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.092236942332238) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.185725952638313) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0303227201569825) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.166039414843544) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0605336360167712) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0524846483953297) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.127474582614377) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.184919631760567) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.10710917362012) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.137697668606415) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.07438844894059) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.131498497538269) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.10505782905966) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.105143673717976) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.159237692365423) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0175733639393002) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.174447519890964) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0310252746101469) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0866374383214861) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.092236942332238) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.185725952638313) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0303227201569825) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.166039414843544) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0605336360167712) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0524846483953297) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.127474582614377) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.184919631760567) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.10710917362012) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.137697668606415) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.07438844894059) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.131498497538269) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.10505782905966) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.105143673717976) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.159237692365423) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0175733639393002) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.174447519890964) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0310252746101469) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0866374383214861) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.092236942332238) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.185725952638313) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0303227201569825) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.166039414843544) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0605336360167712) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0524846483953297) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.127474582614377) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.108592934859917) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.184919631760567) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.10710917362012) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.137697668606415) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.07438844894059) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.131498497538269) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.10505782905966) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.105143673717976) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.159237692365423) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0175733639393002) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.174447519890964) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0310252746101469) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.185725952638313) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

Partial Least Squares Generalized Linear Models  

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  nt  alpha.pvals.expli  RMSE      Rsquared     MAE        Selected
  1   0.10859293         1.009591  0.003063281  0.7972111          
  2   0.03032272         1.009361  0.001232465  0.7979866          
  2   0.13149850         1.009591  0.003063281  0.7972111          
  3   0.10505783         1.009591  0.003063281  0.7972111          
  3   0.10514367         1.009591  0.003063281  0.7972111          
  3   0.10710917         1.009591  0.003063281  0.7972111          
  4   0.01757336         1.009361  0.001232465  0.7979866          
  4   0.12747458         1.009591  0.003063281  0.7972111          
  4   0.18491963         1.007818  0.003733051  0.7950957          
  5   0.06053364         1.009361  0.001232465  0.7979866          
  5   0.09223694         1.009591  0.003063281  0.7972111          
  5   0.17444752         1.007818  0.003733051  0.7950957          
  5   0.18572595         1.007818  0.003733051  0.7950957  *       
  6   0.07438845         1.009361  0.001232465  0.7979866          
  6   0.13769767         1.009591  0.003063281  0.7972111          
  7   0.15923769         1.009591  0.003063281  0.7972111          
  7   0.16603941         1.009591  0.003063281  0.7972111          
  9   0.03102527         1.009361  0.001232465  0.7979866          
  9   0.05248465         1.009361  0.001232465  0.7979866          
  9   0.08663744         1.009361  0.001232465  0.7979866          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nt = 5 and alpha.pvals.expli
 = 0.185726.
[1] "Mon Mar 05 09:45:24 2018"
Projection Pursuit Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  nterms  RMSE      Rsquared     MAE        Selected
   1      1.025893  0.001716387  0.8099076  *       
   2      1.064715  0.003456236  0.8385428          
   3      1.081599  0.001493836  0.8545721          
   4      1.150813  0.008189787  0.9111414          
   5      1.177342  0.013255041  0.9309944          
   6      1.179846  0.011091134  0.9292767          
   7      1.213151  0.012810454  0.9697936          
   8      1.213807  0.017357179  0.9646093          
   9      1.204153  0.005481621  0.9505284          
  10      1.227295  0.003576723  0.9824508          
  11      1.239626  0.009019307  0.9844009          
  12      1.235819  0.006256711  0.9789428          
  13      1.247731  0.005398109  0.9908058          
  14      1.259392  0.002675143  1.0015031          
  15      1.275512  0.007555478  1.0233921          
  16      1.284341  0.004275954  1.0135815          
  17      1.344444  0.004922206  1.0684038          
  18      1.299940  0.002329307  1.0250493          
  19      1.330722  0.003447001  1.0475568          
  20      1.298295  0.005084727  1.0146990          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was nterms = 1.
[1] "Mon Mar 05 09:45:48 2018"
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/src/contrib:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/src/contrib/PACKAGES'
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4:
  cannot open URL 'https://rweb.crmda.ku.edu/cran/bin/windows/contrib/3.4/PACKAGES'
Quantile Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  mtry  RMSE      Rsquared     MAE       Selected
  1     1.652367  0.005387780  1.394612          
  2     1.656411  0.008055075  1.396544          
  3     1.653911  0.005796954  1.393100          
  4     1.665137  0.007225436  1.402239          
  5     1.658922  0.008449616  1.396267          
  6     1.650465  0.003859136  1.389143  *       
  7     1.657918  0.010295846  1.394001          
  9     1.670231  0.010036056  1.405503          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 6.
[1] "Mon Mar 05 09:47:41 2018"
Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  min.node.size  mtry  splitrule   RMSE      Rsquared     MAE        Selected
   1             5     variance    1.045555  0.009440241  0.8315442          
   3             6     variance    1.051799  0.010962718  0.8361763          
   4             2     extratrees  1.016051  0.003565771  0.8070600          
   5             5     variance    1.048348  0.011027852  0.8326657          
   7             5     extratrees  1.024611  0.004542725  0.8149736          
   7             5     maxstat     1.026848  0.007106949  0.8138110          
   8             1     extratrees  1.009195  0.003450948  0.8000137  *       
   8             9     extratrees  1.032197  0.006065366  0.8214295          
   9             6     maxstat     1.027561  0.005622606  0.8159631          
  11             3     variance    1.041146  0.009377055  0.8278541          
  11             5     extratrees  1.023911  0.005171035  0.8146779          
  11             8     extratrees  1.028911  0.006633065  0.8186978          
  11             9     maxstat     1.034402  0.006758776  0.8219884          
  12             4     maxstat     1.022304  0.006489862  0.8111671          
  13             7     variance    1.048370  0.012591138  0.8326089          
  15             8     extratrees  1.025221  0.005050755  0.8151724          
  16             8     maxstat     1.029028  0.004669787  0.8160147          
  20             2     maxstat     1.011373  0.003372311  0.8028214          
  20             3     extratrees  1.013491  0.003452874  0.8057198          
  20             4     maxstat     1.020427  0.005129375  0.8095210          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mtry = 1, splitrule = extratrees
 and min.node.size = 8.
[1] "Mon Mar 05 09:48:32 2018"
Error in code$varImp(object$finalModel, ...) : 
  No importance values available
In addition: Warning messages:
1: package 'gpls' is not available (for R version 3.4.3) 
2: package 'rPython' is not available (for R version 3.4.3) 
Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  predFixed  minNode  RMSE      Rsquared     MAE        Selected
  1          11       1.027750  0.007325928  0.8166558  *       
  2           4       1.039987  0.008128783  0.8273745          
  2          14       1.033127  0.007780858  0.8216739          
  3          11       1.040391  0.006920049  0.8255246          
  4           2       1.047734  0.007401090  0.8309351          
  4          13       1.043962  0.008562202  0.8285248          
  4          19       1.042532  0.009992985  0.8275548          
  5           7       1.048028  0.006208157  0.8309306          
  5          10       1.049936  0.009738858  0.8325959          
  5          18       1.041575  0.008358357  0.8271142          
  5          19       1.043415  0.008477549  0.8284167          
  6           8       1.051771  0.007382201  0.8340925          
  6          14       1.046048  0.008491584  0.8286515          
  7          16       1.047500  0.009406584  0.8294758          
  7          17       1.045563  0.008459823  0.8306555          
  9           4       1.058351  0.008573042  0.8385211          
  9           6       1.055638  0.007502151  0.8355733          
  9           9       1.053459  0.007378660  0.8337455          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were predFixed = 1 and minNode = 11.
[1] "Mon Mar 05 10:00:29 2018"
Loading required package: lars
Loaded lars 1.2

Relaxed Lasso 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  phi         lambda     RMSE      Rsquared     MAE        Selected
  0.08786682   3.781876  1.011044  0.001589833  0.8016526          
  0.15161360   1.727911  1.010775  0.001610659  0.8014910          
  0.15512637  40.096359  1.004727  0.021346530  0.7968583          
  0.26242324  39.338454  1.004133  0.021346530  0.7964042          
  0.30266818   6.585792  1.009740  0.001439536  0.8004124          
  0.37194224   7.711552  1.009381  0.001388298  0.8001107          
  0.43318719  42.457362  1.000511          NaN  0.7941279  *       
  0.46118471   6.219811  1.009259  0.001623692  0.7999829          
  0.52528915   2.994226  1.009302  0.001616586  0.7999303          
  0.52571837   2.861985  1.009300  0.001616617  0.7999287          
  0.53554587   2.131916  1.009344  0.001629722  0.8000333          
  0.54296467   1.034744  1.009319  0.001630167  0.8000061          
  0.63737291   4.268637  1.008895  0.001625242  0.7995100          
  0.65749249   1.471900  1.008929  0.001637696  0.7995889          
  0.68848834   9.324046  1.007307  0.001626968  0.7977722          
  0.79618846  17.205288  1.005095  0.002457461  0.7956840          
  0.83019707  13.545473  1.006012  0.002179023  0.7965179          
  0.87223760   6.801353  1.007485  0.001606556  0.7981281          
  0.92459816   4.079432  1.007929  0.001655743  0.7985173          
  0.92862976   6.552190  1.007321  0.001643892  0.7979603          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 42.45736 and phi = 0.4331872.
[1] "Mon Mar 05 10:00:43 2018"
Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  mtry  RMSE      Rsquared     MAE        Selected
  1     1.027156  0.007224084  0.8174839  *       
  2     1.036660  0.009813562  0.8244066          
  3     1.041443  0.008737544  0.8282829          
  4     1.045870  0.010006303  0.8309123          
  5     1.048162  0.009774174  0.8324005          
  6     1.049910  0.010306928  0.8331967          
  7     1.051420  0.011911106  0.8347321          
  9     1.052538  0.010061633  0.8368045          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 1.
[1] "Mon Mar 05 10:02:03 2018"
Error in varImp[, "%IncMSE"] : subscript out of bounds
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Ridge Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  lambda        RMSE      Rsquared     MAE        Selected
  1.842479e-05  1.010177  0.001391379  0.7986530          
  6.442721e-05  1.010177  0.001391376  0.7986529          
  1.138842e-04  1.010177  0.001391373  0.7986528          
  2.402199e-04  1.010177  0.001391365  0.7986527          
  6.838200e-04  1.010176  0.001391335  0.7986521          
  8.028400e-04  1.010176  0.001391328  0.7986519          
  1.840414e-03  1.010175  0.001391259  0.7986506          
  2.408574e-03  1.010174  0.001391222  0.7986498          
  2.829460e-03  1.010174  0.001391194  0.7986493          
  1.077621e-02  1.010164  0.001390669  0.7986390          
  1.296528e-02  1.010161  0.001390524  0.7986362          
  1.320302e-02  1.010161  0.001390509  0.7986359          
  1.480338e-02  1.010159  0.001390402  0.7986339          
  2.312744e-02  1.010149  0.001389848  0.7986235          
  4.540062e-02  1.010124  0.001388354  0.7985967          
  1.710853e-01  1.010008  0.001379817  0.7984766          
  4.001151e-01  1.009871  0.001365052  0.7983332          
  7.551302e+00  1.009538  0.001260642  0.7980813          
  8.080948e+00  1.009536  0.001259067  0.7980807          
  9.902178e+00  1.009532  0.001254776  0.7980790  *       

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was lambda = 9.902178.
[1] "Mon Mar 05 10:02:17 2018"
Robust Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  intercept  psi           RMSE      Rsquared     MAE        Selected
  FALSE      psi.huber     1.010957  0.001488776  0.8013373          
  FALSE      psi.hampel    1.010764  0.001534487  0.8012389          
  FALSE      psi.bisquare  1.010453  0.001472751  0.8006690          
   TRUE      psi.huber     1.009052  0.001428254  0.7976090          
   TRUE      psi.hampel    1.009200  0.001408723  0.7977321          
   TRUE      psi.bisquare  1.008605  0.001386628  0.7970633  *       

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were intercept = TRUE and psi
 = psi.bisquare.
[1] "Mon Mar 05 10:02:31 2018"
CART 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  cp           RMSE      Rsquared     MAE        Selected
  0.000000000  1.237343  0.007690810  0.9876159          
  0.001577939  1.237343  0.007690810  0.9876159          
  0.004145331  1.233720  0.006220124  0.9838987          
  0.004373837  1.233720  0.006220124  0.9838987          
  0.004397370  1.233720  0.006220124  0.9838987          
  0.004630381  1.233720  0.006220124  0.9838987          
  0.005293457  1.221622  0.005768045  0.9759561          
  0.005643814  1.218771  0.005484900  0.9746136          
  0.006203656  1.208920  0.004859158  0.9681664          
  0.006595793  1.204333  0.005630809  0.9642181          
  0.006757984  1.204333  0.005630809  0.9642181          
  0.007581716  1.187976  0.005418029  0.9531024          
  0.007663341  1.187976  0.005418029  0.9531024          
  0.008281543  1.185428  0.005934212  0.9544036          
  0.008651522  1.177352  0.004290685  0.9469610          
  0.009681122  1.166854  0.003765633  0.9377528  *       

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.009681122.
[1] "Mon Mar 05 10:02:44 2018"
CART 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE      Rsquared    MAE     
  1.161453  0.00389784  0.930748

[1] "Mon Mar 05 10:02:57 2018"
CART 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  maxdepth  RMSE      Rsquared     MAE        Selected
   8        1.097260  0.002746702  0.8665688  *       
   9        1.103051  0.002983681  0.8731031          
  11        1.111972  0.004863774  0.8819758          
  12        1.120734  0.006624213  0.8895171          
  13        1.129480  0.006109068  0.8972575          
  15        1.139795  0.006001744  0.9091977          
  17        1.141439  0.004889589  0.9114718          
  20        1.159413  0.004543202  0.9309090          
  21        1.161000  0.004535090  0.9317999          
  23        1.161453  0.003897840  0.9307480          
  29        1.161453  0.003897840  0.9307480          
  30        1.161453  0.003897840  0.9307480          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was maxdepth = 8.
[1] "Mon Mar 05 10:03:11 2018"
Quantile Regression with LASSO penalty 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  lambda        RMSE       Rsquared      MAE        Selected
  1.842479e-05  1.0129337  0.0015195661  0.7984928          
  6.442721e-05  1.0129337  0.0015195661  0.7984928          
  1.138842e-04  1.0127768  0.0015238166  0.7983655          
  2.402199e-04  1.0127768  0.0015238166  0.7983655          
  6.838200e-04  1.0125162  0.0015206377  0.7982347          
  8.028400e-04  1.0125162  0.0015206377  0.7982347          
  1.840414e-03  1.0116152  0.0013255249  0.7973278          
  2.408574e-03  1.0116112  0.0013307364  0.7973065          
  2.829460e-03  1.0109130  0.0013535601  0.7969237          
  1.077621e-02  1.0074079  0.0030879426  0.7949743          
  1.296528e-02  1.0053592  0.0036509705  0.7939917          
  1.320302e-02  1.0056208  0.0039742155  0.7942314          
  1.480338e-02  1.0048173  0.0038068298  0.7935964          
  2.312744e-02  0.9998818  0.0023539706  0.7895009  *       
  4.540062e-02  1.0004229  0.0009436406  0.7899966          
  1.710853e-01  1.0005142           NaN  0.7903233          
  4.001151e-01  1.0005865           NaN  0.7903233          
  7.551302e+00  1.0005242           NaN  0.7903249          
  8.080948e+00  1.0005242           NaN  0.7903249          
  9.902178e+00  1.0005242           NaN  0.7903249          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was lambda = 0.02312744.
[1] "Mon Mar 05 10:03:26 2018"
Non-Convex Penalized Quantile Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  lambda        penalty  RMSE      Rsquared      MAE        Selected
  1.842479e-05  SCAD     1.012934  0.0015195661  0.7984928          
  6.442721e-05  SCAD     1.012934  0.0015195661  0.7984928          
  1.138842e-04  MCP      1.012934  0.0015195661  0.7984928          
  2.402199e-04  SCAD     1.012777  0.0015238166  0.7983655          
  6.838200e-04  SCAD     1.012777  0.0015238166  0.7983655          
  8.028400e-04  SCAD     1.012777  0.0015238166  0.7983655          
  1.840414e-03  MCP      1.012530  0.0015236851  0.7982583          
  2.408574e-03  SCAD     1.012556  0.0015235013  0.7982834          
  2.829460e-03  SCAD     1.012305  0.0015834806  0.7979987          
  1.077621e-02  MCP      1.014907  0.0025719484  0.8006836          
  1.296528e-02  SCAD     1.014258  0.0043941622  0.7998920          
  1.320302e-02  MCP      1.014569  0.0034207530  0.8008830          
  1.480338e-02  SCAD     1.014223  0.0046200391  0.8000370          
  2.312744e-02  MCP      1.000489  0.0027236540  0.7898152          
  4.540062e-02  SCAD     1.000423  0.0009436406  0.7899966  *       
  1.710853e-01  SCAD     1.000514           NaN  0.7903233          
  4.001151e-01  SCAD     1.000587           NaN  0.7903233          
  7.551302e+00  MCP      1.000524           NaN  0.7903249          
  8.080948e+00  MCP      1.000524           NaN  0.7903249          
  9.902178e+00  MCP      1.000524           NaN  0.7903249          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 0.04540062 and penalty = SCAD.
[1] "Mon Mar 05 10:03:41 2018"
Error : package RRF is required
In addition: Warning messages:
1: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
2: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Error : package RRF is required
Error : package RRF is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 10:03:55 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "RRF"                     
Error : package RRF is required
Error : package RRF is required
Error : package RRF is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 10:04:08 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "RRFglobal"               
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
In addition: There were 11 warnings (use warnings() to see them)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 10:11:02 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "rvmLinear"               
Timing stopped at: 9.29 0.08 9.38
Error in chol.default(crossprod(Kr)/var + diag(1/thetatmp)) : 
  the leading minor of order 405 is not positive definite
In addition: There were 39 warnings (use warnings() to see them)
Timing stopped at: 10.85 0.11 10.97
Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
In addition: There were 17 warnings (use warnings() to see them)
Timing stopped at: 12.84 0.22 13.06
Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 11:18:21 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "rvmPoly"                 
Timing stopped at: 15.07 0.12 15.21
Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
In addition: There were 13 warnings (use warnings() to see them)
Timing stopped at: 14.12 0.1 14.21
Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
Error in .local(object, ...) : test vector does not match model !
In addition: Warning messages:
1: model fit failed for Resample05: sigma=0.08284 Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
2: model fit failed for Resample15: sigma=0.08284 Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
3: In max(abs(logtheta[thetavec[which(nzindex)] != 0] + log(thetavec[thetavec !=  :
  no non-missing arguments to max; returning -Inf
4: model fit failed for Resample24: sigma=0.08284 Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
5: model fit failed for Resample25: sigma=0.08284 Error in crossprod(Kr)/var + diag(1/thetatmp) : non-conformable arrays
 
6: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 11:34:28 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "rvmRadial"               
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
Error in inpvar.ctr[i, ] : incorrect number of dimensions
In addition: There were 50 or more warnings (use warnings() to see the first 50)
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  57%  |                                                                              |========================================                              |  58%  |                                                                              |=========================================                             |  58%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  57%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%  |                                                                              |=======================================                               |  55%  |                                                                              |=======================================                               |  56%  |                                                                              |========================================                              |  57%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%  |                                                                              |======================================                                |  55%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%
  |                                                                              |                                                                      |   0%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%  |                                                                              |======================================                                |  54%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%  |                                                                              |===                                                                   |   4%  |                                                                              |===                                                                   |   5%  |                                                                              |====                                                                  |   5%  |                                                                              |====                                                                  |   6%  |                                                                              |=====                                                                 |   7%  |                                                                              |=====                                                                 |   8%  |                                                                              |======                                                                |   8%  |                                                                              |======                                                                |   9%  |                                                                              |=======                                                               |   9%  |                                                                              |=======                                                               |  10%  |                                                                              |=======                                                               |  11%  |                                                                              |========                                                              |  11%  |                                                                              |========                                                              |  12%  |                                                                              |=========                                                             |  12%  |                                                                              |=========                                                             |  13%  |                                                                              |=========                                                             |  14%  |                                                                              |==========                                                            |  14%  |                                                                              |==========                                                            |  15%  |                                                                              |===========                                                           |  15%  |                                                                              |===========                                                           |  16%  |                                                                              |============                                                          |  16%  |                                                                              |============                                                          |  17%  |                                                                              |============                                                          |  18%  |                                                                              |=============                                                         |  18%  |                                                                              |=============                                                         |  19%  |                                                                              |==============                                                        |  19%  |                                                                              |==============                                                        |  20%  |                                                                              |==============                                                        |  21%  |                                                                              |===============                                                       |  21%  |                                                                              |===============                                                       |  22%  |                                                                              |================                                                      |  22%  |                                                                              |================                                                      |  23%  |                                                                              |================                                                      |  24%  |                                                                              |=================                                                     |  24%  |                                                                              |=================                                                     |  25%  |                                                                              |==================                                                    |  25%  |                                                                              |==================                                                    |  26%  |                                                                              |===================                                                   |  26%  |                                                                              |===================                                                   |  27%  |                                                                              |===================                                                   |  28%  |                                                                              |====================                                                  |  28%  |                                                                              |====================                                                  |  29%  |                                                                              |=====================                                                 |  29%  |                                                                              |=====================                                                 |  30%  |                                                                              |=====================                                                 |  31%  |                                                                              |======================                                                |  31%  |                                                                              |======================                                                |  32%  |                                                                              |=======================                                               |  32%  |                                                                              |=======================                                               |  33%  |                                                                              |=======================                                               |  34%  |                                                                              |========================                                              |  34%  |                                                                              |========================                                              |  35%  |                                                                              |=========================                                             |  35%  |                                                                              |=========================                                             |  36%  |                                                                              |==========================                                            |  36%  |                                                                              |==========================                                            |  37%  |                                                                              |==========================                                            |  38%  |                                                                              |===========================                                           |  38%  |                                                                              |===========================                                           |  39%  |                                                                              |============================                                          |  39%  |                                                                              |============================                                          |  40%  |                                                                              |============================                                          |  41%  |                                                                              |=============================                                         |  41%  |                                                                              |=============================                                         |  42%  |                                                                              |==============================                                        |  42%  |                                                                              |==============================                                        |  43%  |                                                                              |===============================                                       |  44%  |                                                                              |===============================                                       |  45%  |                                                                              |================================                                      |  45%  |                                                                              |================================                                      |  46%  |                                                                              |=================================                                     |  47%  |                                                                              |=================================                                     |  48%  |                                                                              |==================================                                    |  48%  |                                                                              |==================================                                    |  49%  |                                                                              |===================================                                   |  49%  |                                                                              |===================================                                   |  50%  |                                                                              |===================================                                   |  51%  |                                                                              |====================================                                  |  51%  |                                                                              |====================================                                  |  52%  |                                                                              |=====================================                                 |  52%  |                                                                              |=====================================                                 |  53%
  |                                                                              |                                                                      |   0%  |                                                                              |                                                                      |   1%  |                                                                              |=                                                                     |   1%  |                                                                              |=                                                                     |   2%  |                                                                              |==                                                                    |   2%  |                                                                              |==                                                                    |   3%
  |                                                                              |                                                                      |   0%
Error in inpvar.ctr[i, ] : incorrect number of dimensions
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 14:00:46 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "SBC"                     
Partial Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  ncomp  RMSE      Rsquared     MAE        Selected
  1      1.009065  0.001206158  0.7976930  *       
  2      1.010216  0.001459825  0.7987389          
  3      1.010160  0.001386382  0.7986385          
  4      1.010176  0.001391366  0.7986530          
  5      1.010177  0.001391364  0.7986529          
  6      1.010177  0.001391376  0.7986530          
  7      1.010177  0.001391380  0.7986530          
  8      1.010177  0.001391380  0.7986530          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 1.
[1] "Mon Mar 05 14:00:59 2018"
Error in mvrValstats(object = object, estimate = "train") : 
  could not find function "mvrValstats"
Error : package spikeslab is required
Error : package spikeslab is required
Error : package spikeslab is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 14:01:13 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "spikeslab"               
Sparse Partial Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  kappa       eta         K  RMSE      Rsquared     MAE        Selected
  0.02211688  0.54296467  3  1.010115  0.001387041  0.7986044          
  0.06742244  0.65749249  2  1.010133  0.001587135  0.7980725          
  0.08803864  0.15161360  6  1.010177  0.001391380  0.7986530          
  0.11505076  0.53554587  2  1.010253  0.001262947  0.7987208          
  0.15291182  0.52571837  9  1.010177  0.001391380  0.7986530          
  0.15871908  0.52528915  6  1.010177  0.001391380  0.7986530          
  0.18874295  0.08786682  6  1.010177  0.001391380  0.7986530          
  0.19848000  0.92459816  5  1.009082  0.001628308  0.7982958          
  0.20430862  0.63737291  7  1.010177  0.001391381  0.7986530          
  0.25270551  0.46118471  5  1.010177  0.001391378  0.7986529          
  0.25939848  0.92862976  7  1.009986  0.001376987  0.7987327          
  0.26005610  0.30266818  3  1.010171  0.001392178  0.7986471          
  0.26419674  0.87223760  5  1.009941  0.001254732  0.7986802          
  0.28034396  0.37194224  7  1.010177  0.001391381  0.7986530          
  0.30475515  0.68848834  1  1.007728  0.004569896  0.7957859  *       
  0.35276773  0.83019707  5  1.009914  0.001274735  0.7987952          
  0.38351541  0.79618846  7  1.010177  0.001391381  0.7986530          
  0.48983516  0.26242324  4  1.010177  0.001391174  0.7986529          
  0.49228853  0.15512637  8  1.010177  0.001391380  0.7986530          
  0.49964423  0.43318719  7  1.010177  0.001391381  0.7986530          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were K = 1, eta = 0.6884883 and kappa
 = 0.3047551.
[1] "Mon Mar 05 14:01:30 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: Warning messages:
1: predictions failed for Fold1: threshold=0.767, n.components=3 Error in rowMeans(x) : 'x' must be an array of at least two dimensions
 
2: predictions failed for Fold2: threshold=0.767, n.components=3 Error in svd(x, LINPACK = TRUE) : a dimension is zero
 
3: predictions failed for Fold3: threshold=0.767, n.components=3 Error in svd(x, LINPACK = TRUE) : a dimension is zero
 
4: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: Warning messages:
1: predictions failed for Fold1: threshold=0.9232, n.components=3 Error in svd(x, LINPACK = TRUE) : a dimension is zero
 
2: predictions failed for Fold2: threshold=0.9232, n.components=3 Error in svd(x, LINPACK = TRUE) : a dimension is zero
 
3: predictions failed for Fold3: threshold=0.9232, n.components=3 Error in svd(x, LINPACK = TRUE) : a dimension is zero
 
4: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Supervised Principal Component Analysis 

752 samples
  9 predictor

No pre-processing
Resampling: Bootstrapped (25 reps) 
Summary of sample sizes: 752, 752, 752, 752, 752, 752, ... 
Resampling results across tuning parameters:

  n.components  threshold  RMSE       Rsquared     MAE        Selected
  1             0.1        0.9841029  0.002435593  0.7821138  *       
  1             0.5        0.9877093  0.003756576  0.7862049          
  1             0.9        0.9906116  0.002861064  0.7880650          
  2             0.1        0.9885939  0.002758278  0.7869888          
  2             0.5        0.9934803  0.003652164  0.7909406          
  2             0.9        0.9939750  0.004323577  0.7898142          
  3             0.1        0.9910497  0.002760295  0.7895681          
  3             0.5        0.9949024  0.004861871  0.7917878          
  3             0.9        0.9986459  0.005532991  0.7943499          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were threshold = 0.1 and n.components = 1.
[1] "Mon Mar 05 14:01:48 2018"
Error : 'x' should be a character matrix with a single column for string kernel methods
In addition: Warning messages:
1: predictions failed for Resample03: n.components=3, threshold=0.9 Error in svd(x, LINPACK = TRUE) : a dimension is zero
 
2: predictions failed for Resample05: n.components=3, threshold=0.9 Error in rowMeans(x) : 'x' must be an array of at least two dimensions
 
3: predictions failed for Resample07: n.components=3, threshold=0.9 Error in rowMeans(x) : 'x' must be an array of at least two dimensions
 
4: predictions failed for Resample10: n.components=3, threshold=0.9 Error in rowMeans(x) : 'x' must be an array of at least two dimensions
 
5: predictions failed for Resample15: n.components=3, threshold=0.9 Error in rowMeans(x) : 'x' must be an array of at least two dimensions
 
6: predictions failed for Resample16: n.components=3, threshold=0.9 Error in rowMeans(x) : 'x' must be an array of at least two dimensions
 
7: predictions failed for Resample19: n.components=3, threshold=0.9 Error in svd(x, LINPACK = TRUE) : a dimension is zero
 
8: predictions failed for Resample20: n.components=3, threshold=0.9 Error in rowMeans(x) : 'x' must be an array of at least two dimensions
 
9: predictions failed for Resample25: n.components=3, threshold=0.9 Error in rowMeans(x) : 'x' must be an array of at least two dimensions
 
10: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Error : 'x' should be a character matrix with a single column for string kernel methods
Error : 'x' should be a character matrix with a single column for string kernel methods
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 14:02:02 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "svmBoundrangeString"     
Error : 'x' should be a character matrix with a single column for string kernel methods
Error : 'x' should be a character matrix with a single column for string kernel methods
Error : 'x' should be a character matrix with a single column for string kernel methods
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 14:02:15 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "svmExpoString"           
Support Vector Machines with Linear Kernel 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  C             RMSE      Rsquared     MAE        Selected
  4.949773e-02  1.010707  0.002858183  0.7974989          
  1.269800e-01  1.011041  0.002970747  0.7977740          
  1.949477e-01  1.011169  0.002952529  0.7979039          
  3.418707e-01  1.011161  0.002949740  0.7979485          
  7.512445e-01  1.011213  0.002950883  0.7980005          
  8.476687e-01  1.011197  0.002974196  0.7979780          
  1.582591e+00  1.011203  0.002967073  0.7979941          
  1.937773e+00  1.011168  0.002953169  0.7979698          
  2.187463e+00  1.011185  0.002968509  0.7979759          
  5.984228e+00  1.011189  0.002977132  0.7979758          
  6.877834e+00  1.011197  0.002961216  0.7979898          
  6.972534e+00  1.011202  0.002972779  0.7979854          
  7.599487e+00  1.011250  0.002969360  0.7980115          
  1.063184e+01  1.011189  0.002968980  0.7979801          
  1.766295e+01  1.011184  0.002979956  0.7979782          
  4.793581e+01  1.011217  0.002970679  0.7979863          
  9.085300e+01  1.011193  0.002958007  0.7979776          
  8.289002e+02  1.010923  0.002956264  0.7977118          
  8.722850e+02  1.010141  0.003157390  0.7975162  *       
  1.016452e+03  1.010903  0.003047662  0.7974687          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was C = 872.285.
[1] "Mon Mar 05 14:09:17 2018"
Error in if (mean.improvement < 0) { : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In method$predict(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab prediction calculations failed; returning NAs

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations

WARNING: reaching max number of iterations
Support Vector Machines with Linear Kernel 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  cost          RMSE      Rsquared     MAE        Selected
  4.949773e-02  1.010707  0.002858183  0.7974989          
  1.269800e-01  1.011041  0.002970747  0.7977740          
  1.949477e-01  1.011169  0.002952529  0.7979039          
  3.418707e-01  1.011161  0.002949740  0.7979485          
  7.512445e-01  1.011213  0.002950883  0.7980005          
  8.476687e-01  1.011197  0.002974196  0.7979780          
  1.582591e+00  1.011203  0.002967073  0.7979941          
  1.937773e+00  1.011168  0.002953169  0.7979698          
  2.187463e+00  1.011185  0.002968509  0.7979759          
  5.984228e+00  1.011189  0.002977132  0.7979758          
  6.877834e+00  1.011197  0.002961216  0.7979898          
  6.972534e+00  1.011202  0.002972779  0.7979854          
  7.599487e+00  1.011250  0.002969360  0.7980115          
  1.063184e+01  1.011189  0.002968980  0.7979801          
  1.766295e+01  1.011184  0.002979956  0.7979782          
  4.793581e+01  1.011217  0.002970679  0.7979863          
  9.085300e+01  1.011193  0.002958007  0.7979776          
  8.289002e+02  1.010923  0.002956264  0.7977118          
  8.722850e+02  1.010141  0.003157390  0.7975162  *       
  1.016452e+03  1.010903  0.003047662  0.7974687          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cost = 872.285.
[1] "Mon Mar 05 14:16:19 2018"
Error : package LiblineaR is required
Error : package LiblineaR is required
Error : package LiblineaR is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 14:16:32 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "svmLinear3"              
Support Vector Machines with Polynomial Kernel 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  degree  scale         C             RMSE      Rsquared      MAE      
  1       6.363679e-05   27.58620661  1.001836  0.0020980589  0.7910148
  1       6.089386e-03   17.04257581  1.011025  0.0029560084  0.7977746
  1       6.121373e-03  998.56235305  1.011129  0.0030245121  0.7979558
  1       6.901519e-03    0.22182624  1.001389  0.0020473729  0.7906725
  1       7.555653e-03    0.98408852  1.006472  0.0027771819  0.7941476
  1       3.057647e-02    0.17645823  1.005299  0.0025600989  0.7933735
  2       2.922703e-05   18.50012561  1.000923  0.0023061126  0.7903546
  2       4.022102e-04    0.68627195  1.000477  0.0024161273  0.7901124
  2       9.368650e-04   74.24105889  1.012353  0.0030604329  0.7989830
  2       2.784543e-03    3.67849594  1.009973  0.0028511376  0.7971504
  2       2.391844e-02   78.89146628  1.110170  0.0009278755  0.8757829
  2       4.463724e-02    0.03929907  1.004495  0.0027319450  0.7934288
  2       4.204919e-01    6.87458051  1.120387  0.0007635117  0.8841349
  2       7.967509e-01    5.21680880  1.121115  0.0007599183  0.8845974
  2       8.369398e-01   59.75951466  1.126626  0.0009327586  0.8888919
  3       6.642469e-05  200.06400087  1.010059  0.0025726314  0.7970990
  3       2.461011e-04    1.32401194  1.000832  0.0023934257  0.7903524
  3       1.978510e-03   45.36469873  1.020111  0.0024483130  0.8074027
  3       1.661954e-01   36.64809316  1.884355  0.0074717525  1.3497351
  3       2.517095e-01    5.19975562  1.867594  0.0070138026  1.3401601
  Selected
          
          
          
          
          
          
          
  *       
          
          
          
          
          
          
          
          
          
          
          
          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were degree = 2, scale = 0.0004022102 and
 C = 0.686272.
[1] "Mon Mar 05 14:26:20 2018"
Error in if (mean.improvement < 0) { : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In method$predict(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab prediction calculations failed; returning NAs
Support Vector Machines with Radial Basis Function Kernel 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  sigma       C             RMSE      Rsquared      MAE        Selected
  0.01706583    4.97410967  1.048423  0.0020896028  0.8297304          
  0.02437689    1.66531878  1.032440  0.0019345091  0.8182009          
  0.02813516  433.86488856  1.493635  0.0118211811  1.1599113          
  0.02867307    3.27696889  1.062182  0.0017221830  0.8394200          
  0.02868679    1.41599986  1.035075  0.0020215639  0.8201295          
  0.03054687    0.27914889  1.011999  0.0023426329  0.8005259          
  0.03541928  572.02143523  1.662174  0.0104185042  1.2628931          
  0.03595840   28.86483362  1.228049  0.0058088509  0.9627409          
  0.04070416  184.84765673  1.482816  0.0124637400  1.1553276          
  0.04729316    3.42579631  1.098929  0.0023142306  0.8688181          
  0.05103269    2.69512638  1.090702  0.0021044708  0.8625342          
  0.05385757    0.75566451  1.038217  0.0015567360  0.8229414          
  0.06243764    3.11240934  1.117231  0.0034667095  0.8844700          
  0.08717687  898.56694381  1.969623  0.0068640171  1.4928865          
  0.11551128    0.08207331  1.005875  0.0009576674  0.7958762  *       
  0.12726732  193.68350713  1.587694  0.0055988193  1.2403254          
  0.15207130  133.89817807  1.460573  0.0046990860  1.1504627          
  0.23574157   27.80972251  1.228386  0.0023304464  0.9750695          
  0.24362714   32.49185877  1.218877  0.0021739889  0.9670435          
  0.28790739   85.98939630  1.166177  0.0015398805  0.9234214          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were sigma = 0.1155113 and C = 0.08207331.
[1] "Mon Mar 05 14:27:08 2018"
Error in if (mean.improvement < 0) { : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In method$predict(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab prediction calculations failed; returning NAs
Support Vector Machines with Radial Basis Function Kernel 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  C             RMSE      Rsquared     MAE        Selected
  4.949773e-02  1.003270  0.001730946  0.7932345  *       
  1.269800e-01  1.010049  0.001752662  0.7993780          
  1.949477e-01  1.014933  0.001283619  0.8042582          
  3.418707e-01  1.025658  0.001438686  0.8139403          
  7.512445e-01  1.051114  0.001607933  0.8332058          
  8.476687e-01  1.058354  0.001623409  0.8396755          
  1.582591e+00  1.086265  0.002317085  0.8611760          
  1.937773e+00  1.096640  0.002740072  0.8692786          
  2.187463e+00  1.110207  0.003522570  0.8803739          
  5.984228e+00  1.176967  0.005367219  0.9302853          
  6.877834e+00  1.187442  0.005692270  0.9386613          
  6.972534e+00  1.191079  0.005830304  0.9417746          
  7.599487e+00  1.197988  0.006042133  0.9471151          
  1.063184e+01  1.226517  0.006238598  0.9711690          
  1.766295e+01  1.283486  0.008893905  1.0152851          
  4.793581e+01  1.432288  0.008251192  1.1255912          
  9.085300e+01  1.544384  0.006885833  1.2021204          
  8.289002e+02  2.060957  0.008370959  1.5401955          
  8.722850e+02  2.068933  0.008075269  1.5517898          
  1.016452e+03  2.077333  0.007970739  1.5608837          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was C = 0.04949773.
[1] "Mon Mar 05 14:27:51 2018"
Error in if (mean.improvement < 0) { : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In method$predict(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab prediction calculations failed; returning NAs
Support Vector Machines with Radial Basis Function Kernel 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  sigma       C             RMSE      Rsquared      MAE        Selected
  0.01706583    4.97410967  1.048423  0.0020896028  0.8297304          
  0.02437689    1.66531878  1.032440  0.0019345091  0.8182009          
  0.02813516  433.86488856  1.493635  0.0118211811  1.1599113          
  0.02867307    3.27696889  1.062182  0.0017221830  0.8394200          
  0.02868679    1.41599986  1.035075  0.0020215639  0.8201295          
  0.03054687    0.27914889  1.011999  0.0023426329  0.8005259          
  0.03541928  572.02143523  1.662174  0.0104185042  1.2628931          
  0.03595840   28.86483362  1.228049  0.0058088509  0.9627409          
  0.04070416  184.84765673  1.482816  0.0124637400  1.1553276          
  0.04729316    3.42579631  1.098929  0.0023142306  0.8688181          
  0.05103269    2.69512638  1.090702  0.0021044708  0.8625342          
  0.05385757    0.75566451  1.038217  0.0015567360  0.8229414          
  0.06243764    3.11240934  1.117231  0.0034667095  0.8844700          
  0.08717687  898.56694381  1.969623  0.0068640171  1.4928865          
  0.11551128    0.08207331  1.005875  0.0009576674  0.7958762  *       
  0.12726732  193.68350713  1.587694  0.0055988193  1.2403254          
  0.15207130  133.89817807  1.460573  0.0046990860  1.1504627          
  0.23574157   27.80972251  1.228386  0.0023304464  0.9750695          
  0.24362714   32.49185877  1.218877  0.0021739889  0.9670435          
  0.28790739   85.98939630  1.166177  0.0015398805  0.9234214          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were sigma = 0.1155113 and C = 0.08207331.
[1] "Mon Mar 05 14:28:39 2018"
Error in if (mean.improvement < 0) { : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In method$predict(modelFit = modelFit, newdata = newdata, submodels = param) :
  kernlab prediction calculations failed; returning NAs
Error : 'x' should be a character matrix with a single column for string kernel methods
Error : 'x' should be a character matrix with a single column for string kernel methods
Error : 'x' should be a character matrix with a single column for string kernel methods
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 14:28:52 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "svmSpectrumString"       
Bagged CART 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.042469  0.003936332  0.8303831

[1] "Mon Mar 05 14:29:07 2018"
Partial Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  ncomp  RMSE      Rsquared     MAE        Selected
  1      1.009065  0.001206158  0.7976930  *       
  2      1.010216  0.001459825  0.7987389          
  3      1.010160  0.001386382  0.7986385          
  4      1.010176  0.001391366  0.7986530          
  5      1.010177  0.001391364  0.7986529          
  6      1.010177  0.001391375  0.7986530          
  7      1.010174  0.001392219  0.7986490          
  8      1.025043  0.003656041  0.8118751          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 1.
[1] "Mon Mar 05 14:30:29 2018"
Error in mvrValstats(object = object, estimate = "train") : 
  could not find function "mvrValstats"
In addition: Warning messages:
1: In fitFunc(X, Y, ncomp, Y.add = Y.add, ...) :
  No convergence in100iterations

2: In fitFunc(X, Y, ncomp, Y.add = Y.add, ...) :
  No convergence in100iterations

3: In fitFunc(X, Y, ncomp, Y.add = Y.add, ...) :
  No convergence in100iterations

eXtreme Gradient Boosting 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  max_depth  eta         rate_drop   skip_drop   min_child_weight  subsample
   1         0.36876456  0.14289939  0.43320601  18                0.6949255
   2         0.39178262  0.37609397  0.94403953   8                0.8911538
   2         0.50592976  0.02061258  0.74722910   9                0.4166617
   3         0.21683632  0.21872190  0.86977476  20                0.3740241
   4         0.17897697  0.45714918  0.40231428  20                0.9531831
   4         0.44881821  0.38434195  0.61534736  16                0.6882935
   5         0.27570603  0.46415342  0.24707514   2                0.6162539
   5         0.42043969  0.26382466  0.64575125   1                0.3764285
   6         0.11391158  0.13185040  0.29317937  15                0.5865618
   6         0.19974261  0.44513696  0.06841868   6                0.7222752
   6         0.36403679  0.33197878  0.27082742   8                0.4151703
   6         0.59855077  0.05183834  0.85629441  13                0.2751906
   7         0.01420352  0.27972755  0.62843828   5                0.6656657
   7         0.10072945  0.11771685  0.13649077  18                0.4297908
   7         0.45231844  0.19956644  0.74460285   4                0.8420516
   8         0.40814694  0.06394956  0.15555404   4                0.6695128
   9         0.29564586  0.49456360  0.27974325  12                0.6734504
   9         0.31173212  0.38471038  0.86374009  18                0.4663154
  10         0.29583449  0.33112716  0.39729146   3                0.5820876
  10         0.43631712  0.21447902  0.15573161   2                0.7868965
  colsample_bytree  gamma      nrounds  RMSE      Rsquared      MAE      
  0.4277590         0.2758539   378     1.085225  0.0086720898  0.8653982
  0.3993335         2.3134213   177     1.132691  0.0056562522  0.8988396
  0.6294667         3.7679305   985     1.236817  0.0067631189  0.9788308
  0.5020726         8.7093691   980     1.077274  0.0050481319  0.8544468
  0.6665698         9.1859942   521     1.023128  0.0016425252  0.8030962
  0.3389079         0.7112590   561     1.159848  0.0030688172  0.9124521
  0.5530103         1.1953252   506     1.098110  0.0068029504  0.8709613
  0.5293779         2.1419926  1000     1.210882  0.0092646252  0.9608114
  0.3142813         6.5119974   231     1.019262  0.0080568939  0.8039642
  0.4028302         3.7840179    45     1.039517  0.0043300975  0.8166367
  0.6798436         2.0343350   318     1.135749  0.0054178766  0.8993816
  0.3162167         9.5726888   306     1.151357  0.0042949172  0.9141826
  0.3996759         1.3875084   610     1.060178  0.0092431541  0.8441384
  0.3009635         9.0192681   135     1.004327  0.0006357237  0.7909238
  0.5469775         8.5990492   409     1.073206  0.0137347073  0.8505821
  0.6050883         7.3849284   768     1.062325  0.0126740559  0.8449873
  0.4353915         9.8884070   706     1.034998  0.0036859764  0.8165802
  0.5078420         6.3238063   529     1.108081  0.0054472228  0.8798382
  0.6448781         8.9398042   397     1.057106  0.0065561198  0.8383432
  0.6089747         6.8134576   519     1.072053  0.0134488412  0.8504564
  Selected
          
          
          
          
          
          
          
          
          
          
          
          
          
  *       
          
          
          
          
          
          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nrounds = 135, max_depth = 7, eta
 = 0.3009635, rate_drop = 0.1177168, skip_drop = 0.1364908 and
 min_child_weight = 18.
[1] "Mon Mar 05 14:36:58 2018"
eXtreme Gradient Boosting 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  lambda        alpha         nrounds  eta         RMSE      Rsquared   
  1.664059e-05  5.185891e-03   34      1.13520538  1.163275  0.004521676
  4.723071e-05  1.938485e-02   17      2.70578043  1.135670  0.006080222
  7.592528e-05  5.728857e-05   66      0.69402638  1.180388  0.006242208
  1.414189e-04  4.761342e-03   19      1.95359921  1.149579  0.007475017
  3.381568e-04  4.251986e-03  100      2.87180664  1.191186  0.012446215
  3.865368e-04  4.231026e-03   61      0.61030049  1.188855  0.012966131
  7.716663e-04  2.750009e-05   62      0.08275617  1.199677  0.011002705
  9.656060e-04  4.197501e-01   50      2.68194127  1.192548  0.013440624
  1.104298e-03  1.537675e-02   76      2.57971477  1.171991  0.007447151
  3.365542e-03  2.022663e-03   46      0.35859755  1.174769  0.008222123
  3.926312e-03  4.396923e-01   73      2.04403729  1.190641  0.013379532
  3.986218e-03  3.260926e-04   30      2.75579827  1.177370  0.008362180
  4.384978e-03  2.297143e-01   52      1.89714189  1.190480  0.011381859
  6.359744e-03  7.239544e-04   75      0.21337770  1.179774  0.005878502
  1.115710e-02  2.769757e-02    3      0.41625252  1.069122  0.003129699
  3.370368e-02  1.415746e-01   50      2.96652209  1.173677  0.009035810
  6.841543e-02  9.570669e-02   68      2.21547852  1.170328  0.008246795
  7.913189e-01  2.051711e-04   37      2.61281073  1.160022  0.008110080
  8.373081e-01  5.965294e-05   85      1.13037914  1.177859  0.007608912
  9.918415e-01  1.465332e-03   71      0.64259779  1.169705  0.008821161
  MAE        Selected
  0.9238718          
  0.8987939          
  0.9465898          
  0.9176379          
  0.9459484          
  0.9438210          
  0.9562015          
  0.9466228          
  0.9355836          
  0.9422466          
  0.9392944          
  0.9367974          
  0.9429018          
  0.9474312          
  0.8382028  *       
  0.9306478          
  0.9302347          
  0.9106897          
  0.9346625          
  0.9240035          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nrounds = 3, lambda = 0.0111571,
 alpha = 0.02769757 and eta = 0.4162525.
[1] "Mon Mar 05 14:37:52 2018"
eXtreme Gradient Boosting 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  eta         max_depth  gamma      colsample_bytree  min_child_weight
  0.01420352   7         1.3875084  0.5216884          5              
  0.10072945   7         9.0192681  0.3958884          0              
  0.11391158   6         6.5119974  0.4794996          0              
  0.17897697   4         9.1859942  0.6750310         19              
  0.19974261   6         3.7840179  0.5518801          5              
  0.21683632   3         8.7093691  0.3661462         10              
  0.27570603   5         1.1953252  0.4953354         13              
  0.29564586   9         9.8884070  0.5258402          7              
  0.29583449  10         8.9398042  0.4771134         18              
  0.31173212   9         6.3238063  0.4153682         10              
  0.36403679   6         2.0343350  0.3880908         19              
  0.36876456   1         0.2758539  0.5372936          6              
  0.39178262   2         2.3134213  0.6419487          5              
  0.40814694   8         7.3849284  0.5237402         16              
  0.42043969   5         2.1419926  0.3674285         12              
  0.43631712  10         6.8134576  0.5863448         16              
  0.44881821   4         0.7112590  0.5337565          2              
  0.45231844   7         8.5990492  0.6157609         12              
  0.50592976   2         3.7679305  0.3888863         17              
  0.59855077   6         9.5726888  0.3134350          0              
  subsample  nrounds  RMSE      Rsquared     MAE        Selected
  0.6628483   610     1.078064  0.009193005  0.8602547          
  0.4148727   135     1.023452  0.005276921  0.8126658  *       
  0.4365057   231     1.056729  0.002742650  0.8344229          
  0.9344120   521     1.029631  0.003133479  0.8161772          
  0.9160260    45     1.063660  0.004637750  0.8493658          
  0.5694723   980     1.058153  0.003515943  0.8455376          
  0.9451328   506     1.171207  0.010764720  0.9424188          
  0.9916790   706     1.043009  0.003750347  0.8302907          
  0.7415212   397     1.060928  0.009084552  0.8445696          
  0.8235363   529     1.088198  0.003472437  0.8692224          
  0.7428247   318     1.196371  0.008604929  0.9606365          
  0.4534174   378     1.169783  0.010428307  0.9355928          
  0.8103479   177     1.163665  0.008243459  0.9264645          
  0.3325759   768     1.186563  0.002498275  0.9393034          
  0.6385071  1000     1.230875  0.006501937  0.9765456          
  0.5629781   519     1.151022  0.004003586  0.9104695          
  0.8229724   561     1.221314  0.008795686  0.9754004          
  0.5401527   409     1.142241  0.007796620  0.9098667          
  0.2662437   985     1.396762  0.001634422  1.1137839          
  0.3140383   306     1.215181  0.001946888  0.9667415          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nrounds = 135, max_depth = 7, eta
 = 0.1007295, gamma = 9.019268, colsample_bytree = 0.3958884,
 min_child_weight = 0 and subsample = 0.4148727.
[1] "Mon Mar 05 14:42:28 2018"
Self-Organizing Maps 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 502, 502, 500 
Resampling results across tuning parameters:

  xdim  ydim  topo         user.weights  RMSE      Rsquared      MAE      
   1    18    rectangular  0.38177250    1.030917  0.0073417967  0.8075728
   2    18    rectangular  0.38844418    1.072686  0.0004824719  0.8454124
   4     4    rectangular  0.89608204    1.014495  0.0068480342  0.8033538
   4     6    hexagonal    0.16538871    1.061044  0.0010735648  0.8388221
   7     7    rectangular  0.03067759    1.087017  0.0019499830  0.8627205
   7    19    hexagonal    0.91289594    1.193450  0.0034966168  0.9331070
   8    10    rectangular  0.85670369    1.141641  0.0038784762  0.8940187
   8    20    hexagonal    0.18629164    1.273884  0.0049331424  0.9998498
   9     9    hexagonal    0.73036262    1.148911  0.0010480646  0.9034217
   9    16    hexagonal    0.63929354    1.203377  0.0055222535  0.9514289
  10    11    hexagonal    0.09925525    1.249115  0.0011310528  1.0045531
  10    20    hexagonal    0.76345038    1.266312  0.0034842026  0.9973401
  11    13    hexagonal    0.29671976    1.227899  0.0012894977  0.9661653
  11    14    rectangular  0.11451362    1.242684  0.0014158361  0.9708589
  11    14    rectangular  0.30078628    1.268289  0.0024970183  0.9889690
  11    19    hexagonal    0.63313798    1.258878  0.0005217790  0.9926128
  12    19    hexagonal    0.38033621    1.304300  0.0105889292  1.0227294
  15    19    hexagonal    0.48979374    1.324544  0.0043190031  1.0711404
  15    19    rectangular  0.70882996    1.269111  0.0065300321  1.0076155
  17    20    hexagonal    0.37839063    1.306903  0.0033558833  1.0399725
  Selected
          
          
  *       
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were xdim = 4, ydim = 4, user.weights
 = 0.896082 and topo = rectangular.
[1] "Mon Mar 05 14:43:21 2018"
Fitting Repeat 1 

# weights:  177
initial  value 558.365246 
iter  10 value 500.225723
iter  20 value 499.446479
iter  30 value 499.330617
iter  40 value 499.325406
final  value 499.325382 
converged
Fitting Repeat 2 

# weights:  177
initial  value 835.991936 
iter  10 value 516.881869
iter  20 value 514.083426
iter  30 value 512.743968
iter  40 value 512.478861
iter  50 value 512.412551
final  value 512.407068 
converged
Fitting Repeat 3 

# weights:  177
initial  value 799.377331 
iter  10 value 567.127981
iter  20 value 550.165119
iter  30 value 540.696256
iter  40 value 539.105292
iter  50 value 538.716871
iter  60 value 538.691821
iter  70 value 538.686678
final  value 538.686349 
converged
Fitting Repeat 4 

# weights:  177
initial  value 520.903358 
iter  10 value 455.538740
iter  20 value 450.614020
iter  30 value 449.490761
iter  40 value 449.048515
iter  50 value 449.027961
iter  60 value 449.019641
final  value 449.019050 
converged
Fitting Repeat 5 

# weights:  177
initial  value 597.011169 
iter  10 value 485.293785
iter  20 value 481.746110
iter  30 value 480.921838
iter  40 value 480.434014
iter  50 value 480.261881
iter  60 value 480.256641
iter  70 value 480.255659
final  value 480.255622 
converged
Fitting Repeat 1 

# weights:  45
initial  value 596.337362 
iter  10 value 491.355571
iter  20 value 469.366734
iter  30 value 461.430128
iter  40 value 458.290784
iter  50 value 457.968728
iter  60 value 457.868851
iter  70 value 457.806290
iter  80 value 457.803699
iter  80 value 457.803697
iter  80 value 457.803697
final  value 457.803697 
converged
Fitting Repeat 2 

# weights:  45
initial  value 673.603261 
iter  10 value 575.607341
iter  20 value 558.393409
iter  30 value 543.589843
iter  40 value 537.679642
iter  50 value 533.167503
iter  60 value 532.752538
iter  70 value 532.466507
iter  80 value 532.296376
final  value 532.296093 
converged
Fitting Repeat 3 

# weights:  45
initial  value 614.942668 
iter  10 value 537.551989
iter  20 value 513.314839
iter  30 value 495.183336
iter  40 value 480.739540
iter  50 value 473.045329
iter  60 value 470.267941
iter  70 value 468.737660
iter  80 value 468.088682
iter  90 value 465.323399
iter 100 value 462.211562
final  value 462.211562 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  45
initial  value 611.927032 
iter  10 value 508.379836
iter  20 value 482.608233
iter  30 value 477.458190
iter  40 value 472.596190
iter  50 value 470.459281
iter  60 value 469.575871
iter  70 value 469.267270
iter  80 value 469.263244
iter  80 value 469.263241
iter  80 value 469.263241
final  value 469.263241 
converged
Fitting Repeat 5 

# weights:  45
initial  value 585.693242 
iter  10 value 508.312955
iter  20 value 497.095345
iter  30 value 492.729201
iter  40 value 489.370563
iter  50 value 483.499464
iter  60 value 482.234218
iter  70 value 481.690162
iter  80 value 480.926001
iter  90 value 479.154493
iter 100 value 477.898654
final  value 477.898654 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  188
initial  value 895.101913 
iter  10 value 522.473702
iter  20 value 510.315317
iter  30 value 495.116997
iter  40 value 488.464647
iter  50 value 480.757279
iter  60 value 470.650724
iter  70 value 457.958603
iter  80 value 436.131237
iter  90 value 424.683155
iter 100 value 419.669128
final  value 419.669128 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  188
initial  value 663.643705 
iter  10 value 558.293476
iter  20 value 556.878987
iter  30 value 535.021336
iter  40 value 514.373748
iter  50 value 507.016018
iter  60 value 498.747040
iter  70 value 491.975409
iter  80 value 481.602026
iter  90 value 473.281837
iter 100 value 468.554641
final  value 468.554641 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  188
initial  value 660.170545 
iter  10 value 568.405305
iter  20 value 510.427087
iter  30 value 501.182974
iter  40 value 498.448672
iter  50 value 488.313586
iter  60 value 461.055920
iter  70 value 445.829607
iter  80 value 442.558461
iter  90 value 434.926458
iter 100 value 425.262549
final  value 425.262549 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  188
initial  value 534.807241 
iter  10 value 448.809671
iter  20 value 419.713653
iter  30 value 400.178933
iter  40 value 373.548396
iter  50 value 354.636721
iter  60 value 345.173145
iter  70 value 335.201289
iter  80 value 331.815895
iter  90 value 329.446386
iter 100 value 327.298452
final  value 327.298452 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  188
initial  value 529.055716 
iter  10 value 487.734742
iter  20 value 450.610639
iter  30 value 425.279787
iter  40 value 407.340936
iter  50 value 386.928972
iter  60 value 382.758417
iter  70 value 381.002728
iter  80 value 379.909980
iter  90 value 378.943116
iter 100 value 378.504172
final  value 378.504172 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  177
initial  value 733.713979 
iter  10 value 493.473024
iter  20 value 434.385271
iter  30 value 411.387022
iter  40 value 406.071053
iter  50 value 398.602274
iter  60 value 393.640176
iter  70 value 390.934723
iter  80 value 387.050640
iter  90 value 383.487746
iter 100 value 381.769820
final  value 381.769820 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  177
initial  value 659.511830 
iter  10 value 530.151803
iter  20 value 526.961025
iter  30 value 482.925686
iter  40 value 474.125968
iter  50 value 470.654660
iter  60 value 468.848909
iter  70 value 466.280816
iter  80 value 457.362813
iter  90 value 442.845051
iter 100 value 426.930701
final  value 426.930701 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  177
initial  value 588.584967 
iter  10 value 547.166047
iter  20 value 547.134978
iter  30 value 544.242739
iter  40 value 512.705394
iter  50 value 505.237052
iter  60 value 503.834281
iter  70 value 502.090517
iter  80 value 490.827455
iter  90 value 486.322562
iter 100 value 478.495182
final  value 478.495182 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  177
initial  value 521.968568 
iter  10 value 484.844972
iter  20 value 442.029925
iter  30 value 408.098591
iter  40 value 396.696079
iter  50 value 389.037001
iter  60 value 387.229435
iter  70 value 384.470132
iter  80 value 375.952662
iter  90 value 370.611505
iter 100 value 367.647232
final  value 367.647232 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  177
initial  value 748.429273 
iter  10 value 533.241639
iter  20 value 452.703287
iter  30 value 413.946602
iter  40 value 409.785207
iter  50 value 401.743599
iter  60 value 390.537428
iter  70 value 387.271220
iter  80 value 386.260472
iter  90 value 385.643019
iter 100 value 378.125294
final  value 378.125294 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  221
initial  value 689.062322 
iter  10 value 506.974504
iter  20 value 505.049618
iter  30 value 505.041243
final  value 505.041194 
converged
Fitting Repeat 2 

# weights:  221
initial  value 715.058510 
iter  10 value 544.668909
iter  20 value 544.229492
final  value 544.227677 
converged
Fitting Repeat 3 

# weights:  221
initial  value 722.554816 
iter  10 value 514.215036
iter  20 value 513.458896
final  value 513.455828 
converged
Fitting Repeat 4 

# weights:  221
initial  value 666.600037 
iter  10 value 493.407367
iter  20 value 491.886047
final  value 491.884724 
converged
Fitting Repeat 5 

# weights:  221
initial  value 789.241766 
iter  10 value 570.195318
iter  20 value 568.960311
final  value 568.957441 
converged
Fitting Repeat 1 

# weights:  188
initial  value 705.487800 
iter  10 value 513.069753
iter  20 value 483.541311
iter  30 value 469.138214
iter  40 value 458.829218
iter  50 value 452.184334
iter  60 value 447.389895
iter  70 value 442.055148
iter  80 value 438.773917
iter  90 value 433.054082
iter 100 value 426.645783
final  value 426.645783 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  188
initial  value 712.641150 
iter  10 value 513.453481
iter  20 value 468.498044
iter  30 value 455.600604
iter  40 value 448.350743
iter  50 value 443.949308
iter  60 value 439.626145
iter  70 value 432.868458
iter  80 value 430.713268
iter  90 value 426.939044
iter 100 value 422.056253
final  value 422.056253 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  188
initial  value 536.428636 
iter  10 value 513.808063
iter  20 value 510.430092
iter  30 value 484.657174
iter  40 value 466.378830
iter  50 value 453.126820
iter  60 value 442.572450
iter  70 value 431.357821
iter  80 value 421.038274
iter  90 value 418.360737
iter 100 value 416.140264
final  value 416.140264 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  188
initial  value 658.743569 
iter  10 value 513.575876
iter  20 value 487.508829
iter  30 value 466.978963
iter  40 value 459.996854
iter  50 value 453.796926
iter  60 value 449.782381
iter  70 value 447.258610
iter  80 value 439.987605
iter  90 value 435.713417
iter 100 value 428.106493
final  value 428.106493 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  188
initial  value 612.892539 
iter  10 value 513.284896
iter  20 value 491.721859
iter  30 value 472.999991
iter  40 value 456.294155
iter  50 value 446.767983
iter  60 value 440.012376
iter  70 value 434.422481
iter  80 value 427.743884
iter  90 value 424.896909
iter 100 value 422.149133
final  value 422.149133 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  34
initial  value 736.788720 
iter  10 value 537.959943
iter  20 value 536.577532
final  value 536.576910 
converged
Fitting Repeat 2 

# weights:  34
initial  value 575.888560 
iter  10 value 523.680866
iter  20 value 522.607825
final  value 522.606222 
converged
Fitting Repeat 3 

# weights:  34
initial  value 614.121166 
iter  10 value 545.453263
iter  20 value 544.032263
final  value 544.031661 
converged
Fitting Repeat 4 

# weights:  34
initial  value 656.643945 
iter  10 value 502.370210
iter  20 value 501.590508
iter  30 value 501.585023
iter  30 value 501.585020
iter  30 value 501.585020
final  value 501.585020 
converged
Fitting Repeat 5 

# weights:  34
initial  value 677.416244 
iter  10 value 486.046356
iter  20 value 485.864357
final  value 485.864177 
converged
Fitting Repeat 1 

# weights:  122
initial  value 651.588401 
iter  10 value 551.180938
iter  20 value 535.994850
iter  30 value 502.466914
iter  40 value 498.364828
iter  50 value 487.930902
iter  60 value 475.297905
iter  70 value 468.503935
iter  80 value 461.934630
iter  90 value 453.184864
iter 100 value 444.046681
final  value 444.046681 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 855.973894 
iter  10 value 507.797012
iter  20 value 506.518864
iter  30 value 480.816740
iter  40 value 460.382361
iter  50 value 457.241066
iter  60 value 456.113803
iter  70 value 453.212898
iter  80 value 452.501082
iter  90 value 449.832389
iter 100 value 443.490279
final  value 443.490279 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 651.698440 
iter  10 value 521.557736
iter  20 value 490.039605
iter  30 value 475.848550
iter  40 value 462.621430
iter  50 value 451.184594
iter  60 value 445.634212
iter  70 value 441.449074
iter  80 value 439.950311
iter  90 value 439.398965
iter 100 value 438.858406
final  value 438.858406 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 711.229218 
iter  10 value 554.858613
iter  20 value 515.430056
iter  30 value 491.445854
iter  40 value 482.037368
iter  50 value 477.766794
iter  60 value 469.475516
iter  70 value 462.906730
iter  80 value 461.209120
iter  90 value 446.105713
iter 100 value 441.706745
final  value 441.706745 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 803.196540 
iter  10 value 514.960959
iter  20 value 510.452817
iter  30 value 471.054590
iter  40 value 437.775056
iter  50 value 433.551921
iter  60 value 432.009821
iter  70 value 427.149937
iter  80 value 421.335759
iter  90 value 418.534850
iter 100 value 416.152947
final  value 416.152947 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  188
initial  value 634.944847 
iter  10 value 513.781857
iter  20 value 513.739794
iter  30 value 513.682239
iter  40 value 503.972536
iter  50 value 473.019640
iter  60 value 467.530538
iter  70 value 463.058813
iter  80 value 462.690732
iter  90 value 460.363968
iter 100 value 458.390607
final  value 458.390607 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  188
initial  value 520.374742 
final  value 513.750595 
converged
Fitting Repeat 3 

# weights:  188
initial  value 619.699383 
iter  10 value 513.775353
iter  20 value 513.739704
iter  20 value 513.739704
final  value 513.739704 
converged
Fitting Repeat 4 

# weights:  188
initial  value 529.497155 
final  value 513.789977 
converged
Fitting Repeat 5 

# weights:  188
initial  value 548.706176 
iter  10 value 513.745773
final  value 513.739730 
converged
Fitting Repeat 1 

# weights:  89
initial  value 568.648136 
iter  10 value 515.213991
iter  20 value 514.729018
final  value 514.725915 
converged
Fitting Repeat 2 

# weights:  89
initial  value 808.489776 
iter  10 value 515.129888
iter  20 value 514.726651
final  value 514.725914 
converged
Fitting Repeat 3 

# weights:  89
initial  value 555.171923 
iter  10 value 514.924377
iter  20 value 514.727620
final  value 514.725914 
converged
Fitting Repeat 4 

# weights:  89
initial  value 672.652878 
iter  10 value 515.250663
iter  20 value 514.728310
final  value 514.726766 
converged
Fitting Repeat 5 

# weights:  89
initial  value 638.267152 
iter  10 value 514.945145
iter  20 value 514.726362
final  value 514.725914 
converged
Fitting Repeat 1 

# weights:  89
initial  value 824.185438 
iter  10 value 525.378584
iter  20 value 525.292969
final  value 525.292611 
converged
Fitting Repeat 2 

# weights:  89
initial  value 609.037014 
iter  10 value 525.926077
iter  20 value 525.292860
final  value 525.292613 
converged
Fitting Repeat 3 

# weights:  89
initial  value 629.862384 
iter  10 value 525.383901
iter  20 value 525.292691
final  value 525.292603 
converged
Fitting Repeat 4 

# weights:  89
initial  value 604.394267 
iter  10 value 525.332797
final  value 525.292624 
converged
Fitting Repeat 5 

# weights:  89
initial  value 618.787415 
iter  10 value 525.364455
final  value 525.292611 
converged
Fitting Repeat 1 

# weights:  89
initial  value 613.109773 
iter  10 value 532.327305
final  value 532.258378 
converged
Fitting Repeat 2 

# weights:  89
initial  value 628.668771 
iter  10 value 459.719009
iter  20 value 459.596837
iter  30 value 459.596421
iter  40 value 459.595923
iter  50 value 459.595221
iter  60 value 459.594016
iter  70 value 459.591252
iter  80 value 459.579068
iter  90 value 458.402305
iter 100 value 433.989522
final  value 433.989522 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  89
initial  value 672.278211 
iter  10 value 483.952546
iter  20 value 483.809239
iter  30 value 467.315666
iter  40 value 434.027080
iter  50 value 427.335021
iter  60 value 421.876329
iter  70 value 418.081943
iter  80 value 415.740816
iter  90 value 415.003575
iter 100 value 414.448330
final  value 414.448330 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  89
initial  value 623.142559 
iter  10 value 478.319677
iter  20 value 478.208003
iter  30 value 478.207947
iter  40 value 478.207896
iter  50 value 478.207842
iter  60 value 478.207783
iter  70 value 478.207718
iter  80 value 478.207643
iter  90 value 478.207557
iter 100 value 478.207454
final  value 478.207454 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  89
initial  value 575.150755 
iter  10 value 529.914215
iter  20 value 529.880905
iter  30 value 529.876027
iter  40 value 529.858216
iter  50 value 526.118380
iter  60 value 469.447788
iter  70 value 460.531441
iter  80 value 458.428742
iter  90 value 458.088375
iter 100 value 458.068285
final  value 458.068285 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  56
initial  value 681.907197 
iter  10 value 514.154755
iter  20 value 513.742268
iter  30 value 513.738462
iter  40 value 513.718087
iter  50 value 506.679699
iter  60 value 473.996763
iter  70 value 472.989521
iter  80 value 472.719230
iter  90 value 472.642037
iter 100 value 472.603914
final  value 472.603914 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  56
initial  value 537.086450 
iter  10 value 513.767398
iter  20 value 513.733763
iter  30 value 513.658144
iter  40 value 497.291013
iter  50 value 474.347971
iter  60 value 470.767862
iter  70 value 470.126332
iter  80 value 468.774930
iter  90 value 468.198597
iter 100 value 466.129115
final  value 466.129115 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  56
initial  value 598.570078 
iter  10 value 513.921631
iter  20 value 513.745230
iter  30 value 513.744710
iter  40 value 513.743930
iter  50 value 513.742569
iter  60 value 513.739478
iter  70 value 513.726931
iter  80 value 513.064214
iter  90 value 481.889478
iter 100 value 471.618925
final  value 471.618925 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  56
initial  value 553.067492 
iter  10 value 513.796150
iter  20 value 506.862715
iter  30 value 477.801409
iter  40 value 472.807567
iter  50 value 471.189619
iter  60 value 470.651568
iter  70 value 468.766394
iter  80 value 468.206325
iter  90 value 468.132767
iter 100 value 466.740110
final  value 466.740110 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  56
initial  value 719.003160 
iter  10 value 514.066853
iter  20 value 513.747248
iter  30 value 513.747005
iter  40 value 513.746711
iter  50 value 513.746342
iter  60 value 513.745846
iter  70 value 513.745125
iter  80 value 513.743937
iter  90 value 513.741572
iter 100 value 513.734909
final  value 513.734909 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 586.286837 
iter  10 value 514.352799
iter  20 value 513.732641
iter  30 value 513.222059
iter  40 value 489.175827
iter  50 value 477.692701
iter  60 value 468.241425
iter  70 value 458.805561
iter  80 value 451.959525
iter  90 value 446.264718
iter 100 value 445.164854
final  value 445.164854 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 696.755499 
iter  10 value 515.283645
iter  20 value 513.756704
iter  30 value 513.710869
iter  40 value 506.323084
iter  50 value 479.815372
iter  60 value 471.709542
iter  70 value 468.522165
iter  80 value 465.072447
iter  90 value 463.869465
iter 100 value 460.980473
final  value 460.980473 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 789.287244 
iter  10 value 515.230290
iter  20 value 513.755822
iter  30 value 502.565446
iter  40 value 472.435478
iter  50 value 466.610974
iter  60 value 465.828914
iter  70 value 463.989032
iter  80 value 459.827085
iter  90 value 458.848646
iter 100 value 458.291293
final  value 458.291293 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 561.803237 
iter  10 value 514.127644
iter  20 value 513.730912
iter  30 value 510.308537
iter  40 value 475.450474
iter  50 value 467.545753
iter  60 value 463.867434
iter  70 value 462.902932
iter  80 value 461.787336
iter  90 value 460.038126
iter 100 value 458.673288
final  value 458.673288 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 697.114812 
iter  10 value 515.288814
iter  20 value 513.756740
iter  30 value 513.691962
iter  40 value 496.382349
iter  50 value 474.141064
iter  60 value 470.546968
iter  70 value 466.039328
iter  80 value 465.597617
iter  90 value 465.008079
iter 100 value 464.106813
final  value 464.106813 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  23
initial  value 626.655196 
iter  10 value 525.893839
iter  20 value 503.873550
iter  30 value 484.084868
iter  40 value 478.725446
iter  50 value 477.512383
iter  60 value 476.732274
iter  70 value 476.597134
iter  80 value 476.591512
iter  90 value 476.590513
iter  90 value 476.590510
iter  90 value 476.590510
final  value 476.590510 
converged
Fitting Repeat 2 

# weights:  23
initial  value 582.261554 
iter  10 value 529.745840
iter  20 value 504.163581
iter  30 value 470.156460
iter  40 value 462.467418
iter  50 value 457.259972
iter  60 value 456.340010
iter  70 value 456.105318
iter  80 value 456.099746
final  value 456.099719 
converged
Fitting Repeat 3 

# weights:  23
initial  value 532.359548 
iter  10 value 452.275612
iter  20 value 427.156587
iter  30 value 418.786594
iter  40 value 417.824640
iter  50 value 417.790658
iter  60 value 417.787841
final  value 417.787749 
converged
Fitting Repeat 4 

# weights:  23
initial  value 646.124125 
iter  10 value 540.559382
iter  20 value 539.763530
iter  30 value 516.288487
iter  40 value 508.243842
iter  50 value 505.633021
iter  60 value 505.520914
iter  70 value 505.517754
iter  80 value 505.517617
iter  80 value 505.517612
iter  80 value 505.517611
final  value 505.517611 
converged
Fitting Repeat 5 

# weights:  23
initial  value 701.638334 
iter  10 value 496.764972
iter  20 value 496.477660
iter  30 value 482.645058
iter  40 value 451.934199
iter  50 value 449.623728
iter  60 value 449.320836
iter  70 value 449.314891
final  value 449.314792 
converged
Fitting Repeat 1 

# weights:  78
initial  value 678.644378 
iter  10 value 505.807431
iter  20 value 480.211848
iter  30 value 475.602469
iter  40 value 472.907846
iter  50 value 470.418337
iter  60 value 467.619538
iter  70 value 462.949831
iter  80 value 459.441758
iter  90 value 455.617397
iter 100 value 451.491628
final  value 451.491628 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  78
initial  value 618.243430 
iter  10 value 513.846788
iter  20 value 497.904282
iter  30 value 479.796822
iter  40 value 463.378584
iter  50 value 449.579539
iter  60 value 444.973476
iter  70 value 443.312785
iter  80 value 441.514321
iter  90 value 440.449266
iter 100 value 437.855974
final  value 437.855974 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  78
initial  value 605.434349 
iter  10 value 514.630547
iter  20 value 496.933760
iter  30 value 483.699908
iter  40 value 473.907020
iter  50 value 468.082638
iter  60 value 460.190595
iter  70 value 454.864212
iter  80 value 450.187998
iter  90 value 445.607070
iter 100 value 440.215621
final  value 440.215621 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  78
initial  value 673.170207 
iter  10 value 509.743976
iter  20 value 473.428087
iter  30 value 455.664823
iter  40 value 450.997992
iter  50 value 444.245080
iter  60 value 440.060886
iter  70 value 437.765410
iter  80 value 436.094234
iter  90 value 431.346564
iter 100 value 424.420418
final  value 424.420418 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  78
initial  value 655.681409 
iter  10 value 509.769438
iter  20 value 470.442176
iter  30 value 451.733182
iter  40 value 446.918635
iter  50 value 443.514851
iter  60 value 441.969106
iter  70 value 440.150122
iter  80 value 439.525669
iter  90 value 439.163222
iter 100 value 438.422850
final  value 438.422850 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  67
initial  value 592.626756 
iter  10 value 565.103361
iter  20 value 565.087968
iter  30 value 565.046997
iter  40 value 543.158657
iter  50 value 517.233207
iter  60 value 515.513836
iter  70 value 509.977312
iter  80 value 508.804585
iter  90 value 506.747655
iter 100 value 506.327825
final  value 506.327825 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  67
initial  value 592.531348 
iter  10 value 549.831647
iter  20 value 549.793471
iter  30 value 549.792697
iter  40 value 549.791429
iter  50 value 549.788701
iter  60 value 549.777902
iter  70 value 549.200598
iter  80 value 529.718964
iter  90 value 528.687320
iter 100 value 528.348438
final  value 528.348438 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  67
initial  value 592.092878 
iter  10 value 491.191859
iter  20 value 491.065164
iter  30 value 491.062134
iter  40 value 491.053234
iter  50 value 490.821409
iter  60 value 461.537995
iter  70 value 449.620725
iter  80 value 447.449213
iter  90 value 446.886072
iter 100 value 446.726066
final  value 446.726066 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  67
initial  value 641.343611 
iter  10 value 587.809047
iter  20 value 572.650848
iter  30 value 540.303280
iter  40 value 534.549604
iter  50 value 527.480485
iter  60 value 515.904492
iter  70 value 515.214047
iter  80 value 514.728730
iter  90 value 508.641666
iter 100 value 507.653882
final  value 507.653882 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  67
initial  value 527.343319 
iter  10 value 457.218207
iter  20 value 457.128841
iter  30 value 457.125945
iter  40 value 457.119346
iter  50 value 457.067441
iter  60 value 428.553842
iter  70 value 414.660296
iter  80 value 413.994270
iter  90 value 413.780890
iter 100 value 412.188417
final  value 412.188417 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  100
initial  value 728.390344 
iter  10 value 549.558138
iter  20 value 504.602225
iter  30 value 468.541362
iter  40 value 455.491445
iter  50 value 444.864958
iter  60 value 436.536054
iter  70 value 433.043987
iter  80 value 431.489278
iter  90 value 428.738424
iter 100 value 427.376670
final  value 427.376670 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  100
initial  value 600.705582 
iter  10 value 513.092311
iter  20 value 462.849140
iter  30 value 448.274552
iter  40 value 439.623182
iter  50 value 431.116250
iter  60 value 428.836081
iter  70 value 426.857030
iter  80 value 423.201296
iter  90 value 422.261426
iter 100 value 421.388624
final  value 421.388624 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  100
initial  value 915.187089 
iter  10 value 570.314892
iter  20 value 539.168935
iter  30 value 533.722168
iter  40 value 526.124189
iter  50 value 521.374988
iter  60 value 519.723713
iter  70 value 517.666318
iter  80 value 512.539684
iter  90 value 506.705234
iter 100 value 495.019892
final  value 495.019892 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  100
initial  value 589.947064 
iter  10 value 473.637401
iter  20 value 429.984021
iter  30 value 411.732865
iter  40 value 397.047510
iter  50 value 393.680530
iter  60 value 389.180652
iter  70 value 382.910264
iter  80 value 379.435333
iter  90 value 377.296980
iter 100 value 373.186731
final  value 373.186731 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  100
initial  value 740.016729 
iter  10 value 544.793999
iter  20 value 505.794155
iter  30 value 495.615639
iter  40 value 491.302424
iter  50 value 483.032626
iter  60 value 460.133038
iter  70 value 454.863862
iter  80 value 453.714011
iter  90 value 452.717976
iter 100 value 452.123855
final  value 452.123855 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  89
initial  value 510.595462 
iter  10 value 446.525072
iter  20 value 446.484998
iter  30 value 446.484926
iter  40 value 446.484846
iter  50 value 446.484753
iter  60 value 446.484643
iter  70 value 446.484508
iter  80 value 446.484339
iter  90 value 446.484115
iter 100 value 446.483804
final  value 446.483804 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  89
initial  value 809.458558 
iter  10 value 612.595994
iter  20 value 612.415117
iter  30 value 582.876305
iter  40 value 567.875767
iter  50 value 567.603728
iter  60 value 560.889738
iter  70 value 559.757663
iter  80 value 558.700818
iter  90 value 558.423486
iter 100 value 558.333050
final  value 558.333050 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  89
initial  value 662.257192 
iter  10 value 477.647149
iter  20 value 477.563601
iter  30 value 477.563162
iter  40 value 477.562640
iter  50 value 477.561920
iter  60 value 477.560738
iter  70 value 477.558283
iter  80 value 477.550368
iter  90 value 477.436445
iter 100 value 453.176584
final  value 453.176584 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  89
initial  value 752.547045 
iter  10 value 565.032859
iter  20 value 564.930462
iter  30 value 564.908403
iter  40 value 544.723826
iter  50 value 505.782661
iter  60 value 496.828606
iter  70 value 495.639880
iter  80 value 495.622465
iter  90 value 495.615080
iter 100 value 495.404473
final  value 495.404473 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  89
initial  value 843.512616 
iter  10 value 539.390541
iter  20 value 539.298083
iter  30 value 539.293237
iter  40 value 539.289473
iter  50 value 539.265821
iter  60 value 531.336039
iter  70 value 501.391175
iter  80 value 493.558994
iter  90 value 488.170398
iter 100 value 487.687546
final  value 487.687546 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  166
initial  value 755.292716 
iter  10 value 515.643749
iter  20 value 502.003270
iter  30 value 496.772739
iter  40 value 495.122550
iter  50 value 494.079631
iter  60 value 493.321143
iter  70 value 492.802458
iter  80 value 492.160590
iter  90 value 490.049396
iter 100 value 486.408846
final  value 486.408846 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  166
initial  value 683.404430 
iter  10 value 514.350122
iter  20 value 505.594833
iter  30 value 497.625457
iter  40 value 495.319173
iter  50 value 493.790440
iter  60 value 493.005823
iter  70 value 492.709045
iter  80 value 492.101036
iter  90 value 491.552976
iter 100 value 486.800940
final  value 486.800940 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  166
initial  value 531.419869 
iter  10 value 510.874016
iter  20 value 501.653581
iter  30 value 497.454979
iter  40 value 494.865526
iter  50 value 492.372698
iter  60 value 491.500264
iter  70 value 491.198978
iter  80 value 490.987141
iter  90 value 490.766954
iter 100 value 490.603293
final  value 490.603293 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  166
initial  value 697.689944 
iter  10 value 516.835621
iter  20 value 507.042044
iter  30 value 499.447162
iter  40 value 495.243370
iter  50 value 493.051758
iter  60 value 491.711440
iter  70 value 490.878621
iter  80 value 488.594700
iter  90 value 485.995053
iter 100 value 482.748525
final  value 482.748525 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  166
initial  value 866.240325 
iter  10 value 513.210404
iter  20 value 505.064763
iter  30 value 497.083152
iter  40 value 493.578344
iter  50 value 491.834170
iter  60 value 490.690748
iter  70 value 488.644301
iter  80 value 482.608869
iter  90 value 474.057590
iter 100 value 469.844432
final  value 469.844432 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  177
initial  value 592.982935 
iter  10 value 548.658491
iter  20 value 546.598260
iter  30 value 546.409515
iter  40 value 546.407459
iter  40 value 546.407454
iter  40 value 546.407454
final  value 546.407454 
converged
Fitting Repeat 2 

# weights:  177
initial  value 668.339288 
iter  10 value 513.108430
iter  20 value 512.523243
iter  30 value 512.238136
iter  40 value 511.306837
iter  50 value 511.043506
iter  60 value 511.035397
final  value 511.035000 
converged
Fitting Repeat 3 

# weights:  177
initial  value 785.020117 
iter  10 value 439.488324
iter  20 value 433.451779
iter  30 value 432.969845
iter  40 value 432.640105
iter  50 value 432.572570
final  value 432.571507 
converged
Fitting Repeat 4 

# weights:  177
initial  value 600.152827 
iter  10 value 465.564281
iter  20 value 449.887304
iter  30 value 448.932056
iter  40 value 448.705433
iter  50 value 447.590483
iter  60 value 447.485336
iter  70 value 447.478833
iter  80 value 447.474217
iter  90 value 447.473470
final  value 447.473461 
converged
Fitting Repeat 5 

# weights:  177
initial  value 801.477133 
iter  10 value 546.306541
iter  20 value 539.392285
iter  30 value 538.853063
iter  40 value 538.751679
iter  50 value 538.730240
final  value 538.729803 
converged
Fitting Repeat 1 

# weights:  45
initial  value 693.946031 
iter  10 value 498.969204
iter  20 value 478.548071
iter  30 value 470.934633
iter  40 value 467.316549
iter  50 value 465.726389
iter  60 value 463.163190
iter  70 value 462.864739
iter  80 value 462.029969
iter  90 value 460.780115
iter 100 value 459.620926
final  value 459.620926 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  45
initial  value 521.962337 
iter  10 value 460.832428
iter  20 value 433.714067
iter  30 value 424.906769
iter  40 value 422.436708
iter  50 value 422.038690
iter  60 value 422.016315
final  value 422.015612 
converged
Fitting Repeat 3 

# weights:  45
initial  value 667.354402 
iter  10 value 525.935432
iter  20 value 498.167905
iter  30 value 492.704459
iter  40 value 489.488858
iter  50 value 487.542430
iter  60 value 485.931957
iter  70 value 485.691885
iter  80 value 485.688212
iter  90 value 485.418222
iter 100 value 481.303050
final  value 481.303050 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  45
initial  value 806.911550 
iter  10 value 498.441967
iter  20 value 478.995235
iter  30 value 471.653866
iter  40 value 464.361955
iter  50 value 459.284678
iter  60 value 458.836791
iter  70 value 457.865768
iter  80 value 457.335874
final  value 457.299963 
converged
Fitting Repeat 5 

# weights:  45
initial  value 728.850261 
iter  10 value 506.139071
iter  20 value 477.052487
iter  30 value 463.857037
iter  40 value 461.898737
iter  50 value 461.619117
iter  60 value 461.041364
iter  70 value 460.671890
final  value 460.668405 
converged
Fitting Repeat 1 

# weights:  188
initial  value 553.772342 
iter  10 value 490.071646
iter  20 value 450.893779
iter  30 value 430.780470
iter  40 value 413.781560
iter  50 value 402.945650
iter  60 value 392.765535
iter  70 value 376.766879
iter  80 value 371.311290
iter  90 value 365.762539
iter 100 value 362.418736
final  value 362.418736 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  188
initial  value 562.313459 
iter  10 value 502.693656
iter  20 value 470.010677
iter  30 value 442.455055
iter  40 value 427.627849
iter  50 value 414.568052
iter  60 value 400.986026
iter  70 value 389.067964
iter  80 value 385.249932
iter  90 value 383.243983
iter 100 value 381.311450
final  value 381.311450 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  188
initial  value 761.033500 
iter  10 value 529.500432
iter  20 value 498.997985
iter  30 value 472.476520
iter  40 value 463.828717
iter  50 value 458.885037
iter  60 value 452.935009
iter  70 value 450.539203
iter  80 value 446.646706
iter  90 value 442.365562
iter 100 value 434.039230
final  value 434.039230 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  188
initial  value 628.735922 
iter  10 value 452.777627
iter  20 value 414.520847
iter  30 value 392.113917
iter  40 value 371.647608
iter  50 value 358.328025
iter  60 value 352.388753
iter  70 value 350.072440
iter  80 value 347.114735
iter  90 value 342.657795
iter 100 value 339.059440
final  value 339.059440 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  188
initial  value 700.405325 
iter  10 value 452.101752
iter  20 value 424.965703
iter  30 value 402.975945
iter  40 value 392.849972
iter  50 value 378.877877
iter  60 value 362.140377
iter  70 value 352.934704
iter  80 value 342.682850
iter  90 value 337.985233
iter 100 value 335.755464
final  value 335.755464 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  177
initial  value 723.098431 
iter  10 value 570.374428
iter  20 value 534.485840
iter  30 value 525.743497
iter  40 value 494.306533
iter  50 value 480.954129
iter  60 value 476.384190
iter  70 value 470.120703
iter  80 value 465.953700
iter  90 value 457.447433
iter 100 value 443.186235
final  value 443.186235 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  177
initial  value 730.042389 
iter  10 value 529.717544
iter  20 value 486.246440
iter  30 value 448.429442
iter  40 value 417.221195
iter  50 value 402.803662
iter  60 value 393.286401
iter  70 value 388.690827
iter  80 value 384.721442
iter  90 value 375.210537
iter 100 value 371.959887
final  value 371.959887 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  177
initial  value 748.178649 
iter  10 value 533.053839
iter  20 value 498.403488
iter  30 value 463.210257
iter  40 value 426.910153
iter  50 value 406.619638
iter  60 value 395.951263
iter  70 value 392.642078
iter  80 value 388.874241
iter  90 value 384.613661
iter 100 value 381.228292
final  value 381.228292 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  177
initial  value 695.089416 
iter  10 value 528.901632
iter  20 value 515.371141
iter  30 value 476.802145
iter  40 value 462.239990
iter  50 value 451.053089
iter  60 value 442.996767
iter  70 value 437.674740
iter  80 value 435.899973
iter  90 value 434.951012
iter 100 value 431.454756
final  value 431.454756 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  177
initial  value 553.744426 
iter  10 value 514.960905
iter  20 value 466.004080
iter  30 value 456.797800
iter  40 value 453.149361
iter  50 value 443.587500
iter  60 value 440.734481
iter  70 value 439.684122
iter  80 value 438.688229
iter  90 value 435.074330
iter 100 value 424.813884
final  value 424.813884 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  221
initial  value 600.436565 
iter  10 value 520.867954
iter  20 value 520.030048
iter  30 value 519.983613
final  value 519.983321 
converged
Fitting Repeat 2 

# weights:  221
initial  value 609.268934 
iter  10 value 507.685577
iter  20 value 507.439330
iter  30 value 507.427103
iter  40 value 507.425614
final  value 507.425592 
converged
Fitting Repeat 3 

# weights:  221
initial  value 760.462288 
iter  10 value 501.802450
iter  20 value 501.523618
final  value 501.523156 
converged
Fitting Repeat 4 

# weights:  221
initial  value 738.765392 
iter  10 value 498.022121
iter  20 value 496.798857
final  value 496.794899 
converged
Fitting Repeat 5 

# weights:  221
initial  value 935.482023 
iter  10 value 497.033732
iter  20 value 496.287630
final  value 496.287139 
converged
Fitting Repeat 1 

# weights:  188
initial  value 763.701962 
iter  10 value 489.559329
iter  20 value 464.676220
iter  30 value 440.831347
iter  40 value 430.540993
iter  50 value 423.381897
iter  60 value 410.213685
iter  70 value 404.940058
iter  80 value 401.920622
iter  90 value 396.387782
iter 100 value 393.003749
final  value 393.003749 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  188
initial  value 596.070512 
iter  10 value 480.944475
iter  20 value 456.470686
iter  30 value 449.233252
iter  40 value 441.125046
iter  50 value 434.748209
iter  60 value 432.274085
iter  70 value 430.301696
iter  80 value 427.516632
iter  90 value 426.454770
iter 100 value 424.460478
final  value 424.460478 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  188
initial  value 654.663327 
iter  10 value 486.653078
iter  20 value 441.512204
iter  30 value 422.075441
iter  40 value 403.893103
iter  50 value 377.763110
iter  60 value 370.894301
iter  70 value 367.745972
iter  80 value 366.284041
iter  90 value 364.601456
iter 100 value 363.987191
final  value 363.987191 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  188
initial  value 515.119279 
iter  10 value 491.680675
iter  20 value 482.019108
iter  30 value 437.872973
iter  40 value 408.597745
iter  50 value 400.895606
iter  60 value 396.970565
iter  70 value 394.448572
iter  80 value 393.072744
iter  90 value 391.957739
iter 100 value 388.975139
final  value 388.975139 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  188
initial  value 560.675051 
iter  10 value 490.121404
iter  20 value 433.418932
iter  30 value 409.175539
iter  40 value 393.781877
iter  50 value 386.861261
iter  60 value 380.574627
iter  70 value 377.912784
iter  80 value 376.180588
iter  90 value 375.011933
iter 100 value 373.198593
final  value 373.198593 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  34
initial  value 686.736511 
iter  10 value 497.994795
iter  20 value 497.540941
final  value 497.540710 
converged
Fitting Repeat 2 

# weights:  34
initial  value 580.537150 
iter  10 value 489.469282
iter  20 value 487.713801
iter  30 value 487.705782
iter  30 value 487.705778
iter  30 value 487.705776
final  value 487.705776 
converged
Fitting Repeat 3 

# weights:  34
initial  value 540.052608 
iter  10 value 456.850119
iter  20 value 455.660120
final  value 455.659255 
converged
Fitting Repeat 4 

# weights:  34
initial  value 691.305540 
iter  10 value 539.397279
iter  20 value 538.302904
final  value 538.302551 
converged
Fitting Repeat 5 

# weights:  34
initial  value 625.416965 
iter  10 value 477.624616
iter  20 value 476.907394
final  value 476.906078 
converged
Fitting Repeat 1 

# weights:  122
initial  value 600.848466 
iter  10 value 470.959034
iter  20 value 428.896438
iter  30 value 423.146414
iter  40 value 418.759030
iter  50 value 413.679868
iter  60 value 411.075851
iter  70 value 409.468815
iter  80 value 408.006948
iter  90 value 399.330385
iter 100 value 390.054200
final  value 390.054200 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 578.966550 
iter  10 value 476.254086
iter  20 value 449.221406
iter  30 value 424.671467
iter  40 value 408.123641
iter  50 value 400.734632
iter  60 value 396.484014
iter  70 value 390.986830
iter  80 value 384.444510
iter  90 value 377.328246
iter 100 value 373.356504
final  value 373.356504 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 818.139388 
iter  10 value 479.964530
iter  20 value 478.114866
iter  30 value 457.776513
iter  40 value 429.275232
iter  50 value 419.242867
iter  60 value 412.847175
iter  70 value 407.605356
iter  80 value 401.740712
iter  90 value 397.589208
iter 100 value 391.300533
final  value 391.300533 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 635.169426 
iter  10 value 492.969670
iter  20 value 488.998062
iter  30 value 459.606232
iter  40 value 453.326946
iter  50 value 443.570736
iter  60 value 438.838687
iter  70 value 434.649434
iter  80 value 426.818913
iter  90 value 423.824294
iter 100 value 419.532309
final  value 419.532309 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 608.840500 
iter  10 value 432.931642
iter  20 value 396.032968
iter  30 value 342.273656
iter  40 value 331.220507
iter  50 value 325.865040
iter  60 value 323.668941
iter  70 value 320.193212
iter  80 value 319.449811
iter  90 value 318.715218
iter 100 value 318.108556
final  value 318.108556 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  188
initial  value 650.975895 
iter  10 value 491.647182
iter  20 value 491.604096
iter  30 value 491.583631
iter  40 value 486.206241
iter  50 value 457.153573
iter  60 value 438.334901
iter  70 value 432.616841
iter  80 value 428.994354
iter  90 value 426.343629
iter 100 value 424.756493
final  value 424.756493 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  188
initial  value 591.885850 
iter  10 value 491.634033
iter  20 value 491.603827
iter  20 value 491.603827
final  value 491.603827 
converged
Fitting Repeat 3 

# weights:  188
initial  value 515.670092 
iter  10 value 491.608525
iter  20 value 491.603312
iter  30 value 491.603248
iter  40 value 491.603174
iter  50 value 491.603086
iter  60 value 491.602981
iter  70 value 491.602853
iter  80 value 491.602692
iter  90 value 491.602487
iter 100 value 491.602213
final  value 491.602213 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  188
initial  value 780.163173 
iter  10 value 491.648033
iter  20 value 491.604106
iter  30 value 491.593108
iter  40 value 491.498658
iter  50 value 470.508266
iter  60 value 428.916893
iter  70 value 419.378330
iter  80 value 415.062153
iter  90 value 413.570193
iter 100 value 413.172592
final  value 413.172592 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  188
initial  value 609.640624 
iter  10 value 491.637269
iter  20 value 491.603925
iter  20 value 491.603924
final  value 491.603924 
converged
Fitting Repeat 1 

# weights:  89
initial  value 577.382397 
iter  10 value 488.937592
iter  20 value 487.204340
iter  30 value 487.158842
iter  40 value 487.157477
final  value 487.157459 
converged
Fitting Repeat 2 

# weights:  89
initial  value 692.957585 
iter  10 value 488.498555
iter  20 value 487.649425
iter  30 value 487.646452
final  value 487.646429 
converged
Fitting Repeat 3 

# weights:  89
initial  value 686.780217 
iter  10 value 489.466691
iter  20 value 487.664600
iter  30 value 487.186243
iter  40 value 487.157949
final  value 487.157463 
converged
Fitting Repeat 4 

# weights:  89
initial  value 576.374938 
iter  10 value 488.801871
iter  20 value 487.252846
iter  30 value 487.190732
final  value 487.189469 
converged
Fitting Repeat 5 

# weights:  89
initial  value 581.114693 
iter  10 value 489.452172
iter  20 value 487.232092
iter  30 value 487.191323
final  value 487.189470 
converged
Fitting Repeat 1 

# weights:  89
initial  value 637.653145 
iter  10 value 501.773802
iter  20 value 501.649326
final  value 501.649271 
converged
Fitting Repeat 2 

# weights:  89
initial  value 644.096120 
iter  10 value 501.909740
iter  20 value 501.649983
final  value 501.649271 
converged
Fitting Repeat 3 

# weights:  89
initial  value 742.410949 
iter  10 value 502.016001
iter  20 value 501.650472
final  value 501.649284 
converged
Fitting Repeat 4 

# weights:  89
initial  value 692.316637 
iter  10 value 502.078440
iter  20 value 501.651696
final  value 501.649296 
converged
Fitting Repeat 5 

# weights:  89
initial  value 798.711201 
iter  10 value 501.946655
iter  20 value 501.650188
final  value 501.649334 
converged
Fitting Repeat 1 

# weights:  89
initial  value 546.393327 
iter  10 value 457.470841
iter  20 value 457.332491
iter  30 value 436.262021
iter  40 value 399.816330
iter  50 value 390.857003
iter  60 value 387.679579
iter  70 value 385.937005
iter  80 value 385.421681
iter  90 value 385.295811
iter 100 value 385.200584
final  value 385.200584 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  89
initial  value 584.473616 
iter  10 value 443.946283
iter  20 value 443.823451
iter  30 value 443.804738
iter  40 value 443.525472
iter  50 value 413.573448
iter  60 value 404.171593
iter  70 value 402.376987
iter  80 value 399.046709
iter  90 value 393.338025
iter 100 value 392.469115
final  value 392.469115 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  89
initial  value 604.267826 
iter  10 value 450.212530
iter  20 value 446.290729
iter  30 value 403.722610
iter  40 value 393.145353
iter  50 value 390.977128
iter  60 value 390.068138
iter  70 value 389.666219
iter  80 value 389.257698
iter  90 value 389.065076
iter 100 value 388.768740
final  value 388.768740 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  89
initial  value 669.937842 
iter  10 value 522.142324
iter  20 value 521.898743
iter  30 value 490.227427
iter  40 value 450.245446
iter  50 value 443.237057
iter  60 value 441.245660
iter  70 value 440.132906
iter  80 value 440.037703
iter  90 value 439.913086
iter 100 value 439.841645
final  value 439.841645 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  89
initial  value 639.292341 
iter  10 value 486.901058
iter  20 value 486.771659
iter  30 value 486.757276
iter  40 value 482.814418
iter  50 value 442.107218
iter  60 value 418.458846
iter  70 value 408.803707
iter  80 value 407.392701
iter  90 value 406.645850
iter 100 value 406.376036
final  value 406.376036 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  56
initial  value 700.945828 
iter  10 value 491.942346
iter  20 value 491.611569
iter  30 value 491.610943
iter  40 value 491.610053
iter  50 value 491.608618
iter  60 value 491.605797
iter  70 value 491.597604
iter  80 value 491.519773
iter  90 value 471.139651
iter 100 value 446.720457
final  value 446.720457 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  56
initial  value 597.632977 
iter  10 value 491.837129
iter  20 value 491.600011
iter  30 value 491.516263
iter  40 value 472.727995
iter  50 value 446.526623
iter  60 value 442.844450
iter  70 value 442.005902
iter  80 value 441.548629
iter  90 value 441.368922
iter 100 value 441.316109
final  value 441.316109 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  56
initial  value 631.628718 
iter  10 value 491.875106
iter  20 value 491.608161
iter  30 value 491.601136
iter  40 value 491.561360
iter  50 value 477.241281
iter  60 value 447.208729
iter  70 value 442.819440
iter  80 value 442.184306
iter  90 value 441.868101
iter 100 value 441.764495
final  value 441.764495 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  56
initial  value 667.333129 
iter  10 value 491.946873
iter  20 value 491.608018
iter  30 value 491.588808
iter  40 value 487.013492
iter  50 value 452.816863
iter  60 value 444.992658
iter  70 value 442.296540
iter  80 value 441.333459
iter  90 value 440.943036
iter 100 value 439.874959
final  value 439.874959 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  56
initial  value 722.663169 
iter  10 value 491.941080
iter  20 value 488.332720
iter  30 value 463.332453
iter  40 value 453.720896
iter  50 value 453.327435
iter  60 value 450.148210
iter  70 value 447.139294
iter  80 value 446.069170
iter  90 value 445.752073
iter 100 value 445.590736
final  value 445.590736 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 639.977295 
iter  10 value 493.019046
iter  20 value 491.618776
iter  30 value 483.849054
iter  40 value 451.571309
iter  50 value 441.087344
iter  60 value 437.412454
iter  70 value 435.944477
iter  80 value 433.916759
iter  90 value 431.130527
iter 100 value 429.973815
final  value 429.973815 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 555.051127 
iter  10 value 492.121049
iter  20 value 491.615151
iter  30 value 491.613277
iter  40 value 491.609601
iter  50 value 491.597632
iter  60 value 490.673010
iter  70 value 457.618595
iter  80 value 445.741228
iter  90 value 441.817457
iter 100 value 440.241126
final  value 440.241126 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 514.889800 
iter  10 value 491.707949
iter  20 value 491.618954
iter  30 value 491.618095
iter  40 value 491.616989
iter  50 value 491.615407
iter  60 value 491.612714
iter  70 value 491.606308
iter  80 value 491.564785
iter  90 value 471.524384
iter 100 value 443.028314
final  value 443.028314 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 642.381675 
iter  10 value 493.024598
iter  20 value 491.618778
iter  30 value 470.929261
iter  40 value 426.824683
iter  50 value 418.256424
iter  60 value 407.097108
iter  70 value 402.070534
iter  80 value 400.356340
iter  90 value 399.424426
iter 100 value 398.999989
final  value 398.999989 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 855.675842 
iter  10 value 492.218410
iter  20 value 488.159564
iter  30 value 455.760672
iter  40 value 444.425815
iter  50 value 439.352981
iter  60 value 434.631687
iter  70 value 432.190557
iter  80 value 431.328724
iter  90 value 428.953281
iter 100 value 426.052819
final  value 426.052819 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  23
initial  value 648.726058 
iter  10 value 495.343348
iter  20 value 480.708572
iter  30 value 473.153682
iter  40 value 467.010874
iter  50 value 464.664039
iter  60 value 463.669240
iter  70 value 462.441394
iter  80 value 461.931911
iter  90 value 461.900538
iter 100 value 461.821934
final  value 461.821934 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  23
initial  value 654.897755 
iter  10 value 507.171315
iter  20 value 481.635816
iter  30 value 476.959077
iter  40 value 475.525100
iter  50 value 475.421852
final  value 475.420955 
converged
Fitting Repeat 3 

# weights:  23
initial  value 604.675279 
iter  10 value 475.316459
iter  20 value 474.541311
iter  30 value 435.475538
iter  40 value 431.157985
iter  50 value 430.598949
iter  60 value 430.524905
final  value 430.517880 
converged
Fitting Repeat 4 

# weights:  23
initial  value 599.648912 
iter  10 value 454.057009
iter  20 value 437.025718
iter  30 value 419.641230
iter  40 value 416.543753
iter  50 value 415.987919
iter  60 value 414.507859
iter  70 value 414.430593
final  value 414.429969 
converged
Fitting Repeat 5 

# weights:  23
initial  value 576.210423 
iter  10 value 480.604345
iter  20 value 457.938693
iter  30 value 450.905907
iter  40 value 449.751038
iter  50 value 449.593534
iter  60 value 449.587217
iter  70 value 449.585993
final  value 449.585944 
converged
Fitting Repeat 1 

# weights:  78
initial  value 526.642325 
iter  10 value 491.677077
iter  20 value 468.001365
iter  30 value 446.274145
iter  40 value 438.925309
iter  50 value 433.603794
iter  60 value 430.198603
iter  70 value 427.461633
iter  80 value 424.833853
iter  90 value 423.006499
iter 100 value 422.446762
final  value 422.446762 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  78
initial  value 593.286423 
iter  10 value 476.839921
iter  20 value 443.573673
iter  30 value 425.862622
iter  40 value 423.149192
iter  50 value 420.704725
iter  60 value 419.761574
iter  70 value 419.149738
iter  80 value 418.699041
iter  90 value 417.397269
iter 100 value 416.472482
final  value 416.472482 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  78
initial  value 668.093568 
iter  10 value 482.804188
iter  20 value 461.310836
iter  30 value 447.384204
iter  40 value 437.812889
iter  50 value 426.723986
iter  60 value 421.761445
iter  70 value 419.297554
iter  80 value 418.000453
iter  90 value 417.605529
iter 100 value 417.429069
final  value 417.429069 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  78
initial  value 687.304999 
iter  10 value 487.215113
iter  20 value 455.478988
iter  30 value 437.021935
iter  40 value 426.792409
iter  50 value 420.021817
iter  60 value 413.554715
iter  70 value 405.996274
iter  80 value 403.473162
iter  90 value 402.633244
iter 100 value 401.556003
final  value 401.556003 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  78
initial  value 577.230642 
iter  10 value 491.817160
iter  20 value 484.964289
iter  30 value 453.451663
iter  40 value 435.136739
iter  50 value 430.854980
iter  60 value 426.713178
iter  70 value 422.136916
iter  80 value 416.419432
iter  90 value 409.125231
iter 100 value 406.452463
final  value 406.452463 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  67
initial  value 581.789895 
iter  10 value 503.272797
iter  20 value 503.177462
iter  30 value 503.174728
iter  40 value 503.161766
iter  50 value 495.608401
iter  60 value 454.313542
iter  70 value 453.384351
iter  80 value 452.637533
iter  90 value 452.560713
iter 100 value 452.526792
final  value 452.526792 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  67
initial  value 711.483844 
iter  10 value 526.802607
iter  20 value 526.600694
iter  30 value 526.597919
iter  40 value 526.592037
iter  50 value 526.558333
iter  60 value 509.995830
iter  70 value 466.318121
iter  80 value 463.724507
iter  90 value 459.989336
iter 100 value 459.852425
final  value 459.852425 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  67
initial  value 638.696352 
iter  10 value 517.724969
iter  20 value 517.247371
iter  30 value 468.354053
iter  40 value 457.347987
iter  50 value 456.815809
iter  60 value 450.320129
iter  70 value 448.329678
iter  80 value 447.563275
iter  90 value 447.111154
iter 100 value 446.755851
final  value 446.755851 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  67
initial  value 556.369453 
iter  10 value 514.575880
iter  20 value 499.836894
iter  30 value 460.586139
iter  40 value 449.945876
iter  50 value 445.849565
iter  60 value 443.630501
iter  70 value 442.843345
iter  80 value 442.279007
iter  90 value 441.732195
iter 100 value 441.418960
final  value 441.418960 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  67
initial  value 606.010982 
iter  10 value 478.988496
iter  20 value 478.819481
iter  30 value 478.819105
iter  40 value 478.818568
iter  50 value 478.817713
iter  60 value 478.816074
iter  70 value 478.811465
iter  80 value 478.766971
iter  90 value 462.952640
iter 100 value 429.738537
final  value 429.738537 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  100
initial  value 688.632965 
iter  10 value 529.276631
iter  20 value 477.483215
iter  30 value 461.763144
iter  40 value 452.156927
iter  50 value 438.290388
iter  60 value 432.397883
iter  70 value 428.062233
iter  80 value 424.338787
iter  90 value 419.619724
iter 100 value 418.174184
final  value 418.174184 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  100
initial  value 593.195620 
iter  10 value 431.847210
iter  20 value 389.666806
iter  30 value 372.944720
iter  40 value 362.721542
iter  50 value 354.647739
iter  60 value 347.757484
iter  70 value 341.710525
iter  80 value 338.824668
iter  90 value 333.150636
iter 100 value 329.072381
final  value 329.072381 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  100
initial  value 659.114332 
iter  10 value 487.638182
iter  20 value 431.043781
iter  30 value 407.558106
iter  40 value 394.230513
iter  50 value 383.036546
iter  60 value 378.634884
iter  70 value 376.406141
iter  80 value 375.271532
iter  90 value 374.738942
iter 100 value 374.385192
final  value 374.385192 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  100
initial  value 649.368915 
iter  10 value 481.172544
iter  20 value 436.600063
iter  30 value 415.402487
iter  40 value 402.086382
iter  50 value 399.532948
iter  60 value 396.631423
iter  70 value 387.584168
iter  80 value 378.837906
iter  90 value 372.928683
iter 100 value 370.980613
final  value 370.980613 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  100
initial  value 583.118709 
iter  10 value 475.886969
iter  20 value 429.496280
iter  30 value 416.152675
iter  40 value 411.656913
iter  50 value 409.243229
iter  60 value 406.621288
iter  70 value 405.320585
iter  80 value 404.982810
iter  90 value 404.697822
iter 100 value 403.247770
final  value 403.247770 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  89
initial  value 591.183713 
iter  10 value 491.241962
iter  20 value 491.177178
iter  30 value 491.177032
iter  40 value 491.176852
iter  50 value 491.176619
iter  60 value 491.176305
iter  70 value 491.175852
iter  80 value 491.175131
iter  90 value 491.173790
iter 100 value 491.170433
final  value 491.170433 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  89
initial  value 569.964229 
iter  10 value 491.984854
iter  20 value 490.616594
iter  30 value 450.425787
iter  40 value 431.349515
iter  50 value 424.869171
iter  60 value 420.938700
iter  70 value 419.219661
iter  80 value 419.088106
iter  90 value 418.319097
iter 100 value 418.115944
final  value 418.115944 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  89
initial  value 561.461722 
iter  10 value 508.375704
final  value 508.347868 
converged
Fitting Repeat 4 

# weights:  89
initial  value 646.854316 
iter  10 value 475.891261
iter  20 value 475.760177
iter  30 value 475.683292
iter  40 value 427.734831
iter  50 value 409.851860
iter  60 value 406.947805
iter  70 value 405.082918
iter  80 value 404.903600
iter  90 value 404.878020
iter 100 value 404.859312
final  value 404.859312 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  89
initial  value 743.063028 
iter  10 value 503.765813
iter  20 value 503.677113
iter  30 value 503.654037
iter  40 value 485.140760
iter  50 value 437.968636
iter  60 value 435.045228
iter  70 value 431.971811
iter  80 value 431.064598
iter  90 value 424.158653
iter 100 value 420.714937
final  value 420.714937 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  166
initial  value 700.417544 
iter  10 value 493.797942
iter  20 value 478.087286
iter  30 value 473.688268
iter  40 value 470.561324
iter  50 value 468.799909
iter  60 value 467.171870
iter  70 value 466.061201
iter  80 value 464.695992
iter  90 value 462.755826
iter 100 value 461.091912
final  value 461.091912 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  166
initial  value 630.269491 
iter  10 value 488.914321
iter  20 value 475.831945
iter  30 value 471.992320
iter  40 value 468.211219
iter  50 value 465.461841
iter  60 value 463.722918
iter  70 value 461.726066
iter  80 value 460.418535
iter  90 value 458.487725
iter 100 value 454.649365
final  value 454.649365 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  166
initial  value 610.249227 
iter  10 value 490.329643
iter  20 value 476.292763
iter  30 value 472.742911
iter  40 value 470.120588
iter  50 value 466.091243
iter  60 value 464.192245
iter  70 value 463.681659
iter  80 value 463.465863
iter  90 value 463.038656
iter 100 value 461.761989
final  value 461.761989 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  166
initial  value 604.516250 
iter  10 value 488.218007
iter  20 value 477.564120
iter  30 value 473.576347
iter  40 value 470.736328
iter  50 value 469.587332
iter  60 value 468.666339
iter  70 value 466.489089
iter  80 value 463.817860
iter  90 value 459.544614
iter 100 value 455.256858
final  value 455.256858 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  166
initial  value 663.443625 
iter  10 value 491.974167
iter  20 value 477.149800
iter  30 value 473.808811
iter  40 value 470.089472
iter  50 value 466.470444
iter  60 value 464.388050
iter  70 value 462.371492
iter  80 value 461.490475
iter  90 value 460.853563
iter 100 value 460.300385
final  value 460.300385 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  177
initial  value 562.499716 
iter  10 value 455.560279
iter  20 value 437.404578
iter  30 value 434.092928
iter  40 value 433.790800
iter  50 value 433.614679
iter  60 value 433.581202
iter  70 value 433.564397
iter  80 value 433.560384
iter  90 value 433.559952
final  value 433.559899 
converged
Fitting Repeat 2 

# weights:  177
initial  value 647.566166 
iter  10 value 454.056341
iter  20 value 441.174432
iter  30 value 440.718574
iter  40 value 440.699249
iter  50 value 440.697684
final  value 440.697516 
converged
Fitting Repeat 3 

# weights:  177
initial  value 639.965885 
iter  10 value 513.358938
iter  20 value 508.767868
iter  30 value 508.640888
iter  40 value 508.288987
iter  50 value 507.963405
iter  60 value 507.867631
iter  70 value 507.816533
final  value 507.814392 
converged
Fitting Repeat 4 

# weights:  177
initial  value 531.583702 
iter  10 value 472.769116
iter  20 value 466.659780
iter  30 value 466.263799
iter  40 value 465.974575
iter  50 value 465.957585
iter  60 value 465.955186
iter  70 value 465.954648
iter  80 value 465.954336
final  value 465.954277 
converged
Fitting Repeat 5 

# weights:  177
initial  value 600.193349 
iter  10 value 430.409595
iter  20 value 419.677354
iter  30 value 419.100928
iter  40 value 419.066836
iter  50 value 419.062153
iter  60 value 419.060704
final  value 419.060663 
converged
Fitting Repeat 1 

# weights:  45
initial  value 626.962004 
iter  10 value 475.039941
iter  20 value 454.165790
iter  30 value 441.966423
iter  40 value 440.282341
iter  50 value 438.978854
iter  60 value 437.413589
iter  70 value 436.678939
iter  80 value 436.375863
iter  90 value 433.794288
iter 100 value 430.335877
final  value 430.335877 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  45
initial  value 434.238756 
iter  10 value 389.468236
iter  20 value 375.755356
iter  30 value 371.835947
iter  40 value 370.187370
iter  50 value 369.417497
iter  60 value 368.136169
iter  70 value 366.693785
iter  80 value 366.620691
final  value 366.620246 
converged
Fitting Repeat 3 

# weights:  45
initial  value 676.956610 
iter  10 value 464.090550
iter  20 value 440.208994
iter  30 value 429.318277
iter  40 value 425.045502
iter  50 value 424.406747
iter  60 value 422.135531
iter  70 value 421.476006
iter  80 value 420.665664
iter  90 value 420.644782
final  value 420.644302 
converged
Fitting Repeat 4 

# weights:  45
initial  value 644.654934 
iter  10 value 494.180803
iter  20 value 480.019527
iter  30 value 463.227321
iter  40 value 458.757470
iter  50 value 457.323898
iter  60 value 454.874753
iter  70 value 451.701545
iter  80 value 439.774007
iter  90 value 437.805529
iter 100 value 436.931094
final  value 436.931094 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  45
initial  value 629.044798 
iter  10 value 506.821247
iter  20 value 478.208847
iter  30 value 467.036996
iter  40 value 457.560059
iter  50 value 455.888111
iter  60 value 454.100683
iter  70 value 453.959616
final  value 453.957434 
converged
Fitting Repeat 1 

# weights:  188
initial  value 566.272199 
iter  10 value 472.940103
iter  20 value 439.031854
iter  30 value 419.518461
iter  40 value 409.082612
iter  50 value 401.785524
iter  60 value 395.249538
iter  70 value 392.056845
iter  80 value 390.143331
iter  90 value 386.344231
iter 100 value 380.511381
final  value 380.511381 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  188
initial  value 611.555533 
iter  10 value 520.726418
iter  20 value 493.282894
iter  30 value 484.844442
iter  40 value 466.810883
iter  50 value 458.471124
iter  60 value 452.107671
iter  70 value 440.273341
iter  80 value 431.784417
iter  90 value 429.119617
iter 100 value 420.478550
final  value 420.478550 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  188
initial  value 623.451437 
iter  10 value 498.926167
iter  20 value 455.024698
iter  30 value 427.699008
iter  40 value 409.307066
iter  50 value 398.152765
iter  60 value 393.392371
iter  70 value 388.399849
iter  80 value 381.176190
iter  90 value 372.373928
iter 100 value 367.714085
final  value 367.714085 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  188
initial  value 631.339919 
iter  10 value 422.494595
iter  20 value 374.868605
iter  30 value 353.289749
iter  40 value 345.110421
iter  50 value 339.560896
iter  60 value 335.217594
iter  70 value 331.105579
iter  80 value 323.966530
iter  90 value 317.174078
iter 100 value 314.679026
final  value 314.679026 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  188
initial  value 556.678566 
iter  10 value 502.870998
iter  20 value 463.087077
iter  30 value 430.022091
iter  40 value 410.527607
iter  50 value 399.855742
iter  60 value 390.940627
iter  70 value 386.484957
iter  80 value 383.678760
iter  90 value 376.667483
iter 100 value 375.216266
final  value 375.216266 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  177
initial  value 586.454981 
iter  10 value 547.413377
iter  20 value 520.340820
iter  30 value 483.399463
iter  40 value 475.615779
iter  50 value 468.098028
iter  60 value 459.280218
iter  70 value 455.382147
iter  80 value 447.736733
iter  90 value 438.561763
iter 100 value 433.225616
final  value 433.225616 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  177
initial  value 584.783904 
iter  10 value 417.658004
iter  20 value 354.419272
iter  30 value 329.875466
iter  40 value 309.494409
iter  50 value 292.758993
iter  60 value 287.367638
iter  70 value 284.277294
iter  80 value 280.310100
iter  90 value 278.319467
iter 100 value 274.810877
final  value 274.810877 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  177
initial  value 541.247813 
iter  10 value 431.588526
iter  20 value 426.532645
iter  30 value 380.996300
iter  40 value 355.621384
iter  50 value 343.759140
iter  60 value 333.126196
iter  70 value 329.926098
iter  80 value 322.839711
iter  90 value 305.553788
iter 100 value 299.837471
final  value 299.837471 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  177
initial  value 651.330643 
iter  10 value 530.651898
iter  20 value 475.310782
iter  30 value 438.523785
iter  40 value 428.478751
iter  50 value 421.543319
iter  60 value 410.422556
iter  70 value 401.917080
iter  80 value 393.761515
iter  90 value 391.644691
iter 100 value 390.599561
final  value 390.599561 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  177
initial  value 713.790783 
iter  10 value 446.124483
iter  20 value 428.822335
iter  30 value 413.219156
iter  40 value 407.098281
iter  50 value 403.139222
iter  60 value 398.320881
iter  70 value 395.509824
iter  80 value 394.046611
iter  90 value 391.529661
iter 100 value 389.177324
final  value 389.177324 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  221
initial  value 693.281764 
iter  10 value 531.010281
iter  20 value 530.487613
final  value 530.484079 
converged
Fitting Repeat 2 

# weights:  221
initial  value 631.293431 
iter  10 value 497.558038
iter  20 value 496.247182
final  value 496.246221 
converged
Fitting Repeat 3 

# weights:  221
initial  value 876.825083 
iter  10 value 522.038612
iter  20 value 521.109102
iter  30 value 521.081862
final  value 521.081681 
converged
Fitting Repeat 4 

# weights:  221
initial  value 592.920808 
iter  10 value 470.129813
iter  20 value 469.601443
iter  30 value 469.587208
iter  40 value 469.572999
final  value 469.572514 
converged
Fitting Repeat 5 

# weights:  221
initial  value 641.421006 
iter  10 value 501.819731
iter  20 value 501.185792
final  value 501.184283 
converged
Fitting Repeat 1 

# weights:  188
initial  value 802.276011 
iter  10 value 489.647406
iter  20 value 455.315032
iter  30 value 435.288853
iter  40 value 426.041419
iter  50 value 417.988138
iter  60 value 415.111136
iter  70 value 409.533124
iter  80 value 398.471841
iter  90 value 391.799403
iter 100 value 390.369071
final  value 390.369071 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  188
initial  value 776.170552 
iter  10 value 490.604892
iter  20 value 457.575630
iter  30 value 439.797841
iter  40 value 431.365953
iter  50 value 410.689635
iter  60 value 401.192187
iter  70 value 399.006766
iter  80 value 394.841648
iter  90 value 391.188558
iter 100 value 387.177815
final  value 387.177815 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  188
initial  value 682.998601 
iter  10 value 479.936311
iter  20 value 451.502012
iter  30 value 429.163122
iter  40 value 423.189976
iter  50 value 421.114247
iter  60 value 411.333249
iter  70 value 396.084193
iter  80 value 383.384660
iter  90 value 375.879594
iter 100 value 370.244859
final  value 370.244859 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  188
initial  value 510.348840 
iter  10 value 490.833712
iter  20 value 477.275530
iter  30 value 445.909652
iter  40 value 430.547969
iter  50 value 422.945709
iter  60 value 415.312730
iter  70 value 412.602674
iter  80 value 408.921880
iter  90 value 403.396048
iter 100 value 399.647187
final  value 399.647187 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  188
initial  value 719.168897 
iter  10 value 488.351623
iter  20 value 444.282862
iter  30 value 430.044006
iter  40 value 424.150757
iter  50 value 420.462451
iter  60 value 416.620704
iter  70 value 409.317741
iter  80 value 396.912866
iter  90 value 390.777762
iter 100 value 387.232584
final  value 387.232584 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  34
initial  value 628.219796 
iter  10 value 471.456408
iter  20 value 470.134844
final  value 470.134148 
converged
Fitting Repeat 2 

# weights:  34
initial  value 511.171661 
iter  10 value 457.902074
iter  20 value 457.720196
final  value 457.720128 
converged
Fitting Repeat 3 

# weights:  34
initial  value 669.005956 
iter  10 value 487.198944
iter  20 value 486.216842
final  value 486.215762 
converged
Fitting Repeat 4 

# weights:  34
initial  value 626.384326 
iter  10 value 501.268837
iter  20 value 500.585458
final  value 500.584828 
converged
Fitting Repeat 5 

# weights:  34
initial  value 596.091111 
iter  10 value 479.409218
iter  20 value 478.860721
final  value 478.860569 
converged
Fitting Repeat 1 

# weights:  122
initial  value 576.185059 
iter  10 value 466.150364
iter  20 value 442.457215
iter  30 value 413.907326
iter  40 value 400.881274
iter  50 value 393.595723
iter  60 value 390.867805
iter  70 value 389.375913
iter  80 value 384.458631
iter  90 value 380.979768
iter 100 value 376.951726
final  value 376.951726 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 730.886054 
iter  10 value 434.468304
iter  20 value 432.975069
iter  30 value 400.142222
iter  40 value 379.315438
iter  50 value 372.258253
iter  60 value 368.715299
iter  70 value 367.456483
iter  80 value 359.753310
iter  90 value 341.553028
iter 100 value 337.787993
final  value 337.787993 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 563.194502 
iter  10 value 503.784092
iter  20 value 445.543400
iter  30 value 415.007832
iter  40 value 405.138393
iter  50 value 395.326835
iter  60 value 392.080637
iter  70 value 389.253517
iter  80 value 385.068587
iter  90 value 381.648157
iter 100 value 379.502881
final  value 379.502881 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 832.113052 
iter  10 value 568.972185
iter  20 value 534.305373
iter  30 value 508.121144
iter  40 value 495.736201
iter  50 value 480.736532
iter  60 value 471.267320
iter  70 value 467.287851
iter  80 value 465.996743
iter  90 value 464.972982
iter 100 value 463.691427
final  value 463.691427 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 552.030670 
iter  10 value 469.711114
iter  20 value 467.054424
iter  30 value 426.071607
iter  40 value 402.319611
iter  50 value 390.057489
iter  60 value 379.828615
iter  70 value 378.315274
iter  80 value 377.785722
iter  90 value 377.188154
iter 100 value 376.093335
final  value 376.093335 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  188
initial  value 721.550340 
iter  10 value 490.809667
iter  20 value 490.761238
final  value 490.760933 
converged
Fitting Repeat 2 

# weights:  188
initial  value 501.427210 
final  value 490.800639 
converged
Fitting Repeat 3 

# weights:  188
initial  value 526.279743 
iter  10 value 490.768333
iter  20 value 490.758562
iter  30 value 490.757479
iter  40 value 490.755288
iter  50 value 490.748857
iter  60 value 490.674121
iter  70 value 473.976022
iter  80 value 449.996103
iter  90 value 446.723606
iter 100 value 446.071358
final  value 446.071358 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  188
initial  value 507.462805 
final  value 490.826891 
converged
Fitting Repeat 5 

# weights:  188
initial  value 543.859649 
iter  10 value 490.772125
final  value 490.760730 
converged
Fitting Repeat 1 

# weights:  89
initial  value 672.179585 
iter  10 value 488.691010
iter  20 value 488.067504
iter  30 value 488.066136
iter  40 value 488.065902
iter  40 value 488.065899
iter  40 value 488.065899
final  value 488.065899 
converged
Fitting Repeat 2 

# weights:  89
initial  value 641.683908 
iter  10 value 489.876742
iter  20 value 488.078189
iter  30 value 488.066513
iter  40 value 488.065937
final  value 488.065899 
converged
Fitting Repeat 3 

# weights:  89
initial  value 819.269048 
iter  10 value 488.656997
iter  20 value 487.955726
iter  30 value 487.750630
iter  40 value 487.744190
iter  50 value 487.742594
final  value 487.741401 
converged
Fitting Repeat 4 

# weights:  89
initial  value 687.286691 
iter  10 value 489.470329
iter  20 value 487.770645
iter  30 value 487.746158
iter  40 value 487.741028
final  value 487.740665 
converged
Fitting Repeat 5 

# weights:  89
initial  value 682.628422 
iter  10 value 489.318416
iter  20 value 488.080003
iter  30 value 488.066800
iter  40 value 488.066085
final  value 488.065901 
converged
Fitting Repeat 1 

# weights:  89
initial  value 724.252046 
iter  10 value 501.648580
iter  20 value 501.025916
final  value 501.024873 
converged
Fitting Repeat 2 

# weights:  89
initial  value 635.173200 
iter  10 value 501.162616
iter  20 value 501.025181
final  value 501.024738 
converged
Fitting Repeat 3 

# weights:  89
initial  value 649.020354 
iter  10 value 501.242018
iter  20 value 501.025691
final  value 501.024751 
converged
Fitting Repeat 4 

# weights:  89
initial  value 708.206785 
iter  10 value 502.073694
iter  20 value 501.025741
final  value 501.024735 
converged
Fitting Repeat 5 

# weights:  89
initial  value 700.469247 
iter  10 value 501.261612
iter  20 value 501.025151
final  value 501.024736 
converged
Fitting Repeat 1 

# weights:  89
initial  value 558.318165 
iter  10 value 510.362387
iter  20 value 510.327231
iter  30 value 510.327168
iter  40 value 510.327093
iter  50 value 510.327005
iter  60 value 510.326897
iter  70 value 510.326763
iter  80 value 510.326589
iter  90 value 510.326356
iter 100 value 510.326025
final  value 510.326025 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  89
initial  value 610.536039 
iter  10 value 500.116989
iter  20 value 500.035825
iter  30 value 500.035438
iter  40 value 500.034892
iter  50 value 500.034057
iter  60 value 500.032614
iter  70 value 500.029532
iter  80 value 500.019128
iter  90 value 499.739863
iter 100 value 455.319789
final  value 455.319789 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  89
initial  value 532.017550 
iter  10 value 515.414328
final  value 515.409215 
converged
Fitting Repeat 4 

# weights:  89
initial  value 732.085105 
iter  10 value 506.936026
final  value 506.834672 
converged
Fitting Repeat 5 

# weights:  89
initial  value 564.261121 
iter  10 value 508.114782
iter  20 value 508.080507
iter  30 value 508.079892
iter  40 value 508.078902
iter  50 value 508.076862
iter  60 value 508.069850
iter  70 value 507.768133
iter  80 value 464.219927
iter  90 value 422.702095
iter 100 value 416.051607
final  value 416.051607 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  56
initial  value 542.040780 
iter  10 value 490.860973
iter  20 value 476.905133
iter  30 value 455.673710
iter  40 value 449.662738
iter  50 value 449.175817
iter  60 value 448.647928
iter  70 value 446.321658
iter  80 value 446.003318
iter  90 value 445.309104
iter 100 value 445.257852
final  value 445.257852 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  56
initial  value 538.457901 
iter  10 value 490.861592
iter  20 value 478.674534
iter  30 value 452.448992
iter  40 value 449.848758
iter  50 value 449.010028
iter  60 value 448.623954
iter  70 value 448.465856
iter  80 value 448.307775
iter  90 value 448.108419
iter 100 value 446.517725
final  value 446.517725 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  56
initial  value 645.334715 
iter  10 value 491.089489
iter  20 value 490.768510
iter  30 value 490.768029
iter  40 value 490.767354
iter  50 value 490.766305
iter  60 value 490.764400
iter  70 value 490.759799
iter  80 value 490.737651
iter  90 value 480.323614
iter 100 value 460.687608
final  value 460.687608 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  56
initial  value 542.480799 
iter  10 value 490.854757
iter  20 value 490.769824
iter  30 value 490.769609
iter  40 value 490.769358
iter  50 value 490.769055
iter  60 value 490.768677
iter  70 value 490.768181
iter  80 value 490.767483
iter  90 value 490.766407
iter 100 value 490.764485
final  value 490.764485 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  56
initial  value 559.634691 
iter  10 value 490.872471
iter  20 value 490.744567
iter  30 value 488.137351
iter  40 value 454.674338
iter  50 value 442.953393
iter  60 value 439.786395
iter  70 value 438.900562
iter  80 value 438.637992
iter  90 value 438.378796
iter 100 value 438.154878
final  value 438.154878 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  122
initial  value 665.125648 
iter  10 value 492.354276
iter  20 value 490.778624
iter  30 value 490.408487
iter  40 value 462.292432
iter  50 value 445.723177
iter  60 value 445.109322
iter  70 value 444.903791
iter  80 value 444.156759
iter  90 value 443.217871
iter 100 value 441.544654
final  value 441.544654 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  122
initial  value 554.306597 
iter  10 value 491.383021
iter  20 value 490.578775
iter  30 value 458.996618
iter  40 value 450.477894
iter  50 value 449.187294
iter  60 value 446.916550
iter  70 value 446.482131
iter  80 value 445.898229
iter  90 value 444.462642
iter 100 value 441.456274
final  value 441.456274 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  122
initial  value 661.636313 
iter  10 value 492.068863
iter  20 value 490.773988
iter  30 value 490.772999
iter  40 value 490.771564
iter  50 value 490.769109
iter  60 value 490.763385
iter  70 value 490.732015
iter  80 value 473.349733
iter  90 value 448.381627
iter 100 value 445.436407
final  value 445.436407 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  122
initial  value 514.908645 
iter  10 value 490.933060
iter  20 value 489.359096
iter  30 value 456.307950
iter  40 value 449.865758
iter  50 value 444.467659
iter  60 value 443.038940
iter  70 value 432.650643
iter  80 value 428.910266
iter  90 value 427.172809
iter 100 value 419.592242
final  value 419.592242 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  122
initial  value 517.639800 
iter  10 value 490.956590
iter  20 value 490.761322
iter  30 value 490.697468
iter  40 value 463.352959
iter  50 value 445.703070
iter  60 value 443.968230
iter  70 value 440.945829
iter  80 value 439.147838
iter  90 value 438.083530
iter 100 value 436.879331
final  value 436.879331 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  23
initial  value 550.875104 
iter  10 value 488.768227
iter  20 value 460.802843
iter  30 value 451.331829
iter  40 value 447.683810
iter  50 value 441.594513
iter  60 value 438.185543
iter  70 value 437.717337
iter  80 value 437.585751
final  value 437.585055 
converged
Fitting Repeat 2 

# weights:  23
initial  value 706.450612 
iter  10 value 503.149724
iter  20 value 496.375511
iter  30 value 459.316765
iter  40 value 450.723649
iter  50 value 448.385713
iter  60 value 447.839045
iter  70 value 446.951411
iter  80 value 446.387362
iter  90 value 446.171018
iter 100 value 446.161971
final  value 446.161971 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  23
initial  value 560.573279 
iter  10 value 443.311986
iter  20 value 425.915792
iter  30 value 411.261548
iter  40 value 408.413266
iter  50 value 408.106683
iter  60 value 408.095991
final  value 408.095946 
converged
Fitting Repeat 4 

# weights:  23
initial  value 579.497826 
iter  10 value 463.016382
iter  20 value 440.607972
iter  30 value 424.398840
iter  40 value 411.266495
iter  50 value 409.483928
iter  60 value 409.067303
iter  70 value 409.041169
final  value 409.040975 
converged
Fitting Repeat 5 

# weights:  23
initial  value 571.268024 
iter  10 value 471.269157
iter  20 value 431.339750
iter  30 value 426.424374
iter  40 value 425.470369
iter  50 value 424.183868
iter  60 value 422.637183
iter  70 value 422.329371
iter  80 value 422.253409
final  value 422.250791 
converged
Fitting Repeat 1 

# weights:  78
initial  value 599.408390 
iter  10 value 486.421656
iter  20 value 456.425829
iter  30 value 438.779723
iter  40 value 428.197296
iter  50 value 422.788030
iter  60 value 418.624118
iter  70 value 414.948084
iter  80 value 413.803908
iter  90 value 413.041519
iter 100 value 411.351012
final  value 411.351012 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  78
initial  value 542.941126 
iter  10 value 481.292748
iter  20 value 450.779004
iter  30 value 441.954680
iter  40 value 437.480746
iter  50 value 433.987975
iter  60 value 430.845161
iter  70 value 427.562331
iter  80 value 422.880880
iter  90 value 422.323978
iter 100 value 422.170445
final  value 422.170445 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  78
initial  value 672.996237 
iter  10 value 471.173544
iter  20 value 442.699518
iter  30 value 432.161399
iter  40 value 426.477998
iter  50 value 423.865840
iter  60 value 420.818355
iter  70 value 418.262112
iter  80 value 417.481724
iter  90 value 417.036582
iter 100 value 416.909085
final  value 416.909085 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  78
initial  value 542.812717 
iter  10 value 487.686937
iter  20 value 455.529459
iter  30 value 441.618675
iter  40 value 433.501247
iter  50 value 426.204718
iter  60 value 413.705371
iter  70 value 407.755618
iter  80 value 403.685538
iter  90 value 400.357221
iter 100 value 399.009445
final  value 399.009445 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  78
initial  value 608.707606 
iter  10 value 484.902097
iter  20 value 458.450055
iter  30 value 450.492556
iter  40 value 448.564519
iter  50 value 447.515897
iter  60 value 445.331899
iter  70 value 441.041658
iter  80 value 438.910798
iter  90 value 438.340616
iter 100 value 438.094175
final  value 438.094175 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  67
initial  value 616.608436 
iter  10 value 498.823296
iter  20 value 498.699874
iter  30 value 498.699720
iter  40 value 498.699543
iter  50 value 498.699337
iter  60 value 498.699087
iter  70 value 498.698774
iter  80 value 498.698359
iter  90 value 498.697766
iter 100 value 498.696816
final  value 498.696816 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  67
initial  value 732.667334 
iter  10 value 525.355196
iter  20 value 524.958329
iter  30 value 484.759455
iter  40 value 450.167257
iter  50 value 441.474873
iter  60 value 439.608769
iter  70 value 438.918426
iter  80 value 437.949049
iter  90 value 437.875105
iter 100 value 437.791665
final  value 437.791665 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  67
initial  value 617.547966 
iter  10 value 448.945413
iter  20 value 448.735954
iter  30 value 448.711812
iter  40 value 433.263608
iter  50 value 402.209973
iter  60 value 401.282632
iter  70 value 399.575555
iter  80 value 395.104949
iter  90 value 390.562857
iter 100 value 388.262055
final  value 388.262055 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  67
initial  value 498.988698 
iter  10 value 454.432871
iter  20 value 454.395777
iter  30 value 454.395238
iter  40 value 454.394480
iter  50 value 454.393217
iter  60 value 454.390488
iter  70 value 454.380481
iter  80 value 454.141289
iter  90 value 438.670019
iter 100 value 418.324595
final  value 418.324595 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  67
initial  value 507.403323 
iter  10 value 472.574749
iter  20 value 472.526411
iter  30 value 472.526314
iter  40 value 472.526205
iter  50 value 472.526082
iter  60 value 472.525940
iter  70 value 472.525772
iter  80 value 472.525570
iter  90 value 472.525319
iter 100 value 472.524997
final  value 472.524997 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  100
initial  value 892.993395 
iter  10 value 535.561482
iter  20 value 507.853876
iter  30 value 491.624542
iter  40 value 478.143389
iter  50 value 472.898656
iter  60 value 463.731087
iter  70 value 458.052125
iter  80 value 456.430041
iter  90 value 455.424338
iter 100 value 454.807503
final  value 454.807503 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  100
initial  value 537.333134 
iter  10 value 444.592040
iter  20 value 400.698308
iter  30 value 384.745587
iter  40 value 366.178853
iter  50 value 354.954643
iter  60 value 344.777325
iter  70 value 337.731735
iter  80 value 334.344903
iter  90 value 332.945217
iter 100 value 332.593821
final  value 332.593821 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  100
initial  value 586.216445 
iter  10 value 499.486888
iter  20 value 457.313941
iter  30 value 443.580166
iter  40 value 434.855556
iter  50 value 424.956179
iter  60 value 415.598746
iter  70 value 408.761342
iter  80 value 405.930441
iter  90 value 404.678954
iter 100 value 404.113413
final  value 404.113413 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  100
initial  value 694.582218 
iter  10 value 470.365850
iter  20 value 435.250521
iter  30 value 411.057257
iter  40 value 383.397348
iter  50 value 374.929646
iter  60 value 370.772901
iter  70 value 366.645987
iter  80 value 361.154721
iter  90 value 359.088330
iter 100 value 358.245705
final  value 358.245705 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  100
initial  value 593.978225 
iter  10 value 481.631868
iter  20 value 443.854277
iter  30 value 423.072182
iter  40 value 416.127993
iter  50 value 408.252268
iter  60 value 406.877981
iter  70 value 406.351499
iter  80 value 405.938246
iter  90 value 405.190078
iter 100 value 404.928362
final  value 404.928362 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  89
initial  value 657.965945 
iter  10 value 475.323834
iter  20 value 475.216458
iter  30 value 451.350141
iter  40 value 426.871016
iter  50 value 422.788712
iter  60 value 422.485434
iter  70 value 422.386740
iter  80 value 421.755121
iter  90 value 421.497084
iter 100 value 421.448846
final  value 421.448846 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  89
initial  value 546.982849 
iter  10 value 508.664608
final  value 508.653002 
converged
Fitting Repeat 3 

# weights:  89
initial  value 518.014905 
iter  10 value 465.348891
final  value 465.317036 
converged
Fitting Repeat 4 

# weights:  89
initial  value 540.750420 
iter  10 value 475.169592
final  value 475.137981 
converged
Fitting Repeat 5 

# weights:  89
initial  value 681.300178 
iter  10 value 531.179501
iter  20 value 531.094632
iter  30 value 531.091489
iter  40 value 531.080063
iter  50 value 530.277444
iter  60 value 490.431496
iter  70 value 468.277492
iter  80 value 461.997882
iter  90 value 460.102234
iter 100 value 455.745236
final  value 455.745236 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  166
initial  value 664.447219 
iter  10 value 490.535931
iter  20 value 475.288722
iter  30 value 470.581342
iter  40 value 467.521035
iter  50 value 464.635716
iter  60 value 460.912346
iter  70 value 459.880141
iter  80 value 459.645200
iter  90 value 457.521797
iter 100 value 455.245045
final  value 455.245045 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  166
initial  value 672.036421 
iter  10 value 491.648259
iter  20 value 478.443429
iter  30 value 469.978060
iter  40 value 466.682849
iter  50 value 463.939278
iter  60 value 460.936822
iter  70 value 459.562639
iter  80 value 457.936090
iter  90 value 457.392495
iter 100 value 456.884169
final  value 456.884169 
stopped after 100 iterations
Fitting Repeat 3 

# weights:  166
initial  value 552.028652 
iter  10 value 490.465655
iter  20 value 478.350983
iter  30 value 470.393994
iter  40 value 468.240376
iter  50 value 465.838010
iter  60 value 464.123152
iter  70 value 462.775101
iter  80 value 462.078682
iter  90 value 461.706254
iter 100 value 461.191420
final  value 461.191420 
stopped after 100 iterations
Fitting Repeat 4 

# weights:  166
initial  value 527.374338 
iter  10 value 486.062541
iter  20 value 476.444745
iter  30 value 471.976326
iter  40 value 468.495821
iter  50 value 465.558321
iter  60 value 461.935673
iter  70 value 460.045238
iter  80 value 458.952838
iter  90 value 458.195442
iter 100 value 457.674614
final  value 457.674614 
stopped after 100 iterations
Fitting Repeat 5 

# weights:  166
initial  value 579.878912 
iter  10 value 490.979088
iter  20 value 475.035050
iter  30 value 471.071896
iter  40 value 469.214513
iter  50 value 467.909572
iter  60 value 466.807386
iter  70 value 466.452343
iter  80 value 466.171842
iter  90 value 465.247532
iter 100 value 464.455816
final  value 464.455816 
stopped after 100 iterations
Fitting Repeat 1 

# weights:  188
initial  value 1147.954037 
iter  10 value 748.162195
iter  20 value 748.053066
iter  30 value 748.044615
iter  40 value 748.022720
iter  50 value 734.505736
iter  60 value 700.336909
iter  70 value 694.171341
iter  80 value 692.238915
iter  90 value 691.916405
iter 100 value 691.821777
final  value 691.821777 
stopped after 100 iterations
Fitting Repeat 2 

# weights:  188
initial  value 835.828354 
iter  10 value 748.088183
iter  20 value 748.052156
iter  20 value 748.052155
final  value 748.052155 
converged
Fitting Repeat 3 

# weights:  188
initial  value 1041.279560 
iter  10 value 748.171383
iter  20 value 748.053172
final  value 748.052020 
converged
Fitting Repeat 4 

# weights:  188
initial  value 1115.842566 
iter  10 value 748.166523
iter  20 value 748.053116
final  value 748.051979 
converged
Fitting Repeat 5 

# weights:  188
initial  value 1046.353888 
iter  10 value 748.158247
iter  20 value 748.053020
iter  30 value 748.050709
iter  40 value 748.050227
iter  50 value 748.049479
iter  60 value 748.048143
iter  70 value 748.045107
iter  80 value 748.032877
iter  90 value 743.494373
iter 100 value 705.210007
final  value 705.210007 
stopped after 100 iterations
Model Averaged Neural Network 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  size  decay         bag    RMSE       Rsquared      MAE        Selected
   2    7.603262e-03   TRUE  1.0073675  0.0046010704  0.7950596          
   3    1.340566e+00   TRUE  1.0003777  0.0031425755  0.7915211          
   4    1.169352e-01   TRUE  1.0199415  0.0009527355  0.8072411          
   5    1.750871e-04  FALSE  1.0027651  0.0081858552  0.7934206          
   6    8.994709e-05   TRUE  1.0107152  0.0036254510  0.7982240          
   7    7.559708e-03  FALSE  1.0145720  0.0049151359  0.8003630          
   8    3.729581e-05   TRUE  1.0096858  0.0021448650  0.7986466          
   8    4.930297e-05   TRUE  1.0083230  0.0029778468  0.8003350          
   8    6.965925e-01  FALSE  0.9986804  0.0061643917  0.7914253          
   8    5.606832e+00  FALSE  0.9999767  0.0040880796  0.7902745          
   9    4.598641e-02   TRUE  1.0201064  0.0021126534  0.8022363          
  11    4.981650e-04  FALSE  1.0042349  0.0095440892  0.7958706          
  11    3.099262e-03   TRUE  1.0135462  0.0086248371  0.8036869          
  15    1.984492e-01  FALSE  1.0217130  0.0030596027  0.8039097          
  16    4.269257e-03   TRUE  1.0158922  0.0041703303  0.8006515          
  16    6.696733e-01   TRUE  1.0031599  0.0016496563  0.7949524          
  17    1.131853e-05  FALSE  0.9953726  0.0170538134  0.7904734  *       
  17    4.457117e-03  FALSE  1.0158087  0.0054111189  0.8008165          
  17    6.395376e-02   TRUE  1.0402116  0.0016095092  0.8160679          
  20    2.007697e+00   TRUE  0.9979749  0.0022773994  0.7894890          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 17, decay = 1.131853e-05
 and bag = FALSE.
[1] "Mon Mar 05 14:44:57 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :1     NA's   :1     NA's   :1    
Error : Stopping
In addition: Warning messages:
1: model fit failed for Fold1: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
2: model fit failed for Fold2: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
3: model fit failed for Fold3: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
4: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :1     NA's   :1     NA's   :1    
Error : Stopping
In addition: Warning messages:
1: model fit failed for Fold1: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
2: model fit failed for Fold2: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
3: model fit failed for Fold3: vars=9 Error in bag.default(x, y, vars = param$vars, ...) : 
  Please specify 'bagControl' with the appropriate functions
 
4: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :1     NA's   :1     NA's   :1    
Error : Stopping
In addition: There were 26 warnings (use warnings() to see them)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 14:45:11 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "bag"                     
Bagged MARS 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  degree  nprune  RMSE      Rsquared     MAE        Selected
  1        3      1.004674  0.002648258  0.7993847  *       
  1        4      1.007391  0.003348108  0.8010332          
  1        5      1.009046  0.002849465  0.8037686          
  1        6      1.015329  0.006512207  0.8083917          
  1        8      1.020932  0.007168959  0.8119362          
  1       12      1.028529  0.006593792  0.8179117          
  2        3      1.005345  0.004137681  0.7993271          
  2        4      1.006944  0.004538188  0.7989937          
  2        6      1.010994  0.003261193  0.8063720          
  2        7      1.016499  0.004067274  0.8073299          
  2       11      1.031946  0.004555893  0.8215589          
  2       12      1.027995  0.005890192  0.8158975          
  2       14      1.029534  0.004243527  0.8151960          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nprune = 3 and degree = 1.
[1] "Mon Mar 05 14:47:07 2018"
Bagged MARS using gCV Pruning 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.031466  0.006649589  0.8198742

Tuning parameter 'degree' was held constant at a value of 1
[1] "Mon Mar 05 14:48:01 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :6     NA's   :6     NA's   :6    
Error : Stopping
In addition: There were 19 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :5     NA's   :5     NA's   :5    
Error : Stopping
In addition: There were 16 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :2     NA's   :2     NA's   :2    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 14:48:53 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "bam"                     
bartMachine initializing with 80 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 329.2/477.6MB
Iteration 200/1250  mem: 331.6/485.5MB
Iteration 300/1250  mem: 364.7/493.9MB
Iteration 400/1250  mem: 377.4/497MB
Iteration 500/1250  mem: 370.2/480.2MB
Iteration 600/1250  mem: 354/501.2MB
Iteration 700/1250  mem: 438.6/501.7MB
Iteration 800/1250  mem: 399.3/506.5MB
Iteration 900/1250  mem: 353.6/506.5MB
Iteration 1000/1250  mem: 427.7/505.4MB
Iteration 1100/1250  mem: 386.9/505.4MB
Iteration 1200/1250  mem: 461.9/504.9MB
done building BART in 28.056 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 25 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 384.9/502.8MB
Iteration 200/1250  mem: 368.9/500.2MB
Iteration 300/1250  mem: 466.8/500.2MB
Iteration 400/1250  mem: 452.1/500.7MB
Iteration 500/1250  mem: 448.8/501.7MB
Iteration 600/1250  mem: 448.5/489.2MB
Iteration 700/1250  mem: 459.8/491.8MB
Iteration 800/1250  mem: 468.8/485MB
Iteration 900/1250  mem: 411.8/477.6MB
Iteration 1000/1250  mem: 449.3/477.6MB
Iteration 1100/1250  mem: 121/477.6MB
Iteration 1200/1250  mem: 164.3/477.6MB
done building BART in 7.25 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 86 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 162.6/477.6MB
Iteration 200/1250  mem: 155.1/477.6MB
Iteration 300/1250  mem: 202.6/477.6MB
Iteration 400/1250  mem: 221.4/477.6MB
Iteration 500/1250  mem: 215.2/477.6MB
Iteration 600/1250  mem: 238.1/477.6MB
Iteration 700/1250  mem: 235.9/477.6MB
Iteration 800/1250  mem: 234.6/477.6MB
Iteration 900/1250  mem: 292.6/477.6MB
Iteration 1000/1250  mem: 283.1/477.6MB
Iteration 1100/1250  mem: 349.2/477.6MB
Iteration 1200/1250  mem: 346.2/477.6MB
done building BART in 11.572 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 82 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 445/477.6MB
Iteration 200/1250  mem: 333.9/477.6MB
Iteration 300/1250  mem: 361.2/477.6MB
Iteration 400/1250  mem: 404/477.6MB
Iteration 500/1250  mem: 220/490.2MB
Iteration 600/1250  mem: 194.5/490.7MB
Iteration 700/1250  mem: 247.8/488.6MB
Iteration 800/1250  mem: 287.9/489.7MB
Iteration 900/1250  mem: 217.1/489.2MB
Iteration 1000/1250  mem: 221.7/494.9MB
Iteration 1100/1250  mem: 318.7/498.1MB
Iteration 1200/1250  mem: 287.8/502.3MB
done building BART in 6.485 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 98 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 260.6/493.4MB
Iteration 200/1250  mem: 235.5/493.9MB
Iteration 300/1250  mem: 325.4/493.9MB
Iteration 400/1250  mem: 317.4/495.5MB
Iteration 500/1250  mem: 299.5/498.6MB
Iteration 600/1250  mem: 258.4/499.6MB
Iteration 700/1250  mem: 311.9/502.8MB
Iteration 800/1250  mem: 356.9/502.8MB
Iteration 900/1250  mem: 293.2/502.3MB
Iteration 1000/1250  mem: 338/502.3MB
Iteration 1100/1250  mem: 380.6/503.3MB
Iteration 1200/1250  mem: 306.7/500.7MB
done building BART in 7.248 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 85 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 313.7/494.4MB
Iteration 200/1250  mem: 350.7/494.4MB
Iteration 300/1250  mem: 397.2/492.8MB
Iteration 400/1250  mem: 339/497MB
Iteration 500/1250  mem: 366.7/477.6MB
Iteration 600/1250  mem: 406.3/493.9MB
Iteration 700/1250  mem: 365.4/491.3MB
Iteration 800/1250  mem: 400.6/495.5MB
Iteration 900/1250  mem: 417.7/499.6MB
Iteration 1000/1250  mem: 414.1/502.8MB
Iteration 1100/1250  mem: 391.5/505.4MB
Iteration 1200/1250  mem: 353.9/509.1MB
done building BART in 6.35 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 22 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 371.6/510.1MB
Iteration 200/1250  mem: 454.5/510.1MB
Iteration 300/1250  mem: 410.8/508.6MB
Iteration 400/1250  mem: 374/507MB
Iteration 500/1250  mem: 457.5/507MB
Iteration 600/1250  mem: 422.3/505.9MB
Iteration 700/1250  mem: 390.5/506.5MB
Iteration 800/1250  mem: 358.9/500.2MB
Iteration 900/1250  mem: 443.3/500.2MB
Iteration 1000/1250  mem: 418.1/501.2MB
Iteration 1100/1250  mem: 396.1/497MB
Iteration 1200/1250  mem: 379.6/494.9MB
done building BART in 1.578 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 55 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 380.9/481.8MB
Iteration 200/1250  mem: 437.5/481.3MB
Iteration 300/1250  mem: 436/477.6MB
Iteration 400/1250  mem: 432.7/483.4MB
Iteration 500/1250  mem: 66.2/477.6MB
Iteration 600/1250  mem: 114.8/477.6MB
Iteration 700/1250  mem: 99.3/477.6MB
Iteration 800/1250  mem: 80.3/477.6MB
Iteration 900/1250  mem: 126.6/477.6MB
Iteration 1000/1250  mem: 80.4/477.6MB
Iteration 1100/1250  mem: 105.9/477.6MB
Iteration 1200/1250  mem: 120.3/477.6MB
done building BART in 4.245 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 85 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 165.6/477.6MB
Iteration 200/1250  mem: 92.6/477.6MB
Iteration 300/1250  mem: 135.6/477.6MB
Iteration 400/1250  mem: 170.5/477.6MB
Iteration 500/1250  mem: 96.6/477.6MB
Iteration 600/1250  mem: 112/477.6MB
Iteration 700/1250  mem: 127.5/477.6MB
Iteration 800/1250  mem: 128.8/477.6MB
Iteration 900/1250  mem: 110.1/477.6MB
Iteration 1000/1250  mem: 191/477.6MB
Iteration 1100/1250  mem: 143.9/477.6MB
Iteration 1200/1250  mem: 210.8/477.6MB
done building BART in 6.035 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 42 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 171.2/477.6MB
Iteration 200/1250  mem: 207.4/477.6MB
Iteration 300/1250  mem: 239.6/477.6MB
Iteration 400/1250  mem: 155.1/477.6MB
Iteration 500/1250  mem: 197.3/477.6MB
Iteration 600/1250  mem: 236.5/477.6MB
Iteration 700/1250  mem: 164.4/477.6MB
Iteration 800/1250  mem: 211.5/477.6MB
Iteration 900/1250  mem: 145.6/477.6MB
Iteration 1000/1250  mem: 194/477.6MB
Iteration 1100/1250  mem: 242.9/477.6MB
Iteration 1200/1250  mem: 180/477.6MB
done building BART in 3.057 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 43 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 227/477.6MB
Iteration 200/1250  mem: 170.9/477.6MB
Iteration 300/1250  mem: 225.2/477.6MB
Iteration 400/1250  mem: 171.7/477.6MB
Iteration 500/1250  mem: 226/477.6MB
Iteration 600/1250  mem: 163.6/477.6MB
Iteration 700/1250  mem: 218.8/477.6MB
Iteration 800/1250  mem: 266.4/477.6MB
Iteration 900/1250  mem: 201.7/477.6MB
Iteration 1000/1250  mem: 247.9/477.6MB
Iteration 1100/1250  mem: 178.6/477.6MB
Iteration 1200/1250  mem: 226.9/477.6MB
done building BART in 3.168 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 41 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 255.2/477.6MB
Iteration 200/1250  mem: 177.5/477.6MB
Iteration 300/1250  mem: 214.6/477.6MB
Iteration 400/1250  mem: 251.2/477.6MB
Iteration 500/1250  mem: 287.5/477.6MB
Iteration 600/1250  mem: 202.8/477.6MB
Iteration 700/1250  mem: 232.3/477.6MB
Iteration 800/1250  mem: 267.4/477.6MB
Iteration 900/1250  mem: 189.7/477.6MB
Iteration 1000/1250  mem: 229.9/477.6MB
Iteration 1100/1250  mem: 270.2/477.6MB
Iteration 1200/1250  mem: 202.5/477.6MB
done building BART in 2.799 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 28 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 294.9/477.6MB
Iteration 200/1250  mem: 293.1/477.6MB
Iteration 300/1250  mem: 290.3/477.6MB
Iteration 400/1250  mem: 289.9/477.6MB
Iteration 500/1250  mem: 287/477.6MB
Iteration 600/1250  mem: 283.7/477.6MB
Iteration 700/1250  mem: 279.5/477.6MB
Iteration 800/1250  mem: 274.3/477.6MB
Iteration 900/1250  mem: 266.8/477.6MB
Iteration 1000/1250  mem: 259.7/477.6MB
Iteration 1100/1250  mem: 251.9/477.6MB
Iteration 1200/1250  mem: 242.2/477.6MB
done building BART in 2.051 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 55 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 297.4/477.6MB
Iteration 200/1250  mem: 278/477.6MB
Iteration 300/1250  mem: 260.4/477.6MB
Iteration 400/1250  mem: 243.4/477.6MB
Iteration 500/1250  mem: 333.1/477.6MB
Iteration 600/1250  mem: 313.6/477.6MB
Iteration 700/1250  mem: 292.6/477.6MB
Iteration 800/1250  mem: 280/477.6MB
Iteration 900/1250  mem: 264.7/477.6MB
Iteration 1000/1250  mem: 251.9/477.6MB
Iteration 1100/1250  mem: 348.3/477.6MB
Iteration 1200/1250  mem: 329.5/477.6MB
done building BART in 3.957 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 17 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 290.2/477.6MB
Iteration 200/1250  mem: 354.5/477.6MB
Iteration 300/1250  mem: 306.7/477.6MB
Iteration 400/1250  mem: 259.4/477.6MB
Iteration 500/1250  mem: 323.1/477.6MB
Iteration 600/1250  mem: 275/477.6MB
Iteration 700/1250  mem: 340.7/477.6MB
Iteration 800/1250  mem: 291.6/477.6MB
Iteration 900/1250  mem: 357.7/477.6MB
Iteration 1000/1250  mem: 309.4/477.6MB
Iteration 1100/1250  mem: 372.7/477.6MB
Iteration 1200/1250  mem: 325.1/477.6MB
done building BART in 1.232 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 37 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 293.6/477.6MB
Iteration 200/1250  mem: 323.1/477.6MB
Iteration 300/1250  mem: 351.7/477.6MB
Iteration 400/1250  mem: 379.5/477.6MB
Iteration 500/1250  mem: 298.8/477.6MB
Iteration 600/1250  mem: 327.7/477.6MB
Iteration 700/1250  mem: 354.6/477.6MB
Iteration 800/1250  mem: 379.4/477.6MB
Iteration 900/1250  mem: 299.5/477.6MB
Iteration 1000/1250  mem: 327.7/477.6MB
Iteration 1100/1250  mem: 358.4/477.6MB
Iteration 1200/1250  mem: 388.7/477.6MB
done building BART in 2.744 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 33 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 376.7/477.6MB
Iteration 200/1250  mem: 389.6/477.6MB
Iteration 300/1250  mem: 400.4/477.6MB
Iteration 400/1250  mem: 295.5/477.6MB
Iteration 500/1250  mem: 304.4/477.6MB
Iteration 600/1250  mem: 310.2/477.6MB
Iteration 700/1250  mem: 53.7/477.6MB
Iteration 800/1250  mem: 61.1/477.6MB
Iteration 900/1250  mem: 65.4/477.6MB
Iteration 1000/1250  mem: 80.4/477.6MB
Iteration 1100/1250  mem: 92/477.6MB
Iteration 1200/1250  mem: 107.9/477.6MB
done building BART in 2.354 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 49 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 63.4/477.6MB
Iteration 200/1250  mem: 141.4/477.6MB
Iteration 300/1250  mem: 104.9/477.6MB
Iteration 400/1250  mem: 64.5/477.6MB
Iteration 500/1250  mem: 136.1/477.6MB
Iteration 600/1250  mem: 88.5/477.6MB
Iteration 700/1250  mem: 159.9/477.6MB
Iteration 800/1250  mem: 116.7/477.6MB
Iteration 900/1250  mem: 68.4/477.6MB
Iteration 1000/1250  mem: 137.6/477.6MB
Iteration 1100/1250  mem: 86.2/477.6MB
Iteration 1200/1250  mem: 153.6/477.6MB
done building BART in 3.464 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 42 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 183.9/477.6MB
Iteration 200/1250  mem: 94.4/477.6MB
Iteration 300/1250  mem: 128.2/477.6MB
Iteration 400/1250  mem: 163.1/477.6MB
Iteration 500/1250  mem: 195.1/477.6MB
Iteration 600/1250  mem: 112.1/477.6MB
Iteration 700/1250  mem: 153.2/477.6MB
Iteration 800/1250  mem: 194.6/477.6MB
Iteration 900/1250  mem: 131.5/477.6MB
Iteration 1000/1250  mem: 182.3/477.6MB
Iteration 1100/1250  mem: 133.4/477.6MB
Iteration 1200/1250  mem: 190/477.6MB
done building BART in 2.878 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 75 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 122.3/477.6MB
Iteration 200/1250  mem: 179.8/477.6MB
Iteration 300/1250  mem: 169.2/477.6MB
Iteration 400/1250  mem: 220.2/477.6MB
Iteration 500/1250  mem: 181.3/477.6MB
Iteration 600/1250  mem: 218.4/477.6MB
Iteration 700/1250  mem: 228.3/477.6MB
Iteration 800/1250  mem: 255.5/477.6MB
Iteration 900/1250  mem: 225.4/477.6MB
Iteration 1000/1250  mem: 278.2/477.6MB
Iteration 1100/1250  mem: 315.8/477.6MB
Iteration 1200/1250  mem: 329.4/477.6MB
done building BART in 6.57 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 80 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 245.3/489.7MB
Iteration 200/1250  mem: 280.9/493.9MB
Iteration 300/1250  mem: 294.7/495.5MB
Iteration 400/1250  mem: 292.3/501.7MB
Iteration 500/1250  mem: 259.4/504.9MB
Iteration 600/1250  mem: 334.9/504.4MB
Iteration 700/1250  mem: 289.3/507.5MB
Iteration 800/1250  mem: 349.1/508.6MB
Iteration 900/1250  mem: 292.5/502.8MB
Iteration 1000/1250  mem: 248.1/505.4MB
Iteration 1100/1250  mem: 326.7/503.8MB
Iteration 1200/1250  mem: 296.1/504.4MB
done building BART in 5.749 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 25 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 335.3/503.8MB
Iteration 200/1250  mem: 320/502.3MB
Iteration 300/1250  mem: 304.1/503.3MB
Iteration 400/1250  mem: 289/501.2MB
Iteration 500/1250  mem: 280.6/498.6MB
Iteration 600/1250  mem: 269.8/497MB
Iteration 700/1250  mem: 264.7/495.5MB
Iteration 800/1250  mem: 360.5/495.5MB
Iteration 900/1250  mem: 352.1/493.4MB
Iteration 1000/1250  mem: 352.9/490.7MB
Iteration 1100/1250  mem: 355.7/490.2MB
Iteration 1200/1250  mem: 280.3/488.1MB
done building BART in 1.838 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 86 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 316.4/477.6MB
Iteration 200/1250  mem: 367.8/477.6MB
Iteration 300/1250  mem: 318.2/479.2MB
Iteration 400/1250  mem: 364.6/485MB
Iteration 500/1250  mem: 367.4/489.2MB
Iteration 600/1250  mem: 375.2/488.6MB
Iteration 700/1250  mem: 188.9/484.4MB
Iteration 800/1250  mem: 167.6/485MB
Iteration 900/1250  mem: 227.9/485MB
Iteration 1000/1250  mem: 176.7/477.6MB
Iteration 1100/1250  mem: 224/491.8MB
Iteration 1200/1250  mem: 261/492.3MB
done building BART in 6.662 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 82 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 347.1/491.8MB
Iteration 200/1250  mem: 258.7/477.6MB
Iteration 300/1250  mem: 295.6/486MB
Iteration 400/1250  mem: 320.6/485.5MB
Iteration 500/1250  mem: 337.8/488.1MB
Iteration 600/1250  mem: 324.3/492.8MB
Iteration 700/1250  mem: 283.9/499.6MB
Iteration 800/1250  mem: 347.5/501.7MB
Iteration 900/1250  mem: 284.6/492.3MB
Iteration 1000/1250  mem: 355.9/499.6MB
Iteration 1100/1250  mem: 304.3/499.1MB
Iteration 1200/1250  mem: 377.9/499.1MB
done building BART in 5.899 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 98 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 358.7/486.5MB
Iteration 200/1250  mem: 333.9/477.6MB
Iteration 300/1250  mem: 324.8/485.5MB
Iteration 400/1250  mem: 300.1/487.6MB
Iteration 500/1250  mem: 367.9/490.2MB
Iteration 600/1250  mem: 413.4/494.4MB
Iteration 700/1250  mem: 334.3/487.1MB
Iteration 800/1250  mem: 384.1/492.3MB
Iteration 900/1250  mem: 327.7/493.4MB
Iteration 1000/1250  mem: 365.5/494.9MB
Iteration 1100/1250  mem: 395.3/496.5MB
Iteration 1200/1250  mem: 415.9/497MB
done building BART in 7.158 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 85 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 370.6/489.7MB
Iteration 200/1250  mem: 373/481.3MB
Iteration 300/1250  mem: 395.2/488.6MB
Iteration 400/1250  mem: 138.4/477.6MB
Iteration 500/1250  mem: 157.4/477.6MB
Iteration 600/1250  mem: 188.7/477.6MB
Iteration 700/1250  mem: 109.7/477.6MB
Iteration 800/1250  mem: 217.1/477.6MB
Iteration 900/1250  mem: 196.2/479.7MB
Iteration 1000/1250  mem: 164.2/479.7MB
Iteration 1100/1250  mem: 131.6/479.7MB
Iteration 1200/1250  mem: 217.1/480.2MB
done building BART in 6.358 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 22 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 240.7/480.2MB
Iteration 200/1250  mem: 205.8/479.7MB
Iteration 300/1250  mem: 166.8/482.3MB
Iteration 400/1250  mem: 251/482.3MB
Iteration 500/1250  mem: 211.2/479.2MB
Iteration 600/1250  mem: 171.9/479.2MB
Iteration 700/1250  mem: 253.8/479.2MB
Iteration 800/1250  mem: 217.5/477.6MB
Iteration 900/1250  mem: 182.1/478.2MB
Iteration 1000/1250  mem: 148.5/478.7MB
Iteration 1100/1250  mem: 231.2/478.7MB
Iteration 1200/1250  mem: 198.2/477.6MB
done building BART in 1.546 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 55 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 246.7/477.6MB
Iteration 200/1250  mem: 223.1/477.6MB
Iteration 300/1250  mem: 201.3/477.6MB
Iteration 400/1250  mem: 180.4/477.6MB
Iteration 500/1250  mem: 167.2/477.6MB
Iteration 600/1250  mem: 268.6/477.6MB
Iteration 700/1250  mem: 256.5/477.6MB
Iteration 800/1250  mem: 243/477.6MB
Iteration 900/1250  mem: 217.3/477.6MB
Iteration 1000/1250  mem: 184.7/480.2MB
Iteration 1100/1250  mem: 274.4/479.7MB
Iteration 1200/1250  mem: 243.1/478.2MB
done building BART in 3.895 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 85 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 252.4/477.6MB
Iteration 200/1250  mem: 281/477.6MB
Iteration 300/1250  mem: 216.9/477.6MB
Iteration 400/1250  mem: 248.9/477.6MB
Iteration 500/1250  mem: 277.5/477.6MB
Iteration 600/1250  mem: 294.2/477.6MB
Iteration 700/1250  mem: 276/477.6MB
Iteration 800/1250  mem: 237.1/481.8MB
Iteration 900/1250  mem: 315/481.8MB
Iteration 1000/1250  mem: 266.6/482.3MB
Iteration 1100/1250  mem: 341.7/482.3MB
Iteration 1200/1250  mem: 292.2/481.3MB
done building BART in 6.006 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 42 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 266/480.2MB
Iteration 200/1250  mem: 303.5/477.6MB
Iteration 300/1250  mem: 348.6/477.6MB
Iteration 400/1250  mem: 278.1/477.6MB
Iteration 500/1250  mem: 323.1/477.6MB
Iteration 600/1250  mem: 254.6/477.6MB
Iteration 700/1250  mem: 298.6/477.6MB
Iteration 800/1250  mem: 340.5/478.2MB
Iteration 900/1250  mem: 265.7/477.6MB
Iteration 1000/1250  mem: 310.3/478.2MB
Iteration 1100/1250  mem: 352.9/478.2MB
Iteration 1200/1250  mem: 275/477.6MB
done building BART in 3.003 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 43 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 305.4/480.2MB
Iteration 200/1250  mem: 346.8/477.6MB
Iteration 300/1250  mem: 269.1/477.6MB
Iteration 400/1250  mem: 313.8/479.7MB
Iteration 500/1250  mem: 360.3/479.7MB
Iteration 600/1250  mem: 286.1/477.6MB
Iteration 700/1250  mem: 333.2/479.7MB
Iteration 800/1250  mem: 378/479.2MB
Iteration 900/1250  mem: 300.6/479.7MB
Iteration 1000/1250  mem: 344.8/481.3MB
Iteration 1100/1250  mem: 388.6/481.3MB
Iteration 1200/1250  mem: 306/477.6MB
done building BART in 3.1 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 41 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 318.4/481.3MB
Iteration 200/1250  mem: 345.6/479.7MB
Iteration 300/1250  mem: 376.5/477.6MB
Iteration 400/1250  mem: 289.9/479.7MB
Iteration 500/1250  mem: 322.4/479.7MB
Iteration 600/1250  mem: 357.2/477.6MB
Iteration 700/1250  mem: 390.7/479.7MB
Iteration 800/1250  mem: 302.9/479.7MB
Iteration 900/1250  mem: 336.6/479.7MB
Iteration 1000/1250  mem: 367.4/480.2MB
Iteration 1100/1250  mem: 399.3/480.8MB
Iteration 1200/1250  mem: 310.7/480.8MB
done building BART in 2.842 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 28 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 392/479.7MB
Iteration 200/1250  mem: 377.1/480.2MB
Iteration 300/1250  mem: 358.7/481.8MB
Iteration 400/1250  mem: 340.8/482.3MB
Iteration 500/1250  mem: 322/482.3MB
Iteration 600/1250  mem: 428.8/482.3MB
Iteration 700/1250  mem: 408.2/478.2MB
Iteration 800/1250  mem: 387.9/482.3MB
Iteration 900/1250  mem: 370.4/482.3MB
Iteration 1000/1250  mem: 352.1/482.3MB
Iteration 1100/1250  mem: 333.1/482.3MB
Iteration 1200/1250  mem: 441/482.3MB
done building BART in 1.98 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 55 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 354/478.7MB
Iteration 200/1250  mem: 437/477.6MB
Iteration 300/1250  mem: 399.4/477.6MB
Iteration 400/1250  mem: 367.4/479.2MB
Iteration 500/1250  mem: 455.2/480.2MB
Iteration 600/1250  mem: 116.1/477.6MB
Iteration 700/1250  mem: 80.7/477.6MB
Iteration 800/1250  mem: 52.7/477.6MB
Iteration 900/1250  mem: 138.1/477.6MB
Iteration 1000/1250  mem: 107.7/477.6MB
Iteration 1100/1250  mem: 66.9/477.6MB
Iteration 1200/1250  mem: 150.3/477.6MB
done building BART in 3.805 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 17 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 87.6/477.6MB
Iteration 200/1250  mem: 151.6/477.6MB
Iteration 300/1250  mem: 89.9/477.6MB
Iteration 400/1250  mem: 156.6/477.6MB
Iteration 500/1250  mem: 94.4/477.6MB
Iteration 600/1250  mem: 160/477.6MB
Iteration 700/1250  mem: 95/477.6MB
Iteration 800/1250  mem: 159.5/477.6MB
Iteration 900/1250  mem: 95.6/477.6MB
Iteration 1000/1250  mem: 159.1/477.6MB
Iteration 1100/1250  mem: 92.2/477.6MB
Iteration 1200/1250  mem: 154.5/477.6MB
done building BART in 1.112 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 37 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 86.7/477.6MB
Iteration 200/1250  mem: 94.2/477.6MB
Iteration 300/1250  mem: 109.7/477.6MB
Iteration 400/1250  mem: 124.6/477.6MB
Iteration 500/1250  mem: 137.1/477.6MB
Iteration 600/1250  mem: 151.5/477.6MB
Iteration 700/1250  mem: 163.6/477.6MB
Iteration 800/1250  mem: 176.7/477.6MB
Iteration 900/1250  mem: 188.5/477.6MB
Iteration 1000/1250  mem: 199.4/477.6MB
Iteration 1100/1250  mem: 208.6/477.6MB
Iteration 1200/1250  mem: 219.2/477.6MB
done building BART in 2.619 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 33 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 167.9/477.6MB
Iteration 200/1250  mem: 157.6/477.6MB
Iteration 300/1250  mem: 148.2/477.6MB
Iteration 400/1250  mem: 144.3/477.6MB
Iteration 500/1250  mem: 141.2/477.6MB
Iteration 600/1250  mem: 140.9/477.6MB
Iteration 700/1250  mem: 142.1/477.6MB
Iteration 800/1250  mem: 144/477.6MB
Iteration 900/1250  mem: 145.3/477.6MB
Iteration 1000/1250  mem: 146.8/477.6MB
Iteration 1100/1250  mem: 149.1/477.6MB
Iteration 1200/1250  mem: 147.9/477.6MB
done building BART in 2.252 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 49 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 176.3/477.6MB
Iteration 200/1250  mem: 239.1/477.6MB
Iteration 300/1250  mem: 174.2/477.6MB
Iteration 400/1250  mem: 234.3/477.6MB
Iteration 500/1250  mem: 157.5/477.6MB
Iteration 600/1250  mem: 213.8/477.6MB
Iteration 700/1250  mem: 131.5/477.6MB
Iteration 800/1250  mem: 186.4/477.6MB
Iteration 900/1250  mem: 239.9/477.6MB
Iteration 1000/1250  mem: 165/477.6MB
Iteration 1100/1250  mem: 219.2/477.6MB
Iteration 1200/1250  mem: 142.5/477.6MB
done building BART in 3.365 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 42 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 149.2/477.6MB
Iteration 200/1250  mem: 175.9/477.6MB
Iteration 300/1250  mem: 204.1/477.6MB
Iteration 400/1250  mem: 233.6/477.6MB
Iteration 500/1250  mem: 266.4/477.6MB
Iteration 600/1250  mem: 178/477.6MB
Iteration 700/1250  mem: 212.2/477.6MB
Iteration 800/1250  mem: 246/477.6MB
Iteration 900/1250  mem: 279.5/477.6MB
Iteration 1000/1250  mem: 189.8/477.6MB
Iteration 1100/1250  mem: 220.8/477.6MB
Iteration 1200/1250  mem: 252.7/477.6MB
done building BART in 2.837 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 75 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 267.6/477.6MB
Iteration 200/1250  mem: 296.7/477.6MB
Iteration 300/1250  mem: 209.5/477.6MB
Iteration 400/1250  mem: 257.6/477.6MB
Iteration 500/1250  mem: 305.3/477.6MB
Iteration 600/1250  mem: 266.7/477.6MB
Iteration 700/1250  mem: 345.8/477.6MB
Iteration 800/1250  mem: 307.2/477.6MB
Iteration 900/1250  mem: 228.1/508MB
Iteration 1000/1250  mem: 171.4/510.7MB
Iteration 1100/1250  mem: 227.1/512.2MB
Iteration 1200/1250  mem: 280.4/513.8MB
done building BART in 5.506 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 80 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 243.3/517.5MB
Iteration 200/1250  mem: 266.7/517.5MB
Iteration 300/1250  mem: 292.1/517.5MB
Iteration 400/1250  mem: 316.8/516.9MB
Iteration 500/1250  mem: 339.9/517.5MB
Iteration 600/1250  mem: 363.3/514.3MB
Iteration 700/1250  mem: 251.4/516.9MB
Iteration 800/1250  mem: 280.2/515.9MB
Iteration 900/1250  mem: 312/516.4MB
Iteration 1000/1250  mem: 340.6/516.9MB
Iteration 1100/1250  mem: 361.7/518MB
Iteration 1200/1250  mem: 381.1/519MB
done building BART in 5.406 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 25 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 355.9/520.1MB
Iteration 200/1250  mem: 310.7/519.6MB
Iteration 300/1250  mem: 264.7/512.2MB
Iteration 400/1250  mem: 361.4/512.2MB
Iteration 500/1250  mem: 327.1/514.3MB
Iteration 600/1250  mem: 293.6/509.1MB
Iteration 700/1250  mem: 390.5/509.1MB
Iteration 800/1250  mem: 365/505.4MB
Iteration 900/1250  mem: 337.1/512.2MB
Iteration 1000/1250  mem: 309.2/510.7MB
Iteration 1100/1250  mem: 406.3/510.7MB
Iteration 1200/1250  mem: 381.8/511.2MB
done building BART in 1.737 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 86 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 411/511.7MB
Iteration 200/1250  mem: 352.1/512.8MB
Iteration 300/1250  mem: 417.4/513.8MB
Iteration 400/1250  mem: 364/514.3MB
Iteration 500/1250  mem: 161.4/496MB
Iteration 600/1250  mem: 229.1/498.1MB
Iteration 700/1250  mem: 156.2/500.2MB
Iteration 800/1250  mem: 216.4/499.6MB
Iteration 900/1250  mem: 274.9/500.7MB
Iteration 1000/1250  mem: 201.2/500.2MB
Iteration 1100/1250  mem: 269.3/500.2MB
Iteration 1200/1250  mem: 336.9/499.6MB
done building BART in 6.041 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 82 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 286.4/488.6MB
Iteration 200/1250  mem: 310.4/483.4MB
Iteration 300/1250  mem: 337.9/497.5MB
Iteration 400/1250  mem: 369.9/497MB
Iteration 500/1250  mem: 401.1/497MB
Iteration 600/1250  mem: 282.1/499.6MB
Iteration 700/1250  mem: 305.9/499.6MB
Iteration 800/1250  mem: 329.2/499.6MB
Iteration 900/1250  mem: 350.7/501.2MB
Iteration 1000/1250  mem: 365.6/500.2MB
Iteration 1100/1250  mem: 381.2/500.7MB
Iteration 1200/1250  mem: 396.7/501.7MB
done building BART in 5.554 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 98 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 384.5/482.9MB
Iteration 200/1250  mem: 374.4/490.2MB
Iteration 300/1250  mem: 353.7/490.7MB
Iteration 400/1250  mem: 461.5/493.4MB
Iteration 500/1250  mem: 425.2/495.5MB
Iteration 600/1250  mem: 110.5/477.6MB
Iteration 700/1250  mem: 193/478.2MB
Iteration 800/1250  mem: 115.9/479.7MB
Iteration 900/1250  mem: 183.1/480.2MB
Iteration 1000/1250  mem: 245.8/481.8MB
Iteration 1100/1250  mem: 154.1/482.3MB
Iteration 1200/1250  mem: 210.3/482.9MB
done building BART in 6.688 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 85 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 295.3/480.8MB
Iteration 200/1250  mem: 161/479.2MB
Iteration 300/1250  mem: 180.6/478.7MB
Iteration 400/1250  mem: 209/479.2MB
Iteration 500/1250  mem: 227.1/479.7MB
Iteration 600/1250  mem: 250.2/478.2MB
Iteration 700/1250  mem: 274.9/477.6MB
Iteration 800/1250  mem: 302.9/479.2MB
Iteration 900/1250  mem: 177.8/477.6MB
Iteration 1000/1250  mem: 202/479.2MB
Iteration 1100/1250  mem: 223.6/479.7MB
Iteration 1200/1250  mem: 246.7/480.8MB
done building BART in 5.714 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 22 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 204.6/481.3MB
Iteration 200/1250  mem: 287/481.3MB
Iteration 300/1250  mem: 215.4/481.3MB
Iteration 400/1250  mem: 301.5/481.3MB
Iteration 500/1250  mem: 232.8/481.8MB
Iteration 600/1250  mem: 317.6/481.8MB
Iteration 700/1250  mem: 252.1/477.6MB
Iteration 800/1250  mem: 333.1/477.6MB
Iteration 900/1250  mem: 268.2/479.7MB
Iteration 1000/1250  mem: 199.5/478.7MB
Iteration 1100/1250  mem: 284.4/478.7MB
Iteration 1200/1250  mem: 221.3/479.2MB
done building BART in 1.411 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 55 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 352.4/477.6MB
Iteration 200/1250  mem: 262.7/478.7MB
Iteration 300/1250  mem: 318.4/479.2MB
Iteration 400/1250  mem: 229.4/479.2MB
Iteration 500/1250  mem: 288.9/479.2MB
Iteration 600/1250  mem: 346.1/479.7MB
Iteration 700/1250  mem: 247/480.8MB
Iteration 800/1250  mem: 302.5/482.3MB
Iteration 900/1250  mem: 354.3/482.3MB
Iteration 1000/1250  mem: 251.9/482.3MB
Iteration 1100/1250  mem: 305.3/482.9MB
Iteration 1200/1250  mem: 355.7/483.4MB
done building BART in 3.663 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 85 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 348.9/478.2MB
Iteration 200/1250  mem: 362.3/481.3MB
Iteration 300/1250  mem: 376.9/481.3MB
Iteration 400/1250  mem: 391.5/481.8MB
Iteration 500/1250  mem: 405.6/480.2MB
Iteration 600/1250  mem: 274.3/477.6MB
Iteration 700/1250  mem: 298.1/477.6MB
Iteration 800/1250  mem: 330.9/477.6MB
Iteration 900/1250  mem: 355.7/478.7MB
Iteration 1000/1250  mem: 377.9/478.7MB
Iteration 1100/1250  mem: 399.8/479.2MB
Iteration 1200/1250  mem: 416/479.7MB
done building BART in 5.601 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 42 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 303.5/478.7MB
Iteration 200/1250  mem: 312/479.2MB
Iteration 300/1250  mem: 318.9/479.2MB
Iteration 400/1250  mem: 330.5/477.6MB
Iteration 500/1250  mem: 341.4/478.7MB
Iteration 600/1250  mem: 356.4/478.7MB
Iteration 700/1250  mem: 364.7/479.2MB
Iteration 800/1250  mem: 373.2/479.2MB
Iteration 900/1250  mem: 382.3/480.2MB
Iteration 1000/1250  mem: 138.3/477.6MB
Iteration 1100/1250  mem: 146.4/477.6MB
Iteration 1200/1250  mem: 154.4/477.6MB
done building BART in 2.918 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 43 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 112.9/477.6MB
Iteration 200/1250  mem: 122.4/477.6MB
Iteration 300/1250  mem: 132.9/477.6MB
Iteration 400/1250  mem: 140.6/477.6MB
Iteration 500/1250  mem: 151.8/477.6MB
Iteration 600/1250  mem: 163.1/477.6MB
Iteration 700/1250  mem: 173.9/477.6MB
Iteration 800/1250  mem: 182.4/477.6MB
Iteration 900/1250  mem: 190.2/477.6MB
Iteration 1000/1250  mem: 198.4/477.6MB
Iteration 1100/1250  mem: 208.9/477.6MB
Iteration 1200/1250  mem: 217.9/477.6MB
done building BART in 2.924 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 41 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 162.8/477.6MB
Iteration 200/1250  mem: 162.9/477.6MB
Iteration 300/1250  mem: 160.1/477.6MB
Iteration 400/1250  mem: 157.9/477.6MB
Iteration 500/1250  mem: 158.4/477.6MB
Iteration 600/1250  mem: 154.2/477.6MB
Iteration 700/1250  mem: 151.2/477.6MB
Iteration 800/1250  mem: 147.4/477.6MB
Iteration 900/1250  mem: 142.4/477.6MB
Iteration 1000/1250  mem: 138.7/477.6MB
Iteration 1100/1250  mem: 135.4/477.6MB
Iteration 1200/1250  mem: 127/477.6MB
done building BART in 2.605 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 28 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 169.8/477.6MB
Iteration 200/1250  mem: 275.3/477.6MB
Iteration 300/1250  mem: 220.6/477.6MB
Iteration 400/1250  mem: 165.6/477.6MB
Iteration 500/1250  mem: 273/477.6MB
Iteration 600/1250  mem: 222.1/477.6MB
Iteration 700/1250  mem: 168.3/477.6MB
Iteration 800/1250  mem: 275.1/477.6MB
Iteration 900/1250  mem: 223.1/477.6MB
Iteration 1000/1250  mem: 172.6/477.6MB
Iteration 1100/1250  mem: 277.4/477.6MB
Iteration 1200/1250  mem: 225.7/477.6MB
done building BART in 1.848 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 55 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 192.7/477.6MB
Iteration 200/1250  mem: 239.2/477.6MB
Iteration 300/1250  mem: 283.6/477.6MB
Iteration 400/1250  mem: 171.4/477.6MB
Iteration 500/1250  mem: 218.5/477.6MB
Iteration 600/1250  mem: 262.9/477.6MB
Iteration 700/1250  mem: 305.6/477.6MB
Iteration 800/1250  mem: 194.2/477.6MB
Iteration 900/1250  mem: 236.2/477.6MB
Iteration 1000/1250  mem: 281.2/477.6MB
Iteration 1100/1250  mem: 326.4/477.6MB
Iteration 1200/1250  mem: 208.4/477.6MB
done building BART in 3.608 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 17 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 229/477.6MB
Iteration 200/1250  mem: 292.7/477.6MB
Iteration 300/1250  mem: 198/477.6MB
Iteration 400/1250  mem: 262.1/477.6MB
Iteration 500/1250  mem: 328.6/477.6MB
Iteration 600/1250  mem: 234.3/477.6MB
Iteration 700/1250  mem: 298.2/477.6MB
Iteration 800/1250  mem: 204.3/477.6MB
Iteration 900/1250  mem: 269.8/477.6MB
Iteration 1000/1250  mem: 332.6/477.6MB
Iteration 1100/1250  mem: 238.9/477.6MB
Iteration 1200/1250  mem: 304.3/477.6MB
done building BART in 1.077 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 37 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 338/477.6MB
Iteration 200/1250  mem: 323.9/477.6MB
Iteration 300/1250  mem: 302.7/477.6MB
Iteration 400/1250  mem: 284.2/477.6MB
Iteration 500/1250  mem: 266.2/477.6MB
Iteration 600/1250  mem: 248.5/477.6MB
Iteration 700/1250  mem: 229.4/477.6MB
Iteration 800/1250  mem: 369.3/477.6MB
Iteration 900/1250  mem: 348.1/477.6MB
Iteration 1000/1250  mem: 328.4/477.6MB
Iteration 1100/1250  mem: 309.5/477.6MB
Iteration 1200/1250  mem: 288.5/477.6MB
done building BART in 2.764 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 33 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 339.4/477.6MB
Iteration 200/1250  mem: 301.5/477.6MB
Iteration 300/1250  mem: 262.2/477.6MB
Iteration 400/1250  mem: 384.4/477.6MB
Iteration 500/1250  mem: 351.1/477.6MB
Iteration 600/1250  mem: 317.2/477.6MB
Iteration 700/1250  mem: 281.8/477.6MB
Iteration 800/1250  mem: 247.5/477.6MB
Iteration 900/1250  mem: 369.7/477.6MB
Iteration 1000/1250  mem: 331.7/477.6MB
Iteration 1100/1250  mem: 293.4/477.6MB
Iteration 1200/1250  mem: 257/477.6MB
done building BART in 2.112 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 49 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 377.4/477.6MB
Iteration 200/1250  mem: 408.5/477.6MB
Iteration 300/1250  mem: 282.7/477.6MB
Iteration 400/1250  mem: 314.4/477.6MB
Iteration 500/1250  mem: 347.1/477.6MB
Iteration 600/1250  mem: 378.1/477.6MB
Iteration 700/1250  mem: 408.8/477.6MB
Iteration 800/1250  mem: 281.3/477.6MB
Iteration 900/1250  mem: 311.4/477.6MB
Iteration 1000/1250  mem: 341/477.6MB
Iteration 1100/1250  mem: 368.8/477.6MB
Iteration 1200/1250  mem: 395.9/477.6MB
done building BART in 3.259 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 42 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 352.5/477.6MB
Iteration 200/1250  mem: 348.1/477.6MB
Iteration 300/1250  mem: 346.9/477.6MB
Iteration 400/1250  mem: 343.4/477.6MB
Iteration 500/1250  mem: 340.5/477.6MB
Iteration 600/1250  mem: 340.2/477.6MB
Iteration 700/1250  mem: 336.2/477.6MB
Iteration 800/1250  mem: 336.1/477.6MB
Iteration 900/1250  mem: 332.2/477.6MB
Iteration 1000/1250  mem: 332.8/477.6MB
Iteration 1100/1250  mem: 328.8/477.6MB
Iteration 1200/1250  mem: 73/477.6MB
done building BART in 2.739 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 75 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 146.7/477.6MB
Iteration 200/1250  mem: 125.7/477.6MB
Iteration 300/1250  mem: 106.1/477.6MB
Iteration 400/1250  mem: 95.5/477.6MB
Iteration 500/1250  mem: 236/477.6MB
Iteration 600/1250  mem: 231.5/477.6MB
Iteration 700/1250  mem: 239/477.6MB
Iteration 800/1250  mem: 260.6/477.6MB
Iteration 900/1250  mem: 279.2/477.6MB
Iteration 1000/1250  mem: 302.9/477.6MB
Iteration 1100/1250  mem: 325.7/477.6MB
Iteration 1200/1250  mem: 356.3/477.6MB
done building BART in 5.067 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
bartMachine initializing with 43 trees...
bartMachine vars checked...
bartMachine java init...
bartMachine factors created...
bartMachine before preprocess...
bartMachine after preprocess... 10 total features...
bartMachine sigsq estimated...
bartMachine training data finalized...
Now building bartMachine for regression ...
building BART with mem-cache speedup...
Iteration 100/1250  mem: 360.8/477.6MB
Iteration 200/1250  mem: 316.7/477.6MB
Iteration 300/1250  mem: 275.1/477.6MB
Iteration 400/1250  mem: 376.5/477.6MB
Iteration 500/1250  mem: 332.6/477.6MB
Iteration 600/1250  mem: 291/477.6MB
Iteration 700/1250  mem: 389/477.6MB
Iteration 800/1250  mem: 345.3/477.6MB
Iteration 900/1250  mem: 297.4/477.6MB
Iteration 1000/1250  mem: 391.6/477.6MB
Iteration 1100/1250  mem: 334.4/477.6MB
Iteration 1200/1250  mem: 275.4/477.6MB
done building BART in 4.188 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
Bayesian Additive Regression Trees 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  num_trees  k           alpha      beta        nu         RMSE    
  17         2.40083330  0.9287155  2.07163042  4.7643923  1.019030
  22         4.27274019  0.9224040  0.19583016  1.8138996  1.014691
  25         3.38995446  0.9401105  0.41106392  4.9618232  1.035563
  28         1.03604507  0.9688775  2.80028352  1.3856456  1.045001
  33         0.79498925  0.9480409  1.66214549  1.1809895  1.061140
  37         2.39875419  0.9706212  2.22184399  3.2918350  1.030959
  41         0.57739423  0.9129545  1.02819118  2.6652209  1.090840
  42         0.47638340  0.9136653  0.56354691  0.7502737  1.105883
  42         4.03581565  0.9898314  1.87609682  1.9122832  1.020934
  43         4.79059794  0.9550628  3.76290458  2.6340096  1.014428
  49         3.05219126  0.9194683  0.07359576  4.5027765  1.014656
  55         1.41447769  0.9933291  1.44180695  1.0478903  1.070904
  55         2.07604857  0.9028808  1.72781054  2.5661746  1.042271
  75         3.58137453  0.9558056  0.40959177  2.4174844  1.034070
  80         4.02155248  0.9102871  1.67167578  3.9976475  1.022569
  82         2.19196026  0.9339788  3.10473226  3.8559768  1.038241
  85         0.04482497  0.9959611  1.81058222  2.6613747  1.161728
  85         2.20754502  0.9789292  2.58506405  4.9748026  1.040828
  86         3.17155509  0.9432901  0.44838066  4.4539393  1.045656
  98         4.41891511  0.9479949  1.42778830  2.8156117  1.020763
  Rsquared     MAE        Selected
  0.007996824  0.8114062          
  0.003889015  0.8050616          
  0.006949284  0.8229288          
  0.011165868  0.8281834          
  0.014683840  0.8405297          
  0.008533459  0.8177812          
  0.016536332  0.8612455          
  0.010646112  0.8742439          
  0.007612025  0.8115153          
  0.005687022  0.8059785  *       
  0.007121595  0.8063594          
  0.008698665  0.8519812          
  0.009798738  0.8268993          
  0.004467456  0.8221827          
  0.008237284  0.8129365          
  0.008898662  0.8239955          
  0.020171647  0.9140570          
  0.008645979  0.8267003          
  0.007469278  0.8290041          
  0.006519206  0.8105870          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were num_trees = 43, k = 4.790598, alpha
 = 0.9550628, beta = 3.762905 and nu = 2.63401.
[1] "Mon Mar 05 15:02:36 2018"
Error in investigate_var_importance(object, plot = FALSE) : 
  could not find function "investigate_var_importance"
Error : package arm is required
Error : package arm is required
Error : package arm is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 15:02:49 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "bayesglm"                
t=100, m=4
t=200, m=4
t=300, m=3
t=400, m=4
t=500, m=2
t=600, m=6
t=700, m=5
t=800, m=5
t=900, m=2
t=100, m=5
t=200, m=5
t=300, m=3
t=400, m=7
t=500, m=4
t=600, m=3
t=700, m=4
t=800, m=5
t=900, m=8
t=100, m=4
t=200, m=3
t=300, m=7
t=400, m=3
t=500, m=4
t=600, m=4
t=700, m=4
t=800, m=4
t=900, m=6
t=100, m=8
t=200, m=4
t=300, m=5
t=400, m=1
t=500, m=1
t=600, m=5
t=700, m=3
t=800, m=4
t=900, m=3
The Bayesian lasso 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  sparsity    RMSE       Rsquared      MAE        Selected
  0.08509428  0.9968134  0.0025180220  0.7920714          
  0.14056540  0.9968134  0.0025180220  0.7920714          
  0.16908356  0.9968134  0.0025180220  0.7920714          
  0.20472461  0.9968134  0.0025180220  0.7920714          
  0.25284510  0.9968134  0.0025180220  0.7920714          
  0.30001649  0.9968134  0.0025180220  0.7920714          
  0.35048447  0.9968134  0.0025180220  0.7920714          
  0.35304203  0.9968134  0.0025180220  0.7920714          
  0.35682166  0.9968134  0.0025180220  0.7920714          
  0.36504880  0.9968134  0.0025180220  0.7920714          
  0.43719640  0.9968134  0.0025180220  0.7920714  *       
  0.50026452  0.9969504  0.0001831247  0.7921721          
  0.50198995  0.9969512  0.0001862566  0.7921497          
  0.71699918  0.9968233           NaN  0.7920080          
  0.77909068  0.9968233           NaN  0.7920080          
  0.79994739  0.9968233           NaN  0.7920080          
  0.82582888  0.9968233           NaN  0.7920080          
  0.82702510  0.9968233           NaN  0.7920080          
  0.84267825  0.9968233           NaN  0.7920080          
  0.96740112  0.9968233           NaN  0.7920080          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was sparsity = 0.4371964.
[1] "Mon Mar 05 15:03:12 2018"
t=100, m=4
t=200, m=5
t=300, m=2
t=400, m=5
t=500, m=5
t=600, m=5
t=700, m=4
t=800, m=6
t=900, m=1
t=100, m=6
t=200, m=4
t=300, m=5
t=400, m=2
t=500, m=4
t=600, m=4
t=700, m=5
t=800, m=3
t=900, m=4
t=100, m=4
t=200, m=5
t=300, m=3
t=400, m=6
t=500, m=5
t=600, m=3
t=700, m=3
t=800, m=3
t=900, m=3
t=100, m=4
t=200, m=5
t=300, m=5
t=400, m=4
t=500, m=3
t=600, m=5
t=700, m=5
t=800, m=3
t=900, m=3
Bayesian Ridge Regression (Model Averaged) 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE       Rsquared     MAE      
  0.9967031  0.003428988  0.7921402

[1] "Mon Mar 05 15:03:34 2018"
t=100, m=3
t=200, m=6
t=300, m=3
t=400, m=3
t=500, m=5
t=600, m=4
t=700, m=6
t=800, m=4
t=900, m=1
t=100, m=5
t=200, m=2
t=300, m=3
t=400, m=4
t=500, m=8
t=600, m=3
t=700, m=3
t=800, m=3
t=900, m=3
t=100, m=3
t=200, m=6
t=300, m=5
t=400, m=5
t=500, m=4
t=600, m=3
t=700, m=5
t=800, m=6
t=900, m=5
t=100, m=7
t=200, m=4
t=300, m=2
t=400, m=3
t=500, m=3
t=600, m=3
t=700, m=4
t=800, m=6
t=900, m=8
Bayesian Ridge Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE       Rsquared     MAE      
  0.9968736  0.001822046  0.7920613

[1] "Mon Mar 05 15:03:57 2018"
Boosted Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  nu           mstop  RMSE       Rsquared     MAE        Selected
  0.006370032  413    0.9979529  0.001014629  0.7936996  *       
  0.058070731  177    1.0008913  0.002330480  0.7960122          
  0.070171829  175    1.0011313  0.002457940  0.7961992          
  0.096239712  127    1.0011314  0.002452905  0.7962209          
  0.125118199  103    1.0012088  0.002511802  0.7962448          
  0.170454428  251    1.0018562  0.002767831  0.7967654          
  0.249710618  250    1.0018695  0.002770547  0.7967794          
  0.263596839  400    1.0018704  0.002770806  0.7967804          
  0.265463894  413    1.0018704  0.002770806  0.7967804          
  0.288370751  150    1.0018609  0.002768105  0.7967709          
  0.288619829   43    1.0012789  0.002515109  0.7962775          
  0.366652513  219    1.0018703  0.002770797  0.7967803          
  0.380952300  421    1.0018704  0.002770806  0.7967804          
  0.407116544   85    1.0018519  0.002767581  0.7967597          
  0.430048669  358    1.0018704  0.002770806  0.7967804          
  0.482781987  389    1.0018704  0.002770806  0.7967804          
  0.484490715  179    1.0018704  0.002770805  0.7967804          
  0.512874275   71    1.0018615  0.002767689  0.7967701          
  0.530386031  483    1.0018704  0.002770806  0.7967804          
  0.574913633  183    1.0018704  0.002770806  0.7967804          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mstop = 413 and nu = 0.006370032.
[1] "Mon Mar 05 15:05:33 2018"
Conditional Inference Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  mtry  RMSE       Rsquared     MAE        Selected
  1     0.9970771  0.002518244  0.7925505  *       
  2     0.9974340  0.003964963  0.7931162          
  3     0.9978358  0.004122110  0.7936876          
  4     0.9982213  0.002818420  0.7942225          
  5     0.9986156  0.003113492  0.7947788          
  7     0.9994150  0.003141399  0.7956947          
  8     0.9997917  0.005252023  0.7963142          
  9     0.9998437  0.002645595  0.7961715          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 1.
[1] "Mon Mar 05 15:07:10 2018"
Error in varimp(object, ...) : could not find function "varimp"
In addition: Warning message:
In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Conditional Inference Tree 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  mincriterion  RMSE       Rsquared     MAE        Selected
  0.08509428    1.0636991  0.001699632  0.8415561          
  0.14056540    1.0636991  0.001699632  0.8415561          
  0.16908356    1.0317878  0.002405108  0.8191021          
  0.20472461    1.0317878  0.002405108  0.8191021          
  0.25284510    1.0260595  0.002244603  0.8155089          
  0.30001649    1.0243795  0.002403723  0.8152681          
  0.35048447    1.0243795  0.002403723  0.8152681          
  0.35304203    1.0243795  0.002403723  0.8152681          
  0.35682166    1.0243795  0.002403723  0.8152681          
  0.36504880    1.0211569  0.002691443  0.8124274          
  0.43719640    1.0189361  0.001568518  0.8099729          
  0.50026452    1.0093214  0.003048582  0.8034980          
  0.50198995    1.0093214  0.003048582  0.8034980          
  0.71699918    0.9968173          NaN  0.7920966          
  0.77909068    0.9968173          NaN  0.7920966          
  0.79994739    0.9968173          NaN  0.7920966          
  0.82582888    0.9968173          NaN  0.7920966          
  0.82702510    0.9968173          NaN  0.7920966          
  0.84267825    0.9968173          NaN  0.7920966          
  0.96740112    0.9968173          NaN  0.7920966  *       

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mincriterion = 0.9674011.
[1] "Mon Mar 05 15:07:26 2018"
Conditional Inference Tree 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  maxdepth  mincriterion  RMSE       Rsquared     MAE        Selected
   2        0.480166660   1.0116325  0.002901335  0.8058735          
   3        0.677990891   0.9968173          NaN  0.7920966  *       
   3        0.854548038   0.9968173          NaN  0.7920966          
   4        0.158997850   1.0271541  0.006493720  0.8144096          
   4        0.207209013   1.0271541  0.006493720  0.8144096          
   5        0.479750837   1.0093214  0.003048582  0.8034980          
   6        0.095276680   1.0607513  0.002357792  0.8367139          
   6        0.115478847   1.0607513  0.002357792  0.8367139          
   6        0.807163131   0.9968173          NaN  0.7920966          
   6        0.958119588   0.9968173          NaN  0.7920966          
   7        0.610438253   1.0046564  0.004407546  0.7986407          
   8        0.282895539   1.0243795  0.002403723  0.8152681          
   8        0.415209713   1.0189361  0.001568518  0.8099729          
  11        0.716274907   0.9968173          NaN  0.7920966          
  12        0.438392052   1.0189361  0.001568518  0.8099729          
  12        0.804310495   0.9968173          NaN  0.7920966          
  13        0.008964995   1.1329164  0.004313720  0.9040008          
  13        0.441509005   1.0189361  0.001568518  0.8099729          
  13        0.634311019   1.0025382  0.006610317  0.7983222          
  15        0.883783023   0.9968173          NaN  0.7920966          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were maxdepth = 3 and mincriterion
 = 0.6779909.
[1] "Mon Mar 05 15:07:41 2018"
Cubist 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  committees  neighbors  RMSE       Rsquared      MAE        Selected
   1          8          1.0526000  0.0015298459  0.8362040          
  10          3          1.1203233  0.0002819336  0.8852058          
  12          3          1.1203362  0.0002819388  0.8852236          
  16          2          1.1776365  0.0003448466  0.9356976          
  21          2          1.1776365  0.0003451805  0.9357299          
  29          5          1.0789223  0.0016902103  0.8566951          
  42          5          1.0789042  0.0016899302  0.8566522          
  44          7          1.0564591  0.0013148463  0.8403340          
  45          8          1.0526000  0.0015298459  0.8362040          
  48          3          1.1203855  0.0002819587  0.8852902          
  49          0          0.9989256  0.0011474859  0.7925594  *       
  62          4          1.0970191  0.0013918737  0.8671364          
  64          8          1.0525891  0.0015294058  0.8361766          
  68          1          1.3365175  0.0010591279  1.0634039          
  72          7          1.0564652  0.0013151043  0.8403508          
  81          3          1.1204023  0.0002819654  0.8853124          
  81          7          1.0564749  0.0013155103  0.8403772          
  86          1          1.3365150  0.0010592776  1.0634025          
  89          9          1.0510872  0.0020096993  0.8345060          
  96          3          1.1203939  0.0002819620  0.8853013          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were committees = 49 and neighbors = 0.
[1] "Mon Mar 05 15:10:11 2018"
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
begin to train sae ......
training layer 1 autoencoder ...
training layer 2 autoencoder ...
training layer 3 autoencoder ...
sae has been trained.
begin to train deep nn ......
deep nn has been trained.
Stacked AutoEncoder Deep Neural Network 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  layer1  layer2  layer3  hidden_dropout  visible_dropout  RMSE      
   3      11       7      0.36253532      0.6670149          1.034683
   4      18       6      0.03427028      0.2539459          1.591843
   5       5      15      0.49004962      0.1939904          1.359330
   5      14       9      0.07193619      0.6946553          1.077966
   6       5      11      0.29087546      0.1653385          1.186241
   7      11      15      0.38882270      0.4608569          1.225147
   8       3       4      0.09862071      0.1050383          1.073837
   8       4       4      0.17993346      0.3731309          1.244540
   8      17      19      0.32831694      0.2677197          1.357279
   8      20      12      0.65850830      0.3687613          1.053986
  10      13       5      0.01287926      0.6303887          1.028575
  11       7      19      0.25231622      0.1467046          1.814509
  11       9       2      0.30236684      0.3592644          1.141346
  15      15      12      0.07167856      0.3384478          1.162403
  16      17       3      0.29254326      0.5596707          1.043775
  17       2      20      0.31685189      0.3725925        616.153593
  17      10       8      0.54332815      0.5398368          1.211636
  17      10      16      0.45238621      0.6964724          3.353820
  18      14      10      0.07846662      0.6235515          1.013972
  20      18      11      0.24986295      0.3941856          1.163811
  Rsquared      MAE          Selected
  0.0025311648    0.8202085          
  0.0025591997    1.3714415          
  0.0117191942    1.1495942          
  0.0067844931    0.8629893          
  0.0088675475    0.9690000          
  0.0059244506    1.0081851          
  0.0025257735    0.8523091          
  0.0026090191    1.0273604          
  0.0028883857    1.1103866          
  0.0016760461    0.8399158          
  0.0028353030    0.8171095          
  0.0019456957    1.6288687          
  0.0033755689    0.9120363          
  0.0008243016    0.9463414          
  0.0021374197    0.8392857          
  0.0100428000  616.0165887          
  0.0021639004    0.9848372          
  0.0037630692    3.1813987          
  0.0028892746    0.8044697  *       
  0.0044588331    0.9319628          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were layer1 = 18, layer2 = 14, layer3 =
 10, hidden_dropout = 0.07846662 and visible_dropout = 0.6235515.
[1] "Mon Mar 05 15:10:31 2018"
Multivariate Adaptive Regression Spline 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  degree  nprune  RMSE      Rsquared      MAE        Selected
  1        3      1.011617  0.0029491808  0.8078478          
  1        4      1.017035  0.0019953471  0.8125337          
  1        5      1.022486  0.0023361664  0.8141683          
  1        6      1.024766  0.0019853638  0.8181891          
  1        8      1.028503  0.0029936083  0.8212403          
  1       12      1.028503  0.0029936083  0.8212403          
  2        3      1.008794  0.0005514091  0.7993692  *       
  2        4      1.008794  0.0005514091  0.7993692          
  2        6      1.008794  0.0005514091  0.7993692          
  2        7      1.018296  0.0003701211  0.8093697          
  2       11      1.018599  0.0009731879  0.8077109          
  2       12      1.018599  0.0009731879  0.8077109          
  2       14      1.018599  0.0009731879  0.8077109          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nprune = 3 and degree = 2.
[1] "Mon Mar 05 15:10:48 2018"
Extreme Learning Machine 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  nhid  actfun   RMSE       Rsquared     MAE        Selected
   2    radbas   0.9997939  0.001714287  0.7957733          
   3    tansig   0.9980367  0.011751148  0.7943171  *       
   4    purelin  0.9999907  0.001104450  0.7980013          
   4    sin      1.0058867  0.007072406  0.8026113          
   5    sin      1.0070436  0.001950547  0.7998873          
   6    radbas   1.0024886  0.003047978  0.7958374          
   7    sin      1.0100732  0.001836857  0.7993348          
   7    tansig   1.0018557  0.002004565  0.7975278          
   9    purelin  1.0025307  0.002130957  0.7974257          
  10    radbas   1.0171553  0.003969424  0.8089132          
  14    purelin  1.0019650  0.002762589  0.7967089          
  15    tansig   1.0144102  0.000982923  0.8115998          
  16    radbas   1.0031310  0.004211199  0.7964403          
  16    sin      1.0115089  0.003128182  0.8083749          
  17    purelin  1.0019650  0.002762589  0.7967089          
  19    tansig   1.0108408  0.001218748  0.8092326          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nhid = 3 and actfun = tansig.
[1] "Mon Mar 05 15:11:01 2018"
Elasticnet 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  lambda        fraction     RMSE       Rsquared      MAE        Selected
  3.240154e-05  0.480166660  0.9982909  0.0013698529  0.7938980          
  6.972563e-05  0.854548038  1.0012597  0.0024717308  0.7961342          
  1.033954e-04  0.677990891  0.9998138  0.0018954480  0.7950496          
  1.691795e-04  0.207209013  0.9972172  0.0005674971  0.7931130          
  3.289051e-04  0.158997850  0.9970347  0.0007124527  0.7930095          
  6.311011e-04  0.479750837  0.9982884  0.0013689230  0.7938962          
  1.267380e-03  0.115478847  0.9969409  0.0006968198  0.7928937          
  1.312962e-03  0.095276680  0.9968885  0.0006514943  0.7928455          
  1.383343e-03  0.807163131  1.0009518  0.0023422917  0.7959032          
  1.549861e-03  0.958119588  1.0017764  0.0026804521  0.7965450          
  4.199314e-03  0.610438253  0.9992363  0.0017347798  0.7945988          
  1.003661e-02  0.415209713  0.9979677  0.0011032222  0.7936622          
  1.027874e-02  0.282895539  0.9975145  0.0005443842  0.7933152          
  2.004449e-01  0.716274907  1.0001958  0.0020144489  0.7953655          
  4.726548e-01  0.804310495  1.0010387  0.0023472632  0.7960115          
  6.304989e-01  0.438392052  0.9980837  0.0012653354  0.7937869          
  9.015156e-01  0.441509005  0.9981046  0.0012916187  0.7938125          
  9.165382e-01  0.008964995  0.9968282  0.0009357484  0.7922344  *       
  1.137809e+00  0.634311019  0.9995137  0.0019163301  0.7948730          
  6.373922e+00  0.883783023  1.0018250  0.0025846886  0.7965752          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were fraction = 0.008964995 and lambda
 = 0.9165382.
[1] "Mon Mar 05 15:11:16 2018"
Error : package evtree is required
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Error : package evtree is required
Error : package evtree is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 15:11:29 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "evtree"                  
Random Forest by Randomization 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  mtry  numRandomCuts  RMSE      Rsquared     MAE        Selected
  1     13             1.012142  0.012660733  0.8055166  *       
  2      6             1.017778  0.011043652  0.8059255          
  2     17             1.054448  0.012730717  0.8346804          
  2     22             1.059011  0.013806767  0.8380250          
  3      4             1.021786  0.010728125  0.8101144          
  3     12             1.043122  0.013193587  0.8261499          
  4      3             1.024609  0.008883966  0.8114007          
  4     16             1.071070  0.018482915  0.8458246          
  4     21             1.063882  0.012471107  0.8405904          
  4     24             1.070559  0.014409393  0.8435065          
  5      8             1.049000  0.009569492  0.8285075          
  5     11             1.069069  0.008210431  0.8446686          
  7     18             1.077666  0.010482725  0.8517356          
  8      1             1.020043  0.010740103  0.8102249          
  8     11             1.076128  0.006879406  0.8491397          
  8     12             1.073897  0.005212185  0.8460672          
  8     16             1.078522  0.005976897  0.8475964          
  8     21             1.089241  0.008149250  0.8566957          
  9     23             1.090626  0.005936536  0.8583907          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mtry = 1 and numRandomCuts = 13.
[1] "Mon Mar 05 15:28:16 2018"
Ridge Regression with Variable Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  lambda        k  RMSE       Rsquared      MAE        Selected
  3.240154e-05  5  1.0027088  0.0030837328  0.7963234          
  6.972563e-05  8  1.0020211  0.0027748652  0.7966845          
  1.033954e-04  7  1.0026388  0.0027615752  0.7967157          
  1.691795e-04  2  1.0004014  0.0008335877  0.7960894          
  3.289051e-04  2  1.0004002  0.0008335879  0.7960882          
  6.311011e-04  5  1.0027018  0.0030836783  0.7963176          
  1.267380e-03  2  1.0003930  0.0008335888  0.7960810          
  1.312962e-03  1  1.0005574  0.0009373926  0.7983877          
  1.383343e-03  8  1.0020064  0.0027748932  0.7966719          
  1.549861e-03  9  1.0019477  0.0027626408  0.7966942          
  4.199314e-03  6  1.0031345  0.0022764778  0.7965508          
  1.003661e-02  4  1.0014400  0.0027221461  0.7949034          
  1.027874e-02  3  1.0002704  0.0017019520  0.7958077          
  2.004449e-01  7  1.0006477  0.0023879647  0.7954733          
  4.726548e-01  8  0.9991798  0.0031052282  0.7942457          
  6.304989e-01  4  0.9987063  0.0013807132  0.7931777          
  9.015156e-01  4  0.9979026  0.0013106484  0.7927783          
  9.165382e-01  1  0.9979349  0.0009373926  0.7947330          
  1.137809e+00  6  0.9976515  0.0005106956  0.7930514  *       
  6.373922e+00  8  1.0151676  0.0003965372  0.7940523          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were k = 6 and lambda = 1.137809.
[1] "Mon Mar 05 15:28:30 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :4     NA's   :4     NA's   :4    
Error : Stopping
In addition: There were 47 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :4     NA's   :4     NA's   :4    
Error : Stopping
In addition: There were 13 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :2     NA's   :2     NA's   :2    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 15:28:50 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "gam"                     
Boosted Generalized Additive Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  mstop  prune  RMSE      Rsquared     MAE        Selected
   86    yes    1.000555  0.003004011  0.7956468  *       
  141    no     1.015884  0.003733213  0.8094414          
  170    no     1.018288  0.004131394  0.8110393          
  205    yes    1.000555  0.003004011  0.7956468          
  253    yes    1.000555  0.003004011  0.7956468          
  301    yes    1.000555  0.003004011  0.7956468          
  351    yes    1.000555  0.003004011  0.7956468          
  354    yes    1.000555  0.003004011  0.7956468          
  357    no     1.029533  0.006162296  0.8195055          
  366    no     1.030041  0.006241937  0.8198950          
  438    no     1.033255  0.006641078  0.8224920          
  501    yes    1.000555  0.003004011  0.7956468          
  502    yes    1.000555  0.003004011  0.7956468          
  717    no     1.042389  0.007406050  0.8301030          
  780    no     1.043887  0.007532877  0.8313879          
  800    yes    1.000555  0.003004011  0.7956468          
  826    yes    1.000555  0.003004011  0.7956468          
  828    yes    1.000555  0.003004011  0.7956468          
  843    no     1.045313  0.007675360  0.8326008          
  968    no     1.047704  0.007816847  0.8345977          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mstop = 86 and prune = yes.
[1] "Mon Mar 05 15:44:46 2018"
Generalized Additive Model using Splines 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  df         RMSE      Rsquared     MAE        Selected
  0.4254714  1.001965  0.002762563  0.7967090  *       
  0.7028270  1.001965  0.002762563  0.7967090          
  0.8454178  1.001965  0.002762563  0.7967090          
  1.0236231  1.002020  0.002826330  0.7967616          
  1.2642255  1.003001  0.003120947  0.7979164          
  1.5000825  1.004605  0.003027751  0.7993849          
  1.7524223  1.006848  0.002879121  0.8013337          
  1.7652101  1.006975  0.002871979  0.8014394          
  1.7841083  1.007160  0.002864619  0.8015923          
  1.8252440  1.007570  0.002851475  0.8019277          
  2.1859820  1.011452  0.002871827  0.8049034          
  2.5013226  1.015081  0.003120007  0.8076841          
  2.5099497  1.015183  0.003130015  0.8077695          
  3.5849959  1.027874  0.005192379  0.8182208          
  3.8954534  1.031501  0.005906070  0.8211774          
  3.9997369  1.032708  0.006138579  0.8221844          
  4.1291444  1.034196  0.006417111  0.8234405          
  4.1351255  1.034264  0.006429794  0.8234974          
  4.2133912  1.035155  0.006592323  0.8242469          
  4.8370056  1.042132  0.007730993  0.8298658          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was df = 0.4254714.
[1] "Mon Mar 05 15:45:14 2018"
Error in .local(object, ...) : test vector does not match model !
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 15:46:15 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "gaussprLinear"           
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 15:53:45 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "gaussprPoly"             
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 15:55:39 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "gaussprRadial"           
Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0223             nan     0.0183   -0.0007
     2        1.0200             nan     0.0183   -0.0002
     3        1.0181             nan     0.0183    0.0002
     4        1.0158             nan     0.0183    0.0000
     5        1.0140             nan     0.0183   -0.0010
     6        1.0119             nan     0.0183   -0.0008
     7        1.0094             nan     0.0183   -0.0000
     8        1.0070             nan     0.0183    0.0003
     9        1.0035             nan     0.0183    0.0002
    10        1.0017             nan     0.0183   -0.0005
    20        0.9813             nan     0.0183    0.0001
    40        0.9469             nan     0.0183   -0.0003
    60        0.9122             nan     0.0183    0.0000
    80        0.8794             nan     0.0183    0.0001
   100        0.8516             nan     0.0183   -0.0011
   120        0.8257             nan     0.0183   -0.0009
   140        0.8020             nan     0.0183   -0.0013
   160        0.7778             nan     0.0183   -0.0009
   180        0.7571             nan     0.0183   -0.0009
   200        0.7354             nan     0.0183   -0.0002
   220        0.7161             nan     0.0183   -0.0011
   240        0.6953             nan     0.0183   -0.0004
   260        0.6762             nan     0.0183   -0.0006
   280        0.6584             nan     0.0183   -0.0004
   300        0.6417             nan     0.0183   -0.0005
   320        0.6252             nan     0.0183   -0.0011
   340        0.6111             nan     0.0183   -0.0018
   360        0.5955             nan     0.0183   -0.0007
   380        0.5820             nan     0.0183   -0.0010
   400        0.5693             nan     0.0183   -0.0013
   420        0.5553             nan     0.0183   -0.0017
   440        0.5432             nan     0.0183   -0.0009
   460        0.5312             nan     0.0183   -0.0002
   480        0.5193             nan     0.0183   -0.0006
   500        0.5076             nan     0.0183   -0.0010
   520        0.4963             nan     0.0183   -0.0014
   540        0.4855             nan     0.0183   -0.0013
   560        0.4752             nan     0.0183   -0.0008
   580        0.4640             nan     0.0183   -0.0007
   600        0.4540             nan     0.0183   -0.0005
   620        0.4451             nan     0.0183   -0.0008
   640        0.4348             nan     0.0183   -0.0010
   660        0.4255             nan     0.0183   -0.0008
   680        0.4170             nan     0.0183   -0.0012
   700        0.4085             nan     0.0183   -0.0003
   720        0.4006             nan     0.0183   -0.0005
   740        0.3925             nan     0.0183   -0.0006
   760        0.3838             nan     0.0183   -0.0004
   780        0.3765             nan     0.0183   -0.0012
   800        0.3690             nan     0.0183   -0.0004
   820        0.3614             nan     0.0183   -0.0009
   840        0.3532             nan     0.0183   -0.0004
   860        0.3455             nan     0.0183   -0.0007
   880        0.3389             nan     0.0183   -0.0005
   900        0.3322             nan     0.0183   -0.0008
   920        0.3265             nan     0.0183   -0.0005
   940        0.3204             nan     0.0183   -0.0006
   960        0.3151             nan     0.0183   -0.0006
   980        0.3096             nan     0.0183   -0.0007
  1000        0.3033             nan     0.0183   -0.0006
  1020        0.2976             nan     0.0183   -0.0006
  1040        0.2919             nan     0.0183   -0.0001
  1060        0.2864             nan     0.0183   -0.0006
  1080        0.2812             nan     0.0183   -0.0006
  1100        0.2765             nan     0.0183   -0.0005
  1120        0.2710             nan     0.0183   -0.0005
  1140        0.2669             nan     0.0183   -0.0006
  1160        0.2624             nan     0.0183   -0.0003
  1180        0.2574             nan     0.0183   -0.0003
  1200        0.2530             nan     0.0183   -0.0007
  1220        0.2482             nan     0.0183   -0.0007
  1240        0.2439             nan     0.0183   -0.0002
  1260        0.2394             nan     0.0183   -0.0004
  1280        0.2352             nan     0.0183   -0.0006
  1300        0.2313             nan     0.0183   -0.0007
  1320        0.2276             nan     0.0183   -0.0004
  1340        0.2236             nan     0.0183   -0.0004
  1360        0.2193             nan     0.0183   -0.0003
  1380        0.2154             nan     0.0183   -0.0005
  1400        0.2116             nan     0.0183   -0.0006
  1420        0.2079             nan     0.0183   -0.0003
  1440        0.2042             nan     0.0183   -0.0003
  1460        0.2007             nan     0.0183   -0.0004
  1480        0.1973             nan     0.0183   -0.0003
  1500        0.1942             nan     0.0183   -0.0005
  1520        0.1914             nan     0.0183   -0.0005
  1540        0.1879             nan     0.0183   -0.0002
  1560        0.1848             nan     0.0183   -0.0003
  1580        0.1818             nan     0.0183   -0.0004
  1600        0.1791             nan     0.0183   -0.0006
  1620        0.1761             nan     0.0183   -0.0003
  1640        0.1729             nan     0.0183   -0.0005
  1660        0.1703             nan     0.0183   -0.0003
  1680        0.1676             nan     0.0183   -0.0003
  1700        0.1651             nan     0.0183   -0.0002
  1720        0.1624             nan     0.0183   -0.0004
  1740        0.1596             nan     0.0183   -0.0003
  1760        0.1571             nan     0.0183   -0.0006
  1780        0.1542             nan     0.0183   -0.0002
  1800        0.1516             nan     0.0183   -0.0003
  1820        0.1491             nan     0.0183   -0.0003
  1840        0.1467             nan     0.0183   -0.0002
  1860        0.1443             nan     0.0183   -0.0004
  1880        0.1420             nan     0.0183   -0.0002
  1900        0.1397             nan     0.0183   -0.0004
  1920        0.1375             nan     0.0183   -0.0003
  1940        0.1355             nan     0.0183   -0.0003
  1960        0.1333             nan     0.0183   -0.0003
  1980        0.1312             nan     0.0183   -0.0002
  2000        0.1287             nan     0.0183   -0.0001
  2020        0.1269             nan     0.0183   -0.0003
  2040        0.1250             nan     0.0183   -0.0002
  2060        0.1233             nan     0.0183   -0.0003
  2080        0.1211             nan     0.0183   -0.0003
  2100        0.1190             nan     0.0183   -0.0001
  2120        0.1174             nan     0.0183   -0.0003
  2140        0.1154             nan     0.0183   -0.0002
  2160        0.1136             nan     0.0183   -0.0004
  2180        0.1118             nan     0.0183   -0.0001
  2200        0.1100             nan     0.0183   -0.0002
  2220        0.1083             nan     0.0183   -0.0002
  2240        0.1065             nan     0.0183   -0.0002
  2260        0.1051             nan     0.0183   -0.0002
  2280        0.1033             nan     0.0183   -0.0003
  2300        0.1017             nan     0.0183   -0.0001
  2320        0.1001             nan     0.0183   -0.0003
  2340        0.0985             nan     0.0183   -0.0002
  2360        0.0968             nan     0.0183   -0.0003
  2380        0.0954             nan     0.0183   -0.0002
  2400        0.0937             nan     0.0183   -0.0002
  2420        0.0922             nan     0.0183   -0.0002
  2440        0.0907             nan     0.0183   -0.0002
  2460        0.0892             nan     0.0183   -0.0003
  2480        0.0880             nan     0.0183   -0.0002
  2500        0.0865             nan     0.0183   -0.0001
  2501        0.0865             nan     0.0183   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0104             nan     0.0626    0.0015
     2        0.9963             nan     0.0626   -0.0015
     3        0.9811             nan     0.0626    0.0004
     4        0.9720             nan     0.0626   -0.0042
     5        0.9611             nan     0.0626    0.0013
     6        0.9521             nan     0.0626   -0.0072
     7        0.9371             nan     0.0626    0.0069
     8        0.9251             nan     0.0626   -0.0014
     9        0.9149             nan     0.0626    0.0002
    10        0.9013             nan     0.0626   -0.0011
    20        0.8147             nan     0.0626   -0.0048
    40        0.6792             nan     0.0626   -0.0036
    60        0.5738             nan     0.0626   -0.0025
    80        0.4933             nan     0.0626   -0.0056
   100        0.4274             nan     0.0626   -0.0039
   120        0.3721             nan     0.0626   -0.0045
   140        0.3196             nan     0.0626   -0.0038
   160        0.2852             nan     0.0626   -0.0012
   180        0.2510             nan     0.0626   -0.0027
   200        0.2217             nan     0.0626   -0.0008
   220        0.1947             nan     0.0626   -0.0020
   240        0.1714             nan     0.0626   -0.0019
   260        0.1523             nan     0.0626   -0.0013
   280        0.1347             nan     0.0626   -0.0016
   300        0.1200             nan     0.0626   -0.0011
   320        0.1066             nan     0.0626   -0.0002
   340        0.0962             nan     0.0626   -0.0008
   360        0.0857             nan     0.0626   -0.0006
   380        0.0763             nan     0.0626   -0.0006
   400        0.0679             nan     0.0626   -0.0004
   420        0.0610             nan     0.0626   -0.0005
   440        0.0550             nan     0.0626   -0.0006
   460        0.0494             nan     0.0626   -0.0007
   480        0.0442             nan     0.0626   -0.0004
   500        0.0397             nan     0.0626   -0.0003
   520        0.0358             nan     0.0626   -0.0004
   540        0.0321             nan     0.0626   -0.0002
   560        0.0290             nan     0.0626   -0.0002
   580        0.0264             nan     0.0626   -0.0002
   600        0.0239             nan     0.0626   -0.0003
   620        0.0215             nan     0.0626   -0.0002
   640        0.0195             nan     0.0626   -0.0002
   660        0.0178             nan     0.0626   -0.0002
   680        0.0161             nan     0.0626   -0.0001
   700        0.0147             nan     0.0626   -0.0001
   720        0.0133             nan     0.0626   -0.0002
   740        0.0120             nan     0.0626   -0.0002
   760        0.0108             nan     0.0626   -0.0001
   780        0.0100             nan     0.0626   -0.0001
   800        0.0089             nan     0.0626   -0.0001
   820        0.0080             nan     0.0626   -0.0001
   840        0.0073             nan     0.0626   -0.0001
   860        0.0066             nan     0.0626   -0.0001
   880        0.0059             nan     0.0626   -0.0000
   900        0.0054             nan     0.0626   -0.0001
   920        0.0049             nan     0.0626   -0.0001
   940        0.0044             nan     0.0626   -0.0000
   960        0.0040             nan     0.0626   -0.0000
   980        0.0037             nan     0.0626   -0.0000
  1000        0.0033             nan     0.0626   -0.0000
  1020        0.0030             nan     0.0626   -0.0000
  1040        0.0027             nan     0.0626   -0.0000
  1060        0.0024             nan     0.0626   -0.0000
  1080        0.0022             nan     0.0626   -0.0000
  1100        0.0020             nan     0.0626   -0.0000
  1120        0.0019             nan     0.0626   -0.0000
  1140        0.0017             nan     0.0626   -0.0000
  1160        0.0015             nan     0.0626   -0.0000
  1180        0.0014             nan     0.0626   -0.0000
  1200        0.0013             nan     0.0626   -0.0000
  1220        0.0012             nan     0.0626   -0.0000
  1240        0.0011             nan     0.0626   -0.0000
  1260        0.0010             nan     0.0626   -0.0000
  1280        0.0009             nan     0.0626   -0.0000
  1300        0.0008             nan     0.0626   -0.0000
  1320        0.0007             nan     0.0626   -0.0000
  1340        0.0007             nan     0.0626   -0.0000
  1360        0.0006             nan     0.0626   -0.0000
  1380        0.0005             nan     0.0626   -0.0000
  1400        0.0005             nan     0.0626   -0.0000
  1420        0.0005             nan     0.0626   -0.0000
  1440        0.0004             nan     0.0626   -0.0000
  1460        0.0004             nan     0.0626   -0.0000
  1480        0.0003             nan     0.0626   -0.0000
  1500        0.0003             nan     0.0626   -0.0000
  1520        0.0003             nan     0.0626   -0.0000
  1540        0.0003             nan     0.0626   -0.0000
  1560        0.0002             nan     0.0626   -0.0000
  1580        0.0002             nan     0.0626   -0.0000
  1600        0.0002             nan     0.0626   -0.0000
  1620        0.0002             nan     0.0626   -0.0000
  1640        0.0002             nan     0.0626   -0.0000
  1660        0.0002             nan     0.0626   -0.0000
  1680        0.0001             nan     0.0626   -0.0000
  1700        0.0001             nan     0.0626   -0.0000
  1720        0.0001             nan     0.0626   -0.0000
  1740        0.0001             nan     0.0626   -0.0000
  1760        0.0001             nan     0.0626   -0.0000
  1780        0.0001             nan     0.0626   -0.0000
  1800        0.0001             nan     0.0626   -0.0000
  1820        0.0001             nan     0.0626   -0.0000
  1840        0.0001             nan     0.0626   -0.0000
  1860        0.0001             nan     0.0626   -0.0000
  1880        0.0001             nan     0.0626   -0.0000
  1900        0.0000             nan     0.0626   -0.0000
  1920        0.0000             nan     0.0626   -0.0000
  1940        0.0000             nan     0.0626   -0.0000
  1960        0.0000             nan     0.0626   -0.0000
  1980        0.0000             nan     0.0626   -0.0000
  2000        0.0000             nan     0.0626   -0.0000
  2020        0.0000             nan     0.0626   -0.0000
  2040        0.0000             nan     0.0626   -0.0000
  2060        0.0000             nan     0.0626   -0.0000
  2080        0.0000             nan     0.0626   -0.0000
  2100        0.0000             nan     0.0626   -0.0000
  2120        0.0000             nan     0.0626   -0.0000
  2140        0.0000             nan     0.0626   -0.0000
  2160        0.0000             nan     0.0626   -0.0000
  2180        0.0000             nan     0.0626   -0.0000
  2200        0.0000             nan     0.0626   -0.0000
  2220        0.0000             nan     0.0626   -0.0000
  2240        0.0000             nan     0.0626   -0.0000
  2260        0.0000             nan     0.0626   -0.0000
  2280        0.0000             nan     0.0626   -0.0000
  2300        0.0000             nan     0.0626   -0.0000
  2320        0.0000             nan     0.0626   -0.0000
  2340        0.0000             nan     0.0626   -0.0000
  2360        0.0000             nan     0.0626   -0.0000
  2380        0.0000             nan     0.0626   -0.0000
  2400        0.0000             nan     0.0626   -0.0000
  2420        0.0000             nan     0.0626   -0.0000
  2440        0.0000             nan     0.0626   -0.0000
  2460        0.0000             nan     0.0626   -0.0000
  2480        0.0000             nan     0.0626   -0.0000
  2500        0.0000             nan     0.0626   -0.0000
  2520        0.0000             nan     0.0626   -0.0000
  2540        0.0000             nan     0.0626   -0.0000
  2560        0.0000             nan     0.0626   -0.0000
  2580        0.0000             nan     0.0626   -0.0000
  2600        0.0000             nan     0.0626   -0.0000
  2620        0.0000             nan     0.0626   -0.0000
  2640        0.0000             nan     0.0626   -0.0000
  2660        0.0000             nan     0.0626   -0.0000
  2680        0.0000             nan     0.0626   -0.0000
  2700        0.0000             nan     0.0626   -0.0000
  2720        0.0000             nan     0.0626   -0.0000
  2740        0.0000             nan     0.0626   -0.0000
  2760        0.0000             nan     0.0626   -0.0000
  2780        0.0000             nan     0.0626   -0.0000
  2800        0.0000             nan     0.0626   -0.0000
  2820        0.0000             nan     0.0626   -0.0000
  2840        0.0000             nan     0.0626   -0.0000
  2860        0.0000             nan     0.0626   -0.0000
  2880        0.0000             nan     0.0626   -0.0000
  2900        0.0000             nan     0.0626   -0.0000
  2920        0.0000             nan     0.0626   -0.0000
  2940        0.0000             nan     0.0626   -0.0000
  2960        0.0000             nan     0.0626   -0.0000
  2980        0.0000             nan     0.0626   -0.0000
  3000        0.0000             nan     0.0626   -0.0000
  3020        0.0000             nan     0.0626   -0.0000
  3040        0.0000             nan     0.0626   -0.0000
  3060        0.0000             nan     0.0626   -0.0000
  3080        0.0000             nan     0.0626   -0.0000
  3100        0.0000             nan     0.0626   -0.0000
  3120        0.0000             nan     0.0626   -0.0000
  3140        0.0000             nan     0.0626   -0.0000
  3160        0.0000             nan     0.0626   -0.0000
  3180        0.0000             nan     0.0626   -0.0000
  3200        0.0000             nan     0.0626   -0.0000
  3220        0.0000             nan     0.0626   -0.0000
  3240        0.0000             nan     0.0626   -0.0000
  3260        0.0000             nan     0.0626   -0.0000
  3280        0.0000             nan     0.0626   -0.0000
  3300        0.0000             nan     0.0626   -0.0000
  3320        0.0000             nan     0.0626   -0.0000
  3340        0.0000             nan     0.0626   -0.0000
  3360        0.0000             nan     0.0626   -0.0000
  3380        0.0000             nan     0.0626   -0.0000
  3400        0.0000             nan     0.0626   -0.0000
  3420        0.0000             nan     0.0626   -0.0000
  3440        0.0000             nan     0.0626   -0.0000
  3460        0.0000             nan     0.0626   -0.0000
  3480        0.0000             nan     0.0626   -0.0000
  3500        0.0000             nan     0.0626   -0.0000
  3520        0.0000             nan     0.0626   -0.0000
  3540        0.0000             nan     0.0626   -0.0000
  3560        0.0000             nan     0.0626   -0.0000
  3580        0.0000             nan     0.0626   -0.0000
  3600        0.0000             nan     0.0626   -0.0000
  3620        0.0000             nan     0.0626   -0.0000
  3640        0.0000             nan     0.0626   -0.0000
  3660        0.0000             nan     0.0626   -0.0000
  3680        0.0000             nan     0.0626   -0.0000
  3700        0.0000             nan     0.0626   -0.0000
  3720        0.0000             nan     0.0626   -0.0000
  3740        0.0000             nan     0.0626   -0.0000
  3760        0.0000             nan     0.0626   -0.0000
  3780        0.0000             nan     0.0626   -0.0000
  3800        0.0000             nan     0.0626   -0.0000
  3820        0.0000             nan     0.0626   -0.0000
  3840        0.0000             nan     0.0626   -0.0000
  3860        0.0000             nan     0.0626   -0.0000
  3880        0.0000             nan     0.0626   -0.0000
  3895        0.0000             nan     0.0626   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0223             nan     0.0786   -0.0023
     2        1.0180             nan     0.0786   -0.0044
     3        1.0149             nan     0.0786   -0.0035
     4        1.0110             nan     0.0786    0.0003
     5        1.0073             nan     0.0786    0.0011
     6        1.0044             nan     0.0786   -0.0028
     7        1.0006             nan     0.0786   -0.0000
     8        0.9975             nan     0.0786   -0.0017
     9        0.9936             nan     0.0786    0.0005
    10        0.9912             nan     0.0786   -0.0039
    20        0.9588             nan     0.0786   -0.0059
    40        0.9077             nan     0.0786   -0.0034
    60        0.8675             nan     0.0786   -0.0015
    80        0.8320             nan     0.0786   -0.0049
   100        0.7979             nan     0.0786   -0.0051
   120        0.7661             nan     0.0786   -0.0038
   140        0.7418             nan     0.0786   -0.0050
   160        0.7244             nan     0.0786   -0.0025
   180        0.7012             nan     0.0786   -0.0036
   200        0.6813             nan     0.0786   -0.0038
   220        0.6632             nan     0.0786   -0.0035
   240        0.6453             nan     0.0786   -0.0013
   260        0.6269             nan     0.0786   -0.0022
   280        0.6067             nan     0.0786   -0.0015
   300        0.5874             nan     0.0786   -0.0021
   320        0.5690             nan     0.0786   -0.0013
   340        0.5560             nan     0.0786   -0.0011
   360        0.5376             nan     0.0786   -0.0024
   380        0.5265             nan     0.0786   -0.0028
   400        0.5150             nan     0.0786   -0.0025
   420        0.5043             nan     0.0786   -0.0016
   440        0.4943             nan     0.0786   -0.0028
   460        0.4817             nan     0.0786   -0.0017
   480        0.4686             nan     0.0786   -0.0017
   500        0.4554             nan     0.0786   -0.0012
   520        0.4462             nan     0.0786   -0.0027
   540        0.4341             nan     0.0786   -0.0028
   560        0.4256             nan     0.0786   -0.0023
   580        0.4177             nan     0.0786   -0.0019
   600        0.4073             nan     0.0786   -0.0021
   620        0.3972             nan     0.0786   -0.0028
   640        0.3888             nan     0.0786   -0.0015
   660        0.3799             nan     0.0786   -0.0011
   680        0.3694             nan     0.0786   -0.0014
   700        0.3611             nan     0.0786   -0.0014
   720        0.3528             nan     0.0786   -0.0013
   740        0.3437             nan     0.0786   -0.0018
   760        0.3363             nan     0.0786   -0.0012
   780        0.3286             nan     0.0786   -0.0019
   800        0.3208             nan     0.0786   -0.0016
   820        0.3127             nan     0.0786   -0.0007
   840        0.3054             nan     0.0786   -0.0016
   860        0.2987             nan     0.0786   -0.0010
   880        0.2924             nan     0.0786   -0.0006
   900        0.2863             nan     0.0786   -0.0021
   920        0.2807             nan     0.0786   -0.0016
   940        0.2754             nan     0.0786   -0.0006
   960        0.2694             nan     0.0786   -0.0017
   980        0.2638             nan     0.0786   -0.0013
  1000        0.2578             nan     0.0786   -0.0011
  1020        0.2523             nan     0.0786   -0.0014
  1040        0.2476             nan     0.0786   -0.0004
  1060        0.2422             nan     0.0786   -0.0010
  1080        0.2372             nan     0.0786   -0.0019
  1100        0.2332             nan     0.0786   -0.0009
  1120        0.2293             nan     0.0786   -0.0007
  1140        0.2259             nan     0.0786   -0.0011
  1160        0.2218             nan     0.0786   -0.0004
  1180        0.2173             nan     0.0786   -0.0009
  1200        0.2141             nan     0.0786   -0.0012
  1220        0.2099             nan     0.0786   -0.0005
  1240        0.2060             nan     0.0786   -0.0002
  1260        0.2021             nan     0.0786   -0.0005
  1280        0.1986             nan     0.0786   -0.0008
  1300        0.1944             nan     0.0786   -0.0007
  1320        0.1916             nan     0.0786   -0.0007
  1340        0.1878             nan     0.0786   -0.0009
  1360        0.1849             nan     0.0786   -0.0012
  1380        0.1813             nan     0.0786   -0.0008
  1400        0.1777             nan     0.0786   -0.0008
  1420        0.1738             nan     0.0786   -0.0009
  1440        0.1709             nan     0.0786   -0.0006
  1460        0.1681             nan     0.0786   -0.0009
  1480        0.1651             nan     0.0786   -0.0009
  1500        0.1614             nan     0.0786   -0.0009
  1520        0.1585             nan     0.0786   -0.0003
  1540        0.1558             nan     0.0786   -0.0005
  1560        0.1528             nan     0.0786   -0.0004
  1580        0.1493             nan     0.0786   -0.0005
  1600        0.1470             nan     0.0786   -0.0005
  1620        0.1449             nan     0.0786   -0.0006
  1640        0.1423             nan     0.0786   -0.0008
  1660        0.1400             nan     0.0786   -0.0004
  1680        0.1381             nan     0.0786   -0.0006
  1700        0.1359             nan     0.0786   -0.0006
  1720        0.1338             nan     0.0786   -0.0007
  1740        0.1313             nan     0.0786   -0.0008
  1753        0.1299             nan     0.0786   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0222             nan     0.0829   -0.0011
     2        1.0202             nan     0.0829   -0.0037
     3        1.0171             nan     0.0829    0.0018
     4        1.0147             nan     0.0829   -0.0024
     5        1.0145             nan     0.0829   -0.0047
     6        1.0141             nan     0.0829   -0.0039
     7        1.0136             nan     0.0829   -0.0030
     8        1.0118             nan     0.0829   -0.0010
     9        1.0086             nan     0.0829   -0.0004
    10        1.0081             nan     0.0829   -0.0034
    20        0.9876             nan     0.0829   -0.0001
    40        0.9624             nan     0.0829   -0.0016
    60        0.9468             nan     0.0829   -0.0023
    80        0.9325             nan     0.0829   -0.0006
   100        0.9223             nan     0.0829   -0.0023
   120        0.9085             nan     0.0829   -0.0023
   140        0.8940             nan     0.0829   -0.0010
   160        0.8834             nan     0.0829   -0.0021
   180        0.8731             nan     0.0829   -0.0026
   200        0.8669             nan     0.0829   -0.0029
   220        0.8575             nan     0.0829   -0.0034
   240        0.8489             nan     0.0829   -0.0026
   260        0.8396             nan     0.0829   -0.0025
   280        0.8328             nan     0.0829   -0.0054
   300        0.8236             nan     0.0829   -0.0010
   320        0.8171             nan     0.0829   -0.0013
   340        0.8102             nan     0.0829   -0.0012
   360        0.8031             nan     0.0829   -0.0037
   380        0.7967             nan     0.0829   -0.0025
   400        0.7884             nan     0.0829   -0.0018
   420        0.7829             nan     0.0829   -0.0010
   440        0.7790             nan     0.0829   -0.0019
   460        0.7705             nan     0.0829   -0.0003
   480        0.7654             nan     0.0829   -0.0028
   500        0.7596             nan     0.0829   -0.0034
   520        0.7539             nan     0.0829   -0.0038
   540        0.7496             nan     0.0829   -0.0018
   560        0.7439             nan     0.0829   -0.0019
   580        0.7386             nan     0.0829   -0.0015
   600        0.7302             nan     0.0829   -0.0030
   620        0.7262             nan     0.0829   -0.0034
   640        0.7224             nan     0.0829   -0.0028
   660        0.7176             nan     0.0829   -0.0010
   680        0.7127             nan     0.0829   -0.0027
   700        0.7091             nan     0.0829   -0.0040
   720        0.7027             nan     0.0829   -0.0018
   740        0.6988             nan     0.0829   -0.0020
   760        0.6947             nan     0.0829   -0.0041
   780        0.6917             nan     0.0829   -0.0026
   800        0.6879             nan     0.0829   -0.0037
   820        0.6817             nan     0.0829   -0.0012
   840        0.6758             nan     0.0829   -0.0021
   860        0.6724             nan     0.0829   -0.0035
   880        0.6679             nan     0.0829   -0.0020
   900        0.6632             nan     0.0829   -0.0010
   920        0.6586             nan     0.0829   -0.0006
   940        0.6562             nan     0.0829   -0.0017
   960        0.6529             nan     0.0829   -0.0016
   980        0.6473             nan     0.0829   -0.0009
  1000        0.6425             nan     0.0829   -0.0009
  1020        0.6396             nan     0.0829   -0.0019
  1040        0.6382             nan     0.0829   -0.0027
  1060        0.6342             nan     0.0829   -0.0015
  1080        0.6307             nan     0.0829   -0.0016
  1100        0.6262             nan     0.0829   -0.0019
  1120        0.6216             nan     0.0829   -0.0018
  1140        0.6180             nan     0.0829   -0.0015
  1160        0.6140             nan     0.0829   -0.0018
  1180        0.6102             nan     0.0829   -0.0008
  1200        0.6062             nan     0.0829   -0.0024
  1220        0.6031             nan     0.0829   -0.0029
  1240        0.5983             nan     0.0829   -0.0030
  1260        0.5945             nan     0.0829   -0.0012
  1280        0.5922             nan     0.0829   -0.0022
  1300        0.5880             nan     0.0829   -0.0016
  1320        0.5847             nan     0.0829   -0.0013
  1340        0.5810             nan     0.0829   -0.0008
  1360        0.5769             nan     0.0829   -0.0015
  1380        0.5731             nan     0.0829   -0.0017
  1400        0.5710             nan     0.0829   -0.0012
  1420        0.5673             nan     0.0829   -0.0029
  1440        0.5639             nan     0.0829   -0.0015
  1460        0.5616             nan     0.0829   -0.0024
  1480        0.5587             nan     0.0829   -0.0007
  1500        0.5562             nan     0.0829   -0.0018
  1520        0.5524             nan     0.0829   -0.0003
  1540        0.5499             nan     0.0829   -0.0008
  1560        0.5469             nan     0.0829   -0.0026
  1580        0.5450             nan     0.0829   -0.0013
  1600        0.5437             nan     0.0829   -0.0035
  1620        0.5427             nan     0.0829   -0.0027
  1640        0.5390             nan     0.0829   -0.0010
  1660        0.5367             nan     0.0829   -0.0029
  1680        0.5332             nan     0.0829   -0.0009
  1700        0.5311             nan     0.0829   -0.0022
  1720        0.5277             nan     0.0829   -0.0009
  1740        0.5262             nan     0.0829   -0.0011
  1760        0.5230             nan     0.0829   -0.0019
  1765        0.5222             nan     0.0829   -0.0022

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0020             nan     0.1176   -0.0043
     2        0.9764             nan     0.1176   -0.0046
     3        0.9595             nan     0.1176   -0.0051
     4        0.9454             nan     0.1176   -0.0034
     5        0.9344             nan     0.1176   -0.0212
     6        0.9204             nan     0.1176   -0.0173
     7        0.9030             nan     0.1176    0.0014
     8        0.8859             nan     0.1176   -0.0048
     9        0.8673             nan     0.1176   -0.0022
    10        0.8496             nan     0.1176   -0.0032
    20        0.7235             nan     0.1176   -0.0152
    40        0.5425             nan     0.1176   -0.0040
    60        0.4331             nan     0.1176   -0.0063
    80        0.3450             nan     0.1176   -0.0045
   100        0.2761             nan     0.1176   -0.0036
   120        0.2229             nan     0.1176   -0.0023
   140        0.1805             nan     0.1176   -0.0016
   160        0.1482             nan     0.1176   -0.0025
   180        0.1204             nan     0.1176   -0.0009
   200        0.0993             nan     0.1176   -0.0012
   220        0.0805             nan     0.1176   -0.0010
   240        0.0669             nan     0.1176   -0.0011
   260        0.0555             nan     0.1176   -0.0010
   280        0.0464             nan     0.1176   -0.0010
   300        0.0385             nan     0.1176   -0.0004
   320        0.0314             nan     0.1176   -0.0006
   340        0.0259             nan     0.1176   -0.0004
   360        0.0216             nan     0.1176   -0.0006
   380        0.0180             nan     0.1176   -0.0002
   400        0.0148             nan     0.1176   -0.0003
   420        0.0124             nan     0.1176   -0.0001
   440        0.0102             nan     0.1176   -0.0002
   460        0.0087             nan     0.1176   -0.0003
   480        0.0073             nan     0.1176   -0.0001
   500        0.0063             nan     0.1176   -0.0001
   520        0.0052             nan     0.1176   -0.0001
   540        0.0045             nan     0.1176   -0.0001
   560        0.0038             nan     0.1176   -0.0000
   580        0.0031             nan     0.1176   -0.0000
   600        0.0026             nan     0.1176   -0.0000
   620        0.0022             nan     0.1176   -0.0000
   640        0.0018             nan     0.1176   -0.0000
   660        0.0016             nan     0.1176   -0.0000
   680        0.0013             nan     0.1176   -0.0000
   700        0.0011             nan     0.1176   -0.0000
   720        0.0009             nan     0.1176   -0.0000
   740        0.0008             nan     0.1176   -0.0000
   760        0.0006             nan     0.1176   -0.0000
   780        0.0005             nan     0.1176   -0.0000
   800        0.0005             nan     0.1176   -0.0000
   820        0.0004             nan     0.1176   -0.0000
   840        0.0003             nan     0.1176   -0.0000
   860        0.0003             nan     0.1176   -0.0000
   880        0.0002             nan     0.1176   -0.0000
   900        0.0002             nan     0.1176   -0.0000
   920        0.0002             nan     0.1176   -0.0000
   940        0.0001             nan     0.1176   -0.0000
   960        0.0001             nan     0.1176   -0.0000
   980        0.0001             nan     0.1176   -0.0000
  1000        0.0001             nan     0.1176   -0.0000
  1020        0.0001             nan     0.1176   -0.0000
  1040        0.0001             nan     0.1176   -0.0000
  1060        0.0000             nan     0.1176   -0.0000
  1080        0.0000             nan     0.1176   -0.0000
  1100        0.0000             nan     0.1176   -0.0000
  1120        0.0000             nan     0.1176   -0.0000
  1140        0.0000             nan     0.1176   -0.0000
  1160        0.0000             nan     0.1176   -0.0000
  1180        0.0000             nan     0.1176   -0.0000
  1200        0.0000             nan     0.1176   -0.0000
  1220        0.0000             nan     0.1176   -0.0000
  1240        0.0000             nan     0.1176   -0.0000
  1260        0.0000             nan     0.1176   -0.0000
  1280        0.0000             nan     0.1176   -0.0000
  1300        0.0000             nan     0.1176   -0.0000
  1320        0.0000             nan     0.1176   -0.0000
  1340        0.0000             nan     0.1176   -0.0000
  1360        0.0000             nan     0.1176   -0.0000
  1380        0.0000             nan     0.1176   -0.0000
  1400        0.0000             nan     0.1176   -0.0000
  1420        0.0000             nan     0.1176   -0.0000
  1440        0.0000             nan     0.1176   -0.0000
  1460        0.0000             nan     0.1176   -0.0000
  1480        0.0000             nan     0.1176   -0.0000
  1500        0.0000             nan     0.1176   -0.0000
  1520        0.0000             nan     0.1176   -0.0000
  1540        0.0000             nan     0.1176   -0.0000
  1560        0.0000             nan     0.1176   -0.0000
  1580        0.0000             nan     0.1176   -0.0000
  1600        0.0000             nan     0.1176   -0.0000
  1620        0.0000             nan     0.1176   -0.0000
  1640        0.0000             nan     0.1176   -0.0000
  1660        0.0000             nan     0.1176   -0.0000
  1680        0.0000             nan     0.1176   -0.0000
  1700        0.0000             nan     0.1176   -0.0000
  1720        0.0000             nan     0.1176   -0.0000
  1740        0.0000             nan     0.1176   -0.0000
  1760        0.0000             nan     0.1176   -0.0000
  1780        0.0000             nan     0.1176   -0.0000
  1800        0.0000             nan     0.1176   -0.0000
  1820        0.0000             nan     0.1176   -0.0000
  1840        0.0000             nan     0.1176   -0.0000
  1860        0.0000             nan     0.1176   -0.0000
  1880        0.0000             nan     0.1176   -0.0000
  1900        0.0000             nan     0.1176   -0.0000
  1920        0.0000             nan     0.1176   -0.0000
  1940        0.0000             nan     0.1176   -0.0000
  1960        0.0000             nan     0.1176   -0.0000
  1980        0.0000             nan     0.1176   -0.0000
  2000        0.0000             nan     0.1176   -0.0000
  2020        0.0000             nan     0.1176   -0.0000
  2040        0.0000             nan     0.1176   -0.0000
  2060        0.0000             nan     0.1176   -0.0000
  2080        0.0000             nan     0.1176   -0.0000
  2100        0.0000             nan     0.1176   -0.0000
  2120        0.0000             nan     0.1176   -0.0000
  2140        0.0000             nan     0.1176   -0.0000
  2160        0.0000             nan     0.1176   -0.0000
  2180        0.0000             nan     0.1176   -0.0000
  2186        0.0000             nan     0.1176   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0034             nan     0.1352   -0.0163
     2        0.9823             nan     0.1352   -0.0244
     3        0.9522             nan     0.1352   -0.0134
     4        0.9227             nan     0.1352   -0.0025
     5        0.9079             nan     0.1352   -0.0125
     6        0.8925             nan     0.1352   -0.0222
     7        0.8660             nan     0.1352    0.0014
     8        0.8443             nan     0.1352   -0.0120
     9        0.8223             nan     0.1352   -0.0088
    10        0.8048             nan     0.1352   -0.0095
    20        0.6538             nan     0.1352   -0.0107
    40        0.4513             nan     0.1352   -0.0104
    60        0.3259             nan     0.1352   -0.0068
    80        0.2335             nan     0.1352   -0.0062
   100        0.1659             nan     0.1352   -0.0031
   120        0.1238             nan     0.1352   -0.0039
   140        0.0909             nan     0.1352   -0.0023
   160        0.0668             nan     0.1352   -0.0009
   180        0.0516             nan     0.1352   -0.0012
   200        0.0389             nan     0.1352   -0.0006
   220        0.0284             nan     0.1352   -0.0008
   240        0.0216             nan     0.1352   -0.0005
   260        0.0166             nan     0.1352   -0.0006
   280        0.0127             nan     0.1352   -0.0002
   300        0.0094             nan     0.1352   -0.0002
   320        0.0072             nan     0.1352   -0.0002
   340        0.0055             nan     0.1352   -0.0001
   360        0.0042             nan     0.1352   -0.0001
   380        0.0032             nan     0.1352   -0.0001
   400        0.0025             nan     0.1352   -0.0001
   420        0.0019             nan     0.1352   -0.0001
   440        0.0015             nan     0.1352   -0.0000
   460        0.0012             nan     0.1352   -0.0000
   480        0.0009             nan     0.1352   -0.0000
   500        0.0007             nan     0.1352   -0.0000
   520        0.0005             nan     0.1352   -0.0000
   540        0.0004             nan     0.1352   -0.0000
   560        0.0003             nan     0.1352   -0.0000
   580        0.0002             nan     0.1352   -0.0000
   600        0.0002             nan     0.1352   -0.0000
   620        0.0001             nan     0.1352   -0.0000
   640        0.0001             nan     0.1352   -0.0000
   660        0.0001             nan     0.1352   -0.0000
   680        0.0001             nan     0.1352   -0.0000
   700        0.0001             nan     0.1352   -0.0000
   703        0.0001             nan     0.1352   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0080             nan     0.1730   -0.0050
     2        0.9922             nan     0.1730   -0.0109
     3        0.9738             nan     0.1730    0.0043
     4        0.9619             nan     0.1730   -0.0118
     5        0.9397             nan     0.1730   -0.0020
     6        0.9286             nan     0.1730   -0.0127
     7        0.9122             nan     0.1730   -0.0091
     8        0.8963             nan     0.1730    0.0017
     9        0.8903             nan     0.1730   -0.0252
    10        0.8787             nan     0.1730   -0.0121
    20        0.7719             nan     0.1730   -0.0120
    40        0.6102             nan     0.1730   -0.0084
    60        0.5157             nan     0.1730   -0.0075
    80        0.4378             nan     0.1730   -0.0064
   100        0.3737             nan     0.1730   -0.0057
   120        0.3132             nan     0.1730   -0.0077
   140        0.2645             nan     0.1730   -0.0064
   160        0.2258             nan     0.1730   -0.0018
   180        0.1949             nan     0.1730   -0.0036
   200        0.1669             nan     0.1730   -0.0028
   220        0.1459             nan     0.1730   -0.0030
   240        0.1243             nan     0.1730   -0.0029
   260        0.1088             nan     0.1730   -0.0026
   280        0.0946             nan     0.1730   -0.0023
   300        0.0836             nan     0.1730   -0.0019
   320        0.0715             nan     0.1730   -0.0007
   340        0.0625             nan     0.1730   -0.0017
   360        0.0561             nan     0.1730   -0.0012
   380        0.0493             nan     0.1730   -0.0008
   400        0.0429             nan     0.1730   -0.0008
   420        0.0379             nan     0.1730   -0.0005
   426        0.0365             nan     0.1730   -0.0005

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0054             nan     0.2045   -0.0150
     2        0.9875             nan     0.2045   -0.0153
     3        0.9623             nan     0.2045   -0.0083
     4        0.9524             nan     0.2045   -0.0201
     5        0.9362             nan     0.2045   -0.0018
     6        0.9195             nan     0.2045   -0.0153
     7        0.8970             nan     0.2045   -0.0009
     8        0.8801             nan     0.2045   -0.0029
     9        0.8720             nan     0.2045   -0.0116
    10        0.8561             nan     0.2045   -0.0136
    20        0.7712             nan     0.2045   -0.0096
    40        0.6297             nan     0.2045   -0.0099
    60        0.5203             nan     0.2045   -0.0120
    80        0.4334             nan     0.2045   -0.0103
   100        0.3637             nan     0.2045   -0.0086
   120        0.3016             nan     0.2045   -0.0073
   140        0.2546             nan     0.2045   -0.0035
   160        0.2211             nan     0.2045   -0.0067
   180        0.1902             nan     0.2045   -0.0058
   200        0.1635             nan     0.2045   -0.0039
   220        0.1409             nan     0.2045   -0.0024
   240        0.1227             nan     0.2045   -0.0029
   260        0.1052             nan     0.2045   -0.0027
   280        0.0929             nan     0.2045   -0.0022
   300        0.0803             nan     0.2045   -0.0013
   320        0.0692             nan     0.2045   -0.0009
   340        0.0591             nan     0.2045   -0.0009
   360        0.0519             nan     0.2045   -0.0007
   380        0.0454             nan     0.2045   -0.0010
   400        0.0392             nan     0.2045   -0.0011
   420        0.0344             nan     0.2045   -0.0012
   440        0.0303             nan     0.2045   -0.0004
   460        0.0264             nan     0.2045   -0.0007
   480        0.0235             nan     0.2045   -0.0005
   500        0.0205             nan     0.2045   -0.0005
   520        0.0183             nan     0.2045   -0.0003
   540        0.0162             nan     0.2045   -0.0004
   560        0.0141             nan     0.2045   -0.0003
   580        0.0127             nan     0.2045   -0.0002
   600        0.0114             nan     0.2045   -0.0002
   620        0.0100             nan     0.2045   -0.0003
   640        0.0087             nan     0.2045   -0.0002
   660        0.0077             nan     0.2045   -0.0002
   680        0.0068             nan     0.2045   -0.0001
   700        0.0061             nan     0.2045   -0.0002
   720        0.0054             nan     0.2045   -0.0000
   740        0.0047             nan     0.2045   -0.0001
   760        0.0042             nan     0.2045   -0.0001
   780        0.0037             nan     0.2045   -0.0001
   800        0.0033             nan     0.2045   -0.0001
   820        0.0029             nan     0.2045   -0.0001
   840        0.0026             nan     0.2045   -0.0001
   860        0.0023             nan     0.2045   -0.0001
   880        0.0021             nan     0.2045   -0.0001
   900        0.0019             nan     0.2045   -0.0001
   920        0.0016             nan     0.2045   -0.0000
   940        0.0015             nan     0.2045   -0.0000
   960        0.0013             nan     0.2045   -0.0000
   980        0.0012             nan     0.2045   -0.0000
  1000        0.0010             nan     0.2045   -0.0000
  1020        0.0009             nan     0.2045   -0.0000
  1040        0.0008             nan     0.2045   -0.0000
  1060        0.0007             nan     0.2045   -0.0000
  1080        0.0006             nan     0.2045   -0.0000
  1100        0.0005             nan     0.2045   -0.0000
  1120        0.0005             nan     0.2045   -0.0000
  1140        0.0004             nan     0.2045   -0.0000
  1160        0.0004             nan     0.2045   -0.0000
  1180        0.0003             nan     0.2045   -0.0000
  1200        0.0003             nan     0.2045   -0.0000
  1220        0.0003             nan     0.2045   -0.0000
  1240        0.0002             nan     0.2045   -0.0000
  1260        0.0002             nan     0.2045   -0.0000
  1280        0.0002             nan     0.2045   -0.0000
  1300        0.0002             nan     0.2045   -0.0000
  1320        0.0002             nan     0.2045   -0.0000
  1340        0.0001             nan     0.2045   -0.0000
  1360        0.0001             nan     0.2045   -0.0000
  1380        0.0001             nan     0.2045   -0.0000
  1400        0.0001             nan     0.2045   -0.0000
  1420        0.0001             nan     0.2045   -0.0000
  1440        0.0001             nan     0.2045   -0.0000
  1460        0.0001             nan     0.2045   -0.0000
  1480        0.0001             nan     0.2045   -0.0000
  1500        0.0001             nan     0.2045   -0.0000
  1520        0.0000             nan     0.2045   -0.0000
  1540        0.0000             nan     0.2045   -0.0000
  1560        0.0000             nan     0.2045   -0.0000
  1580        0.0000             nan     0.2045   -0.0000
  1600        0.0000             nan     0.2045   -0.0000
  1620        0.0000             nan     0.2045   -0.0000
  1640        0.0000             nan     0.2045   -0.0000
  1660        0.0000             nan     0.2045   -0.0000
  1680        0.0000             nan     0.2045   -0.0000
  1700        0.0000             nan     0.2045   -0.0000
  1720        0.0000             nan     0.2045   -0.0000
  1740        0.0000             nan     0.2045   -0.0000
  1760        0.0000             nan     0.2045   -0.0000
  1780        0.0000             nan     0.2045   -0.0000
  1800        0.0000             nan     0.2045   -0.0000
  1820        0.0000             nan     0.2045   -0.0000
  1840        0.0000             nan     0.2045   -0.0000
  1860        0.0000             nan     0.2045   -0.0000
  1880        0.0000             nan     0.2045   -0.0000
  1900        0.0000             nan     0.2045   -0.0000
  1920        0.0000             nan     0.2045   -0.0000
  1940        0.0000             nan     0.2045   -0.0000
  1960        0.0000             nan     0.2045   -0.0000
  1980        0.0000             nan     0.2045   -0.0000
  2000        0.0000             nan     0.2045   -0.0000
  2020        0.0000             nan     0.2045   -0.0000
  2040        0.0000             nan     0.2045   -0.0000
  2060        0.0000             nan     0.2045   -0.0000
  2080        0.0000             nan     0.2045   -0.0000
  2100        0.0000             nan     0.2045   -0.0000
  2120        0.0000             nan     0.2045   -0.0000
  2140        0.0000             nan     0.2045   -0.0000
  2160        0.0000             nan     0.2045   -0.0000
  2180        0.0000             nan     0.2045   -0.0000
  2200        0.0000             nan     0.2045   -0.0000
  2220        0.0000             nan     0.2045   -0.0000
  2240        0.0000             nan     0.2045   -0.0000
  2260        0.0000             nan     0.2045   -0.0000
  2280        0.0000             nan     0.2045   -0.0000
  2300        0.0000             nan     0.2045   -0.0000
  2320        0.0000             nan     0.2045   -0.0000
  2340        0.0000             nan     0.2045   -0.0000
  2360        0.0000             nan     0.2045   -0.0000
  2380        0.0000             nan     0.2045   -0.0000
  2400        0.0000             nan     0.2045   -0.0000
  2420        0.0000             nan     0.2045   -0.0000
  2440        0.0000             nan     0.2045   -0.0000
  2460        0.0000             nan     0.2045   -0.0000
  2480        0.0000             nan     0.2045   -0.0000
  2500        0.0000             nan     0.2045   -0.0000
  2520        0.0000             nan     0.2045   -0.0000
  2540        0.0000             nan     0.2045   -0.0000
  2560        0.0000             nan     0.2045   -0.0000
  2580        0.0000             nan     0.2045   -0.0000
  2600        0.0000             nan     0.2045   -0.0000
  2620        0.0000             nan     0.2045   -0.0000
  2640        0.0000             nan     0.2045   -0.0000
  2660        0.0000             nan     0.2045   -0.0000
  2680        0.0000             nan     0.2045   -0.0000
  2700        0.0000             nan     0.2045   -0.0000
  2720        0.0000             nan     0.2045   -0.0000
  2740        0.0000             nan     0.2045   -0.0000
  2760        0.0000             nan     0.2045   -0.0000
  2780        0.0000             nan     0.2045   -0.0000
  2800        0.0000             nan     0.2045   -0.0000
  2820        0.0000             nan     0.2045   -0.0000
  2840        0.0000             nan     0.2045   -0.0000
  2860        0.0000             nan     0.2045   -0.0000
  2880        0.0000             nan     0.2045   -0.0000
  2900        0.0000             nan     0.2045   -0.0000
  2920        0.0000             nan     0.2045   -0.0000
  2940        0.0000             nan     0.2045   -0.0000
  2960        0.0000             nan     0.2045   -0.0000
  2980        0.0000             nan     0.2045   -0.0000
  3000        0.0000             nan     0.2045   -0.0000
  3020        0.0000             nan     0.2045   -0.0000
  3040        0.0000             nan     0.2045   -0.0000
  3060        0.0000             nan     0.2045   -0.0000
  3080        0.0000             nan     0.2045   -0.0000
  3100        0.0000             nan     0.2045   -0.0000
  3120        0.0000             nan     0.2045   -0.0000
  3140        0.0000             nan     0.2045   -0.0000
  3160        0.0000             nan     0.2045   -0.0000
  3180        0.0000             nan     0.2045   -0.0000
  3200        0.0000             nan     0.2045   -0.0000
  3220        0.0000             nan     0.2045   -0.0000
  3240        0.0000             nan     0.2045   -0.0000
  3260        0.0000             nan     0.2045   -0.0000
  3280        0.0000             nan     0.2045   -0.0000
  3300        0.0000             nan     0.2045   -0.0000
  3320        0.0000             nan     0.2045   -0.0000
  3340        0.0000             nan     0.2045   -0.0000
  3360        0.0000             nan     0.2045   -0.0000
  3380        0.0000             nan     0.2045   -0.0000
  3400        0.0000             nan     0.2045   -0.0000
  3420        0.0000             nan     0.2045   -0.0000
  3440        0.0000             nan     0.2045   -0.0000
  3460        0.0000             nan     0.2045   -0.0000
  3480        0.0000             nan     0.2045   -0.0000
  3500        0.0000             nan     0.2045   -0.0000
  3520        0.0000             nan     0.2045   -0.0000
  3540        0.0000             nan     0.2045   -0.0000
  3560        0.0000             nan     0.2045   -0.0000
  3580        0.0000             nan     0.2045   -0.0000
  3600        0.0000             nan     0.2045   -0.0000
  3620        0.0000             nan     0.2045   -0.0000
  3640        0.0000             nan     0.2045   -0.0000
  3660        0.0000             nan     0.2045   -0.0000
  3680        0.0000             nan     0.2045   -0.0000
  3700        0.0000             nan     0.2045   -0.0000
  3720        0.0000             nan     0.2045   -0.0000
  3740        0.0000             nan     0.2045   -0.0000
  3760        0.0000             nan     0.2045   -0.0000
  3780        0.0000             nan     0.2045   -0.0000
  3800        0.0000             nan     0.2045   -0.0000
  3820        0.0000             nan     0.2045   -0.0000
  3840        0.0000             nan     0.2045   -0.0000
  3860        0.0000             nan     0.2045   -0.0000
  3880        0.0000             nan     0.2045   -0.0000
  3900        0.0000             nan     0.2045   -0.0000
  3920        0.0000             nan     0.2045   -0.0000
  3940        0.0000             nan     0.2045   -0.0000
  3960        0.0000             nan     0.2045   -0.0000
  3980        0.0000             nan     0.2045   -0.0000
  3999        0.0000             nan     0.2045   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0001             nan     0.2413   -0.0287
     2        0.9679             nan     0.2413   -0.0002
     3        0.9320             nan     0.2413   -0.0142
     4        0.9131             nan     0.2413   -0.0214
     5        0.8984             nan     0.2413   -0.0279
     6        0.8884             nan     0.2413   -0.0463
     7        0.8685             nan     0.2413   -0.0222
     8        0.8529             nan     0.2413   -0.0288
     9        0.8256             nan     0.2413   -0.0171
    10        0.7980             nan     0.2413   -0.0195
    20        0.6195             nan     0.2413   -0.0224
    40        0.4042             nan     0.2413   -0.0119
    60        0.2982             nan     0.2413   -0.0112
    80        0.2042             nan     0.2413   -0.0064
   100        0.1374             nan     0.2413   -0.0026
   120        0.0954             nan     0.2413   -0.0030
   140        0.0682             nan     0.2413   -0.0031
   160        0.0490             nan     0.2413   -0.0019
   180        0.0332             nan     0.2413   -0.0013
   200        0.0239             nan     0.2413   -0.0010
   220        0.0175             nan     0.2413   -0.0006
   240        0.0130             nan     0.2413   -0.0005
   260        0.0094             nan     0.2413   -0.0005
   280        0.0067             nan     0.2413   -0.0003
   300        0.0049             nan     0.2413   -0.0002
   320        0.0036             nan     0.2413   -0.0002
   340        0.0027             nan     0.2413   -0.0001
   360        0.0019             nan     0.2413   -0.0000
   380        0.0014             nan     0.2413   -0.0000
   400        0.0010             nan     0.2413   -0.0000
   420        0.0007             nan     0.2413   -0.0000
   440        0.0005             nan     0.2413   -0.0000
   460        0.0004             nan     0.2413   -0.0000
   480        0.0003             nan     0.2413   -0.0000
   500        0.0002             nan     0.2413   -0.0000
   520        0.0001             nan     0.2413   -0.0000
   540        0.0001             nan     0.2413   -0.0000
   560        0.0001             nan     0.2413   -0.0000
   580        0.0001             nan     0.2413   -0.0000
   600        0.0000             nan     0.2413   -0.0000
   620        0.0000             nan     0.2413   -0.0000
   640        0.0000             nan     0.2413   -0.0000
   660        0.0000             nan     0.2413   -0.0000
   680        0.0000             nan     0.2413   -0.0000
   700        0.0000             nan     0.2413   -0.0000
   720        0.0000             nan     0.2413   -0.0000
   740        0.0000             nan     0.2413   -0.0000
   760        0.0000             nan     0.2413   -0.0000
   780        0.0000             nan     0.2413   -0.0000
   800        0.0000             nan     0.2413   -0.0000
   820        0.0000             nan     0.2413   -0.0000
   840        0.0000             nan     0.2413   -0.0000
   846        0.0000             nan     0.2413   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9856             nan     0.2603   -0.0044
     2        0.9590             nan     0.2603   -0.0276
     3        0.9253             nan     0.2603   -0.0079
     4        0.8960             nan     0.2603   -0.0127
     5        0.8561             nan     0.2603   -0.0136
     6        0.8430             nan     0.2603   -0.0322
     7        0.8374             nan     0.2603   -0.0629
     8        0.7986             nan     0.2603   -0.0042
     9        0.7945             nan     0.2603   -0.0617
    10        0.7795             nan     0.2603   -0.0388
    20        0.6170             nan     0.2603   -0.0171
    40        0.3769             nan     0.2603   -0.0146
    60        0.2504             nan     0.2603   -0.0042
    80        0.1756             nan     0.2603   -0.0066
   100        0.1168             nan     0.2603   -0.0043
   120        0.0838             nan     0.2603   -0.0020
   140        0.0574             nan     0.2603   -0.0021
   160        0.0422             nan     0.2603   -0.0016
   180        0.0298             nan     0.2603   -0.0017
   200        0.0209             nan     0.2603   -0.0006
   220        0.0148             nan     0.2603   -0.0008
   240        0.0100             nan     0.2603   -0.0003
   260        0.0074             nan     0.2603   -0.0004
   280        0.0051             nan     0.2603   -0.0003
   300        0.0037             nan     0.2603   -0.0002
   320        0.0027             nan     0.2603   -0.0001
   340        0.0019             nan     0.2603   -0.0000
   360        0.0013             nan     0.2603   -0.0001
   380        0.0009             nan     0.2603   -0.0000
   400        0.0006             nan     0.2603   -0.0000
   420        0.0005             nan     0.2603   -0.0000
   440        0.0003             nan     0.2603   -0.0000
   460        0.0002             nan     0.2603   -0.0000
   480        0.0002             nan     0.2603   -0.0000
   500        0.0001             nan     0.2603   -0.0000
   520        0.0001             nan     0.2603   -0.0000
   540        0.0001             nan     0.2603   -0.0000
   560        0.0000             nan     0.2603   -0.0000
   580        0.0000             nan     0.2603   -0.0000
   600        0.0000             nan     0.2603   -0.0000
   620        0.0000             nan     0.2603   -0.0000
   640        0.0000             nan     0.2603   -0.0000
   660        0.0000             nan     0.2603   -0.0000
   680        0.0000             nan     0.2603   -0.0000
   700        0.0000             nan     0.2603   -0.0000
   720        0.0000             nan     0.2603   -0.0000
   740        0.0000             nan     0.2603   -0.0000
   760        0.0000             nan     0.2603   -0.0000
   780        0.0000             nan     0.2603   -0.0000
   800        0.0000             nan     0.2603   -0.0000
   820        0.0000             nan     0.2603   -0.0000
   840        0.0000             nan     0.2603   -0.0000
   860        0.0000             nan     0.2603   -0.0000
   880        0.0000             nan     0.2603   -0.0000
   900        0.0000             nan     0.2603   -0.0000
   920        0.0000             nan     0.2603   -0.0000
   940        0.0000             nan     0.2603   -0.0000
   960        0.0000             nan     0.2603   -0.0000
   980        0.0000             nan     0.2603   -0.0000
  1000        0.0000             nan     0.2603   -0.0000
  1020        0.0000             nan     0.2603   -0.0000
  1040        0.0000             nan     0.2603   -0.0000
  1060        0.0000             nan     0.2603   -0.0000
  1080        0.0000             nan     0.2603   -0.0000
  1100        0.0000             nan     0.2603   -0.0000
  1120        0.0000             nan     0.2603   -0.0000
  1140        0.0000             nan     0.2603   -0.0000
  1160        0.0000             nan     0.2603   -0.0000
  1180        0.0000             nan     0.2603   -0.0000
  1200        0.0000             nan     0.2603   -0.0000
  1220        0.0000             nan     0.2603   -0.0000
  1240        0.0000             nan     0.2603   -0.0000
  1260        0.0000             nan     0.2603   -0.0000
  1280        0.0000             nan     0.2603   -0.0000
  1300        0.0000             nan     0.2603   -0.0000
  1320        0.0000             nan     0.2603   -0.0000
  1340        0.0000             nan     0.2603   -0.0000
  1360        0.0000             nan     0.2603   -0.0000
  1380        0.0000             nan     0.2603   -0.0000
  1400        0.0000             nan     0.2603   -0.0000
  1420        0.0000             nan     0.2603   -0.0000
  1440        0.0000             nan     0.2603   -0.0000
  1460        0.0000             nan     0.2603   -0.0000
  1480        0.0000             nan     0.2603   -0.0000
  1500        0.0000             nan     0.2603   -0.0000
  1520        0.0000             nan     0.2603   -0.0000
  1540        0.0000             nan     0.2603   -0.0000
  1560        0.0000             nan     0.2603   -0.0000
  1580        0.0000             nan     0.2603   -0.0000
  1600        0.0000             nan     0.2603   -0.0000
  1620        0.0000             nan     0.2603   -0.0000
  1640        0.0000             nan     0.2603   -0.0000
  1660        0.0000             nan     0.2603   -0.0000
  1680        0.0000             nan     0.2603   -0.0000
  1700        0.0000             nan     0.2603   -0.0000
  1720        0.0000             nan     0.2603   -0.0000
  1740        0.0000             nan     0.2603   -0.0000
  1760        0.0000             nan     0.2603   -0.0000
  1780        0.0000             nan     0.2603   -0.0000
  1800        0.0000             nan     0.2603   -0.0000
  1820        0.0000             nan     0.2603   -0.0000
  1840        0.0000             nan     0.2603   -0.0000
  1860        0.0000             nan     0.2603   -0.0000
  1880        0.0000             nan     0.2603   -0.0000
  1900        0.0000             nan     0.2603   -0.0000
  1920        0.0000             nan     0.2603   -0.0000
  1940        0.0000             nan     0.2603   -0.0000
  1960        0.0000             nan     0.2603   -0.0000
  1980        0.0000             nan     0.2603   -0.0000
  2000        0.0000             nan     0.2603   -0.0000
  2020        0.0000             nan     0.2603   -0.0000
  2040        0.0000             nan     0.2603   -0.0000
  2060        0.0000             nan     0.2603   -0.0000
  2080        0.0000             nan     0.2603   -0.0000
  2100        0.0000             nan     0.2603   -0.0000
  2120        0.0000             nan     0.2603   -0.0000
  2140        0.0000             nan     0.2603   -0.0000
  2160        0.0000             nan     0.2603   -0.0000
  2180        0.0000             nan     0.2603   -0.0000
  2200        0.0000             nan     0.2603   -0.0000
  2220        0.0000             nan     0.2603   -0.0000
  2240        0.0000             nan     0.2603   -0.0000
  2260        0.0000             nan     0.2603   -0.0000
  2280        0.0000             nan     0.2603   -0.0000
  2300        0.0000             nan     0.2603   -0.0000
  2320        0.0000             nan     0.2603   -0.0000
  2340        0.0000             nan     0.2603   -0.0000
  2360        0.0000             nan     0.2603   -0.0000
  2380        0.0000             nan     0.2603   -0.0000
  2400        0.0000             nan     0.2603   -0.0000
  2420        0.0000             nan     0.2603   -0.0000
  2440        0.0000             nan     0.2603   -0.0000
  2460        0.0000             nan     0.2603   -0.0000
  2480        0.0000             nan     0.2603   -0.0000
  2500        0.0000             nan     0.2603   -0.0000
  2520        0.0000             nan     0.2603   -0.0000
  2540        0.0000             nan     0.2603   -0.0000
  2560        0.0000             nan     0.2603   -0.0000
  2580        0.0000             nan     0.2603   -0.0000
  2600        0.0000             nan     0.2603   -0.0000
  2620        0.0000             nan     0.2603   -0.0000
  2640        0.0000             nan     0.2603   -0.0000
  2660        0.0000             nan     0.2603   -0.0000
  2680        0.0000             nan     0.2603   -0.0000
  2700        0.0000             nan     0.2603   -0.0000
  2720        0.0000             nan     0.2603   -0.0000
  2740        0.0000             nan     0.2603   -0.0000
  2760        0.0000             nan     0.2603   -0.0000
  2780        0.0000             nan     0.2603   -0.0000
  2800        0.0000             nan     0.2603   -0.0000
  2820        0.0000             nan     0.2603   -0.0000
  2840        0.0000             nan     0.2603   -0.0000
  2860        0.0000             nan     0.2603   -0.0000
  2880        0.0000             nan     0.2603   -0.0000
  2900        0.0000             nan     0.2603   -0.0000
  2920        0.0000             nan     0.2603   -0.0000
  2940        0.0000             nan     0.2603   -0.0000
  2960        0.0000             nan     0.2603   -0.0000
  2980        0.0000             nan     0.2603   -0.0000
  3000        0.0000             nan     0.2603   -0.0000
  3020        0.0000             nan     0.2603   -0.0000
  3040        0.0000             nan     0.2603   -0.0000
  3060        0.0000             nan     0.2603   -0.0000
  3080        0.0000             nan     0.2603   -0.0000
  3100        0.0000             nan     0.2603   -0.0000
  3120        0.0000             nan     0.2603   -0.0000
  3140        0.0000             nan     0.2603   -0.0000
  3160        0.0000             nan     0.2603   -0.0000
  3180        0.0000             nan     0.2603   -0.0000
  3200        0.0000             nan     0.2603   -0.0000
  3220        0.0000             nan     0.2603   -0.0000
  3240        0.0000             nan     0.2603   -0.0000
  3260        0.0000             nan     0.2603   -0.0000
  3280        0.0000             nan     0.2603   -0.0000
  3300        0.0000             nan     0.2603   -0.0000
  3320        0.0000             nan     0.2603   -0.0000
  3340        0.0000             nan     0.2603   -0.0000
  3360        0.0000             nan     0.2603   -0.0000
  3380        0.0000             nan     0.2603   -0.0000
  3400        0.0000             nan     0.2603   -0.0000
  3420        0.0000             nan     0.2603   -0.0000
  3440        0.0000             nan     0.2603   -0.0000
  3460        0.0000             nan     0.2603   -0.0000
  3480        0.0000             nan     0.2603   -0.0000
  3500        0.0000             nan     0.2603   -0.0000
  3520        0.0000             nan     0.2603   -0.0000
  3540        0.0000             nan     0.2603   -0.0000
  3560        0.0000             nan     0.2603   -0.0000
  3580        0.0000             nan     0.2603   -0.0000
  3600        0.0000             nan     0.2603   -0.0000
  3620        0.0000             nan     0.2603   -0.0000
  3640        0.0000             nan     0.2603   -0.0000
  3660        0.0000             nan     0.2603   -0.0000
  3680        0.0000             nan     0.2603   -0.0000
  3700        0.0000             nan     0.2603   -0.0000
  3720        0.0000             nan     0.2603   -0.0000
  3740        0.0000             nan     0.2603   -0.0000
  3760        0.0000             nan     0.2603   -0.0000
  3780        0.0000             nan     0.2603   -0.0000
  3800        0.0000             nan     0.2603   -0.0000
  3820        0.0000             nan     0.2603   -0.0000
  3840        0.0000             nan     0.2603   -0.0000
  3860        0.0000             nan     0.2603   -0.0000
  3880        0.0000             nan     0.2603   -0.0000
  3900        0.0000             nan     0.2603   -0.0000
  3920        0.0000             nan     0.2603   -0.0000
  3940        0.0000             nan     0.2603   -0.0000
  3960        0.0000             nan     0.2603   -0.0000
  3980        0.0000             nan     0.2603   -0.0000
  4000        0.0000             nan     0.2603   -0.0000
  4020        0.0000             nan     0.2603   -0.0000
  4040        0.0000             nan     0.2603   -0.0000
  4060        0.0000             nan     0.2603   -0.0000
  4080        0.0000             nan     0.2603   -0.0000
  4100        0.0000             nan     0.2603   -0.0000
  4120        0.0000             nan     0.2603   -0.0000
  4140        0.0000             nan     0.2603   -0.0000
  4160        0.0000             nan     0.2603   -0.0000
  4180        0.0000             nan     0.2603   -0.0000
  4200        0.0000             nan     0.2603   -0.0000
  4213        0.0000             nan     0.2603   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9760             nan     0.2885   -0.0057
     2        0.9349             nan     0.2885   -0.0191
     3        0.8915             nan     0.2885   -0.0211
     4        0.8513             nan     0.2885   -0.0259
     5        0.8152             nan     0.2885   -0.0280
     6        0.7878             nan     0.2885   -0.0242
     7        0.7672             nan     0.2885   -0.0329
     8        0.7475             nan     0.2885   -0.0359
     9        0.7201             nan     0.2885   -0.0178
    10        0.6897             nan     0.2885   -0.0233
    20        0.5017             nan     0.2885   -0.0175
    40        0.2994             nan     0.2885   -0.0146
    60        0.1883             nan     0.2885   -0.0093
    80        0.1115             nan     0.2885   -0.0069
   100        0.0690             nan     0.2885   -0.0027
   120        0.0417             nan     0.2885   -0.0024
   140        0.0262             nan     0.2885   -0.0010
   160        0.0169             nan     0.2885   -0.0006
   180        0.0108             nan     0.2885   -0.0006
   200        0.0074             nan     0.2885   -0.0005
   220        0.0045             nan     0.2885   -0.0003
   240        0.0030             nan     0.2885   -0.0001
   260        0.0019             nan     0.2885   -0.0001
   280        0.0013             nan     0.2885   -0.0000
   300        0.0008             nan     0.2885   -0.0000
   320        0.0005             nan     0.2885   -0.0000
   340        0.0004             nan     0.2885   -0.0000
   360        0.0002             nan     0.2885   -0.0000
   380        0.0002             nan     0.2885   -0.0000
   400        0.0001             nan     0.2885   -0.0000
   420        0.0001             nan     0.2885   -0.0000
   440        0.0000             nan     0.2885   -0.0000
   460        0.0000             nan     0.2885   -0.0000
   480        0.0000             nan     0.2885   -0.0000
   500        0.0000             nan     0.2885   -0.0000
   520        0.0000             nan     0.2885   -0.0000
   540        0.0000             nan     0.2885   -0.0000
   560        0.0000             nan     0.2885   -0.0000
   580        0.0000             nan     0.2885   -0.0000
   600        0.0000             nan     0.2885   -0.0000
   620        0.0000             nan     0.2885   -0.0000
   640        0.0000             nan     0.2885   -0.0000
   660        0.0000             nan     0.2885   -0.0000
   680        0.0000             nan     0.2885   -0.0000
   700        0.0000             nan     0.2885   -0.0000
   720        0.0000             nan     0.2885   -0.0000
   740        0.0000             nan     0.2885   -0.0000
   760        0.0000             nan     0.2885   -0.0000
   780        0.0000             nan     0.2885   -0.0000
   800        0.0000             nan     0.2885   -0.0000
   820        0.0000             nan     0.2885   -0.0000
   840        0.0000             nan     0.2885   -0.0000
   860        0.0000             nan     0.2885   -0.0000
   880        0.0000             nan     0.2885   -0.0000
   900        0.0000             nan     0.2885   -0.0000
   920        0.0000             nan     0.2885   -0.0000
   940        0.0000             nan     0.2885   -0.0000
   960        0.0000             nan     0.2885   -0.0000
   980        0.0000             nan     0.2885   -0.0000
  1000        0.0000             nan     0.2885   -0.0000
  1020        0.0000             nan     0.2885   -0.0000
  1040        0.0000             nan     0.2885   -0.0000
  1060        0.0000             nan     0.2885   -0.0000
  1080        0.0000             nan     0.2885   -0.0000
  1100        0.0000             nan     0.2885   -0.0000
  1120        0.0000             nan     0.2885   -0.0000
  1140        0.0000             nan     0.2885   -0.0000
  1160        0.0000             nan     0.2885   -0.0000
  1180        0.0000             nan     0.2885   -0.0000
  1200        0.0000             nan     0.2885   -0.0000
  1220        0.0000             nan     0.2885   -0.0000
  1240        0.0000             nan     0.2885   -0.0000
  1260        0.0000             nan     0.2885   -0.0000
  1280        0.0000             nan     0.2885   -0.0000
  1300        0.0000             nan     0.2885   -0.0000
  1320        0.0000             nan     0.2885   -0.0000
  1340        0.0000             nan     0.2885   -0.0000
  1360        0.0000             nan     0.2885   -0.0000
  1380        0.0000             nan     0.2885   -0.0000
  1400        0.0000             nan     0.2885   -0.0000
  1420        0.0000             nan     0.2885   -0.0000
  1440        0.0000             nan     0.2885   -0.0000
  1460        0.0000             nan     0.2885   -0.0000
  1480        0.0000             nan     0.2885   -0.0000
  1500        0.0000             nan     0.2885   -0.0000
  1520        0.0000             nan     0.2885   -0.0000
  1540        0.0000             nan     0.2885   -0.0000
  1560        0.0000             nan     0.2885   -0.0000
  1580        0.0000             nan     0.2885   -0.0000
  1600        0.0000             nan     0.2885   -0.0000
  1620        0.0000             nan     0.2885   -0.0000
  1640        0.0000             nan     0.2885   -0.0000
  1660        0.0000             nan     0.2885   -0.0000
  1680        0.0000             nan     0.2885   -0.0000
  1700        0.0000             nan     0.2885   -0.0000
  1720        0.0000             nan     0.2885   -0.0000
  1740        0.0000             nan     0.2885   -0.0000
  1760        0.0000             nan     0.2885   -0.0000
  1780        0.0000             nan     0.2885   -0.0000
  1800        0.0000             nan     0.2885   -0.0000
  1820        0.0000             nan     0.2885   -0.0000
  1840        0.0000             nan     0.2885   -0.0000
  1860        0.0000             nan     0.2885   -0.0000
  1880        0.0000             nan     0.2885   -0.0000
  1900        0.0000             nan     0.2885   -0.0000
  1920        0.0000             nan     0.2885   -0.0000
  1940        0.0000             nan     0.2885   -0.0000
  1960        0.0000             nan     0.2885   -0.0000
  1980        0.0000             nan     0.2885   -0.0000
  2000        0.0000             nan     0.2885   -0.0000
  2020        0.0000             nan     0.2885   -0.0000
  2040        0.0000             nan     0.2885   -0.0000
  2060        0.0000             nan     0.2885   -0.0000
  2080        0.0000             nan     0.2885   -0.0000
  2100        0.0000             nan     0.2885   -0.0000
  2120        0.0000             nan     0.2885   -0.0000
  2140        0.0000             nan     0.2885   -0.0000
  2160        0.0000             nan     0.2885   -0.0000
  2180        0.0000             nan     0.2885   -0.0000
  2200        0.0000             nan     0.2885   -0.0000
  2220        0.0000             nan     0.2885   -0.0000
  2240        0.0000             nan     0.2885   -0.0000
  2260        0.0000             nan     0.2885   -0.0000
  2280        0.0000             nan     0.2885   -0.0000
  2300        0.0000             nan     0.2885   -0.0000
  2320        0.0000             nan     0.2885   -0.0000
  2340        0.0000             nan     0.2885   -0.0000
  2360        0.0000             nan     0.2885   -0.0000
  2380        0.0000             nan     0.2885   -0.0000
  2400        0.0000             nan     0.2885   -0.0000
  2420        0.0000             nan     0.2885   -0.0000
  2440        0.0000             nan     0.2885   -0.0000
  2460        0.0000             nan     0.2885   -0.0000
  2480        0.0000             nan     0.2885   -0.0000
  2500        0.0000             nan     0.2885   -0.0000
  2520        0.0000             nan     0.2885   -0.0000
  2540        0.0000             nan     0.2885   -0.0000
  2560        0.0000             nan     0.2885   -0.0000
  2580        0.0000             nan     0.2885   -0.0000
  2600        0.0000             nan     0.2885   -0.0000
  2620        0.0000             nan     0.2885   -0.0000
  2640        0.0000             nan     0.2885   -0.0000
  2660        0.0000             nan     0.2885   -0.0000
  2680        0.0000             nan     0.2885   -0.0000
  2700        0.0000             nan     0.2885   -0.0000
  2720        0.0000             nan     0.2885   -0.0000
  2740        0.0000             nan     0.2885   -0.0000
  2760        0.0000             nan     0.2885   -0.0000
  2780        0.0000             nan     0.2885   -0.0000
  2800        0.0000             nan     0.2885   -0.0000
  2820        0.0000             nan     0.2885   -0.0000
  2840        0.0000             nan     0.2885   -0.0000
  2860        0.0000             nan     0.2885   -0.0000
  2880        0.0000             nan     0.2885   -0.0000
  2900        0.0000             nan     0.2885   -0.0000
  2920        0.0000             nan     0.2885   -0.0000
  2940        0.0000             nan     0.2885   -0.0000
  2960        0.0000             nan     0.2885   -0.0000
  2980        0.0000             nan     0.2885   -0.0000
  3000        0.0000             nan     0.2885   -0.0000
  3020        0.0000             nan     0.2885   -0.0000
  3040        0.0000             nan     0.2885   -0.0000
  3060        0.0000             nan     0.2885   -0.0000
  3080        0.0000             nan     0.2885   -0.0000
  3100        0.0000             nan     0.2885   -0.0000
  3120        0.0000             nan     0.2885   -0.0000
  3140        0.0000             nan     0.2885   -0.0000
  3160        0.0000             nan     0.2885   -0.0000
  3180        0.0000             nan     0.2885   -0.0000
  3200        0.0000             nan     0.2885   -0.0000
  3220        0.0000             nan     0.2885   -0.0000
  3240        0.0000             nan     0.2885   -0.0000
  3260        0.0000             nan     0.2885   -0.0000
  3280        0.0000             nan     0.2885   -0.0000
  3300        0.0000             nan     0.2885   -0.0000
  3320        0.0000             nan     0.2885   -0.0000
  3340        0.0000             nan     0.2885   -0.0000
  3360        0.0000             nan     0.2885   -0.0000
  3380        0.0000             nan     0.2885   -0.0000
  3400        0.0000             nan     0.2885   -0.0000
  3420        0.0000             nan     0.2885   -0.0000
  3440        0.0000             nan     0.2885   -0.0000
  3460        0.0000             nan     0.2885   -0.0000
  3480        0.0000             nan     0.2885   -0.0000
  3500        0.0000             nan     0.2885   -0.0000
  3520        0.0000             nan     0.2885   -0.0000
  3540        0.0000             nan     0.2885   -0.0000
  3560        0.0000             nan     0.2885   -0.0000
  3580        0.0000             nan     0.2885   -0.0000
  3600        0.0000             nan     0.2885   -0.0000
  3620        0.0000             nan     0.2885   -0.0000
  3640        0.0000             nan     0.2885   -0.0000
  3660        0.0000             nan     0.2885   -0.0000
  3680        0.0000             nan     0.2885   -0.0000
  3700        0.0000             nan     0.2885   -0.0000
  3720        0.0000             nan     0.2885   -0.0000
  3740        0.0000             nan     0.2885   -0.0000
  3760        0.0000             nan     0.2885   -0.0000
  3780        0.0000             nan     0.2885   -0.0000
  3800        0.0000             nan     0.2885   -0.0000
  3820        0.0000             nan     0.2885   -0.0000
  3840        0.0000             nan     0.2885   -0.0000
  3860        0.0000             nan     0.2885   -0.0000
  3880        0.0000             nan     0.2885   -0.0000
  3900        0.0000             nan     0.2885   -0.0000
  3920        0.0000             nan     0.2885   -0.0000
  3940        0.0000             nan     0.2885   -0.0000
  3960        0.0000             nan     0.2885   -0.0000
  3980        0.0000             nan     0.2885   -0.0000
  4000        0.0000             nan     0.2885   -0.0000
  4020        0.0000             nan     0.2885   -0.0000
  4040        0.0000             nan     0.2885   -0.0000
  4060        0.0000             nan     0.2885   -0.0000
  4080        0.0000             nan     0.2885   -0.0000
  4100        0.0000             nan     0.2885   -0.0000
  4120        0.0000             nan     0.2885   -0.0000
  4140        0.0000             nan     0.2885   -0.0000
  4160        0.0000             nan     0.2885   -0.0000
  4180        0.0000             nan     0.2885   -0.0000
  4200        0.0000             nan     0.2885   -0.0000
  4220        0.0000             nan     0.2885   -0.0000
  4240        0.0000             nan     0.2885   -0.0000
  4260        0.0000             nan     0.2885   -0.0000
  4280        0.0000             nan     0.2885   -0.0000
  4300        0.0000             nan     0.2885   -0.0000
  4320        0.0000             nan     0.2885   -0.0000
  4340        0.0000             nan     0.2885   -0.0000
  4360        0.0000             nan     0.2885   -0.0000
  4380        0.0000             nan     0.2885   -0.0000
  4400        0.0000             nan     0.2885   -0.0000
  4420        0.0000             nan     0.2885   -0.0000
  4440        0.0000             nan     0.2885   -0.0000
  4460        0.0000             nan     0.2885   -0.0000
  4480        0.0000             nan     0.2885   -0.0000
  4500        0.0000             nan     0.2885   -0.0000
  4520        0.0000             nan     0.2885   -0.0000
  4540        0.0000             nan     0.2885   -0.0000
  4560        0.0000             nan     0.2885   -0.0000
  4580        0.0000             nan     0.2885   -0.0000
  4600        0.0000             nan     0.2885   -0.0000
  4620        0.0000             nan     0.2885   -0.0000
  4640        0.0000             nan     0.2885   -0.0000
  4660        0.0000             nan     0.2885   -0.0000
  4680        0.0000             nan     0.2885   -0.0000
  4700        0.0000             nan     0.2885   -0.0000
  4720        0.0000             nan     0.2885   -0.0000
  4740        0.0000             nan     0.2885   -0.0000
  4760        0.0000             nan     0.2885   -0.0000
  4780        0.0000             nan     0.2885   -0.0000
  4800        0.0000             nan     0.2885   -0.0000
  4820        0.0000             nan     0.2885   -0.0000
  4837        0.0000             nan     0.2885   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0163             nan     0.2888   -0.0180
     2        1.0048             nan     0.2888   -0.0012
     3        0.9963             nan     0.2888   -0.0046
     4        0.9896             nan     0.2888   -0.0144
     5        0.9902             nan     0.2888   -0.0224
     6        0.9811             nan     0.2888   -0.0239
     7        0.9692             nan     0.2888   -0.0060
     8        0.9630             nan     0.2888   -0.0096
     9        0.9546             nan     0.2888   -0.0082
    10        0.9505             nan     0.2888   -0.0207
    20        0.8799             nan     0.2888   -0.0151
    40        0.8051             nan     0.2888   -0.0140
    60        0.7073             nan     0.2888   -0.0110
    80        0.6400             nan     0.2888   -0.0170
   100        0.5765             nan     0.2888   -0.0060
   120        0.5327             nan     0.2888   -0.0077
   140        0.4891             nan     0.2888   -0.0089
   160        0.4528             nan     0.2888   -0.0044
   180        0.4178             nan     0.2888   -0.0058
   200        0.3894             nan     0.2888   -0.0052
   220        0.3545             nan     0.2888   -0.0081
   240        0.3264             nan     0.2888   -0.0054
   260        0.3062             nan     0.2888   -0.0060
   280        0.2876             nan     0.2888   -0.0036
   300        0.2687             nan     0.2888   -0.0050
   320        0.2546             nan     0.2888   -0.0022
   340        0.2382             nan     0.2888   -0.0005
   360        0.2248             nan     0.2888   -0.0028
   380        0.2142             nan     0.2888   -0.0036
   400        0.2016             nan     0.2888   -0.0029
   420        0.1870             nan     0.2888   -0.0033
   440        0.1761             nan     0.2888   -0.0016
   460        0.1665             nan     0.2888   -0.0039
   480        0.1574             nan     0.2888   -0.0012
   500        0.1504             nan     0.2888   -0.0015
   520        0.1421             nan     0.2888   -0.0022
   540        0.1319             nan     0.2888   -0.0020
   560        0.1244             nan     0.2888   -0.0021
   580        0.1161             nan     0.2888   -0.0018
   600        0.1088             nan     0.2888   -0.0018
   620        0.1024             nan     0.2888   -0.0020
   640        0.0972             nan     0.2888   -0.0019
   660        0.0917             nan     0.2888   -0.0018
   680        0.0876             nan     0.2888   -0.0020
   700        0.0819             nan     0.2888   -0.0022
   720        0.0782             nan     0.2888   -0.0014
   740        0.0735             nan     0.2888   -0.0013
   760        0.0699             nan     0.2888   -0.0009
   780        0.0661             nan     0.2888   -0.0015
   800        0.0632             nan     0.2888   -0.0011
   820        0.0598             nan     0.2888   -0.0022
   840        0.0562             nan     0.2888   -0.0004
   860        0.0537             nan     0.2888   -0.0008
   880        0.0504             nan     0.2888   -0.0012
   900        0.0484             nan     0.2888   -0.0009
   920        0.0460             nan     0.2888   -0.0008
   940        0.0435             nan     0.2888   -0.0011
   960        0.0412             nan     0.2888   -0.0009
   980        0.0390             nan     0.2888   -0.0007
  1000        0.0369             nan     0.2888   -0.0010
  1020        0.0347             nan     0.2888   -0.0012
  1040        0.0330             nan     0.2888   -0.0007
  1060        0.0312             nan     0.2888   -0.0008
  1080        0.0295             nan     0.2888   -0.0006
  1100        0.0282             nan     0.2888   -0.0007
  1120        0.0271             nan     0.2888   -0.0005
  1140        0.0256             nan     0.2888   -0.0004
  1160        0.0244             nan     0.2888   -0.0007
  1180        0.0235             nan     0.2888   -0.0006
  1200        0.0223             nan     0.2888   -0.0002
  1220        0.0214             nan     0.2888   -0.0002
  1240        0.0205             nan     0.2888   -0.0003
  1260        0.0193             nan     0.2888   -0.0003
  1264        0.0191             nan     0.2888   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9892             nan     0.3308   -0.0351
     2        0.9625             nan     0.3308   -0.0381
     3        0.9454             nan     0.3308   -0.0333
     4        0.9206             nan     0.3308   -0.0027
     5        0.9046             nan     0.3308   -0.0355
     6        0.8774             nan     0.3308   -0.0043
     7        0.8577             nan     0.3308   -0.0355
     8        0.8354             nan     0.3308   -0.0193
     9        0.8099             nan     0.3308   -0.0155
    10        0.7934             nan     0.3308   -0.0309
    20        0.6846             nan     0.3308   -0.0219
    40        0.4558             nan     0.3308   -0.0200
    60        0.3175             nan     0.3308   -0.0089
    80        0.2424             nan     0.3308   -0.0158
   100        0.1765             nan     0.3308   -0.0059
   120        0.1285             nan     0.3308   -0.0057
   140        0.0962             nan     0.3308   -0.0033
   160        0.0704             nan     0.3308   -0.0009
   180        0.0516             nan     0.3308   -0.0022
   200        0.0392             nan     0.3308   -0.0009
   220        0.0299             nan     0.3308   -0.0005
   240        0.0237             nan     0.3308   -0.0008
   260        0.0178             nan     0.3308   -0.0006
   280        0.0135             nan     0.3308   -0.0006
   300        0.0103             nan     0.3308   -0.0004
   320        0.0078             nan     0.3308   -0.0005
   340        0.0063             nan     0.3308   -0.0001
   360        0.0048             nan     0.3308   -0.0001
   380        0.0038             nan     0.3308   -0.0002
   400        0.0028             nan     0.3308   -0.0001
   420        0.0022             nan     0.3308   -0.0001
   440        0.0019             nan     0.3308   -0.0001
   460        0.0014             nan     0.3308   -0.0001
   480        0.0011             nan     0.3308   -0.0000
   500        0.0008             nan     0.3308   -0.0000
   520        0.0006             nan     0.3308   -0.0000
   540        0.0005             nan     0.3308   -0.0000
   560        0.0004             nan     0.3308   -0.0000
   580        0.0003             nan     0.3308   -0.0000
   600        0.0002             nan     0.3308   -0.0000
   620        0.0002             nan     0.3308   -0.0000
   640        0.0001             nan     0.3308   -0.0000
   660        0.0001             nan     0.3308   -0.0000
   680        0.0001             nan     0.3308   -0.0000
   700        0.0001             nan     0.3308   -0.0000
   720        0.0001             nan     0.3308   -0.0000
   740        0.0000             nan     0.3308   -0.0000
   760        0.0000             nan     0.3308   -0.0000
   780        0.0000             nan     0.3308   -0.0000
   800        0.0000             nan     0.3308   -0.0000
   820        0.0000             nan     0.3308   -0.0000
   840        0.0000             nan     0.3308   -0.0000
   860        0.0000             nan     0.3308   -0.0000
   880        0.0000             nan     0.3308   -0.0000
   900        0.0000             nan     0.3308   -0.0000
   920        0.0000             nan     0.3308   -0.0000
   940        0.0000             nan     0.3308   -0.0000
   960        0.0000             nan     0.3308   -0.0000
   980        0.0000             nan     0.3308   -0.0000
  1000        0.0000             nan     0.3308   -0.0000
  1020        0.0000             nan     0.3308   -0.0000
  1040        0.0000             nan     0.3308   -0.0000
  1060        0.0000             nan     0.3308   -0.0000
  1080        0.0000             nan     0.3308   -0.0000
  1100        0.0000             nan     0.3308   -0.0000
  1120        0.0000             nan     0.3308   -0.0000
  1140        0.0000             nan     0.3308   -0.0000
  1160        0.0000             nan     0.3308   -0.0000
  1180        0.0000             nan     0.3308   -0.0000
  1200        0.0000             nan     0.3308   -0.0000
  1220        0.0000             nan     0.3308   -0.0000
  1240        0.0000             nan     0.3308   -0.0000
  1260        0.0000             nan     0.3308   -0.0000
  1280        0.0000             nan     0.3308   -0.0000
  1300        0.0000             nan     0.3308   -0.0000
  1320        0.0000             nan     0.3308   -0.0000
  1340        0.0000             nan     0.3308   -0.0000
  1360        0.0000             nan     0.3308   -0.0000
  1380        0.0000             nan     0.3308   -0.0000
  1400        0.0000             nan     0.3308   -0.0000
  1420        0.0000             nan     0.3308   -0.0000
  1440        0.0000             nan     0.3308   -0.0000
  1460        0.0000             nan     0.3308   -0.0000
  1480        0.0000             nan     0.3308   -0.0000
  1500        0.0000             nan     0.3308   -0.0000
  1520        0.0000             nan     0.3308   -0.0000
  1540        0.0000             nan     0.3308   -0.0000
  1560        0.0000             nan     0.3308   -0.0000
  1580        0.0000             nan     0.3308   -0.0000
  1600        0.0000             nan     0.3308   -0.0000
  1620        0.0000             nan     0.3308   -0.0000
  1640        0.0000             nan     0.3308   -0.0000
  1660        0.0000             nan     0.3308   -0.0000
  1680        0.0000             nan     0.3308   -0.0000
  1700        0.0000             nan     0.3308   -0.0000
  1720        0.0000             nan     0.3308   -0.0000
  1740        0.0000             nan     0.3308   -0.0000
  1760        0.0000             nan     0.3308   -0.0000
  1780        0.0000             nan     0.3308   -0.0000
  1800        0.0000             nan     0.3308   -0.0000
  1820        0.0000             nan     0.3308   -0.0000
  1825        0.0000             nan     0.3308   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9811             nan     0.3353   -0.0209
     2        0.9257             nan     0.3353   -0.0123
     3        0.8747             nan     0.3353   -0.0076
     4        0.8241             nan     0.3353   -0.0021
     5        0.7921             nan     0.3353   -0.0503
     6        0.7554             nan     0.3353   -0.0252
     7        0.7197             nan     0.3353   -0.0297
     8        0.6932             nan     0.3353   -0.0349
     9        0.6587             nan     0.3353   -0.0136
    10        0.6326             nan     0.3353   -0.0227
    20        0.4652             nan     0.3353   -0.0186
    40        0.2562             nan     0.3353   -0.0145
    60        0.1332             nan     0.3353   -0.0063
    80        0.0813             nan     0.3353   -0.0040
   100        0.0466             nan     0.3353   -0.0010
   120        0.0277             nan     0.3353   -0.0011
   140        0.0176             nan     0.3353   -0.0013
   160        0.0100             nan     0.3353   -0.0003
   180        0.0058             nan     0.3353   -0.0003
   200        0.0034             nan     0.3353   -0.0001
   220        0.0022             nan     0.3353   -0.0002
   240        0.0013             nan     0.3353   -0.0001
   260        0.0008             nan     0.3353   -0.0000
   280        0.0004             nan     0.3353   -0.0000
   300        0.0003             nan     0.3353   -0.0000
   320        0.0002             nan     0.3353   -0.0000
   340        0.0001             nan     0.3353   -0.0000
   360        0.0001             nan     0.3353   -0.0000
   380        0.0000             nan     0.3353   -0.0000
   400        0.0000             nan     0.3353   -0.0000
   420        0.0000             nan     0.3353   -0.0000
   440        0.0000             nan     0.3353   -0.0000
   460        0.0000             nan     0.3353   -0.0000
   480        0.0000             nan     0.3353   -0.0000
   500        0.0000             nan     0.3353   -0.0000
   520        0.0000             nan     0.3353   -0.0000
   540        0.0000             nan     0.3353   -0.0000
   560        0.0000             nan     0.3353   -0.0000
   580        0.0000             nan     0.3353   -0.0000
   600        0.0000             nan     0.3353   -0.0000
   620        0.0000             nan     0.3353   -0.0000
   640        0.0000             nan     0.3353   -0.0000
   660        0.0000             nan     0.3353   -0.0000
   680        0.0000             nan     0.3353   -0.0000
   700        0.0000             nan     0.3353   -0.0000
   720        0.0000             nan     0.3353   -0.0000
   740        0.0000             nan     0.3353   -0.0000
   760        0.0000             nan     0.3353   -0.0000
   780        0.0000             nan     0.3353   -0.0000
   800        0.0000             nan     0.3353   -0.0000
   820        0.0000             nan     0.3353   -0.0000
   840        0.0000             nan     0.3353   -0.0000
   860        0.0000             nan     0.3353   -0.0000
   880        0.0000             nan     0.3353   -0.0000
   900        0.0000             nan     0.3353   -0.0000
   920        0.0000             nan     0.3353   -0.0000
   940        0.0000             nan     0.3353   -0.0000
   960        0.0000             nan     0.3353   -0.0000
   980        0.0000             nan     0.3353   -0.0000
  1000        0.0000             nan     0.3353   -0.0000
  1020        0.0000             nan     0.3353   -0.0000
  1040        0.0000             nan     0.3353   -0.0000
  1060        0.0000             nan     0.3353   -0.0000
  1080        0.0000             nan     0.3353   -0.0000
  1100        0.0000             nan     0.3353   -0.0000
  1120        0.0000             nan     0.3353   -0.0000
  1140        0.0000             nan     0.3353   -0.0000
  1160        0.0000             nan     0.3353   -0.0000
  1180        0.0000             nan     0.3353   -0.0000
  1200        0.0000             nan     0.3353   -0.0000
  1220        0.0000             nan     0.3353   -0.0000
  1240        0.0000             nan     0.3353   -0.0000
  1260        0.0000             nan     0.3353   -0.0000
  1280        0.0000             nan     0.3353   -0.0000
  1300        0.0000             nan     0.3353   -0.0000
  1320        0.0000             nan     0.3353   -0.0000
  1340        0.0000             nan     0.3353   -0.0000
  1360        0.0000             nan     0.3353   -0.0000
  1380        0.0000             nan     0.3353   -0.0000
  1400        0.0000             nan     0.3353   -0.0000
  1420        0.0000             nan     0.3353   -0.0000
  1440        0.0000             nan     0.3353   -0.0000
  1460        0.0000             nan     0.3353   -0.0000
  1480        0.0000             nan     0.3353   -0.0000
  1500        0.0000             nan     0.3353   -0.0000
  1520        0.0000             nan     0.3353   -0.0000
  1540        0.0000             nan     0.3353   -0.0000
  1560        0.0000             nan     0.3353   -0.0000
  1580        0.0000             nan     0.3353   -0.0000
  1600        0.0000             nan     0.3353   -0.0000
  1620        0.0000             nan     0.3353   -0.0000
  1640        0.0000             nan     0.3353   -0.0000
  1660        0.0000             nan     0.3353   -0.0000
  1680        0.0000             nan     0.3353   -0.0000
  1700        0.0000             nan     0.3353   -0.0000
  1720        0.0000             nan     0.3353   -0.0000
  1740        0.0000             nan     0.3353   -0.0000
  1760        0.0000             nan     0.3353   -0.0000
  1780        0.0000             nan     0.3353   -0.0000
  1800        0.0000             nan     0.3353   -0.0000
  1820        0.0000             nan     0.3353   -0.0000
  1840        0.0000             nan     0.3353   -0.0000
  1860        0.0000             nan     0.3353   -0.0000
  1880        0.0000             nan     0.3353   -0.0000
  1900        0.0000             nan     0.3353   -0.0000
  1920        0.0000             nan     0.3353   -0.0000
  1940        0.0000             nan     0.3353   -0.0000
  1960        0.0000             nan     0.3353   -0.0000
  1980        0.0000             nan     0.3353   -0.0000
  2000        0.0000             nan     0.3353   -0.0000
  2020        0.0000             nan     0.3353   -0.0000
  2040        0.0000             nan     0.3353   -0.0000
  2060        0.0000             nan     0.3353   -0.0000
  2080        0.0000             nan     0.3353   -0.0000
  2100        0.0000             nan     0.3353   -0.0000
  2120        0.0000             nan     0.3353   -0.0000
  2140        0.0000             nan     0.3353   -0.0000
  2160        0.0000             nan     0.3353   -0.0000
  2180        0.0000             nan     0.3353   -0.0000
  2200        0.0000             nan     0.3353   -0.0000
  2220        0.0000             nan     0.3353   -0.0000
  2240        0.0000             nan     0.3353   -0.0000
  2260        0.0000             nan     0.3353   -0.0000
  2280        0.0000             nan     0.3353   -0.0000
  2300        0.0000             nan     0.3353   -0.0000
  2320        0.0000             nan     0.3353   -0.0000
  2340        0.0000             nan     0.3353   -0.0000
  2360        0.0000             nan     0.3353   -0.0000
  2380        0.0000             nan     0.3353   -0.0000
  2400        0.0000             nan     0.3353   -0.0000
  2420        0.0000             nan     0.3353   -0.0000
  2440        0.0000             nan     0.3353   -0.0000
  2460        0.0000             nan     0.3353   -0.0000
  2480        0.0000             nan     0.3353   -0.0000
  2500        0.0000             nan     0.3353   -0.0000
  2520        0.0000             nan     0.3353   -0.0000
  2540        0.0000             nan     0.3353   -0.0000
  2560        0.0000             nan     0.3353   -0.0000
  2580        0.0000             nan     0.3353   -0.0000
  2600        0.0000             nan     0.3353   -0.0000
  2620        0.0000             nan     0.3353   -0.0000
  2640        0.0000             nan     0.3353   -0.0000
  2660        0.0000             nan     0.3353   -0.0000
  2680        0.0000             nan     0.3353   -0.0000
  2700        0.0000             nan     0.3353   -0.0000
  2720        0.0000             nan     0.3353   -0.0000
  2740        0.0000             nan     0.3353   -0.0000
  2760        0.0000             nan     0.3353   -0.0000
  2780        0.0000             nan     0.3353   -0.0000
  2800        0.0000             nan     0.3353   -0.0000
  2820        0.0000             nan     0.3353   -0.0000
  2840        0.0000             nan     0.3353   -0.0000
  2860        0.0000             nan     0.3353   -0.0000
  2880        0.0000             nan     0.3353   -0.0000
  2900        0.0000             nan     0.3353   -0.0000
  2920        0.0000             nan     0.3353   -0.0000
  2940        0.0000             nan     0.3353   -0.0000
  2960        0.0000             nan     0.3353   -0.0000
  2980        0.0000             nan     0.3353   -0.0000
  3000        0.0000             nan     0.3353   -0.0000
  3020        0.0000             nan     0.3353   -0.0000
  3040        0.0000             nan     0.3353   -0.0000
  3060        0.0000             nan     0.3353   -0.0000
  3080        0.0000             nan     0.3353   -0.0000
  3100        0.0000             nan     0.3353   -0.0000
  3120        0.0000             nan     0.3353   -0.0000
  3140        0.0000             nan     0.3353   -0.0000
  3160        0.0000             nan     0.3353   -0.0000
  3180        0.0000             nan     0.3353   -0.0000
  3200        0.0000             nan     0.3353   -0.0000
  3220        0.0000             nan     0.3353   -0.0000
  3240        0.0000             nan     0.3353   -0.0000
  3260        0.0000             nan     0.3353   -0.0000
  3280        0.0000             nan     0.3353   -0.0000
  3300        0.0000             nan     0.3353   -0.0000
  3320        0.0000             nan     0.3353   -0.0000
  3340        0.0000             nan     0.3353   -0.0000
  3360        0.0000             nan     0.3353   -0.0000
  3380        0.0000             nan     0.3353   -0.0000
  3400        0.0000             nan     0.3353   -0.0000
  3420        0.0000             nan     0.3353   -0.0000
  3440        0.0000             nan     0.3353   -0.0000
  3460        0.0000             nan     0.3353   -0.0000
  3480        0.0000             nan     0.3353   -0.0000
  3500        0.0000             nan     0.3353   -0.0000
  3520        0.0000             nan     0.3353   -0.0000
  3540        0.0000             nan     0.3353   -0.0000
  3560        0.0000             nan     0.3353   -0.0000
  3580        0.0000             nan     0.3353   -0.0000
  3585        0.0000             nan     0.3353   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0150             nan     0.4136   -0.0338
     2        0.9842             nan     0.4136   -0.0047
     3        0.9748             nan     0.4136   -0.0447
     4        0.9654             nan     0.4136   -0.0404
     5        0.9454             nan     0.4136   -0.0106
     6        0.9387             nan     0.4136   -0.0391
     7        0.9233             nan     0.4136   -0.0252
     8        0.9115             nan     0.4136   -0.0139
     9        0.8981             nan     0.4136   -0.0137
    10        0.8938             nan     0.4136   -0.0304
    20        0.7909             nan     0.4136   -0.0227
    40        0.6449             nan     0.4136   -0.0176
    60        0.5297             nan     0.4136   -0.0179
    80        0.4561             nan     0.4136   -0.0306
   100        0.3881             nan     0.4136   -0.0203
   120        0.3324             nan     0.4136   -0.0148
   140        0.2913             nan     0.4136   -0.0111
   160        0.2428             nan     0.4136   -0.0147
   180        0.2073             nan     0.4136   -0.0034
   200        0.1758             nan     0.4136   -0.0001
   220        0.1562             nan     0.4136   -0.0043
   240        0.1355             nan     0.4136   -0.0038
   260        0.1161             nan     0.4136   -0.0026
   280        0.1045             nan     0.4136   -0.0035
   300        0.0925             nan     0.4136   -0.0049
   320        0.0793             nan     0.4136   -0.0029
   340        0.0710             nan     0.4136   -0.0034
   360        0.0627             nan     0.4136   -0.0010
   380        0.0563             nan     0.4136   -0.0014
   400        0.0497             nan     0.4136   -0.0016
   420        0.0440             nan     0.4136   -0.0008
   440        0.0390             nan     0.4136   -0.0009
   460        0.0343             nan     0.4136   -0.0011
   480        0.0299             nan     0.4136   -0.0010
   500        0.0270             nan     0.4136   -0.0011
   520        0.0235             nan     0.4136   -0.0004
   540        0.0211             nan     0.4136   -0.0003
   560        0.0188             nan     0.4136   -0.0006
   580        0.0165             nan     0.4136   -0.0004
   600        0.0148             nan     0.4136   -0.0001
   620        0.0129             nan     0.4136   -0.0005
   640        0.0117             nan     0.4136   -0.0003
   660        0.0102             nan     0.4136   -0.0004
   680        0.0090             nan     0.4136   -0.0003
   700        0.0080             nan     0.4136   -0.0002
   720        0.0070             nan     0.4136   -0.0001
   740        0.0062             nan     0.4136   -0.0003
   760        0.0053             nan     0.4136   -0.0001
   780        0.0046             nan     0.4136   -0.0002
   800        0.0041             nan     0.4136   -0.0002
   820        0.0037             nan     0.4136   -0.0001
   840        0.0033             nan     0.4136   -0.0001
   860        0.0029             nan     0.4136   -0.0001
   880        0.0026             nan     0.4136   -0.0001
   900        0.0024             nan     0.4136   -0.0001
   920        0.0021             nan     0.4136   -0.0001
   940        0.0020             nan     0.4136   -0.0001
   960        0.0017             nan     0.4136   -0.0000
   980        0.0016             nan     0.4136   -0.0000
  1000        0.0014             nan     0.4136   -0.0001
  1020        0.0012             nan     0.4136   -0.0000
  1024        0.0012             nan     0.4136   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9910             nan     0.4240   -0.0284
     2        0.9764             nan     0.4240   -0.0348
     3        0.9413             nan     0.4240   -0.0197
     4        0.9202             nan     0.4240   -0.0512
     5        0.8874             nan     0.4240   -0.0435
     6        0.8715             nan     0.4240   -0.0371
     7        0.8474             nan     0.4240   -0.0206
     8        0.8449             nan     0.4240   -0.0482
     9        0.8392             nan     0.4240   -0.0502
    10        0.8250             nan     0.4240   -0.0447
    20        0.6440             nan     0.4240   -0.0330
    40        0.4505             nan     0.4240   -0.0233
    60        0.3148             nan     0.4240   -0.0195
    80        0.2083             nan     0.4240   -0.0079
   100        0.1514             nan     0.4240   -0.0036
   120        0.1100             nan     0.4240   -0.0047
   140        0.0824             nan     0.4240   -0.0048
   160        0.0630             nan     0.4240   -0.0016
   180        0.0464             nan     0.4240   -0.0025
   200        0.0325             nan     0.4240   -0.0010
   220        0.0252             nan     0.4240   -0.0017
   240        0.0189             nan     0.4240   -0.0007
   260        0.0145             nan     0.4240   -0.0007
   280        0.0107             nan     0.4240   -0.0006
   300        0.0080             nan     0.4240   -0.0005
   320        0.0061             nan     0.4240   -0.0003
   340        0.0047             nan     0.4240   -0.0005
   360        0.0037             nan     0.4240   -0.0002
   380        0.0029             nan     0.4240   -0.0001
   400        0.0021             nan     0.4240   -0.0000
   420        0.0017             nan     0.4240   -0.0001
   440        0.0013             nan     0.4240   -0.0001
   460        0.0009             nan     0.4240   -0.0000
   480        0.0007             nan     0.4240   -0.0000
   500        0.0006             nan     0.4240   -0.0000
   520        0.0004             nan     0.4240   -0.0000
   540        0.0003             nan     0.4240   -0.0000
   560        0.0002             nan     0.4240   -0.0000
   580        0.0002             nan     0.4240   -0.0000
   600        0.0001             nan     0.4240   -0.0000
   620        0.0001             nan     0.4240   -0.0000
   640        0.0001             nan     0.4240   -0.0000
   660        0.0001             nan     0.4240   -0.0000
   680        0.0000             nan     0.4240   -0.0000
   700        0.0000             nan     0.4240   -0.0000
   720        0.0000             nan     0.4240   -0.0000
   740        0.0000             nan     0.4240   -0.0000
   760        0.0000             nan     0.4240   -0.0000
   780        0.0000             nan     0.4240   -0.0000
   800        0.0000             nan     0.4240   -0.0000
   820        0.0000             nan     0.4240   -0.0000
   840        0.0000             nan     0.4240   -0.0000
   860        0.0000             nan     0.4240   -0.0000
   880        0.0000             nan     0.4240   -0.0000
   900        0.0000             nan     0.4240   -0.0000
   920        0.0000             nan     0.4240   -0.0000
   940        0.0000             nan     0.4240   -0.0000
   960        0.0000             nan     0.4240   -0.0000
   980        0.0000             nan     0.4240   -0.0000
  1000        0.0000             nan     0.4240   -0.0000
  1020        0.0000             nan     0.4240   -0.0000
  1040        0.0000             nan     0.4240   -0.0000
  1060        0.0000             nan     0.4240   -0.0000
  1080        0.0000             nan     0.4240   -0.0000
  1100        0.0000             nan     0.4240   -0.0000
  1120        0.0000             nan     0.4240   -0.0000
  1140        0.0000             nan     0.4240   -0.0000
  1160        0.0000             nan     0.4240   -0.0000
  1180        0.0000             nan     0.4240   -0.0000
  1200        0.0000             nan     0.4240   -0.0000
  1220        0.0000             nan     0.4240   -0.0000
  1240        0.0000             nan     0.4240   -0.0000
  1260        0.0000             nan     0.4240   -0.0000
  1280        0.0000             nan     0.4240   -0.0000
  1300        0.0000             nan     0.4240   -0.0000
  1320        0.0000             nan     0.4240   -0.0000
  1340        0.0000             nan     0.4240   -0.0000
  1360        0.0000             nan     0.4240   -0.0000
  1380        0.0000             nan     0.4240   -0.0000
  1400        0.0000             nan     0.4240   -0.0000
  1420        0.0000             nan     0.4240   -0.0000
  1440        0.0000             nan     0.4240   -0.0000
  1460        0.0000             nan     0.4240   -0.0000
  1480        0.0000             nan     0.4240   -0.0000
  1500        0.0000             nan     0.4240   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9965             nan     0.4738   -0.0155
     2        0.9636             nan     0.4738   -0.0101
     3        0.9404             nan     0.4738   -0.0396
     4        0.9082             nan     0.4738   -0.0466
     5        0.8967             nan     0.4738   -0.0570
     6        0.8687             nan     0.4738   -0.0218
     7        0.8512             nan     0.4738   -0.0183
     8        0.8374             nan     0.4738   -0.0661
     9        0.8151             nan     0.4738   -0.0292
    10        0.7941             nan     0.4738   -0.0478
    20        0.6187             nan     0.4738   -0.0430
    40        0.4027             nan     0.4738   -0.0301
    60        0.2963             nan     0.4738   -0.0062
    80        0.2146             nan     0.4738   -0.0098
   100        0.1546             nan     0.4738   -0.0064
   120        0.1097             nan     0.4738   -0.0086
   140        0.0810             nan     0.4738   -0.0038
   160        0.0584             nan     0.4738   -0.0022
   180        0.0445             nan     0.4738   -0.0014
   200        0.0342             nan     0.4738   -0.0019
   220        0.0262             nan     0.4738   -0.0019
   240        0.0200             nan     0.4738   -0.0013
   260        0.0149             nan     0.4738   -0.0004
   280        0.0107             nan     0.4738   -0.0005
   300        0.0077             nan     0.4738   -0.0006
   320        0.0059             nan     0.4738   -0.0003
   340        0.0045             nan     0.4738   -0.0003
   360        0.0033             nan     0.4738   -0.0002
   380        0.0024             nan     0.4738   -0.0002
   400        0.0018             nan     0.4738   -0.0001
   420        0.0014             nan     0.4738   -0.0001
   440        0.0010             nan     0.4738   -0.0001
   460        0.0008             nan     0.4738   -0.0000
   480        0.0005             nan     0.4738   -0.0000
   500        0.0004             nan     0.4738   -0.0000
   520        0.0003             nan     0.4738   -0.0000
   540        0.0002             nan     0.4738   -0.0000
   560        0.0002             nan     0.4738   -0.0000
   580        0.0001             nan     0.4738   -0.0000
   600        0.0001             nan     0.4738   -0.0000
   620        0.0001             nan     0.4738   -0.0000
   640        0.0001             nan     0.4738   -0.0000
   660        0.0000             nan     0.4738   -0.0000
   680        0.0000             nan     0.4738   -0.0000
   700        0.0000             nan     0.4738   -0.0000
   720        0.0000             nan     0.4738   -0.0000
   740        0.0000             nan     0.4738   -0.0000
   760        0.0000             nan     0.4738   -0.0000
   780        0.0000             nan     0.4738   -0.0000
   800        0.0000             nan     0.4738   -0.0000
   820        0.0000             nan     0.4738   -0.0000
   840        0.0000             nan     0.4738   -0.0000
   860        0.0000             nan     0.4738   -0.0000
   880        0.0000             nan     0.4738   -0.0000
   900        0.0000             nan     0.4738   -0.0000
   920        0.0000             nan     0.4738   -0.0000
   940        0.0000             nan     0.4738   -0.0000
   960        0.0000             nan     0.4738   -0.0000
   980        0.0000             nan     0.4738   -0.0000
  1000        0.0000             nan     0.4738   -0.0000
  1020        0.0000             nan     0.4738   -0.0000
  1040        0.0000             nan     0.4738   -0.0000
  1060        0.0000             nan     0.4738   -0.0000
  1080        0.0000             nan     0.4738   -0.0000
  1100        0.0000             nan     0.4738   -0.0000
  1120        0.0000             nan     0.4738   -0.0000
  1140        0.0000             nan     0.4738   -0.0000
  1160        0.0000             nan     0.4738   -0.0000
  1180        0.0000             nan     0.4738   -0.0000
  1200        0.0000             nan     0.4738   -0.0000
  1220        0.0000             nan     0.4738   -0.0000
  1240        0.0000             nan     0.4738   -0.0000
  1260        0.0000             nan     0.4738   -0.0000
  1280        0.0000             nan     0.4738   -0.0000
  1300        0.0000             nan     0.4738   -0.0000
  1320        0.0000             nan     0.4738   -0.0000
  1340        0.0000             nan     0.4738   -0.0000
  1360        0.0000             nan     0.4738   -0.0000
  1380        0.0000             nan     0.4738   -0.0000
  1400        0.0000             nan     0.4738   -0.0000
  1420        0.0000             nan     0.4738   -0.0000
  1440        0.0000             nan     0.4738   -0.0000
  1460        0.0000             nan     0.4738   -0.0000
  1480        0.0000             nan     0.4738   -0.0000
  1500        0.0000             nan     0.4738   -0.0000
  1520        0.0000             nan     0.4738   -0.0000
  1540        0.0000             nan     0.4738   -0.0000
  1560        0.0000             nan     0.4738   -0.0000
  1580        0.0000             nan     0.4738   -0.0000
  1600        0.0000             nan     0.4738   -0.0000
  1620        0.0000             nan     0.4738   -0.0000
  1640        0.0000             nan     0.4738   -0.0000
  1660        0.0000             nan     0.4738   -0.0000
  1680        0.0000             nan     0.4738   -0.0000
  1700        0.0000             nan     0.4738   -0.0000
  1720        0.0000             nan     0.4738   -0.0000
  1740        0.0000             nan     0.4738   -0.0000
  1760        0.0000             nan     0.4738   -0.0000
  1780        0.0000             nan     0.4738   -0.0000
  1800        0.0000             nan     0.4738   -0.0000
  1820        0.0000             nan     0.4738   -0.0000
  1840        0.0000             nan     0.4738   -0.0000
  1860        0.0000             nan     0.4738   -0.0000
  1880        0.0000             nan     0.4738   -0.0000
  1900        0.0000             nan     0.4738   -0.0000
  1920        0.0000             nan     0.4738   -0.0000
  1940        0.0000             nan     0.4738   -0.0000
  1960        0.0000             nan     0.4738   -0.0000
  1980        0.0000             nan     0.4738   -0.0000
  2000        0.0000             nan     0.4738   -0.0000
  2020        0.0000             nan     0.4738   -0.0000
  2040        0.0000             nan     0.4738   -0.0000
  2060        0.0000             nan     0.4738   -0.0000
  2080        0.0000             nan     0.4738   -0.0000
  2100        0.0000             nan     0.4738   -0.0000
  2120        0.0000             nan     0.4738   -0.0000
  2140        0.0000             nan     0.4738   -0.0000
  2160        0.0000             nan     0.4738   -0.0000
  2180        0.0000             nan     0.4738   -0.0000
  2200        0.0000             nan     0.4738   -0.0000
  2220        0.0000             nan     0.4738   -0.0000
  2240        0.0000             nan     0.4738   -0.0000
  2260        0.0000             nan     0.4738   -0.0000
  2280        0.0000             nan     0.4738   -0.0000
  2300        0.0000             nan     0.4738   -0.0000
  2320        0.0000             nan     0.4738   -0.0000
  2340        0.0000             nan     0.4738   -0.0000
  2360        0.0000             nan     0.4738   -0.0000
  2380        0.0000             nan     0.4738   -0.0000
  2400        0.0000             nan     0.4738   -0.0000
  2420        0.0000             nan     0.4738   -0.0000
  2440        0.0000             nan     0.4738   -0.0000
  2460        0.0000             nan     0.4738   -0.0000
  2480        0.0000             nan     0.4738   -0.0000
  2500        0.0000             nan     0.4738   -0.0000
  2520        0.0000             nan     0.4738   -0.0000
  2540        0.0000             nan     0.4738   -0.0000
  2560        0.0000             nan     0.4738   -0.0000
  2580        0.0000             nan     0.4738   -0.0000
  2600        0.0000             nan     0.4738   -0.0000
  2620        0.0000             nan     0.4738   -0.0000
  2640        0.0000             nan     0.4738   -0.0000
  2660        0.0000             nan     0.4738   -0.0000
  2680        0.0000             nan     0.4738   -0.0000
  2700        0.0000             nan     0.4738   -0.0000
  2720        0.0000             nan     0.4738   -0.0000
  2740        0.0000             nan     0.4738   -0.0000
  2760        0.0000             nan     0.4738   -0.0000
  2780        0.0000             nan     0.4738   -0.0000
  2800        0.0000             nan     0.4738   -0.0000
  2820        0.0000             nan     0.4738   -0.0000
  2840        0.0000             nan     0.4738   -0.0000
  2860        0.0000             nan     0.4738   -0.0000
  2880        0.0000             nan     0.4738   -0.0000
  2900        0.0000             nan     0.4738   -0.0000
  2920        0.0000             nan     0.4738   -0.0000
  2940        0.0000             nan     0.4738   -0.0000
  2960        0.0000             nan     0.4738   -0.0000
  2980        0.0000             nan     0.4738   -0.0000
  3000        0.0000             nan     0.4738   -0.0000
  3020        0.0000             nan     0.4738   -0.0000
  3040        0.0000             nan     0.4738   -0.0000
  3060        0.0000             nan     0.4738   -0.0000
  3080        0.0000             nan     0.4738   -0.0000
  3100        0.0000             nan     0.4738   -0.0000
  3120        0.0000             nan     0.4738   -0.0000
  3140        0.0000             nan     0.4738   -0.0000
  3160        0.0000             nan     0.4738   -0.0000
  3180        0.0000             nan     0.4738   -0.0000
  3200        0.0000             nan     0.4738   -0.0000
  3220        0.0000             nan     0.4738   -0.0000
  3240        0.0000             nan     0.4738   -0.0000
  3260        0.0000             nan     0.4738   -0.0000
  3280        0.0000             nan     0.4738   -0.0000
  3300        0.0000             nan     0.4738   -0.0000
  3320        0.0000             nan     0.4738   -0.0000
  3340        0.0000             nan     0.4738   -0.0000
  3360        0.0000             nan     0.4738   -0.0000
  3380        0.0000             nan     0.4738   -0.0000
  3400        0.0000             nan     0.4738   -0.0000
  3420        0.0000             nan     0.4738   -0.0000
  3440        0.0000             nan     0.4738   -0.0000
  3460        0.0000             nan     0.4738   -0.0000
  3480        0.0000             nan     0.4738   -0.0000
  3500        0.0000             nan     0.4738   -0.0000
  3520        0.0000             nan     0.4738   -0.0000
  3540        0.0000             nan     0.4738   -0.0000
  3560        0.0000             nan     0.4738   -0.0000
  3580        0.0000             nan     0.4738   -0.0000
  3600        0.0000             nan     0.4738   -0.0000
  3620        0.0000             nan     0.4738   -0.0000
  3640        0.0000             nan     0.4738   -0.0000
  3660        0.0000             nan     0.4738   -0.0000
  3680        0.0000             nan     0.4738   -0.0000
  3700        0.0000             nan     0.4738   -0.0000
  3720        0.0000             nan     0.4738   -0.0000
  3740        0.0000             nan     0.4738   -0.0000
  3760        0.0000             nan     0.4738   -0.0000
  3780        0.0000             nan     0.4738   -0.0000
  3800        0.0000             nan     0.4738   -0.0000
  3820        0.0000             nan     0.4738   -0.0000
  3840        0.0000             nan     0.4738   -0.0000
  3860        0.0000             nan     0.4738   -0.0000
  3880        0.0000             nan     0.4738   -0.0000
  3900        0.0000             nan     0.4738   -0.0000
  3920        0.0000             nan     0.4738   -0.0000
  3940        0.0000             nan     0.4738   -0.0000
  3960        0.0000             nan     0.4738   -0.0000
  3980        0.0000             nan     0.4738   -0.0000
  4000        0.0000             nan     0.4738   -0.0000
  4020        0.0000             nan     0.4738   -0.0000
  4040        0.0000             nan     0.4738   -0.0000
  4060        0.0000             nan     0.4738   -0.0000
  4080        0.0000             nan     0.4738   -0.0000
  4100        0.0000             nan     0.4738   -0.0000
  4120        0.0000             nan     0.4738   -0.0000
  4129        0.0000             nan     0.4738   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9738             nan     0.5391   -0.0672
     2        0.9218             nan     0.5391   -0.0353
     3        0.9040             nan     0.5391   -0.1117
     4        0.8582             nan     0.5391   -0.0651
     5        0.8330             nan     0.5391   -0.0669
     6        0.8274             nan     0.5391   -0.0988
     7        0.7992             nan     0.5391   -0.0954
     8        0.7718             nan     0.5391   -0.0593
     9        0.7289             nan     0.5391   -0.0670
    10        0.6855             nan     0.5391   -0.0537
    20        0.4593             nan     0.5391   -0.0384
    40        0.1961             nan     0.5391   -0.0146
    60        0.0991             nan     0.5391   -0.0152
    80        0.0542             nan     0.5391   -0.0043
   100        0.0254             nan     0.5391   -0.0022
   120        0.0139             nan     0.5391   -0.0019
   140        0.0075             nan     0.5391   -0.0010
   160        0.0039             nan     0.5391   -0.0004
   180        0.0020             nan     0.5391   -0.0002
   200        0.0010             nan     0.5391   -0.0001
   220        0.0005             nan     0.5391   -0.0001
   240        0.0003             nan     0.5391   -0.0000
   260        0.0001             nan     0.5391   -0.0000
   280        0.0001             nan     0.5391   -0.0000
   300        0.0000             nan     0.5391   -0.0000
   320        0.0000             nan     0.5391   -0.0000
   340        0.0000             nan     0.5391   -0.0000
   360        0.0000             nan     0.5391   -0.0000
   380        0.0000             nan     0.5391   -0.0000
   400        0.0000             nan     0.5391   -0.0000
   420        0.0000             nan     0.5391   -0.0000
   440        0.0000             nan     0.5391   -0.0000
   460        0.0000             nan     0.5391   -0.0000
   480        0.0000             nan     0.5391   -0.0000
   500        0.0000             nan     0.5391   -0.0000
   520        0.0000             nan     0.5391   -0.0000
   540        0.0000             nan     0.5391   -0.0000
   560        0.0000             nan     0.5391   -0.0000
   580        0.0000             nan     0.5391   -0.0000
   600        0.0000             nan     0.5391   -0.0000
   620        0.0000             nan     0.5391   -0.0000
   640        0.0000             nan     0.5391   -0.0000
   660        0.0000             nan     0.5391   -0.0000
   680        0.0000             nan     0.5391   -0.0000
   700        0.0000             nan     0.5391   -0.0000
   720        0.0000             nan     0.5391   -0.0000
   740        0.0000             nan     0.5391   -0.0000
   760        0.0000             nan     0.5391   -0.0000
   780        0.0000             nan     0.5391   -0.0000
   800        0.0000             nan     0.5391   -0.0000
   820        0.0000             nan     0.5391   -0.0000
   840        0.0000             nan     0.5391   -0.0000
   860        0.0000             nan     0.5391   -0.0000
   880        0.0000             nan     0.5391   -0.0000
   900        0.0000             nan     0.5391   -0.0000
   920        0.0000             nan     0.5391   -0.0000
   940        0.0000             nan     0.5391   -0.0000
   960        0.0000             nan     0.5391   -0.0000
   980        0.0000             nan     0.5391   -0.0000
  1000        0.0000             nan     0.5391   -0.0000
  1020        0.0000             nan     0.5391   -0.0000
  1040        0.0000             nan     0.5391   -0.0000
  1060        0.0000             nan     0.5391   -0.0000
  1080        0.0000             nan     0.5391   -0.0000
  1100        0.0000             nan     0.5391   -0.0000
  1120        0.0000             nan     0.5391   -0.0000
  1140        0.0000             nan     0.5391   -0.0000
  1160        0.0000             nan     0.5391   -0.0000
  1180        0.0000             nan     0.5391   -0.0000
  1200        0.0000             nan     0.5391   -0.0000
  1220        0.0000             nan     0.5391   -0.0000
  1240        0.0000             nan     0.5391   -0.0000
  1260        0.0000             nan     0.5391   -0.0000
  1280        0.0000             nan     0.5391   -0.0000
  1300        0.0000             nan     0.5391   -0.0000
  1320        0.0000             nan     0.5391   -0.0000
  1340        0.0000             nan     0.5391   -0.0000
  1360        0.0000             nan     0.5391   -0.0000
  1380        0.0000             nan     0.5391   -0.0000
  1400        0.0000             nan     0.5391   -0.0000
  1420        0.0000             nan     0.5391   -0.0000
  1440        0.0000             nan     0.5391   -0.0000
  1460        0.0000             nan     0.5391   -0.0000
  1480        0.0000             nan     0.5391   -0.0000
  1500        0.0000             nan     0.5391   -0.0000
  1520        0.0000             nan     0.5391   -0.0000
  1540        0.0000             nan     0.5391   -0.0000
  1560        0.0000             nan     0.5391   -0.0000
  1580        0.0000             nan     0.5391   -0.0000
  1600        0.0000             nan     0.5391   -0.0000
  1620        0.0000             nan     0.5391   -0.0000
  1640        0.0000             nan     0.5391   -0.0000
  1660        0.0000             nan     0.5391   -0.0000
  1680        0.0000             nan     0.5391   -0.0000
  1700        0.0000             nan     0.5391   -0.0000
  1720        0.0000             nan     0.5391   -0.0000
  1740        0.0000             nan     0.5391   -0.0000
  1760        0.0000             nan     0.5391   -0.0000
  1780        0.0000             nan     0.5391   -0.0000
  1784        0.0000             nan     0.5391   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0004             nan     0.5600   -0.0365
     2        0.9992             nan     0.5600   -0.0669
     3        0.9850             nan     0.5600   -0.0290
     4        0.9789             nan     0.5600   -0.0619
     5        0.9602             nan     0.5600   -0.0165
     6        0.9387             nan     0.5600   -0.0302
     7        0.9160             nan     0.5600   -0.0186
     8        0.9040             nan     0.5600   -0.0371
     9        0.8845             nan     0.5600   -0.0519
    10        0.8708             nan     0.5600   -0.0240
    20        0.7505             nan     0.5600   -0.0294
    40        0.5876             nan     0.5600   -0.0429
    60        0.4574             nan     0.5600   -0.0268
    80        0.4192             nan     0.5600   -0.0283
   100        0.3180             nan     0.5600   -0.0160
   120        0.2649             nan     0.5600   -0.0065
   140        0.2218             nan     0.5600   -0.0214
   160        0.1837             nan     0.5600   -0.0108
   180        0.1533             nan     0.5600   -0.0016
   200        0.1290             nan     0.5600   -0.0084
   220        0.1021             nan     0.5600   -0.0055
   240        0.0882             nan     0.5600   -0.0055
   260        0.0732             nan     0.5600   -0.0034
   280        0.0602             nan     0.5600   -0.0052
   300        0.0527             nan     0.5600   -0.0033
   320        0.0441             nan     0.5600   -0.0041
   340        0.0354             nan     0.5600   -0.0019
   360        0.0306             nan     0.5600   -0.0019
   380        0.0256             nan     0.5600   -0.0008
   400        0.0212             nan     0.5600   -0.0004
   420        0.0178             nan     0.5600   -0.0005
   440        0.0139             nan     0.5600   -0.0002
   460        0.0115             nan     0.5600   -0.0004
   480        0.0095             nan     0.5600   -0.0002
   500        0.0079             nan     0.5600   -0.0002
   520        0.0064             nan     0.5600   -0.0001
   540        0.0053             nan     0.5600   -0.0001
   560        0.0046             nan     0.5600   -0.0001
   580        0.0041             nan     0.5600   -0.0003
   600        0.0034             nan     0.5600   -0.0001
   620        0.0028             nan     0.5600   -0.0001
   640        0.0023             nan     0.5600   -0.0001
   660        0.0019             nan     0.5600   -0.0001
   680        0.0017             nan     0.5600   -0.0001
   700        0.0014             nan     0.5600   -0.0001
   720        0.0011             nan     0.5600   -0.0001
   740        0.0010             nan     0.5600   -0.0001
   760        0.0008             nan     0.5600   -0.0000
   780        0.0007             nan     0.5600   -0.0000
   800        0.0006             nan     0.5600   -0.0000
   820        0.0005             nan     0.5600   -0.0000
   840        0.0004             nan     0.5600   -0.0000
   860        0.0004             nan     0.5600   -0.0000
   880        0.0003             nan     0.5600   -0.0000
   900        0.0002             nan     0.5600   -0.0000
   920        0.0002             nan     0.5600   -0.0000
   940        0.0002             nan     0.5600    0.0000
   960        0.0001             nan     0.5600   -0.0000
   980        0.0001             nan     0.5600   -0.0000
  1000        0.0001             nan     0.5600   -0.0000
  1020        0.0001             nan     0.5600   -0.0000
  1040        0.0001             nan     0.5600   -0.0000
  1060        0.0001             nan     0.5600   -0.0000
  1080        0.0001             nan     0.5600   -0.0000
  1100        0.0000             nan     0.5600   -0.0000
  1120        0.0000             nan     0.5600   -0.0000
  1140        0.0000             nan     0.5600   -0.0000
  1160        0.0000             nan     0.5600   -0.0000
  1180        0.0000             nan     0.5600   -0.0000
  1200        0.0000             nan     0.5600   -0.0000
  1220        0.0000             nan     0.5600   -0.0000
  1240        0.0000             nan     0.5600   -0.0000
  1260        0.0000             nan     0.5600   -0.0000
  1280        0.0000             nan     0.5600   -0.0000
  1300        0.0000             nan     0.5600   -0.0000
  1320        0.0000             nan     0.5600   -0.0000
  1340        0.0000             nan     0.5600   -0.0000
  1360        0.0000             nan     0.5600   -0.0000
  1380        0.0000             nan     0.5600   -0.0000
  1400        0.0000             nan     0.5600   -0.0000
  1420        0.0000             nan     0.5600   -0.0000
  1440        0.0000             nan     0.5600   -0.0000
  1460        0.0000             nan     0.5600   -0.0000
  1480        0.0000             nan     0.5600   -0.0000
  1500        0.0000             nan     0.5600   -0.0000
  1520        0.0000             nan     0.5600    0.0000
  1540        0.0000             nan     0.5600   -0.0000
  1560        0.0000             nan     0.5600   -0.0000
  1580        0.0000             nan     0.5600   -0.0000
  1600        0.0000             nan     0.5600   -0.0000
  1620        0.0000             nan     0.5600   -0.0000
  1640        0.0000             nan     0.5600   -0.0000
  1660        0.0000             nan     0.5600   -0.0000
  1680        0.0000             nan     0.5600   -0.0000
  1700        0.0000             nan     0.5600   -0.0000
  1720        0.0000             nan     0.5600   -0.0000
  1740        0.0000             nan     0.5600   -0.0000
  1760        0.0000             nan     0.5600   -0.0000
  1780        0.0000             nan     0.5600   -0.0000
  1800        0.0000             nan     0.5600   -0.0000
  1820        0.0000             nan     0.5600   -0.0000
  1840        0.0000             nan     0.5600   -0.0000
  1860        0.0000             nan     0.5600   -0.0000
  1880        0.0000             nan     0.5600   -0.0000
  1900        0.0000             nan     0.5600   -0.0000
  1920        0.0000             nan     0.5600   -0.0000
  1940        0.0000             nan     0.5600   -0.0000
  1960        0.0000             nan     0.5600   -0.0000
  1980        0.0000             nan     0.5600   -0.0000
  2000        0.0000             nan     0.5600   -0.0000
  2020        0.0000             nan     0.5600   -0.0000
  2040        0.0000             nan     0.5600   -0.0000
  2060        0.0000             nan     0.5600   -0.0000
  2080        0.0000             nan     0.5600   -0.0000
  2100        0.0000             nan     0.5600   -0.0000
  2120        0.0000             nan     0.5600   -0.0000
  2140        0.0000             nan     0.5600   -0.0000
  2160        0.0000             nan     0.5600   -0.0000
  2180        0.0000             nan     0.5600   -0.0000
  2200        0.0000             nan     0.5600   -0.0000
  2220        0.0000             nan     0.5600   -0.0000
  2240        0.0000             nan     0.5600   -0.0000
  2260        0.0000             nan     0.5600   -0.0000
  2280        0.0000             nan     0.5600   -0.0000
  2300        0.0000             nan     0.5600   -0.0000
  2320        0.0000             nan     0.5600   -0.0000
  2340        0.0000             nan     0.5600   -0.0000
  2360        0.0000             nan     0.5600   -0.0000
  2380        0.0000             nan     0.5600   -0.0000
  2400        0.0000             nan     0.5600   -0.0000
  2420        0.0000             nan     0.5600   -0.0000
  2440        0.0000             nan     0.5600   -0.0000
  2460        0.0000             nan     0.5600   -0.0000
  2480        0.0000             nan     0.5600   -0.0000
  2500        0.0000             nan     0.5600    0.0000
  2510        0.0000             nan     0.5600   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        1.0301             nan     0.5758   -0.0415
     2        1.0278             nan     0.5758   -0.0342
     3        1.0214             nan     0.5758   -0.0139
     4        1.0199             nan     0.5758   -0.0217
     5        1.0159             nan     0.5758   -0.0232
     6        1.0155             nan     0.5758   -0.0256
     7        1.0085             nan     0.5758   -0.0109
     8        1.0021             nan     0.5758   -0.0211
     9        0.9975             nan     0.5758   -0.0052
    10        0.9932             nan     0.5758   -0.0044
    20        0.9688             nan     0.5758   -0.0217
    40        0.9061             nan     0.5758   -0.0288
    60        0.8803             nan     0.5758   -0.0269
    80        0.8444             nan     0.5758   -0.0297
   100        0.7997             nan     0.5758   -0.0065
   120        0.7475             nan     0.5758   -0.0040
   140        0.7266             nan     0.5758   -0.0089
   160        0.7010             nan     0.5758   -0.0127
   180        0.6682             nan     0.5758   -0.0153
   200        0.6407             nan     0.5758   -0.0062
   220        0.6154             nan     0.5758   -0.0011
   240        0.6094             nan     0.5758   -0.0095
   260        0.5984             nan     0.5758   -0.0241
   280        0.5720             nan     0.5758   -0.0104
   300        0.5557             nan     0.5758   -0.0150
   320        0.5379             nan     0.5758   -0.0157
   340        0.5328             nan     0.5758   -0.0128
   360        0.5106             nan     0.5758   -0.0168
   380        0.4877             nan     0.5758   -0.0052
   400        0.4863             nan     0.5758   -0.0273
   420        0.4678             nan     0.5758   -0.0081
   440        0.4599             nan     0.5758   -0.0133
   460        0.4454             nan     0.5758   -0.0050
   480        0.4350             nan     0.5758   -0.0167
   500        0.4267             nan     0.5758   -0.0203
   520        0.4225             nan     0.5758   -0.0087
   540        0.4170             nan     0.5758   -0.0122
   560        0.4029             nan     0.5758   -0.0023
   580        0.3868             nan     0.5758   -0.0127
   600        0.3726             nan     0.5758    0.0017
   620        0.3654             nan     0.5758   -0.0088
   640        0.3564             nan     0.5758   -0.0196
   660        0.3477             nan     0.5758   -0.0102
   680        0.3354             nan     0.5758   -0.0105
   700        0.3296             nan     0.5758   -0.0070
   720        0.3167             nan     0.5758   -0.0090
   740        0.3057             nan     0.5758   -0.0047
   760        0.3006             nan     0.5758   -0.0063
   780        0.2926             nan     0.5758   -0.0099
   800        0.2887             nan     0.5758   -0.0055
   820        0.2782             nan     0.5758   -0.0072
   840        0.2725             nan     0.5758   -0.0036
   860        0.2694             nan     0.5758   -0.0012
   880        0.2660             nan     0.5758   -0.0038
   900        0.2620             nan     0.5758    0.0011
   920        0.2535             nan     0.5758   -0.0145
   940        0.2462             nan     0.5758   -0.0029
   960        0.2407             nan     0.5758   -0.0050
   980        0.2334             nan     0.5758   -0.0064
  1000        0.2267             nan     0.5758   -0.0014
  1020        0.2179             nan     0.5758   -0.0021
  1040        0.2177             nan     0.5758   -0.0019
  1060        0.2155             nan     0.5758   -0.0033
  1080        0.2101             nan     0.5758   -0.0074
  1100        0.2038             nan     0.5758   -0.0020
  1120        0.2003             nan     0.5758   -0.0082
  1140        0.1935             nan     0.5758   -0.0048
  1160        0.1870             nan     0.5758   -0.0046
  1180        0.1817             nan     0.5758   -0.0033
  1200        0.1821             nan     0.5758   -0.0050
  1220        0.1792             nan     0.5758   -0.0063
  1240        0.1783             nan     0.5758   -0.0044
  1260        0.1720             nan     0.5758   -0.0030
  1280        0.1655             nan     0.5758   -0.0029
  1300        0.1624             nan     0.5758   -0.0050
  1320        0.1582             nan     0.5758   -0.0025
  1340        0.1551             nan     0.5758   -0.0039
  1360        0.1520             nan     0.5758   -0.0033
  1380        0.1481             nan     0.5758   -0.0023
  1400        0.1437             nan     0.5758   -0.0032
  1420        0.1395             nan     0.5758   -0.0019
  1440        0.1372             nan     0.5758   -0.0040
  1460        0.1352             nan     0.5758   -0.0020
  1480        0.1338             nan     0.5758   -0.0039
  1500        0.1303             nan     0.5758   -0.0059
  1520        0.1280             nan     0.5758   -0.0014
  1540        0.1245             nan     0.5758   -0.0040
  1560        0.1209             nan     0.5758   -0.0052
  1580        0.1162             nan     0.5758   -0.0021
  1600        0.1144             nan     0.5758   -0.0023
  1620        0.1119             nan     0.5758   -0.0014
  1640        0.1118             nan     0.5758   -0.0044
  1660        0.1080             nan     0.5758   -0.0023
  1680        0.1064             nan     0.5758   -0.0010
  1700        0.1045             nan     0.5758   -0.0025
  1720        0.1038             nan     0.5758   -0.0034
  1740        0.0991             nan     0.5758   -0.0008
  1760        0.0983             nan     0.5758   -0.0026
  1780        0.0959             nan     0.5758   -0.0048
  1800        0.0925             nan     0.5758    0.0005
  1820        0.0901             nan     0.5758   -0.0016
  1840        0.0895             nan     0.5758   -0.0008
  1860        0.0874             nan     0.5758   -0.0022
  1880        0.0870             nan     0.5758   -0.0026
  1900        0.0835             nan     0.5758   -0.0020
  1920        0.0841             nan     0.5758   -0.0009
  1940        0.0815             nan     0.5758   -0.0008
  1960        0.0804             nan     0.5758   -0.0011
  1980        0.0783             nan     0.5758   -0.0012
  2000        0.0768             nan     0.5758   -0.0013
  2020        0.0748             nan     0.5758   -0.0017
  2040        0.0743             nan     0.5758   -0.0012
  2060        0.0726             nan     0.5758   -0.0011
  2080        0.0705             nan     0.5758   -0.0027
  2100        0.0683             nan     0.5758   -0.0019
  2120        0.0664             nan     0.5758   -0.0010
  2140        0.0652             nan     0.5758   -0.0015
  2160        0.0642             nan     0.5758   -0.0019
  2180        0.0623             nan     0.5758   -0.0014
  2200        0.0608             nan     0.5758   -0.0008
  2220        0.0600             nan     0.5758   -0.0017
  2240        0.0599             nan     0.5758   -0.0009
  2260        0.0584             nan     0.5758   -0.0012
  2280        0.0573             nan     0.5758   -0.0012
  2300        0.0555             nan     0.5758   -0.0004
  2320        0.0544             nan     0.5758   -0.0010
  2340        0.0523             nan     0.5758   -0.0004
  2360        0.0516             nan     0.5758   -0.0019
  2380        0.0498             nan     0.5758   -0.0001
  2400        0.0487             nan     0.5758   -0.0009
  2420        0.0482             nan     0.5758   -0.0009
  2440        0.0472             nan     0.5758   -0.0004
  2460        0.0463             nan     0.5758   -0.0010
  2480        0.0461             nan     0.5758   -0.0022
  2500        0.0452             nan     0.5758   -0.0005
  2520        0.0442             nan     0.5758   -0.0015
  2540        0.0436             nan     0.5758   -0.0011
  2560        0.0424             nan     0.5758   -0.0016
  2580        0.0407             nan     0.5758   -0.0007
  2600        0.0405             nan     0.5758   -0.0013
  2620        0.0393             nan     0.5758   -0.0010
  2640        0.0395             nan     0.5758   -0.0009
  2660        0.0390             nan     0.5758   -0.0005
  2680        0.0377             nan     0.5758   -0.0014
  2700        0.0363             nan     0.5758   -0.0006
  2720        0.0362             nan     0.5758   -0.0008
  2740        0.0354             nan     0.5758   -0.0005
  2760        0.0345             nan     0.5758   -0.0008
  2780        0.0348             nan     0.5758   -0.0010
  2800        0.0342             nan     0.5758   -0.0008
  2820        0.0335             nan     0.5758   -0.0004
  2840        0.0327             nan     0.5758   -0.0005
  2860        0.0317             nan     0.5758   -0.0003
  2880        0.0315             nan     0.5758   -0.0007
  2900        0.0313             nan     0.5758   -0.0010
  2920        0.0305             nan     0.5758   -0.0004
  2940        0.0305             nan     0.5758   -0.0009
  2960        0.0300             nan     0.5758   -0.0008
  2980        0.0294             nan     0.5758   -0.0009
  3000        0.0284             nan     0.5758   -0.0002
  3020        0.0282             nan     0.5758   -0.0008
  3040        0.0279             nan     0.5758   -0.0007
  3060        0.0267             nan     0.5758   -0.0007
  3080        0.0262             nan     0.5758   -0.0006
  3100        0.0261             nan     0.5758   -0.0013
  3120        0.0257             nan     0.5758   -0.0009
  3140        0.0249             nan     0.5758   -0.0007
  3160        0.0244             nan     0.5758   -0.0004
  3180        0.0241             nan     0.5758   -0.0009
  3200        0.0234             nan     0.5758   -0.0005
  3220        0.0229             nan     0.5758   -0.0006
  3240        0.0226             nan     0.5758   -0.0002
  3260        0.0224             nan     0.5758   -0.0009
  3280        0.0221             nan     0.5758   -0.0008
  3300        0.0221             nan     0.5758   -0.0010
  3320        0.0210             nan     0.5758   -0.0001
  3340        0.0209             nan     0.5758   -0.0001
  3360        0.0206             nan     0.5758   -0.0005
  3380        0.0204             nan     0.5758   -0.0005
  3400        0.0199             nan     0.5758   -0.0004
  3420        0.0195             nan     0.5758   -0.0005
  3440        0.0191             nan     0.5758   -0.0004
  3460        0.0186             nan     0.5758   -0.0006
  3480        0.0181             nan     0.5758   -0.0001
  3500        0.0181             nan     0.5758   -0.0005
  3520        0.0180             nan     0.5758   -0.0007
  3540        0.0177             nan     0.5758   -0.0006
  3560        0.0172             nan     0.5758   -0.0001
  3580        0.0169             nan     0.5758   -0.0005
  3600        0.0167             nan     0.5758   -0.0004
  3620        0.0165             nan     0.5758   -0.0007
  3640        0.0160             nan     0.5758   -0.0005
  3660        0.0157             nan     0.5758   -0.0002
  3680        0.0155             nan     0.5758   -0.0006
  3700        0.0154             nan     0.5758   -0.0006
  3720        0.0150             nan     0.5758   -0.0002
  3740        0.0146             nan     0.5758   -0.0002
  3760        0.0142             nan     0.5758   -0.0002
  3780        0.0143             nan     0.5758   -0.0002
  3800        0.0137             nan     0.5758    0.0001
  3820        0.0135             nan     0.5758   -0.0002
  3840        0.0134             nan     0.5758   -0.0005
  3860        0.0129             nan     0.5758   -0.0002
  3880        0.0129             nan     0.5758   -0.0002
  3900        0.0126             nan     0.5758   -0.0001
  3920        0.0125             nan     0.5758   -0.0003
  3940        0.0126             nan     0.5758   -0.0002
  3960        0.0122             nan     0.5758   -0.0003
  3980        0.0121             nan     0.5758   -0.0004
  4000        0.0118             nan     0.5758   -0.0003
  4020        0.0116             nan     0.5758   -0.0002
  4040        0.0113             nan     0.5758   -0.0001
  4060        0.0113             nan     0.5758   -0.0003
  4080        0.0108             nan     0.5758   -0.0002
  4100        0.0107             nan     0.5758    0.0000
  4120        0.0105             nan     0.5758   -0.0002
  4135        0.0105             nan     0.5758   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9740             nan     0.0183   -0.0004
     2        0.9710             nan     0.0183    0.0020
     3        0.9683             nan     0.0183    0.0007
     4        0.9664             nan     0.0183   -0.0010
     5        0.9647             nan     0.0183   -0.0011
     6        0.9615             nan     0.0183    0.0008
     7        0.9585             nan     0.0183    0.0008
     8        0.9568             nan     0.0183   -0.0009
     9        0.9548             nan     0.0183   -0.0005
    10        0.9521             nan     0.0183   -0.0003
    20        0.9315             nan     0.0183   -0.0002
    40        0.8933             nan     0.0183   -0.0013
    60        0.8594             nan     0.0183   -0.0012
    80        0.8295             nan     0.0183   -0.0010
   100        0.8049             nan     0.0183   -0.0008
   120        0.7816             nan     0.0183   -0.0009
   140        0.7584             nan     0.0183   -0.0002
   160        0.7379             nan     0.0183   -0.0013
   180        0.7188             nan     0.0183   -0.0016
   200        0.6996             nan     0.0183   -0.0013
   220        0.6810             nan     0.0183   -0.0012
   240        0.6619             nan     0.0183   -0.0006
   260        0.6461             nan     0.0183   -0.0003
   280        0.6324             nan     0.0183   -0.0014
   300        0.6177             nan     0.0183   -0.0009
   320        0.6030             nan     0.0183   -0.0010
   340        0.5903             nan     0.0183   -0.0009
   360        0.5779             nan     0.0183   -0.0008
   380        0.5640             nan     0.0183   -0.0008
   400        0.5529             nan     0.0183   -0.0004
   420        0.5400             nan     0.0183   -0.0014
   440        0.5283             nan     0.0183   -0.0008
   460        0.5173             nan     0.0183   -0.0008
   480        0.5066             nan     0.0183   -0.0014
   500        0.4958             nan     0.0183   -0.0006
   520        0.4860             nan     0.0183   -0.0009
   540        0.4753             nan     0.0183   -0.0008
   560        0.4665             nan     0.0183   -0.0009
   580        0.4571             nan     0.0183   -0.0010
   600        0.4470             nan     0.0183   -0.0009
   620        0.4380             nan     0.0183   -0.0008
   640        0.4289             nan     0.0183   -0.0004
   660        0.4202             nan     0.0183   -0.0007
   680        0.4115             nan     0.0183   -0.0009
   700        0.4027             nan     0.0183   -0.0006
   720        0.3946             nan     0.0183   -0.0002
   740        0.3861             nan     0.0183   -0.0008
   760        0.3777             nan     0.0183   -0.0007
   780        0.3694             nan     0.0183   -0.0007
   800        0.3626             nan     0.0183   -0.0009
   820        0.3561             nan     0.0183   -0.0007
   840        0.3487             nan     0.0183   -0.0004
   860        0.3420             nan     0.0183   -0.0004
   880        0.3358             nan     0.0183   -0.0005
   900        0.3295             nan     0.0183   -0.0006
   920        0.3232             nan     0.0183   -0.0006
   940        0.3169             nan     0.0183   -0.0004
   960        0.3101             nan     0.0183   -0.0004
   980        0.3045             nan     0.0183   -0.0006
  1000        0.2985             nan     0.0183   -0.0006
  1020        0.2925             nan     0.0183   -0.0004
  1040        0.2871             nan     0.0183   -0.0006
  1060        0.2824             nan     0.0183   -0.0005
  1080        0.2775             nan     0.0183   -0.0006
  1100        0.2724             nan     0.0183   -0.0005
  1120        0.2678             nan     0.0183   -0.0003
  1140        0.2630             nan     0.0183   -0.0005
  1160        0.2584             nan     0.0183   -0.0005
  1180        0.2539             nan     0.0183   -0.0006
  1200        0.2495             nan     0.0183   -0.0006
  1220        0.2454             nan     0.0183   -0.0002
  1240        0.2414             nan     0.0183   -0.0006
  1260        0.2368             nan     0.0183   -0.0004
  1280        0.2324             nan     0.0183   -0.0002
  1300        0.2282             nan     0.0183   -0.0005
  1320        0.2248             nan     0.0183   -0.0004
  1340        0.2211             nan     0.0183   -0.0005
  1360        0.2169             nan     0.0183   -0.0004
  1380        0.2128             nan     0.0183   -0.0003
  1400        0.2091             nan     0.0183   -0.0002
  1420        0.2051             nan     0.0183   -0.0005
  1440        0.2013             nan     0.0183   -0.0002
  1460        0.1977             nan     0.0183   -0.0002
  1480        0.1940             nan     0.0183   -0.0003
  1500        0.1907             nan     0.0183   -0.0003
  1520        0.1875             nan     0.0183   -0.0004
  1540        0.1846             nan     0.0183   -0.0003
  1560        0.1813             nan     0.0183   -0.0004
  1580        0.1782             nan     0.0183   -0.0003
  1600        0.1750             nan     0.0183   -0.0003
  1620        0.1716             nan     0.0183   -0.0002
  1640        0.1688             nan     0.0183   -0.0004
  1660        0.1659             nan     0.0183   -0.0002
  1680        0.1629             nan     0.0183   -0.0002
  1700        0.1602             nan     0.0183   -0.0003
  1720        0.1574             nan     0.0183   -0.0003
  1740        0.1550             nan     0.0183   -0.0003
  1760        0.1522             nan     0.0183   -0.0003
  1780        0.1497             nan     0.0183   -0.0004
  1800        0.1473             nan     0.0183   -0.0003
  1820        0.1451             nan     0.0183   -0.0004
  1840        0.1428             nan     0.0183   -0.0003
  1860        0.1404             nan     0.0183   -0.0002
  1880        0.1383             nan     0.0183   -0.0001
  1900        0.1361             nan     0.0183   -0.0003
  1920        0.1336             nan     0.0183   -0.0002
  1940        0.1316             nan     0.0183   -0.0003
  1960        0.1292             nan     0.0183   -0.0002
  1980        0.1271             nan     0.0183   -0.0002
  2000        0.1253             nan     0.0183   -0.0003
  2020        0.1233             nan     0.0183   -0.0002
  2040        0.1216             nan     0.0183   -0.0002
  2060        0.1195             nan     0.0183   -0.0003
  2080        0.1177             nan     0.0183   -0.0003
  2100        0.1157             nan     0.0183   -0.0002
  2120        0.1138             nan     0.0183   -0.0003
  2140        0.1121             nan     0.0183   -0.0002
  2160        0.1103             nan     0.0183   -0.0002
  2180        0.1089             nan     0.0183   -0.0003
  2200        0.1070             nan     0.0183   -0.0002
  2220        0.1054             nan     0.0183   -0.0003
  2240        0.1038             nan     0.0183   -0.0001
  2260        0.1023             nan     0.0183   -0.0003
  2280        0.1006             nan     0.0183   -0.0003
  2300        0.0989             nan     0.0183   -0.0001
  2320        0.0973             nan     0.0183   -0.0003
  2340        0.0957             nan     0.0183   -0.0002
  2360        0.0942             nan     0.0183   -0.0001
  2380        0.0927             nan     0.0183   -0.0002
  2400        0.0912             nan     0.0183   -0.0001
  2420        0.0898             nan     0.0183   -0.0002
  2440        0.0883             nan     0.0183   -0.0001
  2460        0.0869             nan     0.0183   -0.0002
  2480        0.0856             nan     0.0183   -0.0001
  2500        0.0843             nan     0.0183   -0.0002
  2501        0.0842             nan     0.0183   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9654             nan     0.0626   -0.0045
     2        0.9527             nan     0.0626   -0.0039
     3        0.9444             nan     0.0626   -0.0059
     4        0.9323             nan     0.0626    0.0019
     5        0.9228             nan     0.0626   -0.0036
     6        0.9108             nan     0.0626   -0.0025
     7        0.9001             nan     0.0626   -0.0029
     8        0.8904             nan     0.0626   -0.0034
     9        0.8795             nan     0.0626    0.0008
    10        0.8700             nan     0.0626   -0.0041
    20        0.7849             nan     0.0626   -0.0021
    40        0.6567             nan     0.0626   -0.0032
    60        0.5643             nan     0.0626   -0.0033
    80        0.4837             nan     0.0626   -0.0040
   100        0.4227             nan     0.0626   -0.0038
   120        0.3735             nan     0.0626   -0.0050
   140        0.3272             nan     0.0626   -0.0018
   160        0.2870             nan     0.0626   -0.0029
   180        0.2530             nan     0.0626   -0.0020
   200        0.2214             nan     0.0626   -0.0024
   220        0.1955             nan     0.0626   -0.0015
   240        0.1747             nan     0.0626   -0.0009
   260        0.1576             nan     0.0626   -0.0014
   280        0.1397             nan     0.0626   -0.0017
   300        0.1246             nan     0.0626   -0.0015
   320        0.1115             nan     0.0626   -0.0008
   340        0.0995             nan     0.0626   -0.0009
   360        0.0884             nan     0.0626   -0.0007
   380        0.0790             nan     0.0626   -0.0004
   400        0.0708             nan     0.0626   -0.0007
   420        0.0634             nan     0.0626   -0.0009
   440        0.0567             nan     0.0626   -0.0006
   460        0.0505             nan     0.0626   -0.0006
   480        0.0454             nan     0.0626   -0.0006
   500        0.0408             nan     0.0626   -0.0003
   520        0.0366             nan     0.0626   -0.0002
   540        0.0330             nan     0.0626   -0.0001
   560        0.0298             nan     0.0626   -0.0003
   580        0.0271             nan     0.0626   -0.0001
   600        0.0243             nan     0.0626   -0.0002
   620        0.0219             nan     0.0626   -0.0002
   640        0.0197             nan     0.0626   -0.0002
   660        0.0176             nan     0.0626   -0.0002
   680        0.0158             nan     0.0626   -0.0002
   700        0.0144             nan     0.0626   -0.0001
   720        0.0129             nan     0.0626   -0.0001
   740        0.0117             nan     0.0626   -0.0001
   760        0.0105             nan     0.0626   -0.0001
   780        0.0095             nan     0.0626   -0.0001
   800        0.0086             nan     0.0626   -0.0001
   820        0.0077             nan     0.0626   -0.0001
   840        0.0070             nan     0.0626   -0.0001
   860        0.0063             nan     0.0626   -0.0001
   880        0.0057             nan     0.0626   -0.0001
   900        0.0052             nan     0.0626   -0.0000
   920        0.0047             nan     0.0626   -0.0001
   940        0.0043             nan     0.0626   -0.0000
   960        0.0039             nan     0.0626   -0.0001
   980        0.0035             nan     0.0626   -0.0000
  1000        0.0032             nan     0.0626   -0.0000
  1020        0.0029             nan     0.0626   -0.0000
  1040        0.0027             nan     0.0626   -0.0000
  1060        0.0024             nan     0.0626   -0.0000
  1080        0.0022             nan     0.0626   -0.0000
  1100        0.0020             nan     0.0626   -0.0000
  1120        0.0018             nan     0.0626   -0.0000
  1140        0.0016             nan     0.0626   -0.0000
  1160        0.0015             nan     0.0626   -0.0000
  1180        0.0013             nan     0.0626   -0.0000
  1200        0.0012             nan     0.0626   -0.0000
  1220        0.0011             nan     0.0626   -0.0000
  1240        0.0010             nan     0.0626   -0.0000
  1260        0.0009             nan     0.0626   -0.0000
  1280        0.0008             nan     0.0626   -0.0000
  1300        0.0008             nan     0.0626   -0.0000
  1320        0.0007             nan     0.0626   -0.0000
  1340        0.0006             nan     0.0626   -0.0000
  1360        0.0006             nan     0.0626   -0.0000
  1380        0.0005             nan     0.0626   -0.0000
  1400        0.0005             nan     0.0626   -0.0000
  1420        0.0004             nan     0.0626   -0.0000
  1440        0.0004             nan     0.0626   -0.0000
  1460        0.0004             nan     0.0626   -0.0000
  1480        0.0003             nan     0.0626   -0.0000
  1500        0.0003             nan     0.0626   -0.0000
  1520        0.0003             nan     0.0626   -0.0000
  1540        0.0002             nan     0.0626   -0.0000
  1560        0.0002             nan     0.0626   -0.0000
  1580        0.0002             nan     0.0626   -0.0000
  1600        0.0002             nan     0.0626   -0.0000
  1620        0.0002             nan     0.0626   -0.0000
  1640        0.0002             nan     0.0626   -0.0000
  1660        0.0001             nan     0.0626   -0.0000
  1680        0.0001             nan     0.0626   -0.0000
  1700        0.0001             nan     0.0626   -0.0000
  1720        0.0001             nan     0.0626   -0.0000
  1740        0.0001             nan     0.0626   -0.0000
  1760        0.0001             nan     0.0626   -0.0000
  1780        0.0001             nan     0.0626   -0.0000
  1800        0.0001             nan     0.0626   -0.0000
  1820        0.0001             nan     0.0626   -0.0000
  1840        0.0001             nan     0.0626   -0.0000
  1860        0.0001             nan     0.0626   -0.0000
  1880        0.0001             nan     0.0626   -0.0000
  1900        0.0000             nan     0.0626   -0.0000
  1920        0.0000             nan     0.0626   -0.0000
  1940        0.0000             nan     0.0626   -0.0000
  1960        0.0000             nan     0.0626   -0.0000
  1980        0.0000             nan     0.0626   -0.0000
  2000        0.0000             nan     0.0626   -0.0000
  2020        0.0000             nan     0.0626   -0.0000
  2040        0.0000             nan     0.0626   -0.0000
  2060        0.0000             nan     0.0626   -0.0000
  2080        0.0000             nan     0.0626   -0.0000
  2100        0.0000             nan     0.0626   -0.0000
  2120        0.0000             nan     0.0626   -0.0000
  2140        0.0000             nan     0.0626   -0.0000
  2160        0.0000             nan     0.0626   -0.0000
  2180        0.0000             nan     0.0626   -0.0000
  2200        0.0000             nan     0.0626   -0.0000
  2220        0.0000             nan     0.0626   -0.0000
  2240        0.0000             nan     0.0626   -0.0000
  2260        0.0000             nan     0.0626   -0.0000
  2280        0.0000             nan     0.0626   -0.0000
  2300        0.0000             nan     0.0626   -0.0000
  2320        0.0000             nan     0.0626   -0.0000
  2340        0.0000             nan     0.0626   -0.0000
  2360        0.0000             nan     0.0626   -0.0000
  2380        0.0000             nan     0.0626   -0.0000
  2400        0.0000             nan     0.0626   -0.0000
  2420        0.0000             nan     0.0626   -0.0000
  2440        0.0000             nan     0.0626   -0.0000
  2460        0.0000             nan     0.0626   -0.0000
  2480        0.0000             nan     0.0626   -0.0000
  2500        0.0000             nan     0.0626   -0.0000
  2520        0.0000             nan     0.0626   -0.0000
  2540        0.0000             nan     0.0626   -0.0000
  2560        0.0000             nan     0.0626   -0.0000
  2580        0.0000             nan     0.0626   -0.0000
  2600        0.0000             nan     0.0626   -0.0000
  2620        0.0000             nan     0.0626   -0.0000
  2640        0.0000             nan     0.0626   -0.0000
  2660        0.0000             nan     0.0626   -0.0000
  2680        0.0000             nan     0.0626   -0.0000
  2700        0.0000             nan     0.0626   -0.0000
  2720        0.0000             nan     0.0626   -0.0000
  2740        0.0000             nan     0.0626   -0.0000
  2760        0.0000             nan     0.0626   -0.0000
  2780        0.0000             nan     0.0626   -0.0000
  2800        0.0000             nan     0.0626   -0.0000
  2820        0.0000             nan     0.0626   -0.0000
  2840        0.0000             nan     0.0626   -0.0000
  2860        0.0000             nan     0.0626   -0.0000
  2880        0.0000             nan     0.0626   -0.0000
  2900        0.0000             nan     0.0626   -0.0000
  2920        0.0000             nan     0.0626   -0.0000
  2940        0.0000             nan     0.0626   -0.0000
  2960        0.0000             nan     0.0626   -0.0000
  2980        0.0000             nan     0.0626   -0.0000
  3000        0.0000             nan     0.0626   -0.0000
  3020        0.0000             nan     0.0626   -0.0000
  3040        0.0000             nan     0.0626   -0.0000
  3060        0.0000             nan     0.0626   -0.0000
  3080        0.0000             nan     0.0626   -0.0000
  3100        0.0000             nan     0.0626   -0.0000
  3120        0.0000             nan     0.0626   -0.0000
  3140        0.0000             nan     0.0626   -0.0000
  3160        0.0000             nan     0.0626   -0.0000
  3180        0.0000             nan     0.0626   -0.0000
  3200        0.0000             nan     0.0626   -0.0000
  3220        0.0000             nan     0.0626   -0.0000
  3240        0.0000             nan     0.0626   -0.0000
  3260        0.0000             nan     0.0626   -0.0000
  3280        0.0000             nan     0.0626   -0.0000
  3300        0.0000             nan     0.0626   -0.0000
  3320        0.0000             nan     0.0626   -0.0000
  3340        0.0000             nan     0.0626   -0.0000
  3360        0.0000             nan     0.0626   -0.0000
  3380        0.0000             nan     0.0626   -0.0000
  3400        0.0000             nan     0.0626   -0.0000
  3420        0.0000             nan     0.0626   -0.0000
  3440        0.0000             nan     0.0626   -0.0000
  3460        0.0000             nan     0.0626   -0.0000
  3480        0.0000             nan     0.0626   -0.0000
  3500        0.0000             nan     0.0626   -0.0000
  3520        0.0000             nan     0.0626   -0.0000
  3540        0.0000             nan     0.0626   -0.0000
  3560        0.0000             nan     0.0626   -0.0000
  3580        0.0000             nan     0.0626   -0.0000
  3600        0.0000             nan     0.0626   -0.0000
  3620        0.0000             nan     0.0626   -0.0000
  3640        0.0000             nan     0.0626   -0.0000
  3660        0.0000             nan     0.0626   -0.0000
  3680        0.0000             nan     0.0626   -0.0000
  3700        0.0000             nan     0.0626   -0.0000
  3720        0.0000             nan     0.0626   -0.0000
  3740        0.0000             nan     0.0626   -0.0000
  3760        0.0000             nan     0.0626   -0.0000
  3780        0.0000             nan     0.0626   -0.0000
  3800        0.0000             nan     0.0626   -0.0000
  3820        0.0000             nan     0.0626   -0.0000
  3840        0.0000             nan     0.0626   -0.0000
  3860        0.0000             nan     0.0626   -0.0000
  3880        0.0000             nan     0.0626   -0.0000
  3895        0.0000             nan     0.0626   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9732             nan     0.0786   -0.0019
     2        0.9691             nan     0.0786    0.0016
     3        0.9661             nan     0.0786   -0.0039
     4        0.9606             nan     0.0786    0.0032
     5        0.9569             nan     0.0786   -0.0012
     6        0.9525             nan     0.0786   -0.0002
     7        0.9487             nan     0.0786   -0.0057
     8        0.9448             nan     0.0786   -0.0011
     9        0.9404             nan     0.0786   -0.0009
    10        0.9362             nan     0.0786   -0.0017
    20        0.9027             nan     0.0786   -0.0035
    40        0.8584             nan     0.0786   -0.0051
    60        0.8199             nan     0.0786   -0.0017
    80        0.7909             nan     0.0786   -0.0027
   100        0.7606             nan     0.0786   -0.0025
   120        0.7284             nan     0.0786   -0.0048
   140        0.7063             nan     0.0786   -0.0030
   160        0.6874             nan     0.0786   -0.0024
   180        0.6699             nan     0.0786   -0.0037
   200        0.6517             nan     0.0786   -0.0023
   220        0.6327             nan     0.0786   -0.0022
   240        0.6126             nan     0.0786   -0.0013
   260        0.5958             nan     0.0786   -0.0032
   280        0.5825             nan     0.0786   -0.0057
   300        0.5660             nan     0.0786   -0.0035
   320        0.5517             nan     0.0786   -0.0025
   340        0.5366             nan     0.0786   -0.0021
   360        0.5221             nan     0.0786   -0.0020
   380        0.5119             nan     0.0786   -0.0035
   400        0.4994             nan     0.0786   -0.0029
   420        0.4880             nan     0.0786   -0.0033
   440        0.4756             nan     0.0786   -0.0017
   460        0.4617             nan     0.0786   -0.0027
   480        0.4488             nan     0.0786   -0.0007
   500        0.4389             nan     0.0786   -0.0029
   520        0.4303             nan     0.0786   -0.0024
   540        0.4197             nan     0.0786   -0.0020
   560        0.4119             nan     0.0786   -0.0015
   580        0.4042             nan     0.0786   -0.0023
   600        0.3959             nan     0.0786   -0.0023
   620        0.3869             nan     0.0786   -0.0015
   640        0.3782             nan     0.0786   -0.0028
   660        0.3719             nan     0.0786   -0.0020
   680        0.3635             nan     0.0786   -0.0011
   700        0.3556             nan     0.0786   -0.0012
   720        0.3466             nan     0.0786   -0.0009
   740        0.3395             nan     0.0786   -0.0014
   760        0.3315             nan     0.0786   -0.0007
   780        0.3248             nan     0.0786   -0.0022
   800        0.3165             nan     0.0786   -0.0008
   820        0.3095             nan     0.0786   -0.0022
   840        0.3033             nan     0.0786   -0.0009
   860        0.2977             nan     0.0786   -0.0008
   880        0.2920             nan     0.0786   -0.0009
   900        0.2862             nan     0.0786   -0.0014
   920        0.2813             nan     0.0786   -0.0014
   940        0.2761             nan     0.0786   -0.0014
   960        0.2707             nan     0.0786   -0.0010
   980        0.2645             nan     0.0786   -0.0014
  1000        0.2588             nan     0.0786   -0.0010
  1020        0.2543             nan     0.0786   -0.0008
  1040        0.2494             nan     0.0786   -0.0014
  1060        0.2445             nan     0.0786   -0.0010
  1080        0.2400             nan     0.0786   -0.0006
  1100        0.2350             nan     0.0786   -0.0008
  1120        0.2293             nan     0.0786   -0.0006
  1140        0.2248             nan     0.0786   -0.0012
  1160        0.2199             nan     0.0786   -0.0010
  1180        0.2153             nan     0.0786   -0.0009
  1200        0.2110             nan     0.0786   -0.0005
  1220        0.2074             nan     0.0786   -0.0010
  1240        0.2032             nan     0.0786   -0.0009
  1260        0.1991             nan     0.0786   -0.0010
  1280        0.1955             nan     0.0786   -0.0010
  1300        0.1925             nan     0.0786   -0.0010
  1320        0.1884             nan     0.0786   -0.0008
  1340        0.1840             nan     0.0786   -0.0007
  1360        0.1803             nan     0.0786   -0.0006
  1380        0.1763             nan     0.0786   -0.0005
  1400        0.1737             nan     0.0786   -0.0006
  1420        0.1709             nan     0.0786   -0.0010
  1440        0.1682             nan     0.0786   -0.0006
  1460        0.1646             nan     0.0786   -0.0007
  1480        0.1614             nan     0.0786   -0.0005
  1500        0.1585             nan     0.0786   -0.0008
  1520        0.1559             nan     0.0786   -0.0007
  1540        0.1521             nan     0.0786   -0.0009
  1560        0.1501             nan     0.0786   -0.0006
  1580        0.1478             nan     0.0786   -0.0009
  1600        0.1446             nan     0.0786   -0.0006
  1620        0.1419             nan     0.0786   -0.0006
  1640        0.1399             nan     0.0786   -0.0006
  1660        0.1372             nan     0.0786   -0.0007
  1680        0.1348             nan     0.0786   -0.0007
  1700        0.1328             nan     0.0786   -0.0004
  1720        0.1306             nan     0.0786   -0.0008
  1740        0.1279             nan     0.0786   -0.0007
  1753        0.1263             nan     0.0786   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9756             nan     0.0829   -0.0047
     2        0.9726             nan     0.0829   -0.0006
     3        0.9701             nan     0.0829    0.0011
     4        0.9688             nan     0.0829   -0.0012
     5        0.9682             nan     0.0829   -0.0028
     6        0.9657             nan     0.0829    0.0007
     7        0.9629             nan     0.0829   -0.0010
     8        0.9597             nan     0.0829   -0.0020
     9        0.9574             nan     0.0829   -0.0006
    10        0.9551             nan     0.0829   -0.0005
    20        0.9362             nan     0.0829   -0.0021
    40        0.9119             nan     0.0829   -0.0026
    60        0.8946             nan     0.0829   -0.0028
    80        0.8776             nan     0.0829   -0.0032
   100        0.8622             nan     0.0829   -0.0024
   120        0.8518             nan     0.0829   -0.0021
   140        0.8397             nan     0.0829   -0.0012
   160        0.8287             nan     0.0829   -0.0021
   180        0.8191             nan     0.0829   -0.0037
   200        0.8069             nan     0.0829   -0.0022
   220        0.7987             nan     0.0829   -0.0012
   240        0.7906             nan     0.0829   -0.0014
   260        0.7816             nan     0.0829   -0.0010
   280        0.7747             nan     0.0829   -0.0016
   300        0.7665             nan     0.0829   -0.0030
   320        0.7596             nan     0.0829   -0.0020
   340        0.7529             nan     0.0829   -0.0016
   360        0.7466             nan     0.0829   -0.0016
   380        0.7408             nan     0.0829   -0.0016
   400        0.7351             nan     0.0829   -0.0014
   420        0.7305             nan     0.0829   -0.0013
   440        0.7231             nan     0.0829   -0.0015
   460        0.7168             nan     0.0829   -0.0017
   480        0.7099             nan     0.0829   -0.0023
   500        0.7030             nan     0.0829   -0.0021
   520        0.6990             nan     0.0829   -0.0025
   540        0.6941             nan     0.0829   -0.0022
   560        0.6887             nan     0.0829   -0.0031
   580        0.6846             nan     0.0829   -0.0019
   600        0.6819             nan     0.0829   -0.0015
   620        0.6777             nan     0.0829   -0.0026
   640        0.6726             nan     0.0829   -0.0012
   660        0.6678             nan     0.0829   -0.0009
   680        0.6634             nan     0.0829   -0.0017
   700        0.6591             nan     0.0829   -0.0028
   720        0.6560             nan     0.0829   -0.0024
   740        0.6514             nan     0.0829   -0.0016
   760        0.6468             nan     0.0829   -0.0021
   780        0.6427             nan     0.0829   -0.0013
   800        0.6387             nan     0.0829   -0.0017
   820        0.6341             nan     0.0829   -0.0012
   840        0.6315             nan     0.0829   -0.0019
   860        0.6276             nan     0.0829   -0.0005
   880        0.6247             nan     0.0829   -0.0022
   900        0.6220             nan     0.0829   -0.0017
   920        0.6170             nan     0.0829   -0.0010
   940        0.6145             nan     0.0829   -0.0012
   960        0.6113             nan     0.0829   -0.0038
   980        0.6065             nan     0.0829   -0.0048
  1000        0.6019             nan     0.0829   -0.0023
  1020        0.5977             nan     0.0829   -0.0011
  1040        0.5946             nan     0.0829   -0.0021
  1060        0.5915             nan     0.0829   -0.0013
  1080        0.5878             nan     0.0829   -0.0021
  1100        0.5840             nan     0.0829   -0.0012
  1120        0.5800             nan     0.0829   -0.0011
  1140        0.5774             nan     0.0829   -0.0010
  1160        0.5745             nan     0.0829   -0.0012
  1180        0.5715             nan     0.0829   -0.0015
  1200        0.5683             nan     0.0829   -0.0014
  1220        0.5652             nan     0.0829   -0.0023
  1240        0.5621             nan     0.0829   -0.0015
  1260        0.5593             nan     0.0829   -0.0022
  1280        0.5572             nan     0.0829   -0.0021
  1300        0.5533             nan     0.0829   -0.0011
  1320        0.5496             nan     0.0829   -0.0015
  1340        0.5474             nan     0.0829   -0.0012
  1360        0.5455             nan     0.0829   -0.0009
  1380        0.5418             nan     0.0829   -0.0012
  1400        0.5380             nan     0.0829   -0.0014
  1420        0.5359             nan     0.0829   -0.0028
  1440        0.5321             nan     0.0829   -0.0008
  1460        0.5292             nan     0.0829   -0.0012
  1480        0.5266             nan     0.0829   -0.0018
  1500        0.5245             nan     0.0829   -0.0006
  1520        0.5222             nan     0.0829   -0.0015
  1540        0.5200             nan     0.0829   -0.0010
  1560        0.5173             nan     0.0829   -0.0014
  1580        0.5142             nan     0.0829   -0.0019
  1600        0.5124             nan     0.0829   -0.0020
  1620        0.5093             nan     0.0829   -0.0024
  1640        0.5068             nan     0.0829   -0.0022
  1660        0.5055             nan     0.0829   -0.0024
  1680        0.5018             nan     0.0829   -0.0018
  1700        0.4995             nan     0.0829   -0.0012
  1720        0.4970             nan     0.0829   -0.0026
  1740        0.4931             nan     0.0829   -0.0010
  1760        0.4914             nan     0.0829   -0.0008
  1765        0.4913             nan     0.0829   -0.0017

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9558             nan     0.1176    0.0015
     2        0.9339             nan     0.1176    0.0045
     3        0.9217             nan     0.1176   -0.0111
     4        0.8997             nan     0.1176   -0.0005
     5        0.8853             nan     0.1176   -0.0057
     6        0.8646             nan     0.1176   -0.0012
     7        0.8504             nan     0.1176   -0.0168
     8        0.8362             nan     0.1176   -0.0054
     9        0.8261             nan     0.1176   -0.0089
    10        0.8123             nan     0.1176   -0.0005
    20        0.6894             nan     0.1176   -0.0083
    40        0.5311             nan     0.1176   -0.0045
    60        0.4205             nan     0.1176   -0.0040
    80        0.3302             nan     0.1176   -0.0038
   100        0.2653             nan     0.1176   -0.0024
   120        0.2127             nan     0.1176   -0.0025
   140        0.1733             nan     0.1176   -0.0012
   160        0.1450             nan     0.1176   -0.0017
   180        0.1193             nan     0.1176   -0.0018
   200        0.1003             nan     0.1176   -0.0012
   220        0.0820             nan     0.1176   -0.0012
   240        0.0680             nan     0.1176   -0.0011
   260        0.0574             nan     0.1176   -0.0004
   280        0.0470             nan     0.1176   -0.0006
   300        0.0387             nan     0.1176   -0.0008
   320        0.0325             nan     0.1176   -0.0004
   340        0.0273             nan     0.1176   -0.0003
   360        0.0227             nan     0.1176   -0.0004
   380        0.0187             nan     0.1176   -0.0003
   400        0.0158             nan     0.1176   -0.0002
   420        0.0130             nan     0.1176   -0.0002
   440        0.0111             nan     0.1176   -0.0001
   460        0.0096             nan     0.1176   -0.0001
   480        0.0080             nan     0.1176   -0.0001
   500        0.0067             nan     0.1176   -0.0001
   520        0.0058             nan     0.1176   -0.0001
   540        0.0049             nan     0.1176   -0.0000
   560        0.0041             nan     0.1176   -0.0001
   580        0.0035             nan     0.1176   -0.0001
   600        0.0030             nan     0.1176   -0.0000
   620        0.0025             nan     0.1176   -0.0000
   640        0.0021             nan     0.1176   -0.0000
   660        0.0018             nan     0.1176   -0.0000
   680        0.0015             nan     0.1176   -0.0000
   700        0.0013             nan     0.1176   -0.0000
   720        0.0011             nan     0.1176   -0.0000
   740        0.0009             nan     0.1176   -0.0000
   760        0.0008             nan     0.1176   -0.0000
   780        0.0006             nan     0.1176   -0.0000
   800        0.0006             nan     0.1176   -0.0000
   820        0.0005             nan     0.1176   -0.0000
   840        0.0004             nan     0.1176   -0.0000
   860        0.0003             nan     0.1176   -0.0000
   880        0.0003             nan     0.1176   -0.0000
   900        0.0002             nan     0.1176   -0.0000
   920        0.0002             nan     0.1176   -0.0000
   940        0.0002             nan     0.1176   -0.0000
   960        0.0001             nan     0.1176   -0.0000
   980        0.0001             nan     0.1176   -0.0000
  1000        0.0001             nan     0.1176   -0.0000
  1020        0.0001             nan     0.1176   -0.0000
  1040        0.0001             nan     0.1176   -0.0000
  1060        0.0001             nan     0.1176   -0.0000
  1080        0.0001             nan     0.1176   -0.0000
  1100        0.0000             nan     0.1176   -0.0000
  1120        0.0000             nan     0.1176   -0.0000
  1140        0.0000             nan     0.1176   -0.0000
  1160        0.0000             nan     0.1176   -0.0000
  1180        0.0000             nan     0.1176   -0.0000
  1200        0.0000             nan     0.1176   -0.0000
  1220        0.0000             nan     0.1176   -0.0000
  1240        0.0000             nan     0.1176   -0.0000
  1260        0.0000             nan     0.1176   -0.0000
  1280        0.0000             nan     0.1176   -0.0000
  1300        0.0000             nan     0.1176   -0.0000
  1320        0.0000             nan     0.1176   -0.0000
  1340        0.0000             nan     0.1176   -0.0000
  1360        0.0000             nan     0.1176   -0.0000
  1380        0.0000             nan     0.1176   -0.0000
  1400        0.0000             nan     0.1176   -0.0000
  1420        0.0000             nan     0.1176   -0.0000
  1440        0.0000             nan     0.1176   -0.0000
  1460        0.0000             nan     0.1176   -0.0000
  1480        0.0000             nan     0.1176   -0.0000
  1500        0.0000             nan     0.1176   -0.0000
  1520        0.0000             nan     0.1176   -0.0000
  1540        0.0000             nan     0.1176   -0.0000
  1560        0.0000             nan     0.1176   -0.0000
  1580        0.0000             nan     0.1176   -0.0000
  1600        0.0000             nan     0.1176   -0.0000
  1620        0.0000             nan     0.1176   -0.0000
  1640        0.0000             nan     0.1176   -0.0000
  1660        0.0000             nan     0.1176   -0.0000
  1680        0.0000             nan     0.1176   -0.0000
  1700        0.0000             nan     0.1176   -0.0000
  1720        0.0000             nan     0.1176   -0.0000
  1740        0.0000             nan     0.1176   -0.0000
  1760        0.0000             nan     0.1176   -0.0000
  1780        0.0000             nan     0.1176   -0.0000
  1800        0.0000             nan     0.1176   -0.0000
  1820        0.0000             nan     0.1176   -0.0000
  1840        0.0000             nan     0.1176   -0.0000
  1860        0.0000             nan     0.1176   -0.0000
  1880        0.0000             nan     0.1176   -0.0000
  1900        0.0000             nan     0.1176   -0.0000
  1920        0.0000             nan     0.1176   -0.0000
  1940        0.0000             nan     0.1176   -0.0000
  1960        0.0000             nan     0.1176   -0.0000
  1980        0.0000             nan     0.1176   -0.0000
  2000        0.0000             nan     0.1176   -0.0000
  2020        0.0000             nan     0.1176   -0.0000
  2040        0.0000             nan     0.1176   -0.0000
  2060        0.0000             nan     0.1176   -0.0000
  2080        0.0000             nan     0.1176   -0.0000
  2100        0.0000             nan     0.1176   -0.0000
  2120        0.0000             nan     0.1176   -0.0000
  2140        0.0000             nan     0.1176   -0.0000
  2160        0.0000             nan     0.1176   -0.0000
  2180        0.0000             nan     0.1176   -0.0000
  2186        0.0000             nan     0.1176   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9585             nan     0.1352   -0.0089
     2        0.9302             nan     0.1352   -0.0057
     3        0.9078             nan     0.1352   -0.0018
     4        0.8915             nan     0.1352   -0.0181
     5        0.8689             nan     0.1352    0.0001
     6        0.8520             nan     0.1352   -0.0145
     7        0.8289             nan     0.1352   -0.0091
     8        0.8066             nan     0.1352   -0.0035
     9        0.7841             nan     0.1352   -0.0023
    10        0.7607             nan     0.1352   -0.0056
    20        0.6200             nan     0.1352   -0.0105
    40        0.4303             nan     0.1352   -0.0037
    60        0.3103             nan     0.1352   -0.0053
    80        0.2280             nan     0.1352   -0.0046
   100        0.1733             nan     0.1352   -0.0045
   120        0.1301             nan     0.1352   -0.0024
   140        0.0958             nan     0.1352   -0.0030
   160        0.0724             nan     0.1352   -0.0006
   180        0.0534             nan     0.1352   -0.0018
   200        0.0408             nan     0.1352   -0.0008
   220        0.0317             nan     0.1352   -0.0006
   240        0.0245             nan     0.1352   -0.0008
   260        0.0189             nan     0.1352   -0.0004
   280        0.0144             nan     0.1352   -0.0003
   300        0.0106             nan     0.1352   -0.0002
   320        0.0080             nan     0.1352   -0.0001
   340        0.0061             nan     0.1352   -0.0002
   360        0.0046             nan     0.1352   -0.0001
   380        0.0036             nan     0.1352   -0.0000
   400        0.0027             nan     0.1352   -0.0000
   420        0.0021             nan     0.1352   -0.0000
   440        0.0016             nan     0.1352   -0.0000
   460        0.0013             nan     0.1352   -0.0000
   480        0.0010             nan     0.1352   -0.0000
   500        0.0008             nan     0.1352   -0.0000
   520        0.0006             nan     0.1352   -0.0000
   540        0.0005             nan     0.1352   -0.0000
   560        0.0004             nan     0.1352   -0.0000
   580        0.0003             nan     0.1352   -0.0000
   600        0.0002             nan     0.1352   -0.0000
   620        0.0002             nan     0.1352   -0.0000
   640        0.0001             nan     0.1352   -0.0000
   660        0.0001             nan     0.1352   -0.0000
   680        0.0001             nan     0.1352   -0.0000
   700        0.0001             nan     0.1352   -0.0000
   703        0.0001             nan     0.1352   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9540             nan     0.1730   -0.0046
     2        0.9263             nan     0.1730   -0.0018
     3        0.9106             nan     0.1730   -0.0008
     4        0.9021             nan     0.1730   -0.0195
     5        0.8840             nan     0.1730   -0.0075
     6        0.8718             nan     0.1730   -0.0136
     7        0.8601             nan     0.1730   -0.0080
     8        0.8485             nan     0.1730   -0.0110
     9        0.8371             nan     0.1730   -0.0073
    10        0.8300             nan     0.1730   -0.0094
    20        0.7582             nan     0.1730   -0.0103
    40        0.6273             nan     0.1730   -0.0070
    60        0.5038             nan     0.1730   -0.0065
    80        0.4380             nan     0.1730   -0.0058
   100        0.3691             nan     0.1730   -0.0129
   120        0.3114             nan     0.1730   -0.0035
   140        0.2609             nan     0.1730   -0.0067
   160        0.2206             nan     0.1730   -0.0036
   180        0.1908             nan     0.1730   -0.0030
   200        0.1693             nan     0.1730   -0.0039
   220        0.1448             nan     0.1730   -0.0015
   240        0.1272             nan     0.1730   -0.0034
   260        0.1116             nan     0.1730   -0.0029
   280        0.0950             nan     0.1730   -0.0004
   300        0.0828             nan     0.1730   -0.0018
   320        0.0729             nan     0.1730   -0.0012
   340        0.0643             nan     0.1730   -0.0012
   360        0.0566             nan     0.1730   -0.0013
   380        0.0503             nan     0.1730   -0.0016
   400        0.0451             nan     0.1730   -0.0009
   420        0.0394             nan     0.1730   -0.0004
   426        0.0384             nan     0.1730   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9653             nan     0.2045   -0.0135
     2        0.9389             nan     0.2045    0.0006
     3        0.9251             nan     0.2045   -0.0040
     4        0.9170             nan     0.2045   -0.0293
     5        0.9040             nan     0.2045   -0.0147
     6        0.8907             nan     0.2045   -0.0082
     7        0.8726             nan     0.2045   -0.0092
     8        0.8585             nan     0.2045   -0.0018
     9        0.8430             nan     0.2045   -0.0086
    10        0.8391             nan     0.2045   -0.0235
    20        0.7330             nan     0.2045   -0.0181
    40        0.5944             nan     0.2045   -0.0188
    60        0.4906             nan     0.2045   -0.0065
    80        0.4117             nan     0.2045   -0.0064
   100        0.3463             nan     0.2045   -0.0092
   120        0.2931             nan     0.2045   -0.0048
   140        0.2517             nan     0.2045   -0.0060
   160        0.2147             nan     0.2045   -0.0057
   180        0.1789             nan     0.2045   -0.0033
   200        0.1537             nan     0.2045   -0.0019
   220        0.1305             nan     0.2045   -0.0013
   240        0.1132             nan     0.2045   -0.0024
   260        0.0972             nan     0.2045   -0.0025
   280        0.0850             nan     0.2045   -0.0025
   300        0.0722             nan     0.2045   -0.0015
   320        0.0633             nan     0.2045   -0.0017
   340        0.0563             nan     0.2045   -0.0016
   360        0.0493             nan     0.2045   -0.0010
   380        0.0424             nan     0.2045   -0.0010
   400        0.0379             nan     0.2045   -0.0010
   420        0.0328             nan     0.2045   -0.0002
   440        0.0283             nan     0.2045   -0.0004
   460        0.0254             nan     0.2045   -0.0005
   480        0.0221             nan     0.2045   -0.0004
   500        0.0193             nan     0.2045   -0.0005
   520        0.0173             nan     0.2045   -0.0004
   540        0.0155             nan     0.2045   -0.0004
   560        0.0135             nan     0.2045   -0.0003
   580        0.0121             nan     0.2045   -0.0005
   600        0.0106             nan     0.2045   -0.0001
   620        0.0094             nan     0.2045   -0.0002
   640        0.0085             nan     0.2045   -0.0001
   660        0.0075             nan     0.2045   -0.0001
   680        0.0066             nan     0.2045   -0.0002
   700        0.0058             nan     0.2045   -0.0001
   720        0.0051             nan     0.2045   -0.0001
   740        0.0047             nan     0.2045   -0.0001
   760        0.0040             nan     0.2045   -0.0001
   780        0.0036             nan     0.2045   -0.0001
   800        0.0032             nan     0.2045   -0.0001
   820        0.0028             nan     0.2045   -0.0001
   840        0.0025             nan     0.2045   -0.0001
   860        0.0022             nan     0.2045   -0.0000
   880        0.0020             nan     0.2045   -0.0000
   900        0.0018             nan     0.2045   -0.0000
   920        0.0016             nan     0.2045   -0.0000
   940        0.0014             nan     0.2045   -0.0000
   960        0.0012             nan     0.2045   -0.0000
   980        0.0011             nan     0.2045   -0.0000
  1000        0.0010             nan     0.2045   -0.0000
  1020        0.0009             nan     0.2045   -0.0000
  1040        0.0008             nan     0.2045   -0.0000
  1060        0.0007             nan     0.2045   -0.0000
  1080        0.0006             nan     0.2045   -0.0000
  1100        0.0006             nan     0.2045   -0.0000
  1120        0.0005             nan     0.2045   -0.0000
  1140        0.0005             nan     0.2045   -0.0000
  1160        0.0004             nan     0.2045   -0.0000
  1180        0.0004             nan     0.2045   -0.0000
  1200        0.0003             nan     0.2045   -0.0000
  1220        0.0003             nan     0.2045   -0.0000
  1240        0.0003             nan     0.2045   -0.0000
  1260        0.0002             nan     0.2045   -0.0000
  1280        0.0002             nan     0.2045   -0.0000
  1300        0.0002             nan     0.2045   -0.0000
  1320        0.0002             nan     0.2045   -0.0000
  1340        0.0001             nan     0.2045   -0.0000
  1360        0.0001             nan     0.2045   -0.0000
  1380        0.0001             nan     0.2045   -0.0000
  1400        0.0001             nan     0.2045   -0.0000
  1420        0.0001             nan     0.2045   -0.0000
  1440        0.0001             nan     0.2045   -0.0000
  1460        0.0001             nan     0.2045   -0.0000
  1480        0.0001             nan     0.2045   -0.0000
  1500        0.0001             nan     0.2045   -0.0000
  1520        0.0001             nan     0.2045   -0.0000
  1540        0.0000             nan     0.2045   -0.0000
  1560        0.0000             nan     0.2045   -0.0000
  1580        0.0000             nan     0.2045   -0.0000
  1600        0.0000             nan     0.2045   -0.0000
  1620        0.0000             nan     0.2045   -0.0000
  1640        0.0000             nan     0.2045   -0.0000
  1660        0.0000             nan     0.2045   -0.0000
  1680        0.0000             nan     0.2045   -0.0000
  1700        0.0000             nan     0.2045   -0.0000
  1720        0.0000             nan     0.2045   -0.0000
  1740        0.0000             nan     0.2045   -0.0000
  1760        0.0000             nan     0.2045   -0.0000
  1780        0.0000             nan     0.2045   -0.0000
  1800        0.0000             nan     0.2045   -0.0000
  1820        0.0000             nan     0.2045   -0.0000
  1840        0.0000             nan     0.2045   -0.0000
  1860        0.0000             nan     0.2045   -0.0000
  1880        0.0000             nan     0.2045   -0.0000
  1900        0.0000             nan     0.2045   -0.0000
  1920        0.0000             nan     0.2045   -0.0000
  1940        0.0000             nan     0.2045   -0.0000
  1960        0.0000             nan     0.2045   -0.0000
  1980        0.0000             nan     0.2045   -0.0000
  2000        0.0000             nan     0.2045   -0.0000
  2020        0.0000             nan     0.2045   -0.0000
  2040        0.0000             nan     0.2045   -0.0000
  2060        0.0000             nan     0.2045   -0.0000
  2080        0.0000             nan     0.2045   -0.0000
  2100        0.0000             nan     0.2045   -0.0000
  2120        0.0000             nan     0.2045   -0.0000
  2140        0.0000             nan     0.2045   -0.0000
  2160        0.0000             nan     0.2045   -0.0000
  2180        0.0000             nan     0.2045   -0.0000
  2200        0.0000             nan     0.2045   -0.0000
  2220        0.0000             nan     0.2045   -0.0000
  2240        0.0000             nan     0.2045   -0.0000
  2260        0.0000             nan     0.2045   -0.0000
  2280        0.0000             nan     0.2045   -0.0000
  2300        0.0000             nan     0.2045   -0.0000
  2320        0.0000             nan     0.2045   -0.0000
  2340        0.0000             nan     0.2045   -0.0000
  2360        0.0000             nan     0.2045   -0.0000
  2380        0.0000             nan     0.2045   -0.0000
  2400        0.0000             nan     0.2045   -0.0000
  2420        0.0000             nan     0.2045   -0.0000
  2440        0.0000             nan     0.2045   -0.0000
  2460        0.0000             nan     0.2045   -0.0000
  2480        0.0000             nan     0.2045   -0.0000
  2500        0.0000             nan     0.2045   -0.0000
  2520        0.0000             nan     0.2045   -0.0000
  2540        0.0000             nan     0.2045   -0.0000
  2560        0.0000             nan     0.2045   -0.0000
  2580        0.0000             nan     0.2045   -0.0000
  2600        0.0000             nan     0.2045   -0.0000
  2620        0.0000             nan     0.2045   -0.0000
  2640        0.0000             nan     0.2045   -0.0000
  2660        0.0000             nan     0.2045   -0.0000
  2680        0.0000             nan     0.2045   -0.0000
  2700        0.0000             nan     0.2045   -0.0000
  2720        0.0000             nan     0.2045   -0.0000
  2740        0.0000             nan     0.2045   -0.0000
  2760        0.0000             nan     0.2045   -0.0000
  2780        0.0000             nan     0.2045   -0.0000
  2800        0.0000             nan     0.2045   -0.0000
  2820        0.0000             nan     0.2045   -0.0000
  2840        0.0000             nan     0.2045   -0.0000
  2860        0.0000             nan     0.2045   -0.0000
  2880        0.0000             nan     0.2045   -0.0000
  2900        0.0000             nan     0.2045   -0.0000
  2920        0.0000             nan     0.2045   -0.0000
  2940        0.0000             nan     0.2045   -0.0000
  2960        0.0000             nan     0.2045   -0.0000
  2980        0.0000             nan     0.2045   -0.0000
  3000        0.0000             nan     0.2045   -0.0000
  3020        0.0000             nan     0.2045   -0.0000
  3040        0.0000             nan     0.2045   -0.0000
  3060        0.0000             nan     0.2045   -0.0000
  3080        0.0000             nan     0.2045   -0.0000
  3100        0.0000             nan     0.2045   -0.0000
  3120        0.0000             nan     0.2045   -0.0000
  3140        0.0000             nan     0.2045   -0.0000
  3160        0.0000             nan     0.2045   -0.0000
  3180        0.0000             nan     0.2045   -0.0000
  3200        0.0000             nan     0.2045   -0.0000
  3220        0.0000             nan     0.2045   -0.0000
  3240        0.0000             nan     0.2045   -0.0000
  3260        0.0000             nan     0.2045   -0.0000
  3280        0.0000             nan     0.2045   -0.0000
  3300        0.0000             nan     0.2045   -0.0000
  3320        0.0000             nan     0.2045   -0.0000
  3340        0.0000             nan     0.2045   -0.0000
  3360        0.0000             nan     0.2045   -0.0000
  3380        0.0000             nan     0.2045   -0.0000
  3400        0.0000             nan     0.2045   -0.0000
  3420        0.0000             nan     0.2045   -0.0000
  3440        0.0000             nan     0.2045   -0.0000
  3460        0.0000             nan     0.2045   -0.0000
  3480        0.0000             nan     0.2045   -0.0000
  3500        0.0000             nan     0.2045   -0.0000
  3520        0.0000             nan     0.2045   -0.0000
  3540        0.0000             nan     0.2045   -0.0000
  3560        0.0000             nan     0.2045   -0.0000
  3580        0.0000             nan     0.2045   -0.0000
  3600        0.0000             nan     0.2045   -0.0000
  3620        0.0000             nan     0.2045   -0.0000
  3640        0.0000             nan     0.2045   -0.0000
  3660        0.0000             nan     0.2045   -0.0000
  3680        0.0000             nan     0.2045   -0.0000
  3700        0.0000             nan     0.2045   -0.0000
  3720        0.0000             nan     0.2045   -0.0000
  3740        0.0000             nan     0.2045   -0.0000
  3760        0.0000             nan     0.2045   -0.0000
  3780        0.0000             nan     0.2045   -0.0000
  3800        0.0000             nan     0.2045   -0.0000
  3820        0.0000             nan     0.2045   -0.0000
  3840        0.0000             nan     0.2045   -0.0000
  3860        0.0000             nan     0.2045   -0.0000
  3880        0.0000             nan     0.2045   -0.0000
  3900        0.0000             nan     0.2045   -0.0000
  3920        0.0000             nan     0.2045   -0.0000
  3940        0.0000             nan     0.2045   -0.0000
  3960        0.0000             nan     0.2045   -0.0000
  3980        0.0000             nan     0.2045   -0.0000
  3999        0.0000             nan     0.2045   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9292             nan     0.2413    0.0029
     2        0.8956             nan     0.2413   -0.0100
     3        0.8691             nan     0.2413   -0.0250
     4        0.8486             nan     0.2413   -0.0351
     5        0.8137             nan     0.2413   -0.0069
     6        0.7990             nan     0.2413   -0.0330
     7        0.7773             nan     0.2413   -0.0138
     8        0.7659             nan     0.2413   -0.0367
     9        0.7415             nan     0.2413   -0.0122
    10        0.7176             nan     0.2413   -0.0096
    20        0.5714             nan     0.2413   -0.0296
    40        0.3901             nan     0.2413   -0.0109
    60        0.2697             nan     0.2413   -0.0106
    80        0.1923             nan     0.2413   -0.0061
   100        0.1363             nan     0.2413   -0.0085
   120        0.0907             nan     0.2413   -0.0040
   140        0.0615             nan     0.2413   -0.0018
   160        0.0447             nan     0.2413   -0.0031
   180        0.0324             nan     0.2413   -0.0016
   200        0.0230             nan     0.2413   -0.0008
   220        0.0163             nan     0.2413   -0.0004
   240        0.0123             nan     0.2413   -0.0007
   260        0.0093             nan     0.2413   -0.0004
   280        0.0069             nan     0.2413   -0.0003
   300        0.0050             nan     0.2413   -0.0003
   320        0.0036             nan     0.2413   -0.0001
   340        0.0026             nan     0.2413   -0.0002
   360        0.0019             nan     0.2413   -0.0001
   380        0.0014             nan     0.2413   -0.0001
   400        0.0011             nan     0.2413   -0.0001
   420        0.0008             nan     0.2413   -0.0000
   440        0.0006             nan     0.2413   -0.0000
   460        0.0004             nan     0.2413   -0.0000
   480        0.0003             nan     0.2413   -0.0000
   500        0.0002             nan     0.2413   -0.0000
   520        0.0002             nan     0.2413   -0.0000
   540        0.0001             nan     0.2413   -0.0000
   560        0.0001             nan     0.2413   -0.0000
   580        0.0001             nan     0.2413   -0.0000
   600        0.0000             nan     0.2413   -0.0000
   620        0.0000             nan     0.2413   -0.0000
   640        0.0000             nan     0.2413   -0.0000
   660        0.0000             nan     0.2413   -0.0000
   680        0.0000             nan     0.2413   -0.0000
   700        0.0000             nan     0.2413   -0.0000
   720        0.0000             nan     0.2413   -0.0000
   740        0.0000             nan     0.2413   -0.0000
   760        0.0000             nan     0.2413   -0.0000
   780        0.0000             nan     0.2413   -0.0000
   800        0.0000             nan     0.2413   -0.0000
   820        0.0000             nan     0.2413   -0.0000
   840        0.0000             nan     0.2413   -0.0000
   846        0.0000             nan     0.2413   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9500             nan     0.2603   -0.0437
     2        0.9107             nan     0.2603   -0.0047
     3        0.8861             nan     0.2603   -0.0281
     4        0.8637             nan     0.2603   -0.0232
     5        0.8477             nan     0.2603   -0.0385
     6        0.8270             nan     0.2603   -0.0274
     7        0.8100             nan     0.2603   -0.0367
     8        0.7917             nan     0.2603   -0.0299
     9        0.7638             nan     0.2603   -0.0136
    10        0.7411             nan     0.2603   -0.0121
    20        0.5493             nan     0.2603   -0.0167
    40        0.3610             nan     0.2603   -0.0070
    60        0.2391             nan     0.2603   -0.0039
    80        0.1605             nan     0.2603   -0.0027
   100        0.1073             nan     0.2603   -0.0035
   120        0.0761             nan     0.2603   -0.0043
   140        0.0518             nan     0.2603   -0.0009
   160        0.0367             nan     0.2603   -0.0014
   180        0.0258             nan     0.2603   -0.0007
   200        0.0183             nan     0.2603   -0.0007
   220        0.0131             nan     0.2603   -0.0004
   240        0.0088             nan     0.2603   -0.0001
   260        0.0064             nan     0.2603   -0.0003
   280        0.0045             nan     0.2603   -0.0001
   300        0.0030             nan     0.2603   -0.0001
   320        0.0022             nan     0.2603   -0.0001
   340        0.0016             nan     0.2603   -0.0001
   360        0.0011             nan     0.2603   -0.0001
   380        0.0008             nan     0.2603   -0.0000
   400        0.0006             nan     0.2603   -0.0000
   420        0.0004             nan     0.2603   -0.0000
   440        0.0003             nan     0.2603   -0.0000
   460        0.0002             nan     0.2603   -0.0000
   480        0.0001             nan     0.2603   -0.0000
   500        0.0001             nan     0.2603   -0.0000
   520        0.0001             nan     0.2603   -0.0000
   540        0.0001             nan     0.2603   -0.0000
   560        0.0000             nan     0.2603   -0.0000
   580        0.0000             nan     0.2603   -0.0000
   600        0.0000             nan     0.2603   -0.0000
   620        0.0000             nan     0.2603   -0.0000
   640        0.0000             nan     0.2603   -0.0000
   660        0.0000             nan     0.2603   -0.0000
   680        0.0000             nan     0.2603   -0.0000
   700        0.0000             nan     0.2603   -0.0000
   720        0.0000             nan     0.2603   -0.0000
   740        0.0000             nan     0.2603   -0.0000
   760        0.0000             nan     0.2603   -0.0000
   780        0.0000             nan     0.2603   -0.0000
   800        0.0000             nan     0.2603   -0.0000
   820        0.0000             nan     0.2603   -0.0000
   840        0.0000             nan     0.2603   -0.0000
   860        0.0000             nan     0.2603   -0.0000
   880        0.0000             nan     0.2603   -0.0000
   900        0.0000             nan     0.2603   -0.0000
   920        0.0000             nan     0.2603   -0.0000
   940        0.0000             nan     0.2603   -0.0000
   960        0.0000             nan     0.2603   -0.0000
   980        0.0000             nan     0.2603   -0.0000
  1000        0.0000             nan     0.2603   -0.0000
  1020        0.0000             nan     0.2603   -0.0000
  1040        0.0000             nan     0.2603   -0.0000
  1060        0.0000             nan     0.2603   -0.0000
  1080        0.0000             nan     0.2603   -0.0000
  1100        0.0000             nan     0.2603   -0.0000
  1120        0.0000             nan     0.2603   -0.0000
  1140        0.0000             nan     0.2603   -0.0000
  1160        0.0000             nan     0.2603   -0.0000
  1180        0.0000             nan     0.2603   -0.0000
  1200        0.0000             nan     0.2603   -0.0000
  1220        0.0000             nan     0.2603   -0.0000
  1240        0.0000             nan     0.2603   -0.0000
  1260        0.0000             nan     0.2603   -0.0000
  1280        0.0000             nan     0.2603   -0.0000
  1300        0.0000             nan     0.2603   -0.0000
  1320        0.0000             nan     0.2603   -0.0000
  1340        0.0000             nan     0.2603   -0.0000
  1360        0.0000             nan     0.2603   -0.0000
  1380        0.0000             nan     0.2603   -0.0000
  1400        0.0000             nan     0.2603   -0.0000
  1420        0.0000             nan     0.2603   -0.0000
  1440        0.0000             nan     0.2603   -0.0000
  1460        0.0000             nan     0.2603   -0.0000
  1480        0.0000             nan     0.2603   -0.0000
  1500        0.0000             nan     0.2603   -0.0000
  1520        0.0000             nan     0.2603   -0.0000
  1540        0.0000             nan     0.2603   -0.0000
  1560        0.0000             nan     0.2603   -0.0000
  1580        0.0000             nan     0.2603   -0.0000
  1600        0.0000             nan     0.2603   -0.0000
  1620        0.0000             nan     0.2603   -0.0000
  1640        0.0000             nan     0.2603   -0.0000
  1660        0.0000             nan     0.2603   -0.0000
  1680        0.0000             nan     0.2603   -0.0000
  1700        0.0000             nan     0.2603   -0.0000
  1720        0.0000             nan     0.2603   -0.0000
  1740        0.0000             nan     0.2603   -0.0000
  1760        0.0000             nan     0.2603   -0.0000
  1780        0.0000             nan     0.2603   -0.0000
  1800        0.0000             nan     0.2603   -0.0000
  1820        0.0000             nan     0.2603   -0.0000
  1840        0.0000             nan     0.2603   -0.0000
  1860        0.0000             nan     0.2603   -0.0000
  1880        0.0000             nan     0.2603   -0.0000
  1900        0.0000             nan     0.2603   -0.0000
  1920        0.0000             nan     0.2603   -0.0000
  1940        0.0000             nan     0.2603   -0.0000
  1960        0.0000             nan     0.2603   -0.0000
  1980        0.0000             nan     0.2603   -0.0000
  2000        0.0000             nan     0.2603   -0.0000
  2020        0.0000             nan     0.2603   -0.0000
  2040        0.0000             nan     0.2603   -0.0000
  2060        0.0000             nan     0.2603   -0.0000
  2080        0.0000             nan     0.2603   -0.0000
  2100        0.0000             nan     0.2603   -0.0000
  2120        0.0000             nan     0.2603   -0.0000
  2140        0.0000             nan     0.2603   -0.0000
  2160        0.0000             nan     0.2603   -0.0000
  2180        0.0000             nan     0.2603   -0.0000
  2200        0.0000             nan     0.2603   -0.0000
  2220        0.0000             nan     0.2603   -0.0000
  2240        0.0000             nan     0.2603   -0.0000
  2260        0.0000             nan     0.2603   -0.0000
  2280        0.0000             nan     0.2603   -0.0000
  2300        0.0000             nan     0.2603   -0.0000
  2320        0.0000             nan     0.2603   -0.0000
  2340        0.0000             nan     0.2603   -0.0000
  2360        0.0000             nan     0.2603   -0.0000
  2380        0.0000             nan     0.2603   -0.0000
  2400        0.0000             nan     0.2603   -0.0000
  2420        0.0000             nan     0.2603   -0.0000
  2440        0.0000             nan     0.2603   -0.0000
  2460        0.0000             nan     0.2603   -0.0000
  2480        0.0000             nan     0.2603   -0.0000
  2500        0.0000             nan     0.2603   -0.0000
  2520        0.0000             nan     0.2603   -0.0000
  2540        0.0000             nan     0.2603   -0.0000
  2560        0.0000             nan     0.2603   -0.0000
  2580        0.0000             nan     0.2603   -0.0000
  2600        0.0000             nan     0.2603   -0.0000
  2620        0.0000             nan     0.2603   -0.0000
  2640        0.0000             nan     0.2603   -0.0000
  2660        0.0000             nan     0.2603   -0.0000
  2680        0.0000             nan     0.2603   -0.0000
  2700        0.0000             nan     0.2603   -0.0000
  2720        0.0000             nan     0.2603   -0.0000
  2740        0.0000             nan     0.2603   -0.0000
  2760        0.0000             nan     0.2603   -0.0000
  2780        0.0000             nan     0.2603   -0.0000
  2800        0.0000             nan     0.2603   -0.0000
  2820        0.0000             nan     0.2603   -0.0000
  2840        0.0000             nan     0.2603   -0.0000
  2860        0.0000             nan     0.2603   -0.0000
  2880        0.0000             nan     0.2603   -0.0000
  2900        0.0000             nan     0.2603   -0.0000
  2920        0.0000             nan     0.2603   -0.0000
  2940        0.0000             nan     0.2603   -0.0000
  2960        0.0000             nan     0.2603   -0.0000
  2980        0.0000             nan     0.2603   -0.0000
  3000        0.0000             nan     0.2603   -0.0000
  3020        0.0000             nan     0.2603   -0.0000
  3040        0.0000             nan     0.2603   -0.0000
  3060        0.0000             nan     0.2603   -0.0000
  3080        0.0000             nan     0.2603   -0.0000
  3100        0.0000             nan     0.2603   -0.0000
  3120        0.0000             nan     0.2603   -0.0000
  3140        0.0000             nan     0.2603   -0.0000
  3160        0.0000             nan     0.2603   -0.0000
  3180        0.0000             nan     0.2603   -0.0000
  3200        0.0000             nan     0.2603   -0.0000
  3220        0.0000             nan     0.2603   -0.0000
  3240        0.0000             nan     0.2603   -0.0000
  3260        0.0000             nan     0.2603   -0.0000
  3280        0.0000             nan     0.2603   -0.0000
  3300        0.0000             nan     0.2603   -0.0000
  3320        0.0000             nan     0.2603   -0.0000
  3340        0.0000             nan     0.2603   -0.0000
  3360        0.0000             nan     0.2603   -0.0000
  3380        0.0000             nan     0.2603   -0.0000
  3400        0.0000             nan     0.2603   -0.0000
  3420        0.0000             nan     0.2603   -0.0000
  3440        0.0000             nan     0.2603   -0.0000
  3460        0.0000             nan     0.2603   -0.0000
  3480        0.0000             nan     0.2603   -0.0000
  3500        0.0000             nan     0.2603   -0.0000
  3520        0.0000             nan     0.2603   -0.0000
  3540        0.0000             nan     0.2603   -0.0000
  3560        0.0000             nan     0.2603   -0.0000
  3580        0.0000             nan     0.2603   -0.0000
  3600        0.0000             nan     0.2603   -0.0000
  3620        0.0000             nan     0.2603   -0.0000
  3640        0.0000             nan     0.2603   -0.0000
  3660        0.0000             nan     0.2603   -0.0000
  3680        0.0000             nan     0.2603   -0.0000
  3700        0.0000             nan     0.2603   -0.0000
  3720        0.0000             nan     0.2603   -0.0000
  3740        0.0000             nan     0.2603   -0.0000
  3760        0.0000             nan     0.2603   -0.0000
  3780        0.0000             nan     0.2603   -0.0000
  3800        0.0000             nan     0.2603   -0.0000
  3820        0.0000             nan     0.2603   -0.0000
  3840        0.0000             nan     0.2603   -0.0000
  3860        0.0000             nan     0.2603   -0.0000
  3880        0.0000             nan     0.2603   -0.0000
  3900        0.0000             nan     0.2603   -0.0000
  3920        0.0000             nan     0.2603   -0.0000
  3940        0.0000             nan     0.2603   -0.0000
  3960        0.0000             nan     0.2603   -0.0000
  3980        0.0000             nan     0.2603   -0.0000
  4000        0.0000             nan     0.2603   -0.0000
  4020        0.0000             nan     0.2603   -0.0000
  4040        0.0000             nan     0.2603   -0.0000
  4060        0.0000             nan     0.2603   -0.0000
  4080        0.0000             nan     0.2603   -0.0000
  4100        0.0000             nan     0.2603   -0.0000
  4120        0.0000             nan     0.2603   -0.0000
  4140        0.0000             nan     0.2603   -0.0000
  4160        0.0000             nan     0.2603   -0.0000
  4180        0.0000             nan     0.2603   -0.0000
  4200        0.0000             nan     0.2603   -0.0000
  4213        0.0000             nan     0.2603   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9304             nan     0.2885   -0.0177
     2        0.8972             nan     0.2885   -0.0406
     3        0.8676             nan     0.2885   -0.0214
     4        0.8421             nan     0.2885   -0.0458
     5        0.8131             nan     0.2885   -0.0274
     6        0.7901             nan     0.2885   -0.0385
     7        0.7637             nan     0.2885   -0.0294
     8        0.7385             nan     0.2885   -0.0239
     9        0.7196             nan     0.2885   -0.0462
    10        0.7042             nan     0.2885   -0.0220
    20        0.5298             nan     0.2885   -0.0339
    40        0.3044             nan     0.2885   -0.0074
    60        0.1887             nan     0.2885   -0.0102
    80        0.1118             nan     0.2885   -0.0056
   100        0.0656             nan     0.2885   -0.0031
   120        0.0416             nan     0.2885   -0.0022
   140        0.0265             nan     0.2885   -0.0012
   160        0.0179             nan     0.2885   -0.0010
   180        0.0119             nan     0.2885   -0.0004
   200        0.0079             nan     0.2885   -0.0003
   220        0.0054             nan     0.2885   -0.0002
   240        0.0036             nan     0.2885   -0.0002
   260        0.0022             nan     0.2885   -0.0002
   280        0.0015             nan     0.2885   -0.0001
   300        0.0010             nan     0.2885   -0.0001
   320        0.0006             nan     0.2885   -0.0000
   340        0.0004             nan     0.2885   -0.0000
   360        0.0003             nan     0.2885   -0.0000
   380        0.0002             nan     0.2885   -0.0000
   400        0.0001             nan     0.2885   -0.0000
   420        0.0001             nan     0.2885   -0.0000
   440        0.0001             nan     0.2885   -0.0000
   460        0.0000             nan     0.2885   -0.0000
   480        0.0000             nan     0.2885   -0.0000
   500        0.0000             nan     0.2885   -0.0000
   520        0.0000             nan     0.2885   -0.0000
   540        0.0000             nan     0.2885   -0.0000
   560        0.0000             nan     0.2885   -0.0000
   580        0.0000             nan     0.2885   -0.0000
   600        0.0000             nan     0.2885   -0.0000
   620        0.0000             nan     0.2885   -0.0000
   640        0.0000             nan     0.2885   -0.0000
   660        0.0000             nan     0.2885   -0.0000
   680        0.0000             nan     0.2885   -0.0000
   700        0.0000             nan     0.2885   -0.0000
   720        0.0000             nan     0.2885   -0.0000
   740        0.0000             nan     0.2885   -0.0000
   760        0.0000             nan     0.2885   -0.0000
   780        0.0000             nan     0.2885   -0.0000
   800        0.0000             nan     0.2885   -0.0000
   820        0.0000             nan     0.2885   -0.0000
   840        0.0000             nan     0.2885   -0.0000
   860        0.0000             nan     0.2885   -0.0000
   880        0.0000             nan     0.2885   -0.0000
   900        0.0000             nan     0.2885   -0.0000
   920        0.0000             nan     0.2885   -0.0000
   940        0.0000             nan     0.2885   -0.0000
   960        0.0000             nan     0.2885   -0.0000
   980        0.0000             nan     0.2885   -0.0000
  1000        0.0000             nan     0.2885   -0.0000
  1020        0.0000             nan     0.2885   -0.0000
  1040        0.0000             nan     0.2885   -0.0000
  1060        0.0000             nan     0.2885   -0.0000
  1080        0.0000             nan     0.2885   -0.0000
  1100        0.0000             nan     0.2885   -0.0000
  1120        0.0000             nan     0.2885   -0.0000
  1140        0.0000             nan     0.2885   -0.0000
  1160        0.0000             nan     0.2885   -0.0000
  1180        0.0000             nan     0.2885   -0.0000
  1200        0.0000             nan     0.2885   -0.0000
  1220        0.0000             nan     0.2885   -0.0000
  1240        0.0000             nan     0.2885   -0.0000
  1260        0.0000             nan     0.2885   -0.0000
  1280        0.0000             nan     0.2885   -0.0000
  1300        0.0000             nan     0.2885   -0.0000
  1320        0.0000             nan     0.2885   -0.0000
  1340        0.0000             nan     0.2885   -0.0000
  1360        0.0000             nan     0.2885   -0.0000
  1380        0.0000             nan     0.2885   -0.0000
  1400        0.0000             nan     0.2885   -0.0000
  1420        0.0000             nan     0.2885   -0.0000
  1440        0.0000             nan     0.2885   -0.0000
  1460        0.0000             nan     0.2885   -0.0000
  1480        0.0000             nan     0.2885   -0.0000
  1500        0.0000             nan     0.2885   -0.0000
  1520        0.0000             nan     0.2885   -0.0000
  1540        0.0000             nan     0.2885   -0.0000
  1560        0.0000             nan     0.2885   -0.0000
  1580        0.0000             nan     0.2885   -0.0000
  1600        0.0000             nan     0.2885   -0.0000
  1620        0.0000             nan     0.2885   -0.0000
  1640        0.0000             nan     0.2885   -0.0000
  1660        0.0000             nan     0.2885   -0.0000
  1680        0.0000             nan     0.2885   -0.0000
  1700        0.0000             nan     0.2885   -0.0000
  1720        0.0000             nan     0.2885   -0.0000
  1740        0.0000             nan     0.2885   -0.0000
  1760        0.0000             nan     0.2885   -0.0000
  1780        0.0000             nan     0.2885   -0.0000
  1800        0.0000             nan     0.2885   -0.0000
  1820        0.0000             nan     0.2885   -0.0000
  1840        0.0000             nan     0.2885   -0.0000
  1860        0.0000             nan     0.2885   -0.0000
  1880        0.0000             nan     0.2885   -0.0000
  1900        0.0000             nan     0.2885   -0.0000
  1920        0.0000             nan     0.2885   -0.0000
  1940        0.0000             nan     0.2885   -0.0000
  1960        0.0000             nan     0.2885   -0.0000
  1980        0.0000             nan     0.2885   -0.0000
  2000        0.0000             nan     0.2885   -0.0000
  2020        0.0000             nan     0.2885   -0.0000
  2040        0.0000             nan     0.2885   -0.0000
  2060        0.0000             nan     0.2885   -0.0000
  2080        0.0000             nan     0.2885   -0.0000
  2100        0.0000             nan     0.2885   -0.0000
  2120        0.0000             nan     0.2885   -0.0000
  2140        0.0000             nan     0.2885   -0.0000
  2160        0.0000             nan     0.2885   -0.0000
  2180        0.0000             nan     0.2885   -0.0000
  2200        0.0000             nan     0.2885   -0.0000
  2220        0.0000             nan     0.2885   -0.0000
  2240        0.0000             nan     0.2885   -0.0000
  2260        0.0000             nan     0.2885   -0.0000
  2280        0.0000             nan     0.2885   -0.0000
  2300        0.0000             nan     0.2885   -0.0000
  2320        0.0000             nan     0.2885   -0.0000
  2340        0.0000             nan     0.2885   -0.0000
  2360        0.0000             nan     0.2885   -0.0000
  2380        0.0000             nan     0.2885   -0.0000
  2400        0.0000             nan     0.2885   -0.0000
  2420        0.0000             nan     0.2885   -0.0000
  2440        0.0000             nan     0.2885   -0.0000
  2460        0.0000             nan     0.2885   -0.0000
  2480        0.0000             nan     0.2885   -0.0000
  2500        0.0000             nan     0.2885   -0.0000
  2520        0.0000             nan     0.2885   -0.0000
  2540        0.0000             nan     0.2885   -0.0000
  2560        0.0000             nan     0.2885   -0.0000
  2580        0.0000             nan     0.2885   -0.0000
  2600        0.0000             nan     0.2885   -0.0000
  2620        0.0000             nan     0.2885   -0.0000
  2640        0.0000             nan     0.2885   -0.0000
  2660        0.0000             nan     0.2885   -0.0000
  2680        0.0000             nan     0.2885   -0.0000
  2700        0.0000             nan     0.2885   -0.0000
  2720        0.0000             nan     0.2885   -0.0000
  2740        0.0000             nan     0.2885   -0.0000
  2760        0.0000             nan     0.2885   -0.0000
  2780        0.0000             nan     0.2885   -0.0000
  2800        0.0000             nan     0.2885   -0.0000
  2820        0.0000             nan     0.2885   -0.0000
  2840        0.0000             nan     0.2885   -0.0000
  2860        0.0000             nan     0.2885   -0.0000
  2880        0.0000             nan     0.2885   -0.0000
  2900        0.0000             nan     0.2885   -0.0000
  2920        0.0000             nan     0.2885   -0.0000
  2940        0.0000             nan     0.2885   -0.0000
  2960        0.0000             nan     0.2885   -0.0000
  2980        0.0000             nan     0.2885   -0.0000
  3000        0.0000             nan     0.2885   -0.0000
  3020        0.0000             nan     0.2885   -0.0000
  3040        0.0000             nan     0.2885   -0.0000
  3060        0.0000             nan     0.2885   -0.0000
  3080        0.0000             nan     0.2885   -0.0000
  3100        0.0000             nan     0.2885   -0.0000
  3120        0.0000             nan     0.2885   -0.0000
  3140        0.0000             nan     0.2885   -0.0000
  3160        0.0000             nan     0.2885   -0.0000
  3180        0.0000             nan     0.2885   -0.0000
  3200        0.0000             nan     0.2885   -0.0000
  3220        0.0000             nan     0.2885   -0.0000
  3240        0.0000             nan     0.2885   -0.0000
  3260        0.0000             nan     0.2885   -0.0000
  3280        0.0000             nan     0.2885   -0.0000
  3300        0.0000             nan     0.2885   -0.0000
  3320        0.0000             nan     0.2885   -0.0000
  3340        0.0000             nan     0.2885   -0.0000
  3360        0.0000             nan     0.2885   -0.0000
  3380        0.0000             nan     0.2885   -0.0000
  3400        0.0000             nan     0.2885   -0.0000
  3420        0.0000             nan     0.2885   -0.0000
  3440        0.0000             nan     0.2885   -0.0000
  3460        0.0000             nan     0.2885   -0.0000
  3480        0.0000             nan     0.2885   -0.0000
  3500        0.0000             nan     0.2885   -0.0000
  3520        0.0000             nan     0.2885   -0.0000
  3540        0.0000             nan     0.2885   -0.0000
  3560        0.0000             nan     0.2885   -0.0000
  3580        0.0000             nan     0.2885   -0.0000
  3600        0.0000             nan     0.2885   -0.0000
  3620        0.0000             nan     0.2885   -0.0000
  3640        0.0000             nan     0.2885   -0.0000
  3660        0.0000             nan     0.2885   -0.0000
  3680        0.0000             nan     0.2885   -0.0000
  3700        0.0000             nan     0.2885   -0.0000
  3720        0.0000             nan     0.2885   -0.0000
  3740        0.0000             nan     0.2885   -0.0000
  3760        0.0000             nan     0.2885   -0.0000
  3780        0.0000             nan     0.2885   -0.0000
  3800        0.0000             nan     0.2885   -0.0000
  3820        0.0000             nan     0.2885   -0.0000
  3840        0.0000             nan     0.2885   -0.0000
  3860        0.0000             nan     0.2885   -0.0000
  3880        0.0000             nan     0.2885   -0.0000
  3900        0.0000             nan     0.2885   -0.0000
  3920        0.0000             nan     0.2885   -0.0000
  3940        0.0000             nan     0.2885   -0.0000
  3960        0.0000             nan     0.2885   -0.0000
  3980        0.0000             nan     0.2885   -0.0000
  4000        0.0000             nan     0.2885   -0.0000
  4020        0.0000             nan     0.2885   -0.0000
  4040        0.0000             nan     0.2885   -0.0000
  4060        0.0000             nan     0.2885   -0.0000
  4080        0.0000             nan     0.2885   -0.0000
  4100        0.0000             nan     0.2885   -0.0000
  4120        0.0000             nan     0.2885   -0.0000
  4140        0.0000             nan     0.2885   -0.0000
  4160        0.0000             nan     0.2885   -0.0000
  4180        0.0000             nan     0.2885   -0.0000
  4200        0.0000             nan     0.2885   -0.0000
  4220        0.0000             nan     0.2885   -0.0000
  4240        0.0000             nan     0.2885   -0.0000
  4260        0.0000             nan     0.2885   -0.0000
  4280        0.0000             nan     0.2885   -0.0000
  4300        0.0000             nan     0.2885   -0.0000
  4320        0.0000             nan     0.2885   -0.0000
  4340        0.0000             nan     0.2885   -0.0000
  4360        0.0000             nan     0.2885   -0.0000
  4380        0.0000             nan     0.2885   -0.0000
  4400        0.0000             nan     0.2885   -0.0000
  4420        0.0000             nan     0.2885   -0.0000
  4440        0.0000             nan     0.2885   -0.0000
  4460        0.0000             nan     0.2885   -0.0000
  4480        0.0000             nan     0.2885   -0.0000
  4500        0.0000             nan     0.2885   -0.0000
  4520        0.0000             nan     0.2885   -0.0000
  4540        0.0000             nan     0.2885   -0.0000
  4560        0.0000             nan     0.2885   -0.0000
  4580        0.0000             nan     0.2885   -0.0000
  4600        0.0000             nan     0.2885   -0.0000
  4620        0.0000             nan     0.2885   -0.0000
  4640        0.0000             nan     0.2885   -0.0000
  4660        0.0000             nan     0.2885   -0.0000
  4680        0.0000             nan     0.2885   -0.0000
  4700        0.0000             nan     0.2885   -0.0000
  4720        0.0000             nan     0.2885   -0.0000
  4740        0.0000             nan     0.2885   -0.0000
  4760        0.0000             nan     0.2885   -0.0000
  4780        0.0000             nan     0.2885   -0.0000
  4800        0.0000             nan     0.2885   -0.0000
  4820        0.0000             nan     0.2885   -0.0000
  4837        0.0000             nan     0.2885   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9683             nan     0.2888   -0.0268
     2        0.9549             nan     0.2888   -0.0036
     3        0.9359             nan     0.2888    0.0127
     4        0.9316             nan     0.2888   -0.0185
     5        0.9239             nan     0.2888   -0.0037
     6        0.9138             nan     0.2888   -0.0013
     7        0.9015             nan     0.2888    0.0029
     8        0.8977             nan     0.2888   -0.0176
     9        0.8933             nan     0.2888   -0.0203
    10        0.8862             nan     0.2888   -0.0117
    20        0.8300             nan     0.2888   -0.0061
    40        0.7407             nan     0.2888   -0.0098
    60        0.6603             nan     0.2888   -0.0113
    80        0.6080             nan     0.2888   -0.0136
   100        0.5696             nan     0.2888   -0.0059
   120        0.5288             nan     0.2888   -0.0063
   140        0.4967             nan     0.2888   -0.0118
   160        0.4666             nan     0.2888   -0.0045
   180        0.4304             nan     0.2888   -0.0012
   200        0.4073             nan     0.2888   -0.0087
   220        0.3841             nan     0.2888   -0.0053
   240        0.3664             nan     0.2888   -0.0072
   260        0.3398             nan     0.2888   -0.0027
   280        0.3200             nan     0.2888   -0.0079
   300        0.2987             nan     0.2888   -0.0050
   320        0.2832             nan     0.2888   -0.0046
   340        0.2680             nan     0.2888   -0.0059
   360        0.2563             nan     0.2888   -0.0059
   380        0.2363             nan     0.2888   -0.0050
   400        0.2263             nan     0.2888   -0.0041
   420        0.2150             nan     0.2888   -0.0057
   440        0.1991             nan     0.2888   -0.0042
   460        0.1875             nan     0.2888   -0.0023
   480        0.1764             nan     0.2888   -0.0048
   500        0.1682             nan     0.2888   -0.0038
   520        0.1543             nan     0.2888   -0.0020
   540        0.1471             nan     0.2888   -0.0020
   560        0.1417             nan     0.2888   -0.0026
   580        0.1321             nan     0.2888   -0.0033
   600        0.1237             nan     0.2888   -0.0010
   620        0.1170             nan     0.2888   -0.0022
   640        0.1113             nan     0.2888   -0.0017
   660        0.1061             nan     0.2888   -0.0028
   680        0.1014             nan     0.2888   -0.0019
   700        0.0960             nan     0.2888   -0.0026
   720        0.0903             nan     0.2888   -0.0028
   740        0.0854             nan     0.2888   -0.0022
   760        0.0812             nan     0.2888   -0.0016
   780        0.0776             nan     0.2888   -0.0013
   800        0.0731             nan     0.2888   -0.0006
   820        0.0695             nan     0.2888   -0.0013
   840        0.0652             nan     0.2888   -0.0021
   860        0.0605             nan     0.2888   -0.0014
   880        0.0577             nan     0.2888   -0.0013
   900        0.0543             nan     0.2888   -0.0011
   920        0.0519             nan     0.2888   -0.0009
   940        0.0497             nan     0.2888   -0.0017
   960        0.0467             nan     0.2888   -0.0011
   980        0.0444             nan     0.2888   -0.0004
  1000        0.0419             nan     0.2888   -0.0008
  1020        0.0395             nan     0.2888   -0.0007
  1040        0.0377             nan     0.2888   -0.0007
  1060        0.0361             nan     0.2888   -0.0009
  1080        0.0349             nan     0.2888   -0.0013
  1100        0.0329             nan     0.2888   -0.0008
  1120        0.0311             nan     0.2888   -0.0003
  1140        0.0292             nan     0.2888   -0.0002
  1160        0.0277             nan     0.2888   -0.0004
  1180        0.0260             nan     0.2888   -0.0005
  1200        0.0248             nan     0.2888   -0.0010
  1220        0.0239             nan     0.2888   -0.0006
  1240        0.0229             nan     0.2888   -0.0005
  1260        0.0218             nan     0.2888   -0.0002
  1264        0.0217             nan     0.2888   -0.0004

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9525             nan     0.3308   -0.0302
     2        0.9236             nan     0.3308   -0.0179
     3        0.9024             nan     0.3308   -0.0347
     4        0.8795             nan     0.3308   -0.0169
     5        0.8653             nan     0.3308   -0.0284
     6        0.8453             nan     0.3308   -0.0330
     7        0.8265             nan     0.3308   -0.0205
     8        0.8070             nan     0.3308   -0.0281
     9        0.7804             nan     0.3308   -0.0142
    10        0.7555             nan     0.3308   -0.0079
    20        0.6104             nan     0.3308   -0.0215
    40        0.4367             nan     0.3308   -0.0254
    60        0.3096             nan     0.3308   -0.0016
    80        0.2221             nan     0.3308   -0.0046
   100        0.1663             nan     0.3308   -0.0052
   120        0.1275             nan     0.3308   -0.0061
   140        0.0948             nan     0.3308   -0.0031
   160        0.0691             nan     0.3308   -0.0013
   180        0.0519             nan     0.3308   -0.0026
   200        0.0377             nan     0.3308   -0.0012
   220        0.0301             nan     0.3308   -0.0015
   240        0.0228             nan     0.3308   -0.0007
   260        0.0185             nan     0.3308   -0.0007
   280        0.0146             nan     0.3308   -0.0011
   300        0.0111             nan     0.3308   -0.0007
   320        0.0085             nan     0.3308   -0.0005
   340        0.0063             nan     0.3308   -0.0001
   360        0.0050             nan     0.3308   -0.0002
   380        0.0037             nan     0.3308   -0.0002
   400        0.0029             nan     0.3308   -0.0001
   420        0.0023             nan     0.3308   -0.0001
   440        0.0018             nan     0.3308   -0.0001
   460        0.0014             nan     0.3308   -0.0001
   480        0.0011             nan     0.3308   -0.0001
   500        0.0008             nan     0.3308   -0.0000
   520        0.0006             nan     0.3308   -0.0000
   540        0.0005             nan     0.3308   -0.0000
   560        0.0004             nan     0.3308   -0.0000
   580        0.0003             nan     0.3308   -0.0000
   600        0.0002             nan     0.3308   -0.0000
   620        0.0002             nan     0.3308   -0.0000
   640        0.0001             nan     0.3308   -0.0000
   660        0.0001             nan     0.3308   -0.0000
   680        0.0001             nan     0.3308   -0.0000
   700        0.0001             nan     0.3308   -0.0000
   720        0.0001             nan     0.3308   -0.0000
   740        0.0000             nan     0.3308   -0.0000
   760        0.0000             nan     0.3308   -0.0000
   780        0.0000             nan     0.3308   -0.0000
   800        0.0000             nan     0.3308   -0.0000
   820        0.0000             nan     0.3308   -0.0000
   840        0.0000             nan     0.3308   -0.0000
   860        0.0000             nan     0.3308   -0.0000
   880        0.0000             nan     0.3308   -0.0000
   900        0.0000             nan     0.3308   -0.0000
   920        0.0000             nan     0.3308   -0.0000
   940        0.0000             nan     0.3308   -0.0000
   960        0.0000             nan     0.3308   -0.0000
   980        0.0000             nan     0.3308   -0.0000
  1000        0.0000             nan     0.3308   -0.0000
  1020        0.0000             nan     0.3308   -0.0000
  1040        0.0000             nan     0.3308   -0.0000
  1060        0.0000             nan     0.3308   -0.0000
  1080        0.0000             nan     0.3308   -0.0000
  1100        0.0000             nan     0.3308   -0.0000
  1120        0.0000             nan     0.3308   -0.0000
  1140        0.0000             nan     0.3308   -0.0000
  1160        0.0000             nan     0.3308   -0.0000
  1180        0.0000             nan     0.3308   -0.0000
  1200        0.0000             nan     0.3308   -0.0000
  1220        0.0000             nan     0.3308   -0.0000
  1240        0.0000             nan     0.3308   -0.0000
  1260        0.0000             nan     0.3308   -0.0000
  1280        0.0000             nan     0.3308   -0.0000
  1300        0.0000             nan     0.3308   -0.0000
  1320        0.0000             nan     0.3308   -0.0000
  1340        0.0000             nan     0.3308   -0.0000
  1360        0.0000             nan     0.3308   -0.0000
  1380        0.0000             nan     0.3308   -0.0000
  1400        0.0000             nan     0.3308   -0.0000
  1420        0.0000             nan     0.3308   -0.0000
  1440        0.0000             nan     0.3308   -0.0000
  1460        0.0000             nan     0.3308   -0.0000
  1480        0.0000             nan     0.3308   -0.0000
  1500        0.0000             nan     0.3308   -0.0000
  1520        0.0000             nan     0.3308   -0.0000
  1540        0.0000             nan     0.3308   -0.0000
  1560        0.0000             nan     0.3308   -0.0000
  1580        0.0000             nan     0.3308   -0.0000
  1600        0.0000             nan     0.3308   -0.0000
  1620        0.0000             nan     0.3308   -0.0000
  1640        0.0000             nan     0.3308   -0.0000
  1660        0.0000             nan     0.3308   -0.0000
  1680        0.0000             nan     0.3308   -0.0000
  1700        0.0000             nan     0.3308   -0.0000
  1720        0.0000             nan     0.3308   -0.0000
  1740        0.0000             nan     0.3308   -0.0000
  1760        0.0000             nan     0.3308   -0.0000
  1780        0.0000             nan     0.3308   -0.0000
  1800        0.0000             nan     0.3308   -0.0000
  1820        0.0000             nan     0.3308   -0.0000
  1825        0.0000             nan     0.3308   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9344             nan     0.3353   -0.0376
     2        0.9002             nan     0.3353   -0.0493
     3        0.8663             nan     0.3353   -0.0299
     4        0.8236             nan     0.3353   -0.0360
     5        0.7941             nan     0.3353   -0.0261
     6        0.7687             nan     0.3353   -0.0457
     7        0.7323             nan     0.3353   -0.0163
     8        0.7023             nan     0.3353   -0.0191
     9        0.6820             nan     0.3353   -0.0347
    10        0.6537             nan     0.3353   -0.0366
    20        0.4676             nan     0.3353   -0.0415
    40        0.2653             nan     0.3353   -0.0083
    60        0.1473             nan     0.3353   -0.0059
    80        0.0831             nan     0.3353   -0.0054
   100        0.0527             nan     0.3353   -0.0030
   120        0.0320             nan     0.3353   -0.0018
   140        0.0192             nan     0.3353   -0.0013
   160        0.0118             nan     0.3353   -0.0007
   180        0.0077             nan     0.3353   -0.0005
   200        0.0046             nan     0.3353   -0.0001
   220        0.0029             nan     0.3353   -0.0002
   240        0.0018             nan     0.3353   -0.0001
   260        0.0011             nan     0.3353   -0.0001
   280        0.0007             nan     0.3353   -0.0000
   300        0.0004             nan     0.3353   -0.0000
   320        0.0002             nan     0.3353   -0.0000
   340        0.0002             nan     0.3353   -0.0000
   360        0.0001             nan     0.3353   -0.0000
   380        0.0001             nan     0.3353   -0.0000
   400        0.0000             nan     0.3353   -0.0000
   420        0.0000             nan     0.3353   -0.0000
   440        0.0000             nan     0.3353   -0.0000
   460        0.0000             nan     0.3353   -0.0000
   480        0.0000             nan     0.3353   -0.0000
   500        0.0000             nan     0.3353   -0.0000
   520        0.0000             nan     0.3353   -0.0000
   540        0.0000             nan     0.3353   -0.0000
   560        0.0000             nan     0.3353   -0.0000
   580        0.0000             nan     0.3353   -0.0000
   600        0.0000             nan     0.3353   -0.0000
   620        0.0000             nan     0.3353   -0.0000
   640        0.0000             nan     0.3353   -0.0000
   660        0.0000             nan     0.3353   -0.0000
   680        0.0000             nan     0.3353   -0.0000
   700        0.0000             nan     0.3353   -0.0000
   720        0.0000             nan     0.3353   -0.0000
   740        0.0000             nan     0.3353   -0.0000
   760        0.0000             nan     0.3353   -0.0000
   780        0.0000             nan     0.3353   -0.0000
   800        0.0000             nan     0.3353   -0.0000
   820        0.0000             nan     0.3353   -0.0000
   840        0.0000             nan     0.3353   -0.0000
   860        0.0000             nan     0.3353   -0.0000
   880        0.0000             nan     0.3353   -0.0000
   900        0.0000             nan     0.3353   -0.0000
   920        0.0000             nan     0.3353   -0.0000
   940        0.0000             nan     0.3353   -0.0000
   960        0.0000             nan     0.3353   -0.0000
   980        0.0000             nan     0.3353   -0.0000
  1000        0.0000             nan     0.3353   -0.0000
  1020        0.0000             nan     0.3353   -0.0000
  1040        0.0000             nan     0.3353   -0.0000
  1060        0.0000             nan     0.3353   -0.0000
  1080        0.0000             nan     0.3353   -0.0000
  1100        0.0000             nan     0.3353   -0.0000
  1120        0.0000             nan     0.3353   -0.0000
  1140        0.0000             nan     0.3353   -0.0000
  1160        0.0000             nan     0.3353   -0.0000
  1180        0.0000             nan     0.3353   -0.0000
  1200        0.0000             nan     0.3353   -0.0000
  1220        0.0000             nan     0.3353   -0.0000
  1240        0.0000             nan     0.3353   -0.0000
  1260        0.0000             nan     0.3353   -0.0000
  1280        0.0000             nan     0.3353   -0.0000
  1300        0.0000             nan     0.3353   -0.0000
  1320        0.0000             nan     0.3353   -0.0000
  1340        0.0000             nan     0.3353   -0.0000
  1360        0.0000             nan     0.3353   -0.0000
  1380        0.0000             nan     0.3353   -0.0000
  1400        0.0000             nan     0.3353   -0.0000
  1420        0.0000             nan     0.3353   -0.0000
  1440        0.0000             nan     0.3353   -0.0000
  1460        0.0000             nan     0.3353   -0.0000
  1480        0.0000             nan     0.3353   -0.0000
  1500        0.0000             nan     0.3353   -0.0000
  1520        0.0000             nan     0.3353   -0.0000
  1540        0.0000             nan     0.3353   -0.0000
  1560        0.0000             nan     0.3353   -0.0000
  1580        0.0000             nan     0.3353   -0.0000
  1600        0.0000             nan     0.3353   -0.0000
  1620        0.0000             nan     0.3353   -0.0000
  1640        0.0000             nan     0.3353   -0.0000
  1660        0.0000             nan     0.3353   -0.0000
  1680        0.0000             nan     0.3353   -0.0000
  1700        0.0000             nan     0.3353   -0.0000
  1720        0.0000             nan     0.3353   -0.0000
  1740        0.0000             nan     0.3353   -0.0000
  1760        0.0000             nan     0.3353   -0.0000
  1780        0.0000             nan     0.3353   -0.0000
  1800        0.0000             nan     0.3353   -0.0000
  1820        0.0000             nan     0.3353   -0.0000
  1840        0.0000             nan     0.3353   -0.0000
  1860        0.0000             nan     0.3353   -0.0000
  1880        0.0000             nan     0.3353   -0.0000
  1900        0.0000             nan     0.3353   -0.0000
  1920        0.0000             nan     0.3353   -0.0000
  1940        0.0000             nan     0.3353   -0.0000
  1960        0.0000             nan     0.3353   -0.0000
  1980        0.0000             nan     0.3353   -0.0000
  2000        0.0000             nan     0.3353   -0.0000
  2020        0.0000             nan     0.3353   -0.0000
  2040        0.0000             nan     0.3353   -0.0000
  2060        0.0000             nan     0.3353   -0.0000
  2080        0.0000             nan     0.3353   -0.0000
  2100        0.0000             nan     0.3353   -0.0000
  2120        0.0000             nan     0.3353   -0.0000
  2140        0.0000             nan     0.3353   -0.0000
  2160        0.0000             nan     0.3353   -0.0000
  2180        0.0000             nan     0.3353   -0.0000
  2200        0.0000             nan     0.3353   -0.0000
  2220        0.0000             nan     0.3353   -0.0000
  2240        0.0000             nan     0.3353   -0.0000
  2260        0.0000             nan     0.3353   -0.0000
  2280        0.0000             nan     0.3353   -0.0000
  2300        0.0000             nan     0.3353   -0.0000
  2320        0.0000             nan     0.3353   -0.0000
  2340        0.0000             nan     0.3353   -0.0000
  2360        0.0000             nan     0.3353   -0.0000
  2380        0.0000             nan     0.3353   -0.0000
  2400        0.0000             nan     0.3353   -0.0000
  2420        0.0000             nan     0.3353   -0.0000
  2440        0.0000             nan     0.3353   -0.0000
  2460        0.0000             nan     0.3353   -0.0000
  2480        0.0000             nan     0.3353   -0.0000
  2500        0.0000             nan     0.3353   -0.0000
  2520        0.0000             nan     0.3353   -0.0000
  2540        0.0000             nan     0.3353   -0.0000
  2560        0.0000             nan     0.3353   -0.0000
  2580        0.0000             nan     0.3353   -0.0000
  2600        0.0000             nan     0.3353   -0.0000
  2620        0.0000             nan     0.3353   -0.0000
  2640        0.0000             nan     0.3353   -0.0000
  2660        0.0000             nan     0.3353   -0.0000
  2680        0.0000             nan     0.3353   -0.0000
  2700        0.0000             nan     0.3353   -0.0000
  2720        0.0000             nan     0.3353   -0.0000
  2740        0.0000             nan     0.3353   -0.0000
  2760        0.0000             nan     0.3353   -0.0000
  2780        0.0000             nan     0.3353   -0.0000
  2800        0.0000             nan     0.3353   -0.0000
  2820        0.0000             nan     0.3353   -0.0000
  2840        0.0000             nan     0.3353   -0.0000
  2860        0.0000             nan     0.3353   -0.0000
  2880        0.0000             nan     0.3353   -0.0000
  2900        0.0000             nan     0.3353   -0.0000
  2920        0.0000             nan     0.3353   -0.0000
  2940        0.0000             nan     0.3353   -0.0000
  2960        0.0000             nan     0.3353   -0.0000
  2980        0.0000             nan     0.3353   -0.0000
  3000        0.0000             nan     0.3353   -0.0000
  3020        0.0000             nan     0.3353   -0.0000
  3040        0.0000             nan     0.3353   -0.0000
  3060        0.0000             nan     0.3353   -0.0000
  3080        0.0000             nan     0.3353   -0.0000
  3100        0.0000             nan     0.3353   -0.0000
  3120        0.0000             nan     0.3353   -0.0000
  3140        0.0000             nan     0.3353   -0.0000
  3160        0.0000             nan     0.3353   -0.0000
  3180        0.0000             nan     0.3353   -0.0000
  3200        0.0000             nan     0.3353   -0.0000
  3220        0.0000             nan     0.3353   -0.0000
  3240        0.0000             nan     0.3353   -0.0000
  3260        0.0000             nan     0.3353   -0.0000
  3280        0.0000             nan     0.3353   -0.0000
  3300        0.0000             nan     0.3353   -0.0000
  3320        0.0000             nan     0.3353   -0.0000
  3340        0.0000             nan     0.3353   -0.0000
  3360        0.0000             nan     0.3353   -0.0000
  3380        0.0000             nan     0.3353   -0.0000
  3400        0.0000             nan     0.3353   -0.0000
  3420        0.0000             nan     0.3353   -0.0000
  3440        0.0000             nan     0.3353   -0.0000
  3460        0.0000             nan     0.3353   -0.0000
  3480        0.0000             nan     0.3353   -0.0000
  3500        0.0000             nan     0.3353   -0.0000
  3520        0.0000             nan     0.3353   -0.0000
  3540        0.0000             nan     0.3353   -0.0000
  3560        0.0000             nan     0.3353   -0.0000
  3580        0.0000             nan     0.3353   -0.0000
  3585        0.0000             nan     0.3353   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9590             nan     0.4136   -0.0297
     2        0.9369             nan     0.4136   -0.0105
     3        0.9152             nan     0.4136   -0.0433
     4        0.8965             nan     0.4136   -0.0177
     5        0.8789             nan     0.4136   -0.0218
     6        0.8499             nan     0.4136   -0.0191
     7        0.8375             nan     0.4136   -0.0129
     8        0.8248             nan     0.4136   -0.0193
     9        0.8173             nan     0.4136   -0.0177
    10        0.8120             nan     0.4136   -0.0239
    20        0.7178             nan     0.4136   -0.0287
    40        0.5777             nan     0.4136   -0.0178
    60        0.4747             nan     0.4136   -0.0196
    80        0.4088             nan     0.4136   -0.0162
   100        0.3531             nan     0.4136   -0.0138
   120        0.3061             nan     0.4136   -0.0046
   140        0.2551             nan     0.4136   -0.0108
   160        0.2136             nan     0.4136   -0.0061
   180        0.1864             nan     0.4136   -0.0077
   200        0.1614             nan     0.4136   -0.0034
   220        0.1393             nan     0.4136   -0.0034
   240        0.1240             nan     0.4136   -0.0053
   260        0.1093             nan     0.4136   -0.0034
   280        0.0944             nan     0.4136   -0.0004
   300        0.0874             nan     0.4136   -0.0046
   320        0.0763             nan     0.4136   -0.0020
   340        0.0653             nan     0.4136   -0.0019
   360        0.0582             nan     0.4136   -0.0026
   380        0.0500             nan     0.4136   -0.0010
   400        0.0435             nan     0.4136   -0.0003
   420        0.0375             nan     0.4136   -0.0019
   440        0.0332             nan     0.4136   -0.0007
   460        0.0294             nan     0.4136   -0.0007
   480        0.0263             nan     0.4136   -0.0009
   500        0.0234             nan     0.4136   -0.0005
   520        0.0199             nan     0.4136   -0.0005
   540        0.0173             nan     0.4136   -0.0004
   560        0.0157             nan     0.4136   -0.0004
   580        0.0140             nan     0.4136   -0.0004
   600        0.0128             nan     0.4136   -0.0003
   620        0.0119             nan     0.4136   -0.0004
   640        0.0106             nan     0.4136   -0.0005
   660        0.0093             nan     0.4136   -0.0003
   680        0.0083             nan     0.4136   -0.0004
   700        0.0076             nan     0.4136   -0.0003
   720        0.0065             nan     0.4136   -0.0002
   740        0.0058             nan     0.4136   -0.0001
   760        0.0052             nan     0.4136   -0.0001
   780        0.0046             nan     0.4136   -0.0001
   800        0.0041             nan     0.4136   -0.0001
   820        0.0038             nan     0.4136   -0.0001
   840        0.0033             nan     0.4136   -0.0002
   860        0.0030             nan     0.4136   -0.0001
   880        0.0027             nan     0.4136   -0.0001
   900        0.0024             nan     0.4136   -0.0001
   920        0.0021             nan     0.4136   -0.0001
   940        0.0019             nan     0.4136   -0.0001
   960        0.0017             nan     0.4136   -0.0000
   980        0.0015             nan     0.4136   -0.0000
  1000        0.0013             nan     0.4136   -0.0000
  1020        0.0012             nan     0.4136   -0.0000
  1024        0.0012             nan     0.4136   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9455             nan     0.4240   -0.0379
     2        0.9228             nan     0.4240   -0.0276
     3        0.8901             nan     0.4240   -0.0176
     4        0.8733             nan     0.4240   -0.0415
     5        0.8525             nan     0.4240   -0.0349
     6        0.8237             nan     0.4240   -0.0187
     7        0.8075             nan     0.4240   -0.0384
     8        0.7900             nan     0.4240   -0.0338
     9        0.7623             nan     0.4240   -0.0049
    10        0.7421             nan     0.4240   -0.0174
    20        0.5687             nan     0.4240   -0.0221
    40        0.4012             nan     0.4240   -0.0062
    60        0.2851             nan     0.4240   -0.0156
    80        0.1986             nan     0.4240   -0.0130
   100        0.1412             nan     0.4240   -0.0100
   120        0.1069             nan     0.4240   -0.0067
   140        0.0777             nan     0.4240   -0.0044
   160        0.0597             nan     0.4240   -0.0030
   180        0.0458             nan     0.4240   -0.0029
   200        0.0335             nan     0.4240   -0.0027
   220        0.0247             nan     0.4240   -0.0015
   240        0.0183             nan     0.4240   -0.0013
   260        0.0142             nan     0.4240   -0.0007
   280        0.0112             nan     0.4240   -0.0004
   300        0.0083             nan     0.4240   -0.0004
   320        0.0061             nan     0.4240   -0.0003
   340        0.0047             nan     0.4240   -0.0002
   360        0.0036             nan     0.4240   -0.0003
   380        0.0029             nan     0.4240   -0.0002
   400        0.0022             nan     0.4240   -0.0001
   420        0.0017             nan     0.4240   -0.0001
   440        0.0013             nan     0.4240   -0.0001
   460        0.0010             nan     0.4240   -0.0000
   480        0.0008             nan     0.4240   -0.0000
   500        0.0006             nan     0.4240   -0.0000
   520        0.0004             nan     0.4240   -0.0000
   540        0.0003             nan     0.4240   -0.0000
   560        0.0003             nan     0.4240   -0.0000
   580        0.0002             nan     0.4240   -0.0000
   600        0.0002             nan     0.4240   -0.0000
   620        0.0001             nan     0.4240   -0.0000
   640        0.0001             nan     0.4240   -0.0000
   660        0.0001             nan     0.4240   -0.0000
   680        0.0001             nan     0.4240   -0.0000
   700        0.0000             nan     0.4240   -0.0000
   720        0.0000             nan     0.4240   -0.0000
   740        0.0000             nan     0.4240   -0.0000
   760        0.0000             nan     0.4240   -0.0000
   780        0.0000             nan     0.4240   -0.0000
   800        0.0000             nan     0.4240   -0.0000
   820        0.0000             nan     0.4240   -0.0000
   840        0.0000             nan     0.4240   -0.0000
   860        0.0000             nan     0.4240   -0.0000
   880        0.0000             nan     0.4240   -0.0000
   900        0.0000             nan     0.4240   -0.0000
   920        0.0000             nan     0.4240   -0.0000
   940        0.0000             nan     0.4240   -0.0000
   960        0.0000             nan     0.4240   -0.0000
   980        0.0000             nan     0.4240   -0.0000
  1000        0.0000             nan     0.4240   -0.0000
  1020        0.0000             nan     0.4240   -0.0000
  1040        0.0000             nan     0.4240   -0.0000
  1060        0.0000             nan     0.4240   -0.0000
  1080        0.0000             nan     0.4240   -0.0000
  1100        0.0000             nan     0.4240   -0.0000
  1120        0.0000             nan     0.4240   -0.0000
  1140        0.0000             nan     0.4240   -0.0000
  1160        0.0000             nan     0.4240   -0.0000
  1180        0.0000             nan     0.4240   -0.0000
  1200        0.0000             nan     0.4240   -0.0000
  1220        0.0000             nan     0.4240   -0.0000
  1240        0.0000             nan     0.4240   -0.0000
  1260        0.0000             nan     0.4240   -0.0000
  1280        0.0000             nan     0.4240   -0.0000
  1300        0.0000             nan     0.4240   -0.0000
  1320        0.0000             nan     0.4240   -0.0000
  1340        0.0000             nan     0.4240   -0.0000
  1360        0.0000             nan     0.4240   -0.0000
  1380        0.0000             nan     0.4240   -0.0000
  1400        0.0000             nan     0.4240   -0.0000
  1420        0.0000             nan     0.4240   -0.0000
  1440        0.0000             nan     0.4240   -0.0000
  1460        0.0000             nan     0.4240   -0.0000
  1480        0.0000             nan     0.4240   -0.0000
  1500        0.0000             nan     0.4240   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9691             nan     0.4738   -0.0671
     2        0.9313             nan     0.4738   -0.0287
     3        0.9098             nan     0.4738   -0.0266
     4        0.8714             nan     0.4738   -0.0235
     5        0.8627             nan     0.4738   -0.0605
     6        0.8423             nan     0.4738   -0.0417
     7        0.8153             nan     0.4738   -0.0176
     8        0.8017             nan     0.4738   -0.0331
     9        0.7700             nan     0.4738   -0.0107
    10        0.7653             nan     0.4738   -0.0528
    20        0.6029             nan     0.4738   -0.0218
    40        0.4213             nan     0.4738   -0.0165
    60        0.3000             nan     0.4738   -0.0109
    80        0.2163             nan     0.4738   -0.0134
   100        0.1543             nan     0.4738   -0.0055
   120        0.1160             nan     0.4738   -0.0086
   140        0.0862             nan     0.4738   -0.0070
   160        0.0639             nan     0.4738   -0.0047
   180        0.0464             nan     0.4738   -0.0022
   200        0.0336             nan     0.4738   -0.0019
   220        0.0248             nan     0.4738   -0.0017
   240        0.0175             nan     0.4738   -0.0008
   260        0.0135             nan     0.4738   -0.0008
   280        0.0101             nan     0.4738   -0.0001
   300        0.0073             nan     0.4738   -0.0005
   320        0.0052             nan     0.4738   -0.0003
   340        0.0041             nan     0.4738   -0.0004
   360        0.0029             nan     0.4738   -0.0002
   380        0.0022             nan     0.4738   -0.0001
   400        0.0017             nan     0.4738   -0.0001
   420        0.0013             nan     0.4738   -0.0000
   440        0.0010             nan     0.4738   -0.0001
   460        0.0007             nan     0.4738   -0.0000
   480        0.0005             nan     0.4738   -0.0000
   500        0.0004             nan     0.4738   -0.0000
   520        0.0003             nan     0.4738   -0.0000
   540        0.0002             nan     0.4738   -0.0000
   560        0.0002             nan     0.4738   -0.0000
   580        0.0001             nan     0.4738   -0.0000
   600        0.0001             nan     0.4738   -0.0000
   620        0.0001             nan     0.4738   -0.0000
   640        0.0001             nan     0.4738   -0.0000
   660        0.0000             nan     0.4738   -0.0000
   680        0.0000             nan     0.4738   -0.0000
   700        0.0000             nan     0.4738   -0.0000
   720        0.0000             nan     0.4738   -0.0000
   740        0.0000             nan     0.4738   -0.0000
   760        0.0000             nan     0.4738   -0.0000
   780        0.0000             nan     0.4738   -0.0000
   800        0.0000             nan     0.4738   -0.0000
   820        0.0000             nan     0.4738   -0.0000
   840        0.0000             nan     0.4738   -0.0000
   860        0.0000             nan     0.4738   -0.0000
   880        0.0000             nan     0.4738   -0.0000
   900        0.0000             nan     0.4738   -0.0000
   920        0.0000             nan     0.4738   -0.0000
   940        0.0000             nan     0.4738   -0.0000
   960        0.0000             nan     0.4738   -0.0000
   980        0.0000             nan     0.4738   -0.0000
  1000        0.0000             nan     0.4738   -0.0000
  1020        0.0000             nan     0.4738   -0.0000
  1040        0.0000             nan     0.4738   -0.0000
  1060        0.0000             nan     0.4738   -0.0000
  1080        0.0000             nan     0.4738   -0.0000
  1100        0.0000             nan     0.4738   -0.0000
  1120        0.0000             nan     0.4738   -0.0000
  1140        0.0000             nan     0.4738   -0.0000
  1160        0.0000             nan     0.4738   -0.0000
  1180        0.0000             nan     0.4738   -0.0000
  1200        0.0000             nan     0.4738   -0.0000
  1220        0.0000             nan     0.4738   -0.0000
  1240        0.0000             nan     0.4738   -0.0000
  1260        0.0000             nan     0.4738   -0.0000
  1280        0.0000             nan     0.4738   -0.0000
  1300        0.0000             nan     0.4738   -0.0000
  1320        0.0000             nan     0.4738   -0.0000
  1340        0.0000             nan     0.4738   -0.0000
  1360        0.0000             nan     0.4738   -0.0000
  1380        0.0000             nan     0.4738   -0.0000
  1400        0.0000             nan     0.4738   -0.0000
  1420        0.0000             nan     0.4738   -0.0000
  1440        0.0000             nan     0.4738   -0.0000
  1460        0.0000             nan     0.4738   -0.0000
  1480        0.0000             nan     0.4738   -0.0000
  1500        0.0000             nan     0.4738   -0.0000
  1520        0.0000             nan     0.4738   -0.0000
  1540        0.0000             nan     0.4738   -0.0000
  1560        0.0000             nan     0.4738   -0.0000
  1580        0.0000             nan     0.4738   -0.0000
  1600        0.0000             nan     0.4738   -0.0000
  1620        0.0000             nan     0.4738   -0.0000
  1640        0.0000             nan     0.4738   -0.0000
  1660        0.0000             nan     0.4738   -0.0000
  1680        0.0000             nan     0.4738   -0.0000
  1700        0.0000             nan     0.4738   -0.0000
  1720        0.0000             nan     0.4738   -0.0000
  1740        0.0000             nan     0.4738   -0.0000
  1760        0.0000             nan     0.4738   -0.0000
  1780        0.0000             nan     0.4738   -0.0000
  1800        0.0000             nan     0.4738   -0.0000
  1820        0.0000             nan     0.4738   -0.0000
  1840        0.0000             nan     0.4738   -0.0000
  1860        0.0000             nan     0.4738   -0.0000
  1880        0.0000             nan     0.4738   -0.0000
  1900        0.0000             nan     0.4738   -0.0000
  1920        0.0000             nan     0.4738   -0.0000
  1940        0.0000             nan     0.4738   -0.0000
  1960        0.0000             nan     0.4738   -0.0000
  1980        0.0000             nan     0.4738   -0.0000
  2000        0.0000             nan     0.4738   -0.0000
  2020        0.0000             nan     0.4738   -0.0000
  2040        0.0000             nan     0.4738   -0.0000
  2060        0.0000             nan     0.4738   -0.0000
  2080        0.0000             nan     0.4738   -0.0000
  2100        0.0000             nan     0.4738   -0.0000
  2120        0.0000             nan     0.4738   -0.0000
  2140        0.0000             nan     0.4738   -0.0000
  2160        0.0000             nan     0.4738   -0.0000
  2180        0.0000             nan     0.4738   -0.0000
  2200        0.0000             nan     0.4738   -0.0000
  2220        0.0000             nan     0.4738   -0.0000
  2240        0.0000             nan     0.4738   -0.0000
  2260        0.0000             nan     0.4738   -0.0000
  2280        0.0000             nan     0.4738   -0.0000
  2300        0.0000             nan     0.4738   -0.0000
  2320        0.0000             nan     0.4738   -0.0000
  2340        0.0000             nan     0.4738   -0.0000
  2360        0.0000             nan     0.4738   -0.0000
  2380        0.0000             nan     0.4738   -0.0000
  2400        0.0000             nan     0.4738   -0.0000
  2420        0.0000             nan     0.4738   -0.0000
  2440        0.0000             nan     0.4738   -0.0000
  2460        0.0000             nan     0.4738   -0.0000
  2480        0.0000             nan     0.4738   -0.0000
  2500        0.0000             nan     0.4738   -0.0000
  2520        0.0000             nan     0.4738   -0.0000
  2540        0.0000             nan     0.4738   -0.0000
  2560        0.0000             nan     0.4738   -0.0000
  2580        0.0000             nan     0.4738   -0.0000
  2600        0.0000             nan     0.4738   -0.0000
  2620        0.0000             nan     0.4738   -0.0000
  2640        0.0000             nan     0.4738   -0.0000
  2660        0.0000             nan     0.4738   -0.0000
  2680        0.0000             nan     0.4738   -0.0000
  2700        0.0000             nan     0.4738   -0.0000
  2720        0.0000             nan     0.4738   -0.0000
  2740        0.0000             nan     0.4738   -0.0000
  2760        0.0000             nan     0.4738   -0.0000
  2780        0.0000             nan     0.4738   -0.0000
  2800        0.0000             nan     0.4738   -0.0000
  2820        0.0000             nan     0.4738   -0.0000
  2840        0.0000             nan     0.4738   -0.0000
  2860        0.0000             nan     0.4738   -0.0000
  2880        0.0000             nan     0.4738   -0.0000
  2900        0.0000             nan     0.4738   -0.0000
  2920        0.0000             nan     0.4738   -0.0000
  2940        0.0000             nan     0.4738   -0.0000
  2960        0.0000             nan     0.4738   -0.0000
  2980        0.0000             nan     0.4738   -0.0000
  3000        0.0000             nan     0.4738   -0.0000
  3020        0.0000             nan     0.4738   -0.0000
  3040        0.0000             nan     0.4738   -0.0000
  3060        0.0000             nan     0.4738   -0.0000
  3080        0.0000             nan     0.4738   -0.0000
  3100        0.0000             nan     0.4738   -0.0000
  3120        0.0000             nan     0.4738   -0.0000
  3140        0.0000             nan     0.4738   -0.0000
  3160        0.0000             nan     0.4738   -0.0000
  3180        0.0000             nan     0.4738   -0.0000
  3200        0.0000             nan     0.4738   -0.0000
  3220        0.0000             nan     0.4738   -0.0000
  3240        0.0000             nan     0.4738   -0.0000
  3260        0.0000             nan     0.4738   -0.0000
  3280        0.0000             nan     0.4738   -0.0000
  3300        0.0000             nan     0.4738   -0.0000
  3320        0.0000             nan     0.4738   -0.0000
  3340        0.0000             nan     0.4738   -0.0000
  3360        0.0000             nan     0.4738   -0.0000
  3380        0.0000             nan     0.4738   -0.0000
  3400        0.0000             nan     0.4738   -0.0000
  3420        0.0000             nan     0.4738   -0.0000
  3440        0.0000             nan     0.4738   -0.0000
  3460        0.0000             nan     0.4738   -0.0000
  3480        0.0000             nan     0.4738   -0.0000
  3500        0.0000             nan     0.4738   -0.0000
  3520        0.0000             nan     0.4738   -0.0000
  3540        0.0000             nan     0.4738   -0.0000
  3560        0.0000             nan     0.4738   -0.0000
  3580        0.0000             nan     0.4738   -0.0000
  3600        0.0000             nan     0.4738   -0.0000
  3620        0.0000             nan     0.4738   -0.0000
  3640        0.0000             nan     0.4738   -0.0000
  3660        0.0000             nan     0.4738   -0.0000
  3680        0.0000             nan     0.4738   -0.0000
  3700        0.0000             nan     0.4738   -0.0000
  3720        0.0000             nan     0.4738   -0.0000
  3740        0.0000             nan     0.4738   -0.0000
  3760        0.0000             nan     0.4738   -0.0000
  3780        0.0000             nan     0.4738   -0.0000
  3800        0.0000             nan     0.4738   -0.0000
  3820        0.0000             nan     0.4738   -0.0000
  3840        0.0000             nan     0.4738   -0.0000
  3860        0.0000             nan     0.4738   -0.0000
  3880        0.0000             nan     0.4738   -0.0000
  3900        0.0000             nan     0.4738   -0.0000
  3920        0.0000             nan     0.4738   -0.0000
  3940        0.0000             nan     0.4738   -0.0000
  3960        0.0000             nan     0.4738   -0.0000
  3980        0.0000             nan     0.4738   -0.0000
  4000        0.0000             nan     0.4738   -0.0000
  4020        0.0000             nan     0.4738   -0.0000
  4040        0.0000             nan     0.4738   -0.0000
  4060        0.0000             nan     0.4738   -0.0000
  4080        0.0000             nan     0.4738   -0.0000
  4100        0.0000             nan     0.4738   -0.0000
  4120        0.0000             nan     0.4738   -0.0000
  4129        0.0000             nan     0.4738   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9467             nan     0.5391   -0.1031
     2        0.8934             nan     0.5391   -0.0456
     3        0.8580             nan     0.5391   -0.0933
     4        0.8334             nan     0.5391   -0.0968
     5        0.7835             nan     0.5391   -0.0401
     6        0.7499             nan     0.5391   -0.0648
     7        0.6996             nan     0.5391   -0.0337
     8        0.6641             nan     0.5391   -0.0402
     9        0.6362             nan     0.5391   -0.0612
    10        0.6160             nan     0.5391   -0.0690
    20        0.4286             nan     0.5391   -0.0032
    40        0.2040             nan     0.5391   -0.0170
    60        0.0957             nan     0.5391   -0.0124
    80        0.0437             nan     0.5391   -0.0032
   100        0.0237             nan     0.5391   -0.0026
   120        0.0119             nan     0.5391   -0.0008
   140        0.0064             nan     0.5391   -0.0008
   160        0.0033             nan     0.5391   -0.0003
   180        0.0014             nan     0.5391   -0.0001
   200        0.0007             nan     0.5391   -0.0001
   220        0.0003             nan     0.5391   -0.0000
   240        0.0002             nan     0.5391   -0.0000
   260        0.0001             nan     0.5391   -0.0000
   280        0.0000             nan     0.5391   -0.0000
   300        0.0000             nan     0.5391   -0.0000
   320        0.0000             nan     0.5391   -0.0000
   340        0.0000             nan     0.5391   -0.0000
   360        0.0000             nan     0.5391   -0.0000
   380        0.0000             nan     0.5391   -0.0000
   400        0.0000             nan     0.5391   -0.0000
   420        0.0000             nan     0.5391   -0.0000
   440        0.0000             nan     0.5391   -0.0000
   460        0.0000             nan     0.5391   -0.0000
   480        0.0000             nan     0.5391   -0.0000
   500        0.0000             nan     0.5391   -0.0000
   520        0.0000             nan     0.5391   -0.0000
   540        0.0000             nan     0.5391   -0.0000
   560        0.0000             nan     0.5391   -0.0000
   580        0.0000             nan     0.5391   -0.0000
   600        0.0000             nan     0.5391   -0.0000
   620        0.0000             nan     0.5391   -0.0000
   640        0.0000             nan     0.5391   -0.0000
   660        0.0000             nan     0.5391   -0.0000
   680        0.0000             nan     0.5391   -0.0000
   700        0.0000             nan     0.5391   -0.0000
   720        0.0000             nan     0.5391   -0.0000
   740        0.0000             nan     0.5391   -0.0000
   760        0.0000             nan     0.5391   -0.0000
   780        0.0000             nan     0.5391   -0.0000
   800        0.0000             nan     0.5391   -0.0000
   820        0.0000             nan     0.5391   -0.0000
   840        0.0000             nan     0.5391   -0.0000
   860        0.0000             nan     0.5391   -0.0000
   880        0.0000             nan     0.5391   -0.0000
   900        0.0000             nan     0.5391   -0.0000
   920        0.0000             nan     0.5391   -0.0000
   940        0.0000             nan     0.5391   -0.0000
   960        0.0000             nan     0.5391   -0.0000
   980        0.0000             nan     0.5391   -0.0000
  1000        0.0000             nan     0.5391   -0.0000
  1020        0.0000             nan     0.5391   -0.0000
  1040        0.0000             nan     0.5391   -0.0000
  1060        0.0000             nan     0.5391   -0.0000
  1080        0.0000             nan     0.5391   -0.0000
  1100        0.0000             nan     0.5391   -0.0000
  1120        0.0000             nan     0.5391   -0.0000
  1140        0.0000             nan     0.5391   -0.0000
  1160        0.0000             nan     0.5391   -0.0000
  1180        0.0000             nan     0.5391   -0.0000
  1200        0.0000             nan     0.5391   -0.0000
  1220        0.0000             nan     0.5391   -0.0000
  1240        0.0000             nan     0.5391   -0.0000
  1260        0.0000             nan     0.5391   -0.0000
  1280        0.0000             nan     0.5391   -0.0000
  1300        0.0000             nan     0.5391   -0.0000
  1320        0.0000             nan     0.5391   -0.0000
  1340        0.0000             nan     0.5391   -0.0000
  1360        0.0000             nan     0.5391   -0.0000
  1380        0.0000             nan     0.5391   -0.0000
  1400        0.0000             nan     0.5391   -0.0000
  1420        0.0000             nan     0.5391   -0.0000
  1440        0.0000             nan     0.5391   -0.0000
  1460        0.0000             nan     0.5391   -0.0000
  1480        0.0000             nan     0.5391   -0.0000
  1500        0.0000             nan     0.5391   -0.0000
  1520        0.0000             nan     0.5391   -0.0000
  1540        0.0000             nan     0.5391   -0.0000
  1560        0.0000             nan     0.5391   -0.0000
  1580        0.0000             nan     0.5391   -0.0000
  1600        0.0000             nan     0.5391   -0.0000
  1620        0.0000             nan     0.5391   -0.0000
  1640        0.0000             nan     0.5391   -0.0000
  1660        0.0000             nan     0.5391   -0.0000
  1680        0.0000             nan     0.5391   -0.0000
  1700        0.0000             nan     0.5391   -0.0000
  1720        0.0000             nan     0.5391   -0.0000
  1740        0.0000             nan     0.5391   -0.0000
  1760        0.0000             nan     0.5391   -0.0000
  1780        0.0000             nan     0.5391   -0.0000
  1784        0.0000             nan     0.5391   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9644             nan     0.5600   -0.0837
     2        0.9411             nan     0.5600   -0.0409
     3        0.9325             nan     0.5600   -0.0656
     4        0.9215             nan     0.5600   -0.0436
     5        0.8901             nan     0.5600    0.0010
     6        0.8870             nan     0.5600   -0.0556
     7        0.8765             nan     0.5600   -0.0455
     8        0.8676             nan     0.5600   -0.0338
     9        0.8546             nan     0.5600   -0.0463
    10        0.8294             nan     0.5600   -0.0175
    20        0.7180             nan     0.5600   -0.0365
    40        0.5644             nan     0.5600   -0.0266
    60        0.4676             nan     0.5600   -0.0094
    80        0.3777             nan     0.5600   -0.0189
   100        0.3132             nan     0.5600   -0.0152
   120        0.2649             nan     0.5600   -0.0064
   140        0.2137             nan     0.5600   -0.0082
   160        0.1811             nan     0.5600   -0.0035
   180        0.1535             nan     0.5600   -0.0015
   200        0.1288             nan     0.5600   -0.0094
   220        0.1046             nan     0.5600   -0.0049
   240        0.0891             nan     0.5600   -0.0056
   260        0.0763             nan     0.5600   -0.0041
   280        0.0581             nan     0.5600   -0.0014
   300        0.0467             nan     0.5600   -0.0027
   320        0.0390             nan     0.5600   -0.0022
   340        0.0316             nan     0.5600   -0.0010
   360        0.0260             nan     0.5600   -0.0010
   380        0.0213             nan     0.5600   -0.0007
   400        0.0170             nan     0.5600   -0.0007
   420        0.0147             nan     0.5600   -0.0010
   440        0.0117             nan     0.5600   -0.0004
   460        0.0101             nan     0.5600   -0.0004
   480        0.0086             nan     0.5600   -0.0005
   500        0.0072             nan     0.5600   -0.0003
   520        0.0061             nan     0.5600   -0.0003
   540        0.0052             nan     0.5600   -0.0005
   560        0.0039             nan     0.5600   -0.0003
   580        0.0034             nan     0.5600   -0.0001
   600        0.0028             nan     0.5600   -0.0002
   620        0.0023             nan     0.5600   -0.0001
   640        0.0018             nan     0.5600   -0.0001
   660        0.0016             nan     0.5600   -0.0000
   680        0.0014             nan     0.5600   -0.0001
   700        0.0012             nan     0.5600   -0.0000
   720        0.0010             nan     0.5600   -0.0001
   740        0.0009             nan     0.5600   -0.0000
   760        0.0008             nan     0.5600   -0.0000
   780        0.0007             nan     0.5600   -0.0000
   800        0.0006             nan     0.5600   -0.0001
   820        0.0005             nan     0.5600   -0.0000
   840        0.0004             nan     0.5600   -0.0000
   860        0.0003             nan     0.5600   -0.0000
   880        0.0003             nan     0.5600   -0.0000
   900        0.0002             nan     0.5600   -0.0000
   920        0.0002             nan     0.5600   -0.0000
   940        0.0002             nan     0.5600   -0.0000
   960        0.0001             nan     0.5600   -0.0000
   980        0.0001             nan     0.5600   -0.0000
  1000        0.0001             nan     0.5600   -0.0000
  1020        0.0001             nan     0.5600   -0.0000
  1040        0.0001             nan     0.5600   -0.0000
  1060        0.0001             nan     0.5600   -0.0000
  1080        0.0001             nan     0.5600   -0.0000
  1100        0.0000             nan     0.5600   -0.0000
  1120        0.0000             nan     0.5600   -0.0000
  1140        0.0000             nan     0.5600   -0.0000
  1160        0.0000             nan     0.5600   -0.0000
  1180        0.0000             nan     0.5600   -0.0000
  1200        0.0000             nan     0.5600   -0.0000
  1220        0.0000             nan     0.5600   -0.0000
  1240        0.0000             nan     0.5600   -0.0000
  1260        0.0000             nan     0.5600   -0.0000
  1280        0.0000             nan     0.5600   -0.0000
  1300        0.0000             nan     0.5600   -0.0000
  1320        0.0000             nan     0.5600   -0.0000
  1340        0.0000             nan     0.5600   -0.0000
  1360        0.0000             nan     0.5600   -0.0000
  1380        0.0000             nan     0.5600   -0.0000
  1400        0.0000             nan     0.5600   -0.0000
  1420        0.0000             nan     0.5600   -0.0000
  1440        0.0000             nan     0.5600   -0.0000
  1460        0.0000             nan     0.5600   -0.0000
  1480        0.0000             nan     0.5600   -0.0000
  1500        0.0000             nan     0.5600   -0.0000
  1520        0.0000             nan     0.5600   -0.0000
  1540        0.0000             nan     0.5600   -0.0000
  1560        0.0000             nan     0.5600   -0.0000
  1580        0.0000             nan     0.5600   -0.0000
  1600        0.0000             nan     0.5600   -0.0000
  1620        0.0000             nan     0.5600   -0.0000
  1640        0.0000             nan     0.5600   -0.0000
  1660        0.0000             nan     0.5600   -0.0000
  1680        0.0000             nan     0.5600   -0.0000
  1700        0.0000             nan     0.5600   -0.0000
  1720        0.0000             nan     0.5600   -0.0000
  1740        0.0000             nan     0.5600   -0.0000
  1760        0.0000             nan     0.5600   -0.0000
  1780        0.0000             nan     0.5600   -0.0000
  1800        0.0000             nan     0.5600   -0.0000
  1820        0.0000             nan     0.5600   -0.0000
  1840        0.0000             nan     0.5600   -0.0000
  1860        0.0000             nan     0.5600   -0.0000
  1880        0.0000             nan     0.5600   -0.0000
  1900        0.0000             nan     0.5600   -0.0000
  1920        0.0000             nan     0.5600   -0.0000
  1940        0.0000             nan     0.5600   -0.0000
  1960        0.0000             nan     0.5600   -0.0000
  1980        0.0000             nan     0.5600   -0.0000
  2000        0.0000             nan     0.5600   -0.0000
  2020        0.0000             nan     0.5600   -0.0000
  2040        0.0000             nan     0.5600   -0.0000
  2060        0.0000             nan     0.5600   -0.0000
  2080        0.0000             nan     0.5600   -0.0000
  2100        0.0000             nan     0.5600   -0.0000
  2120        0.0000             nan     0.5600   -0.0000
  2140        0.0000             nan     0.5600   -0.0000
  2160        0.0000             nan     0.5600   -0.0000
  2180        0.0000             nan     0.5600   -0.0000
  2200        0.0000             nan     0.5600   -0.0000
  2220        0.0000             nan     0.5600   -0.0000
  2240        0.0000             nan     0.5600   -0.0000
  2260        0.0000             nan     0.5600   -0.0000
  2280        0.0000             nan     0.5600   -0.0000
  2300        0.0000             nan     0.5600   -0.0000
  2320        0.0000             nan     0.5600   -0.0000
  2340        0.0000             nan     0.5600   -0.0000
  2360        0.0000             nan     0.5600   -0.0000
  2380        0.0000             nan     0.5600   -0.0000
  2400        0.0000             nan     0.5600   -0.0000
  2420        0.0000             nan     0.5600   -0.0000
  2440        0.0000             nan     0.5600   -0.0000
  2460        0.0000             nan     0.5600   -0.0000
  2480        0.0000             nan     0.5600   -0.0000
  2500        0.0000             nan     0.5600   -0.0000
  2510        0.0000             nan     0.5600   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9665             nan     0.5758   -0.0051
     2        0.9697             nan     0.5758   -0.0264
     3        0.9613             nan     0.5758   -0.0079
     4        0.9611             nan     0.5758   -0.0274
     5        0.9515             nan     0.5758   -0.0100
     6        0.9356             nan     0.5758   -0.0004
     7        0.9285             nan     0.5758   -0.0066
     8        0.9244             nan     0.5758   -0.0136
     9        0.9207             nan     0.5758   -0.0102
    10        0.9179             nan     0.5758   -0.0154
    20        0.8950             nan     0.5758   -0.0148
    40        0.8306             nan     0.5758   -0.0191
    60        0.7797             nan     0.5758   -0.0094
    80        0.7476             nan     0.5758   -0.0187
   100        0.7199             nan     0.5758   -0.0386
   120        0.7004             nan     0.5758   -0.0234
   140        0.6707             nan     0.5758   -0.0202
   160        0.6519             nan     0.5758   -0.0084
   180        0.6279             nan     0.5758   -0.0038
   200        0.6057             nan     0.5758   -0.0100
   220        0.5976             nan     0.5758   -0.0129
   240        0.5682             nan     0.5758   -0.0211
   260        0.5548             nan     0.5758   -0.0114
   280        0.5467             nan     0.5758   -0.0163
   300        0.5178             nan     0.5758   -0.0211
   320        0.4990             nan     0.5758   -0.0143
   340        0.4912             nan     0.5758   -0.0157
   360        0.4785             nan     0.5758   -0.0107
   380        0.4604             nan     0.5758   -0.0054
   400        0.4467             nan     0.5758   -0.0030
   420        0.4369             nan     0.5758   -0.0170
   440        0.4242             nan     0.5758   -0.0097
   460        0.4101             nan     0.5758   -0.0037
   480        0.4019             nan     0.5758   -0.0114
   500        0.3873             nan     0.5758   -0.0104
   520        0.3807             nan     0.5758   -0.0159
   540        0.3711             nan     0.5758   -0.0160
   560        0.3652             nan     0.5758   -0.0048
   580        0.3547             nan     0.5758   -0.0031
   600        0.3485             nan     0.5758   -0.0145
   620        0.3387             nan     0.5758   -0.0140
   640        0.3327             nan     0.5758   -0.0069
   660        0.3283             nan     0.5758   -0.0139
   680        0.3162             nan     0.5758   -0.0045
   700        0.3103             nan     0.5758   -0.0038
   720        0.2917             nan     0.5758   -0.0016
   740        0.2930             nan     0.5758   -0.0059
   760        0.2851             nan     0.5758   -0.0029
   780        0.2719             nan     0.5758   -0.0055
   800        0.2645             nan     0.5758   -0.0057
   820        0.2647             nan     0.5758   -0.0071
   840        0.2564             nan     0.5758   -0.0068
   860        0.2497             nan     0.5758   -0.0111
   880        0.2373             nan     0.5758   -0.0030
   900        0.2370             nan     0.5758   -0.0059
   920        0.2318             nan     0.5758   -0.0051
   940        0.2231             nan     0.5758   -0.0012
   960        0.2200             nan     0.5758   -0.0093
   980        0.2120             nan     0.5758   -0.0051
  1000        0.2058             nan     0.5758   -0.0064
  1020        0.2018             nan     0.5758   -0.0013
  1040        0.2016             nan     0.5758   -0.0039
  1060        0.1943             nan     0.5758   -0.0037
  1080        0.1895             nan     0.5758   -0.0038
  1100        0.1875             nan     0.5758   -0.0067
  1120        0.1844             nan     0.5758   -0.0033
  1140        0.1801             nan     0.5758   -0.0051
  1160        0.1759             nan     0.5758   -0.0070
  1180        0.1660             nan     0.5758   -0.0010
  1200        0.1653             nan     0.5758   -0.0053
  1220        0.1575             nan     0.5758   -0.0018
  1240        0.1540             nan     0.5758   -0.0030
  1260        0.1510             nan     0.5758   -0.0071
  1280        0.1516             nan     0.5758    0.0005
  1300        0.1457             nan     0.5758   -0.0018
  1320        0.1418             nan     0.5758   -0.0027
  1340        0.1411             nan     0.5758   -0.0042
  1360        0.1361             nan     0.5758   -0.0033
  1380        0.1341             nan     0.5758   -0.0062
  1400        0.1291             nan     0.5758   -0.0003
  1420        0.1252             nan     0.5758   -0.0037
  1440        0.1235             nan     0.5758   -0.0019
  1460        0.1205             nan     0.5758   -0.0019
  1480        0.1191             nan     0.5758   -0.0037
  1500        0.1160             nan     0.5758   -0.0005
  1520        0.1132             nan     0.5758   -0.0006
  1540        0.1110             nan     0.5758   -0.0021
  1560        0.1090             nan     0.5758   -0.0027
  1580        0.1096             nan     0.5758   -0.0040
  1600        0.1052             nan     0.5758   -0.0011
  1620        0.1024             nan     0.5758   -0.0027
  1640        0.0998             nan     0.5758   -0.0015
  1660        0.0966             nan     0.5758   -0.0016
  1680        0.0949             nan     0.5758   -0.0015
  1700        0.0934             nan     0.5758   -0.0021
  1720        0.0911             nan     0.5758   -0.0002
  1740        0.0885             nan     0.5758   -0.0037
  1760        0.0864             nan     0.5758   -0.0022
  1780        0.0848             nan     0.5758   -0.0010
  1800        0.0840             nan     0.5758   -0.0019
  1820        0.0822             nan     0.5758   -0.0011
  1840        0.0816             nan     0.5758   -0.0009
  1860        0.0790             nan     0.5758   -0.0015
  1880        0.0771             nan     0.5758   -0.0018
  1900        0.0753             nan     0.5758   -0.0022
  1920        0.0731             nan     0.5758   -0.0009
  1940        0.0728             nan     0.5758   -0.0007
  1960        0.0709             nan     0.5758   -0.0008
  1980        0.0698             nan     0.5758   -0.0009
  2000        0.0686             nan     0.5758   -0.0010
  2020        0.0672             nan     0.5758   -0.0022
  2040        0.0656             nan     0.5758   -0.0007
  2060        0.0633             nan     0.5758   -0.0016
  2080        0.0632             nan     0.5758   -0.0021
  2100        0.0606             nan     0.5758   -0.0013
  2120        0.0592             nan     0.5758   -0.0009
  2140        0.0581             nan     0.5758   -0.0005
  2160        0.0565             nan     0.5758   -0.0020
  2180        0.0550             nan     0.5758   -0.0005
  2200        0.0546             nan     0.5758   -0.0014
  2220        0.0528             nan     0.5758   -0.0009
  2240        0.0513             nan     0.5758   -0.0015
  2260        0.0506             nan     0.5758   -0.0006
  2280        0.0503             nan     0.5758   -0.0006
  2300        0.0486             nan     0.5758   -0.0011
  2320        0.0481             nan     0.5758   -0.0011
  2340        0.0472             nan     0.5758   -0.0002
  2360        0.0465             nan     0.5758   -0.0005
  2380        0.0458             nan     0.5758   -0.0007
  2400        0.0452             nan     0.5758   -0.0001
  2420        0.0447             nan     0.5758   -0.0013
  2440        0.0437             nan     0.5758   -0.0009
  2460        0.0433             nan     0.5758   -0.0008
  2480        0.0423             nan     0.5758   -0.0016
  2500        0.0413             nan     0.5758   -0.0010
  2520        0.0405             nan     0.5758   -0.0009
  2540        0.0395             nan     0.5758   -0.0008
  2560        0.0393             nan     0.5758   -0.0011
  2580        0.0382             nan     0.5758   -0.0005
  2600        0.0377             nan     0.5758   -0.0007
  2620        0.0374             nan     0.5758   -0.0006
  2640        0.0365             nan     0.5758   -0.0007
  2660        0.0359             nan     0.5758   -0.0011
  2680        0.0349             nan     0.5758   -0.0006
  2700        0.0339             nan     0.5758   -0.0006
  2720        0.0335             nan     0.5758   -0.0006
  2740        0.0333             nan     0.5758   -0.0004
  2760        0.0325             nan     0.5758   -0.0004
  2780        0.0322             nan     0.5758   -0.0006
  2800        0.0327             nan     0.5758   -0.0004
  2820        0.0318             nan     0.5758   -0.0010
  2840        0.0300             nan     0.5758   -0.0004
  2860        0.0294             nan     0.5758   -0.0009
  2880        0.0293             nan     0.5758   -0.0010
  2900        0.0283             nan     0.5758    0.0000
  2920        0.0279             nan     0.5758   -0.0002
  2940        0.0266             nan     0.5758    0.0002
  2960        0.0265             nan     0.5758   -0.0004
  2980        0.0257             nan     0.5758   -0.0004
  3000        0.0255             nan     0.5758   -0.0003
  3020        0.0253             nan     0.5758   -0.0007
  3040        0.0242             nan     0.5758   -0.0002
  3060        0.0238             nan     0.5758   -0.0003
  3080        0.0233             nan     0.5758   -0.0000
  3100        0.0230             nan     0.5758   -0.0004
  3120        0.0223             nan     0.5758   -0.0005
  3140        0.0222             nan     0.5758   -0.0007
  3160        0.0215             nan     0.5758   -0.0003
  3180        0.0214             nan     0.5758   -0.0006
  3200        0.0211             nan     0.5758   -0.0006
  3220        0.0202             nan     0.5758   -0.0003
  3240        0.0201             nan     0.5758   -0.0001
  3260        0.0195             nan     0.5758   -0.0005
  3280        0.0195             nan     0.5758   -0.0004
  3300        0.0190             nan     0.5758   -0.0004
  3320        0.0186             nan     0.5758   -0.0002
  3340        0.0181             nan     0.5758   -0.0000
  3360        0.0178             nan     0.5758   -0.0003
  3380        0.0174             nan     0.5758   -0.0004
  3400        0.0174             nan     0.5758   -0.0007
  3420        0.0172             nan     0.5758   -0.0001
  3440        0.0169             nan     0.5758   -0.0004
  3460        0.0167             nan     0.5758   -0.0003
  3480        0.0164             nan     0.5758   -0.0009
  3500        0.0163             nan     0.5758   -0.0006
  3520        0.0157             nan     0.5758   -0.0003
  3540        0.0155             nan     0.5758   -0.0004
  3560        0.0155             nan     0.5758   -0.0003
  3580        0.0153             nan     0.5758   -0.0004
  3600        0.0153             nan     0.5758   -0.0008
  3620        0.0150             nan     0.5758   -0.0005
  3640        0.0145             nan     0.5758   -0.0001
  3660        0.0144             nan     0.5758   -0.0002
  3680        0.0142             nan     0.5758   -0.0006
  3700        0.0140             nan     0.5758    0.0001
  3720        0.0136             nan     0.5758   -0.0000
  3740        0.0134             nan     0.5758   -0.0002
  3760        0.0132             nan     0.5758   -0.0004
  3780        0.0129             nan     0.5758   -0.0002
  3800        0.0129             nan     0.5758   -0.0003
  3820        0.0126             nan     0.5758   -0.0002
  3840        0.0125             nan     0.5758   -0.0001
  3860        0.0122             nan     0.5758   -0.0002
  3880        0.0120             nan     0.5758   -0.0004
  3900        0.0119             nan     0.5758   -0.0002
  3920        0.0114             nan     0.5758   -0.0002
  3940        0.0113             nan     0.5758   -0.0003
  3960        0.0109             nan     0.5758   -0.0002
  3980        0.0108             nan     0.5758   -0.0002
  4000        0.0106             nan     0.5758   -0.0002
  4020        0.0104             nan     0.5758   -0.0002
  4040        0.0101             nan     0.5758   -0.0003
  4060        0.0099             nan     0.5758   -0.0001
  4080        0.0099             nan     0.5758   -0.0001
  4100        0.0096             nan     0.5758   -0.0003
  4120        0.0095             nan     0.5758   -0.0001
  4135        0.0094             nan     0.5758   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9785             nan     0.0183   -0.0007
     2        0.9762             nan     0.0183    0.0005
     3        0.9733             nan     0.0183    0.0010
     4        0.9710             nan     0.0183    0.0003
     5        0.9691             nan     0.0183   -0.0003
     6        0.9670             nan     0.0183    0.0000
     7        0.9651             nan     0.0183   -0.0017
     8        0.9638             nan     0.0183   -0.0005
     9        0.9616             nan     0.0183   -0.0006
    10        0.9596             nan     0.0183   -0.0011
    20        0.9362             nan     0.0183   -0.0006
    40        0.8988             nan     0.0183   -0.0004
    60        0.8647             nan     0.0183   -0.0015
    80        0.8359             nan     0.0183   -0.0008
   100        0.8072             nan     0.0183   -0.0002
   120        0.7834             nan     0.0183   -0.0004
   140        0.7613             nan     0.0183   -0.0011
   160        0.7402             nan     0.0183   -0.0018
   180        0.7215             nan     0.0183   -0.0007
   200        0.7007             nan     0.0183   -0.0015
   220        0.6836             nan     0.0183   -0.0009
   240        0.6661             nan     0.0183   -0.0006
   260        0.6478             nan     0.0183   -0.0010
   280        0.6318             nan     0.0183   -0.0002
   300        0.6157             nan     0.0183   -0.0012
   320        0.5997             nan     0.0183   -0.0002
   340        0.5855             nan     0.0183   -0.0004
   360        0.5708             nan     0.0183   -0.0013
   380        0.5571             nan     0.0183   -0.0010
   400        0.5451             nan     0.0183   -0.0012
   420        0.5330             nan     0.0183   -0.0009
   440        0.5195             nan     0.0183   -0.0009
   460        0.5078             nan     0.0183   -0.0009
   480        0.4959             nan     0.0183   -0.0010
   500        0.4860             nan     0.0183   -0.0009
   520        0.4763             nan     0.0183   -0.0009
   540        0.4658             nan     0.0183   -0.0005
   560        0.4568             nan     0.0183   -0.0005
   580        0.4473             nan     0.0183   -0.0006
   600        0.4393             nan     0.0183   -0.0006
   620        0.4308             nan     0.0183   -0.0009
   640        0.4219             nan     0.0183   -0.0009
   660        0.4138             nan     0.0183   -0.0007
   680        0.4053             nan     0.0183   -0.0008
   700        0.3971             nan     0.0183   -0.0010
   720        0.3900             nan     0.0183   -0.0007
   740        0.3826             nan     0.0183   -0.0012
   760        0.3746             nan     0.0183   -0.0007
   780        0.3676             nan     0.0183   -0.0011
   800        0.3604             nan     0.0183   -0.0007
   820        0.3534             nan     0.0183   -0.0004
   840        0.3460             nan     0.0183   -0.0006
   860        0.3393             nan     0.0183   -0.0007
   880        0.3334             nan     0.0183   -0.0011
   900        0.3266             nan     0.0183   -0.0002
   920        0.3205             nan     0.0183   -0.0005
   940        0.3145             nan     0.0183   -0.0010
   960        0.3082             nan     0.0183   -0.0009
   980        0.3028             nan     0.0183   -0.0005
  1000        0.2970             nan     0.0183   -0.0006
  1020        0.2917             nan     0.0183   -0.0008
  1040        0.2870             nan     0.0183   -0.0002
  1060        0.2822             nan     0.0183   -0.0005
  1080        0.2772             nan     0.0183   -0.0006
  1100        0.2720             nan     0.0183   -0.0004
  1120        0.2675             nan     0.0183   -0.0005
  1140        0.2623             nan     0.0183   -0.0004
  1160        0.2575             nan     0.0183   -0.0003
  1180        0.2526             nan     0.0183   -0.0005
  1200        0.2482             nan     0.0183   -0.0006
  1220        0.2438             nan     0.0183   -0.0003
  1240        0.2391             nan     0.0183   -0.0003
  1260        0.2351             nan     0.0183   -0.0005
  1280        0.2311             nan     0.0183   -0.0003
  1300        0.2275             nan     0.0183   -0.0006
  1320        0.2234             nan     0.0183   -0.0004
  1340        0.2191             nan     0.0183   -0.0003
  1360        0.2154             nan     0.0183   -0.0002
  1380        0.2117             nan     0.0183   -0.0003
  1400        0.2077             nan     0.0183   -0.0004
  1420        0.2044             nan     0.0183   -0.0005
  1440        0.2005             nan     0.0183   -0.0003
  1460        0.1968             nan     0.0183   -0.0003
  1480        0.1938             nan     0.0183   -0.0004
  1500        0.1900             nan     0.0183   -0.0002
  1520        0.1867             nan     0.0183   -0.0003
  1540        0.1837             nan     0.0183   -0.0003
  1560        0.1808             nan     0.0183   -0.0004
  1580        0.1778             nan     0.0183   -0.0003
  1600        0.1751             nan     0.0183   -0.0004
  1620        0.1721             nan     0.0183   -0.0003
  1640        0.1694             nan     0.0183   -0.0004
  1660        0.1663             nan     0.0183   -0.0003
  1680        0.1633             nan     0.0183   -0.0002
  1700        0.1605             nan     0.0183   -0.0003
  1720        0.1575             nan     0.0183   -0.0002
  1740        0.1549             nan     0.0183   -0.0003
  1760        0.1520             nan     0.0183   -0.0001
  1780        0.1496             nan     0.0183   -0.0004
  1800        0.1470             nan     0.0183   -0.0005
  1820        0.1444             nan     0.0183   -0.0003
  1840        0.1422             nan     0.0183   -0.0002
  1860        0.1398             nan     0.0183   -0.0003
  1880        0.1375             nan     0.0183   -0.0002
  1900        0.1355             nan     0.0183   -0.0002
  1920        0.1332             nan     0.0183   -0.0004
  1940        0.1312             nan     0.0183   -0.0002
  1960        0.1291             nan     0.0183   -0.0003
  1980        0.1270             nan     0.0183   -0.0002
  2000        0.1249             nan     0.0183   -0.0003
  2020        0.1229             nan     0.0183   -0.0003
  2040        0.1207             nan     0.0183   -0.0002
  2060        0.1185             nan     0.0183   -0.0003
  2080        0.1166             nan     0.0183   -0.0001
  2100        0.1147             nan     0.0183   -0.0002
  2120        0.1130             nan     0.0183   -0.0002
  2140        0.1113             nan     0.0183   -0.0003
  2160        0.1096             nan     0.0183   -0.0002
  2180        0.1079             nan     0.0183   -0.0003
  2200        0.1060             nan     0.0183   -0.0003
  2220        0.1043             nan     0.0183   -0.0002
  2240        0.1027             nan     0.0183   -0.0002
  2260        0.1010             nan     0.0183   -0.0001
  2280        0.0992             nan     0.0183   -0.0002
  2300        0.0977             nan     0.0183   -0.0002
  2320        0.0963             nan     0.0183   -0.0002
  2340        0.0947             nan     0.0183   -0.0003
  2360        0.0933             nan     0.0183   -0.0002
  2380        0.0919             nan     0.0183   -0.0002
  2400        0.0906             nan     0.0183   -0.0003
  2420        0.0893             nan     0.0183   -0.0001
  2440        0.0879             nan     0.0183   -0.0001
  2460        0.0864             nan     0.0183   -0.0002
  2480        0.0852             nan     0.0183   -0.0002
  2500        0.0839             nan     0.0183   -0.0002
  2501        0.0838             nan     0.0183   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9680             nan     0.0626   -0.0004
     2        0.9546             nan     0.0626    0.0040
     3        0.9424             nan     0.0626   -0.0046
     4        0.9316             nan     0.0626   -0.0016
     5        0.9219             nan     0.0626   -0.0066
     6        0.9073             nan     0.0626    0.0001
     7        0.8974             nan     0.0626   -0.0036
     8        0.8845             nan     0.0626    0.0010
     9        0.8759             nan     0.0626   -0.0054
    10        0.8630             nan     0.0626    0.0042
    20        0.7743             nan     0.0626   -0.0012
    40        0.6413             nan     0.0626   -0.0050
    60        0.5433             nan     0.0626   -0.0036
    80        0.4675             nan     0.0626   -0.0031
   100        0.4003             nan     0.0626   -0.0034
   120        0.3447             nan     0.0626   -0.0017
   140        0.2965             nan     0.0626   -0.0032
   160        0.2571             nan     0.0626   -0.0020
   180        0.2275             nan     0.0626   -0.0019
   200        0.1988             nan     0.0626   -0.0006
   220        0.1752             nan     0.0626   -0.0014
   240        0.1552             nan     0.0626   -0.0005
   260        0.1374             nan     0.0626   -0.0014
   280        0.1227             nan     0.0626   -0.0010
   300        0.1095             nan     0.0626   -0.0007
   320        0.0980             nan     0.0626   -0.0007
   340        0.0866             nan     0.0626   -0.0012
   360        0.0769             nan     0.0626   -0.0008
   380        0.0685             nan     0.0626   -0.0004
   400        0.0613             nan     0.0626   -0.0006
   420        0.0553             nan     0.0626   -0.0005
   440        0.0496             nan     0.0626   -0.0005
   460        0.0444             nan     0.0626   -0.0005
   480        0.0402             nan     0.0626   -0.0004
   500        0.0362             nan     0.0626   -0.0003
   520        0.0330             nan     0.0626   -0.0004
   540        0.0296             nan     0.0626   -0.0004
   560        0.0267             nan     0.0626   -0.0002
   580        0.0240             nan     0.0626   -0.0003
   600        0.0217             nan     0.0626   -0.0001
   620        0.0198             nan     0.0626   -0.0002
   640        0.0177             nan     0.0626   -0.0001
   660        0.0160             nan     0.0626   -0.0001
   680        0.0145             nan     0.0626   -0.0002
   700        0.0133             nan     0.0626   -0.0001
   720        0.0120             nan     0.0626   -0.0001
   740        0.0108             nan     0.0626   -0.0001
   760        0.0098             nan     0.0626   -0.0001
   780        0.0088             nan     0.0626   -0.0001
   800        0.0080             nan     0.0626   -0.0001
   820        0.0073             nan     0.0626   -0.0001
   840        0.0066             nan     0.0626   -0.0001
   860        0.0060             nan     0.0626   -0.0001
   880        0.0054             nan     0.0626   -0.0001
   900        0.0049             nan     0.0626   -0.0001
   920        0.0045             nan     0.0626   -0.0001
   940        0.0041             nan     0.0626   -0.0000
   960        0.0037             nan     0.0626   -0.0000
   980        0.0034             nan     0.0626   -0.0000
  1000        0.0031             nan     0.0626   -0.0000
  1020        0.0028             nan     0.0626   -0.0000
  1040        0.0025             nan     0.0626   -0.0000
  1060        0.0023             nan     0.0626   -0.0000
  1080        0.0021             nan     0.0626   -0.0000
  1100        0.0019             nan     0.0626   -0.0000
  1120        0.0017             nan     0.0626   -0.0000
  1140        0.0016             nan     0.0626   -0.0000
  1160        0.0014             nan     0.0626   -0.0000
  1180        0.0013             nan     0.0626   -0.0000
  1200        0.0012             nan     0.0626   -0.0000
  1220        0.0011             nan     0.0626   -0.0000
  1240        0.0010             nan     0.0626   -0.0000
  1260        0.0009             nan     0.0626   -0.0000
  1280        0.0008             nan     0.0626   -0.0000
  1300        0.0007             nan     0.0626   -0.0000
  1320        0.0007             nan     0.0626   -0.0000
  1340        0.0006             nan     0.0626   -0.0000
  1360        0.0006             nan     0.0626   -0.0000
  1380        0.0005             nan     0.0626   -0.0000
  1400        0.0005             nan     0.0626   -0.0000
  1420        0.0004             nan     0.0626   -0.0000
  1440        0.0004             nan     0.0626   -0.0000
  1460        0.0004             nan     0.0626   -0.0000
  1480        0.0003             nan     0.0626   -0.0000
  1500        0.0003             nan     0.0626   -0.0000
  1520        0.0003             nan     0.0626   -0.0000
  1540        0.0002             nan     0.0626   -0.0000
  1560        0.0002             nan     0.0626   -0.0000
  1580        0.0002             nan     0.0626   -0.0000
  1600        0.0002             nan     0.0626   -0.0000
  1620        0.0002             nan     0.0626   -0.0000
  1640        0.0002             nan     0.0626   -0.0000
  1660        0.0001             nan     0.0626   -0.0000
  1680        0.0001             nan     0.0626   -0.0000
  1700        0.0001             nan     0.0626   -0.0000
  1720        0.0001             nan     0.0626   -0.0000
  1740        0.0001             nan     0.0626   -0.0000
  1760        0.0001             nan     0.0626   -0.0000
  1780        0.0001             nan     0.0626   -0.0000
  1800        0.0001             nan     0.0626   -0.0000
  1820        0.0001             nan     0.0626   -0.0000
  1840        0.0001             nan     0.0626   -0.0000
  1860        0.0001             nan     0.0626   -0.0000
  1880        0.0001             nan     0.0626   -0.0000
  1900        0.0000             nan     0.0626   -0.0000
  1920        0.0000             nan     0.0626   -0.0000
  1940        0.0000             nan     0.0626   -0.0000
  1960        0.0000             nan     0.0626   -0.0000
  1980        0.0000             nan     0.0626   -0.0000
  2000        0.0000             nan     0.0626   -0.0000
  2020        0.0000             nan     0.0626   -0.0000
  2040        0.0000             nan     0.0626   -0.0000
  2060        0.0000             nan     0.0626   -0.0000
  2080        0.0000             nan     0.0626   -0.0000
  2100        0.0000             nan     0.0626   -0.0000
  2120        0.0000             nan     0.0626   -0.0000
  2140        0.0000             nan     0.0626   -0.0000
  2160        0.0000             nan     0.0626   -0.0000
  2180        0.0000             nan     0.0626   -0.0000
  2200        0.0000             nan     0.0626   -0.0000
  2220        0.0000             nan     0.0626   -0.0000
  2240        0.0000             nan     0.0626   -0.0000
  2260        0.0000             nan     0.0626   -0.0000
  2280        0.0000             nan     0.0626   -0.0000
  2300        0.0000             nan     0.0626   -0.0000
  2320        0.0000             nan     0.0626   -0.0000
  2340        0.0000             nan     0.0626   -0.0000
  2360        0.0000             nan     0.0626   -0.0000
  2380        0.0000             nan     0.0626   -0.0000
  2400        0.0000             nan     0.0626   -0.0000
  2420        0.0000             nan     0.0626   -0.0000
  2440        0.0000             nan     0.0626   -0.0000
  2460        0.0000             nan     0.0626   -0.0000
  2480        0.0000             nan     0.0626   -0.0000
  2500        0.0000             nan     0.0626   -0.0000
  2520        0.0000             nan     0.0626   -0.0000
  2540        0.0000             nan     0.0626   -0.0000
  2560        0.0000             nan     0.0626   -0.0000
  2580        0.0000             nan     0.0626   -0.0000
  2600        0.0000             nan     0.0626   -0.0000
  2620        0.0000             nan     0.0626   -0.0000
  2640        0.0000             nan     0.0626   -0.0000
  2660        0.0000             nan     0.0626   -0.0000
  2680        0.0000             nan     0.0626   -0.0000
  2700        0.0000             nan     0.0626   -0.0000
  2720        0.0000             nan     0.0626   -0.0000
  2740        0.0000             nan     0.0626   -0.0000
  2760        0.0000             nan     0.0626   -0.0000
  2780        0.0000             nan     0.0626   -0.0000
  2800        0.0000             nan     0.0626   -0.0000
  2820        0.0000             nan     0.0626   -0.0000
  2840        0.0000             nan     0.0626   -0.0000
  2860        0.0000             nan     0.0626   -0.0000
  2880        0.0000             nan     0.0626   -0.0000
  2900        0.0000             nan     0.0626   -0.0000
  2920        0.0000             nan     0.0626   -0.0000
  2940        0.0000             nan     0.0626   -0.0000
  2960        0.0000             nan     0.0626   -0.0000
  2980        0.0000             nan     0.0626   -0.0000
  3000        0.0000             nan     0.0626   -0.0000
  3020        0.0000             nan     0.0626   -0.0000
  3040        0.0000             nan     0.0626   -0.0000
  3060        0.0000             nan     0.0626   -0.0000
  3080        0.0000             nan     0.0626   -0.0000
  3100        0.0000             nan     0.0626   -0.0000
  3120        0.0000             nan     0.0626   -0.0000
  3140        0.0000             nan     0.0626   -0.0000
  3160        0.0000             nan     0.0626   -0.0000
  3180        0.0000             nan     0.0626   -0.0000
  3200        0.0000             nan     0.0626   -0.0000
  3220        0.0000             nan     0.0626   -0.0000
  3240        0.0000             nan     0.0626   -0.0000
  3260        0.0000             nan     0.0626   -0.0000
  3280        0.0000             nan     0.0626   -0.0000
  3300        0.0000             nan     0.0626   -0.0000
  3320        0.0000             nan     0.0626   -0.0000
  3340        0.0000             nan     0.0626   -0.0000
  3360        0.0000             nan     0.0626   -0.0000
  3380        0.0000             nan     0.0626   -0.0000
  3400        0.0000             nan     0.0626   -0.0000
  3420        0.0000             nan     0.0626   -0.0000
  3440        0.0000             nan     0.0626   -0.0000
  3460        0.0000             nan     0.0626   -0.0000
  3480        0.0000             nan     0.0626   -0.0000
  3500        0.0000             nan     0.0626   -0.0000
  3520        0.0000             nan     0.0626   -0.0000
  3540        0.0000             nan     0.0626   -0.0000
  3560        0.0000             nan     0.0626   -0.0000
  3580        0.0000             nan     0.0626   -0.0000
  3600        0.0000             nan     0.0626   -0.0000
  3620        0.0000             nan     0.0626   -0.0000
  3640        0.0000             nan     0.0626   -0.0000
  3660        0.0000             nan     0.0626   -0.0000
  3680        0.0000             nan     0.0626   -0.0000
  3700        0.0000             nan     0.0626   -0.0000
  3720        0.0000             nan     0.0626   -0.0000
  3740        0.0000             nan     0.0626   -0.0000
  3760        0.0000             nan     0.0626   -0.0000
  3780        0.0000             nan     0.0626   -0.0000
  3800        0.0000             nan     0.0626   -0.0000
  3820        0.0000             nan     0.0626   -0.0000
  3840        0.0000             nan     0.0626   -0.0000
  3860        0.0000             nan     0.0626   -0.0000
  3880        0.0000             nan     0.0626   -0.0000
  3895        0.0000             nan     0.0626   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9764             nan     0.0786    0.0015
     2        0.9704             nan     0.0786    0.0034
     3        0.9681             nan     0.0786   -0.0033
     4        0.9616             nan     0.0786    0.0040
     5        0.9544             nan     0.0786    0.0033
     6        0.9516             nan     0.0786   -0.0037
     7        0.9484             nan     0.0786   -0.0034
     8        0.9464             nan     0.0786   -0.0059
     9        0.9433             nan     0.0786   -0.0032
    10        0.9401             nan     0.0786   -0.0025
    20        0.9068             nan     0.0786   -0.0029
    40        0.8605             nan     0.0786   -0.0017
    60        0.8229             nan     0.0786   -0.0030
    80        0.7860             nan     0.0786   -0.0042
   100        0.7591             nan     0.0786   -0.0079
   120        0.7272             nan     0.0786   -0.0036
   140        0.6995             nan     0.0786   -0.0038
   160        0.6755             nan     0.0786   -0.0014
   180        0.6529             nan     0.0786   -0.0040
   200        0.6342             nan     0.0786   -0.0018
   220        0.6106             nan     0.0786   -0.0007
   240        0.5943             nan     0.0786   -0.0036
   260        0.5747             nan     0.0786   -0.0019
   280        0.5570             nan     0.0786   -0.0018
   300        0.5436             nan     0.0786   -0.0012
   320        0.5286             nan     0.0786   -0.0010
   340        0.5154             nan     0.0786   -0.0020
   360        0.4957             nan     0.0786   -0.0025
   380        0.4831             nan     0.0786   -0.0017
   400        0.4689             nan     0.0786   -0.0021
   420        0.4575             nan     0.0786   -0.0013
   440        0.4470             nan     0.0786   -0.0026
   460        0.4385             nan     0.0786   -0.0015
   480        0.4239             nan     0.0786   -0.0024
   500        0.4127             nan     0.0786   -0.0015
   520        0.4022             nan     0.0786   -0.0013
   540        0.3925             nan     0.0786   -0.0017
   560        0.3820             nan     0.0786   -0.0018
   580        0.3733             nan     0.0786   -0.0020
   600        0.3662             nan     0.0786   -0.0023
   620        0.3566             nan     0.0786   -0.0014
   640        0.3470             nan     0.0786   -0.0025
   660        0.3383             nan     0.0786   -0.0021
   680        0.3299             nan     0.0786   -0.0008
   700        0.3223             nan     0.0786   -0.0015
   720        0.3158             nan     0.0786   -0.0009
   740        0.3093             nan     0.0786   -0.0016
   760        0.3031             nan     0.0786   -0.0012
   780        0.2959             nan     0.0786   -0.0018
   800        0.2895             nan     0.0786    0.0002
   820        0.2823             nan     0.0786   -0.0016
   840        0.2765             nan     0.0786   -0.0009
   860        0.2699             nan     0.0786   -0.0014
   880        0.2639             nan     0.0786   -0.0011
   900        0.2576             nan     0.0786   -0.0003
   920        0.2517             nan     0.0786   -0.0009
   940        0.2458             nan     0.0786   -0.0010
   960        0.2422             nan     0.0786   -0.0004
   980        0.2378             nan     0.0786   -0.0011
  1000        0.2333             nan     0.0786   -0.0011
  1020        0.2290             nan     0.0786   -0.0017
  1040        0.2244             nan     0.0786   -0.0020
  1060        0.2194             nan     0.0786   -0.0006
  1080        0.2141             nan     0.0786   -0.0010
  1100        0.2100             nan     0.0786   -0.0012
  1120        0.2061             nan     0.0786   -0.0010
  1140        0.2026             nan     0.0786   -0.0015
  1160        0.1987             nan     0.0786   -0.0009
  1180        0.1951             nan     0.0786   -0.0006
  1200        0.1907             nan     0.0786   -0.0009
  1220        0.1860             nan     0.0786   -0.0014
  1240        0.1827             nan     0.0786   -0.0007
  1260        0.1790             nan     0.0786   -0.0012
  1280        0.1754             nan     0.0786   -0.0009
  1300        0.1718             nan     0.0786   -0.0008
  1320        0.1691             nan     0.0786   -0.0009
  1340        0.1655             nan     0.0786   -0.0010
  1360        0.1632             nan     0.0786   -0.0007
  1380        0.1604             nan     0.0786   -0.0006
  1400        0.1569             nan     0.0786   -0.0007
  1420        0.1546             nan     0.0786   -0.0010
  1440        0.1515             nan     0.0786   -0.0007
  1460        0.1487             nan     0.0786   -0.0011
  1480        0.1462             nan     0.0786   -0.0004
  1500        0.1434             nan     0.0786   -0.0007
  1520        0.1410             nan     0.0786   -0.0007
  1540        0.1386             nan     0.0786   -0.0007
  1560        0.1365             nan     0.0786   -0.0007
  1580        0.1341             nan     0.0786   -0.0008
  1600        0.1320             nan     0.0786   -0.0006
  1620        0.1300             nan     0.0786   -0.0004
  1640        0.1278             nan     0.0786   -0.0006
  1660        0.1258             nan     0.0786   -0.0003
  1680        0.1233             nan     0.0786   -0.0006
  1700        0.1216             nan     0.0786   -0.0005
  1720        0.1195             nan     0.0786   -0.0004
  1740        0.1176             nan     0.0786   -0.0006
  1753        0.1160             nan     0.0786   -0.0008

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9781             nan     0.0829   -0.0042
     2        0.9770             nan     0.0829   -0.0034
     3        0.9759             nan     0.0829   -0.0029
     4        0.9741             nan     0.0829   -0.0030
     5        0.9723             nan     0.0829   -0.0014
     6        0.9699             nan     0.0829   -0.0014
     7        0.9681             nan     0.0829   -0.0018
     8        0.9669             nan     0.0829   -0.0009
     9        0.9649             nan     0.0829   -0.0010
    10        0.9638             nan     0.0829   -0.0007
    20        0.9440             nan     0.0829   -0.0024
    40        0.9212             nan     0.0829   -0.0029
    60        0.8960             nan     0.0829   -0.0007
    80        0.8829             nan     0.0829   -0.0028
   100        0.8659             nan     0.0829   -0.0044
   120        0.8524             nan     0.0829   -0.0018
   140        0.8382             nan     0.0829   -0.0014
   160        0.8285             nan     0.0829   -0.0013
   180        0.8141             nan     0.0829   -0.0008
   200        0.8048             nan     0.0829   -0.0044
   220        0.7968             nan     0.0829   -0.0022
   240        0.7887             nan     0.0829   -0.0030
   260        0.7789             nan     0.0829   -0.0005
   280        0.7696             nan     0.0829   -0.0017
   300        0.7627             nan     0.0829   -0.0032
   320        0.7578             nan     0.0829   -0.0012
   340        0.7511             nan     0.0829   -0.0022
   360        0.7427             nan     0.0829   -0.0014
   380        0.7349             nan     0.0829   -0.0017
   400        0.7284             nan     0.0829   -0.0019
   420        0.7225             nan     0.0829   -0.0025
   440        0.7174             nan     0.0829   -0.0025
   460        0.7120             nan     0.0829   -0.0004
   480        0.7044             nan     0.0829   -0.0015
   500        0.6997             nan     0.0829   -0.0014
   520        0.6917             nan     0.0829   -0.0010
   540        0.6856             nan     0.0829   -0.0015
   560        0.6807             nan     0.0829   -0.0022
   580        0.6754             nan     0.0829   -0.0029
   600        0.6698             nan     0.0829   -0.0016
   620        0.6638             nan     0.0829   -0.0025
   640        0.6591             nan     0.0829   -0.0021
   660        0.6545             nan     0.0829   -0.0015
   680        0.6490             nan     0.0829   -0.0022
   700        0.6434             nan     0.0829   -0.0014
   720        0.6386             nan     0.0829   -0.0015
   740        0.6340             nan     0.0829   -0.0021
   760        0.6297             nan     0.0829   -0.0016
   780        0.6250             nan     0.0829   -0.0012
   800        0.6208             nan     0.0829   -0.0012
   820        0.6152             nan     0.0829   -0.0010
   840        0.6108             nan     0.0829   -0.0030
   860        0.6061             nan     0.0829   -0.0021
   880        0.6015             nan     0.0829   -0.0010
   900        0.5982             nan     0.0829   -0.0029
   920        0.5940             nan     0.0829   -0.0016
   940        0.5901             nan     0.0829   -0.0020
   960        0.5858             nan     0.0829   -0.0021
   980        0.5830             nan     0.0829   -0.0013
  1000        0.5792             nan     0.0829   -0.0019
  1020        0.5751             nan     0.0829   -0.0014
  1040        0.5732             nan     0.0829   -0.0012
  1060        0.5687             nan     0.0829   -0.0017
  1080        0.5648             nan     0.0829   -0.0011
  1100        0.5622             nan     0.0829   -0.0020
  1120        0.5583             nan     0.0829   -0.0015
  1140        0.5556             nan     0.0829   -0.0024
  1160        0.5518             nan     0.0829   -0.0011
  1180        0.5479             nan     0.0829   -0.0011
  1200        0.5444             nan     0.0829   -0.0023
  1220        0.5399             nan     0.0829   -0.0011
  1240        0.5363             nan     0.0829   -0.0008
  1260        0.5332             nan     0.0829   -0.0013
  1280        0.5299             nan     0.0829   -0.0009
  1300        0.5270             nan     0.0829   -0.0015
  1320        0.5242             nan     0.0829   -0.0012
  1340        0.5204             nan     0.0829   -0.0014
  1360        0.5176             nan     0.0829   -0.0013
  1380        0.5149             nan     0.0829   -0.0018
  1400        0.5111             nan     0.0829   -0.0016
  1420        0.5087             nan     0.0829   -0.0009
  1440        0.5055             nan     0.0829   -0.0014
  1460        0.5025             nan     0.0829   -0.0020
  1480        0.4999             nan     0.0829   -0.0014
  1500        0.4968             nan     0.0829   -0.0014
  1520        0.4933             nan     0.0829   -0.0015
  1540        0.4912             nan     0.0829   -0.0019
  1560        0.4887             nan     0.0829   -0.0011
  1580        0.4866             nan     0.0829   -0.0023
  1600        0.4838             nan     0.0829   -0.0016
  1620        0.4812             nan     0.0829   -0.0009
  1640        0.4792             nan     0.0829   -0.0012
  1660        0.4759             nan     0.0829   -0.0012
  1680        0.4731             nan     0.0829   -0.0012
  1700        0.4720             nan     0.0829   -0.0017
  1720        0.4690             nan     0.0829   -0.0010
  1740        0.4674             nan     0.0829   -0.0013
  1760        0.4653             nan     0.0829   -0.0028
  1765        0.4650             nan     0.0829   -0.0015

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9602             nan     0.1176   -0.0036
     2        0.9422             nan     0.1176   -0.0143
     3        0.9252             nan     0.1176   -0.0010
     4        0.9078             nan     0.1176   -0.0061
     5        0.8932             nan     0.1176   -0.0111
     6        0.8799             nan     0.1176   -0.0194
     7        0.8681             nan     0.1176   -0.0042
     8        0.8544             nan     0.1176   -0.0088
     9        0.8414             nan     0.1176   -0.0133
    10        0.8287             nan     0.1176   -0.0115
    20        0.7234             nan     0.1176   -0.0126
    40        0.5592             nan     0.1176   -0.0062
    60        0.4325             nan     0.1176   -0.0058
    80        0.3483             nan     0.1176   -0.0048
   100        0.2734             nan     0.1176   -0.0047
   120        0.2166             nan     0.1176   -0.0026
   140        0.1795             nan     0.1176   -0.0024
   160        0.1470             nan     0.1176   -0.0016
   180        0.1215             nan     0.1176   -0.0016
   200        0.1009             nan     0.1176   -0.0012
   220        0.0833             nan     0.1176   -0.0013
   240        0.0685             nan     0.1176   -0.0009
   260        0.0570             nan     0.1176   -0.0013
   280        0.0461             nan     0.1176   -0.0004
   300        0.0386             nan     0.1176   -0.0007
   320        0.0323             nan     0.1176   -0.0007
   340        0.0272             nan     0.1176   -0.0005
   360        0.0227             nan     0.1176   -0.0005
   380        0.0185             nan     0.1176   -0.0003
   400        0.0158             nan     0.1176   -0.0002
   420        0.0132             nan     0.1176   -0.0001
   440        0.0109             nan     0.1176   -0.0002
   460        0.0091             nan     0.1176   -0.0001
   480        0.0076             nan     0.1176   -0.0001
   500        0.0063             nan     0.1176   -0.0000
   520        0.0052             nan     0.1176   -0.0001
   540        0.0044             nan     0.1176   -0.0000
   560        0.0036             nan     0.1176   -0.0001
   580        0.0030             nan     0.1176   -0.0000
   600        0.0025             nan     0.1176   -0.0001
   620        0.0021             nan     0.1176   -0.0000
   640        0.0018             nan     0.1176   -0.0000
   660        0.0015             nan     0.1176   -0.0000
   680        0.0013             nan     0.1176   -0.0000
   700        0.0010             nan     0.1176   -0.0000
   720        0.0009             nan     0.1176   -0.0000
   740        0.0007             nan     0.1176   -0.0000
   760        0.0006             nan     0.1176   -0.0000
   780        0.0005             nan     0.1176   -0.0000
   800        0.0004             nan     0.1176   -0.0000
   820        0.0004             nan     0.1176   -0.0000
   840        0.0003             nan     0.1176   -0.0000
   860        0.0003             nan     0.1176   -0.0000
   880        0.0002             nan     0.1176   -0.0000
   900        0.0002             nan     0.1176   -0.0000
   920        0.0002             nan     0.1176   -0.0000
   940        0.0001             nan     0.1176   -0.0000
   960        0.0001             nan     0.1176   -0.0000
   980        0.0001             nan     0.1176   -0.0000
  1000        0.0001             nan     0.1176   -0.0000
  1020        0.0001             nan     0.1176   -0.0000
  1040        0.0001             nan     0.1176   -0.0000
  1060        0.0001             nan     0.1176   -0.0000
  1080        0.0000             nan     0.1176   -0.0000
  1100        0.0000             nan     0.1176   -0.0000
  1120        0.0000             nan     0.1176   -0.0000
  1140        0.0000             nan     0.1176   -0.0000
  1160        0.0000             nan     0.1176   -0.0000
  1180        0.0000             nan     0.1176   -0.0000
  1200        0.0000             nan     0.1176   -0.0000
  1220        0.0000             nan     0.1176   -0.0000
  1240        0.0000             nan     0.1176   -0.0000
  1260        0.0000             nan     0.1176   -0.0000
  1280        0.0000             nan     0.1176   -0.0000
  1300        0.0000             nan     0.1176   -0.0000
  1320        0.0000             nan     0.1176   -0.0000
  1340        0.0000             nan     0.1176   -0.0000
  1360        0.0000             nan     0.1176   -0.0000
  1380        0.0000             nan     0.1176   -0.0000
  1400        0.0000             nan     0.1176   -0.0000
  1420        0.0000             nan     0.1176   -0.0000
  1440        0.0000             nan     0.1176   -0.0000
  1460        0.0000             nan     0.1176   -0.0000
  1480        0.0000             nan     0.1176   -0.0000
  1500        0.0000             nan     0.1176   -0.0000
  1520        0.0000             nan     0.1176   -0.0000
  1540        0.0000             nan     0.1176   -0.0000
  1560        0.0000             nan     0.1176   -0.0000
  1580        0.0000             nan     0.1176   -0.0000
  1600        0.0000             nan     0.1176   -0.0000
  1620        0.0000             nan     0.1176   -0.0000
  1640        0.0000             nan     0.1176   -0.0000
  1660        0.0000             nan     0.1176   -0.0000
  1680        0.0000             nan     0.1176   -0.0000
  1700        0.0000             nan     0.1176   -0.0000
  1720        0.0000             nan     0.1176   -0.0000
  1740        0.0000             nan     0.1176   -0.0000
  1760        0.0000             nan     0.1176   -0.0000
  1780        0.0000             nan     0.1176   -0.0000
  1800        0.0000             nan     0.1176   -0.0000
  1820        0.0000             nan     0.1176   -0.0000
  1840        0.0000             nan     0.1176   -0.0000
  1860        0.0000             nan     0.1176   -0.0000
  1880        0.0000             nan     0.1176   -0.0000
  1900        0.0000             nan     0.1176   -0.0000
  1920        0.0000             nan     0.1176   -0.0000
  1940        0.0000             nan     0.1176   -0.0000
  1960        0.0000             nan     0.1176   -0.0000
  1980        0.0000             nan     0.1176   -0.0000
  2000        0.0000             nan     0.1176   -0.0000
  2020        0.0000             nan     0.1176   -0.0000
  2040        0.0000             nan     0.1176   -0.0000
  2060        0.0000             nan     0.1176   -0.0000
  2080        0.0000             nan     0.1176   -0.0000
  2100        0.0000             nan     0.1176   -0.0000
  2120        0.0000             nan     0.1176   -0.0000
  2140        0.0000             nan     0.1176   -0.0000
  2160        0.0000             nan     0.1176   -0.0000
  2180        0.0000             nan     0.1176   -0.0000
  2186        0.0000             nan     0.1176   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9671             nan     0.1352   -0.0289
     2        0.9355             nan     0.1352   -0.0075
     3        0.9116             nan     0.1352   -0.0060
     4        0.8971             nan     0.1352   -0.0109
     5        0.8669             nan     0.1352    0.0005
     6        0.8457             nan     0.1352   -0.0077
     7        0.8172             nan     0.1352    0.0041
     8        0.8033             nan     0.1352   -0.0150
     9        0.7820             nan     0.1352   -0.0034
    10        0.7687             nan     0.1352   -0.0162
    20        0.6213             nan     0.1352   -0.0102
    40        0.4126             nan     0.1352   -0.0116
    60        0.3039             nan     0.1352   -0.0083
    80        0.2173             nan     0.1352   -0.0059
   100        0.1606             nan     0.1352   -0.0019
   120        0.1174             nan     0.1352   -0.0007
   140        0.0858             nan     0.1352   -0.0018
   160        0.0633             nan     0.1352   -0.0014
   180        0.0482             nan     0.1352   -0.0007
   200        0.0357             nan     0.1352   -0.0003
   220        0.0264             nan     0.1352   -0.0004
   240        0.0202             nan     0.1352   -0.0004
   260        0.0149             nan     0.1352   -0.0004
   280        0.0115             nan     0.1352   -0.0002
   300        0.0086             nan     0.1352   -0.0002
   320        0.0067             nan     0.1352   -0.0002
   340        0.0052             nan     0.1352   -0.0001
   360        0.0039             nan     0.1352   -0.0001
   380        0.0030             nan     0.1352   -0.0000
   400        0.0023             nan     0.1352   -0.0000
   420        0.0017             nan     0.1352   -0.0000
   440        0.0013             nan     0.1352   -0.0000
   460        0.0010             nan     0.1352   -0.0000
   480        0.0008             nan     0.1352   -0.0000
   500        0.0006             nan     0.1352   -0.0000
   520        0.0005             nan     0.1352   -0.0000
   540        0.0003             nan     0.1352   -0.0000
   560        0.0003             nan     0.1352   -0.0000
   580        0.0002             nan     0.1352   -0.0000
   600        0.0002             nan     0.1352   -0.0000
   620        0.0001             nan     0.1352   -0.0000
   640        0.0001             nan     0.1352   -0.0000
   660        0.0001             nan     0.1352   -0.0000
   680        0.0001             nan     0.1352   -0.0000
   700        0.0000             nan     0.1352   -0.0000
   703        0.0000             nan     0.1352   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9684             nan     0.1730   -0.0094
     2        0.9572             nan     0.1730   -0.0212
     3        0.9444             nan     0.1730   -0.0192
     4        0.9292             nan     0.1730   -0.0042
     5        0.9107             nan     0.1730   -0.0027
     6        0.8971             nan     0.1730   -0.0075
     7        0.8838             nan     0.1730   -0.0096
     8        0.8716             nan     0.1730   -0.0156
     9        0.8568             nan     0.1730   -0.0056
    10        0.8444             nan     0.1730   -0.0113
    20        0.7533             nan     0.1730   -0.0128
    40        0.6070             nan     0.1730   -0.0136
    60        0.4962             nan     0.1730   -0.0085
    80        0.4139             nan     0.1730   -0.0048
   100        0.3433             nan     0.1730   -0.0020
   120        0.2920             nan     0.1730   -0.0015
   140        0.2496             nan     0.1730   -0.0031
   160        0.2119             nan     0.1730   -0.0045
   180        0.1815             nan     0.1730   -0.0018
   200        0.1565             nan     0.1730   -0.0035
   220        0.1356             nan     0.1730   -0.0021
   240        0.1186             nan     0.1730   -0.0016
   260        0.1034             nan     0.1730   -0.0021
   280        0.0894             nan     0.1730   -0.0008
   300        0.0780             nan     0.1730   -0.0005
   320        0.0676             nan     0.1730   -0.0009
   340        0.0591             nan     0.1730   -0.0013
   360        0.0522             nan     0.1730   -0.0008
   380        0.0462             nan     0.1730   -0.0014
   400        0.0404             nan     0.1730   -0.0009
   420        0.0354             nan     0.1730   -0.0006
   426        0.0344             nan     0.1730   -0.0009

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9673             nan     0.2045   -0.0085
     2        0.9570             nan     0.2045   -0.0134
     3        0.9330             nan     0.2045   -0.0141
     4        0.9173             nan     0.2045   -0.0229
     5        0.8962             nan     0.2045   -0.0158
     6        0.8824             nan     0.2045   -0.0045
     7        0.8730             nan     0.2045   -0.0165
     8        0.8615             nan     0.2045   -0.0171
     9        0.8530             nan     0.2045   -0.0142
    10        0.8393             nan     0.2045   -0.0109
    20        0.7407             nan     0.2045   -0.0110
    40        0.6220             nan     0.2045   -0.0129
    60        0.5199             nan     0.2045   -0.0106
    80        0.4422             nan     0.2045   -0.0055
   100        0.3683             nan     0.2045   -0.0050
   120        0.3160             nan     0.2045   -0.0036
   140        0.2695             nan     0.2045   -0.0071
   160        0.2336             nan     0.2045   -0.0056
   180        0.1987             nan     0.2045   -0.0046
   200        0.1702             nan     0.2045   -0.0034
   220        0.1495             nan     0.2045   -0.0052
   240        0.1284             nan     0.2045   -0.0029
   260        0.1134             nan     0.2045   -0.0020
   280        0.0976             nan     0.2045   -0.0027
   300        0.0829             nan     0.2045   -0.0020
   320        0.0729             nan     0.2045   -0.0012
   340        0.0635             nan     0.2045   -0.0009
   360        0.0546             nan     0.2045   -0.0022
   380        0.0487             nan     0.2045   -0.0017
   400        0.0414             nan     0.2045   -0.0008
   420        0.0360             nan     0.2045   -0.0008
   440        0.0313             nan     0.2045   -0.0010
   460        0.0274             nan     0.2045   -0.0007
   480        0.0245             nan     0.2045   -0.0008
   500        0.0214             nan     0.2045   -0.0004
   520        0.0186             nan     0.2045   -0.0005
   540        0.0165             nan     0.2045   -0.0003
   560        0.0144             nan     0.2045   -0.0004
   580        0.0127             nan     0.2045   -0.0002
   600        0.0112             nan     0.2045   -0.0003
   620        0.0098             nan     0.2045   -0.0002
   640        0.0087             nan     0.2045   -0.0003
   660        0.0077             nan     0.2045   -0.0001
   680        0.0069             nan     0.2045   -0.0002
   700        0.0062             nan     0.2045   -0.0001
   720        0.0055             nan     0.2045   -0.0001
   740        0.0049             nan     0.2045   -0.0001
   760        0.0043             nan     0.2045   -0.0001
   780        0.0038             nan     0.2045   -0.0001
   800        0.0034             nan     0.2045   -0.0001
   820        0.0030             nan     0.2045   -0.0001
   840        0.0026             nan     0.2045   -0.0001
   860        0.0023             nan     0.2045   -0.0001
   880        0.0021             nan     0.2045   -0.0001
   900        0.0019             nan     0.2045   -0.0000
   920        0.0017             nan     0.2045   -0.0000
   940        0.0015             nan     0.2045   -0.0000
   960        0.0013             nan     0.2045   -0.0000
   980        0.0012             nan     0.2045   -0.0000
  1000        0.0010             nan     0.2045   -0.0000
  1020        0.0009             nan     0.2045   -0.0000
  1040        0.0008             nan     0.2045   -0.0000
  1060        0.0007             nan     0.2045   -0.0000
  1080        0.0006             nan     0.2045   -0.0000
  1100        0.0006             nan     0.2045   -0.0000
  1120        0.0005             nan     0.2045   -0.0000
  1140        0.0005             nan     0.2045   -0.0000
  1160        0.0004             nan     0.2045   -0.0000
  1180        0.0004             nan     0.2045   -0.0000
  1200        0.0003             nan     0.2045   -0.0000
  1220        0.0003             nan     0.2045   -0.0000
  1240        0.0003             nan     0.2045   -0.0000
  1260        0.0002             nan     0.2045   -0.0000
  1280        0.0002             nan     0.2045   -0.0000
  1300        0.0002             nan     0.2045   -0.0000
  1320        0.0002             nan     0.2045   -0.0000
  1340        0.0002             nan     0.2045   -0.0000
  1360        0.0001             nan     0.2045   -0.0000
  1380        0.0001             nan     0.2045   -0.0000
  1400        0.0001             nan     0.2045   -0.0000
  1420        0.0001             nan     0.2045   -0.0000
  1440        0.0001             nan     0.2045   -0.0000
  1460        0.0001             nan     0.2045   -0.0000
  1480        0.0001             nan     0.2045   -0.0000
  1500        0.0001             nan     0.2045   -0.0000
  1520        0.0001             nan     0.2045   -0.0000
  1540        0.0000             nan     0.2045   -0.0000
  1560        0.0000             nan     0.2045   -0.0000
  1580        0.0000             nan     0.2045   -0.0000
  1600        0.0000             nan     0.2045   -0.0000
  1620        0.0000             nan     0.2045   -0.0000
  1640        0.0000             nan     0.2045   -0.0000
  1660        0.0000             nan     0.2045   -0.0000
  1680        0.0000             nan     0.2045   -0.0000
  1700        0.0000             nan     0.2045   -0.0000
  1720        0.0000             nan     0.2045   -0.0000
  1740        0.0000             nan     0.2045   -0.0000
  1760        0.0000             nan     0.2045   -0.0000
  1780        0.0000             nan     0.2045   -0.0000
  1800        0.0000             nan     0.2045   -0.0000
  1820        0.0000             nan     0.2045   -0.0000
  1840        0.0000             nan     0.2045   -0.0000
  1860        0.0000             nan     0.2045   -0.0000
  1880        0.0000             nan     0.2045   -0.0000
  1900        0.0000             nan     0.2045   -0.0000
  1920        0.0000             nan     0.2045   -0.0000
  1940        0.0000             nan     0.2045   -0.0000
  1960        0.0000             nan     0.2045   -0.0000
  1980        0.0000             nan     0.2045   -0.0000
  2000        0.0000             nan     0.2045   -0.0000
  2020        0.0000             nan     0.2045   -0.0000
  2040        0.0000             nan     0.2045   -0.0000
  2060        0.0000             nan     0.2045   -0.0000
  2080        0.0000             nan     0.2045   -0.0000
  2100        0.0000             nan     0.2045   -0.0000
  2120        0.0000             nan     0.2045   -0.0000
  2140        0.0000             nan     0.2045   -0.0000
  2160        0.0000             nan     0.2045   -0.0000
  2180        0.0000             nan     0.2045   -0.0000
  2200        0.0000             nan     0.2045   -0.0000
  2220        0.0000             nan     0.2045   -0.0000
  2240        0.0000             nan     0.2045   -0.0000
  2260        0.0000             nan     0.2045   -0.0000
  2280        0.0000             nan     0.2045   -0.0000
  2300        0.0000             nan     0.2045   -0.0000
  2320        0.0000             nan     0.2045   -0.0000
  2340        0.0000             nan     0.2045   -0.0000
  2360        0.0000             nan     0.2045   -0.0000
  2380        0.0000             nan     0.2045   -0.0000
  2400        0.0000             nan     0.2045   -0.0000
  2420        0.0000             nan     0.2045   -0.0000
  2440        0.0000             nan     0.2045   -0.0000
  2460        0.0000             nan     0.2045   -0.0000
  2480        0.0000             nan     0.2045   -0.0000
  2500        0.0000             nan     0.2045   -0.0000
  2520        0.0000             nan     0.2045   -0.0000
  2540        0.0000             nan     0.2045   -0.0000
  2560        0.0000             nan     0.2045   -0.0000
  2580        0.0000             nan     0.2045   -0.0000
  2600        0.0000             nan     0.2045   -0.0000
  2620        0.0000             nan     0.2045   -0.0000
  2640        0.0000             nan     0.2045   -0.0000
  2660        0.0000             nan     0.2045   -0.0000
  2680        0.0000             nan     0.2045   -0.0000
  2700        0.0000             nan     0.2045   -0.0000
  2720        0.0000             nan     0.2045   -0.0000
  2740        0.0000             nan     0.2045   -0.0000
  2760        0.0000             nan     0.2045   -0.0000
  2780        0.0000             nan     0.2045   -0.0000
  2800        0.0000             nan     0.2045   -0.0000
  2820        0.0000             nan     0.2045   -0.0000
  2840        0.0000             nan     0.2045   -0.0000
  2860        0.0000             nan     0.2045   -0.0000
  2880        0.0000             nan     0.2045   -0.0000
  2900        0.0000             nan     0.2045   -0.0000
  2920        0.0000             nan     0.2045   -0.0000
  2940        0.0000             nan     0.2045   -0.0000
  2960        0.0000             nan     0.2045   -0.0000
  2980        0.0000             nan     0.2045   -0.0000
  3000        0.0000             nan     0.2045   -0.0000
  3020        0.0000             nan     0.2045   -0.0000
  3040        0.0000             nan     0.2045   -0.0000
  3060        0.0000             nan     0.2045   -0.0000
  3080        0.0000             nan     0.2045   -0.0000
  3100        0.0000             nan     0.2045   -0.0000
  3120        0.0000             nan     0.2045   -0.0000
  3140        0.0000             nan     0.2045   -0.0000
  3160        0.0000             nan     0.2045   -0.0000
  3180        0.0000             nan     0.2045   -0.0000
  3200        0.0000             nan     0.2045   -0.0000
  3220        0.0000             nan     0.2045   -0.0000
  3240        0.0000             nan     0.2045   -0.0000
  3260        0.0000             nan     0.2045   -0.0000
  3280        0.0000             nan     0.2045   -0.0000
  3300        0.0000             nan     0.2045   -0.0000
  3320        0.0000             nan     0.2045   -0.0000
  3340        0.0000             nan     0.2045   -0.0000
  3360        0.0000             nan     0.2045   -0.0000
  3380        0.0000             nan     0.2045   -0.0000
  3400        0.0000             nan     0.2045   -0.0000
  3420        0.0000             nan     0.2045   -0.0000
  3440        0.0000             nan     0.2045   -0.0000
  3460        0.0000             nan     0.2045   -0.0000
  3480        0.0000             nan     0.2045   -0.0000
  3500        0.0000             nan     0.2045   -0.0000
  3520        0.0000             nan     0.2045   -0.0000
  3540        0.0000             nan     0.2045   -0.0000
  3560        0.0000             nan     0.2045   -0.0000
  3580        0.0000             nan     0.2045   -0.0000
  3600        0.0000             nan     0.2045   -0.0000
  3620        0.0000             nan     0.2045   -0.0000
  3640        0.0000             nan     0.2045   -0.0000
  3660        0.0000             nan     0.2045   -0.0000
  3680        0.0000             nan     0.2045   -0.0000
  3700        0.0000             nan     0.2045   -0.0000
  3720        0.0000             nan     0.2045   -0.0000
  3740        0.0000             nan     0.2045   -0.0000
  3760        0.0000             nan     0.2045   -0.0000
  3780        0.0000             nan     0.2045   -0.0000
  3800        0.0000             nan     0.2045   -0.0000
  3820        0.0000             nan     0.2045   -0.0000
  3840        0.0000             nan     0.2045   -0.0000
  3860        0.0000             nan     0.2045   -0.0000
  3880        0.0000             nan     0.2045   -0.0000
  3900        0.0000             nan     0.2045   -0.0000
  3920        0.0000             nan     0.2045   -0.0000
  3940        0.0000             nan     0.2045   -0.0000
  3960        0.0000             nan     0.2045   -0.0000
  3980        0.0000             nan     0.2045   -0.0000
  3999        0.0000             nan     0.2045   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9467             nan     0.2413   -0.0342
     2        0.9037             nan     0.2413   -0.0062
     3        0.8822             nan     0.2413   -0.0375
     4        0.8556             nan     0.2413   -0.0262
     5        0.8197             nan     0.2413   -0.0121
     6        0.8005             nan     0.2413   -0.0159
     7        0.7817             nan     0.2413   -0.0266
     8        0.7681             nan     0.2413   -0.0293
     9        0.7423             nan     0.2413   -0.0161
    10        0.7210             nan     0.2413   -0.0257
    20        0.5745             nan     0.2413   -0.0227
    40        0.3667             nan     0.2413   -0.0102
    60        0.2389             nan     0.2413   -0.0055
    80        0.1624             nan     0.2413   -0.0040
   100        0.1138             nan     0.2413   -0.0045
   120        0.0774             nan     0.2413   -0.0024
   140        0.0533             nan     0.2413   -0.0009
   160        0.0366             nan     0.2413   -0.0014
   180        0.0267             nan     0.2413   -0.0008
   200        0.0195             nan     0.2413   -0.0006
   220        0.0145             nan     0.2413   -0.0005
   240        0.0107             nan     0.2413   -0.0006
   260        0.0076             nan     0.2413   -0.0005
   280        0.0053             nan     0.2413   -0.0002
   300        0.0037             nan     0.2413   -0.0001
   320        0.0027             nan     0.2413   -0.0001
   340        0.0019             nan     0.2413   -0.0001
   360        0.0014             nan     0.2413   -0.0001
   380        0.0010             nan     0.2413   -0.0000
   400        0.0008             nan     0.2413   -0.0000
   420        0.0006             nan     0.2413   -0.0000
   440        0.0004             nan     0.2413   -0.0000
   460        0.0003             nan     0.2413   -0.0000
   480        0.0002             nan     0.2413   -0.0000
   500        0.0002             nan     0.2413   -0.0000
   520        0.0001             nan     0.2413   -0.0000
   540        0.0001             nan     0.2413   -0.0000
   560        0.0001             nan     0.2413   -0.0000
   580        0.0000             nan     0.2413   -0.0000
   600        0.0000             nan     0.2413   -0.0000
   620        0.0000             nan     0.2413   -0.0000
   640        0.0000             nan     0.2413   -0.0000
   660        0.0000             nan     0.2413   -0.0000
   680        0.0000             nan     0.2413   -0.0000
   700        0.0000             nan     0.2413   -0.0000
   720        0.0000             nan     0.2413   -0.0000
   740        0.0000             nan     0.2413   -0.0000
   760        0.0000             nan     0.2413   -0.0000
   780        0.0000             nan     0.2413   -0.0000
   800        0.0000             nan     0.2413   -0.0000
   820        0.0000             nan     0.2413   -0.0000
   840        0.0000             nan     0.2413   -0.0000
   846        0.0000             nan     0.2413   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9425             nan     0.2603   -0.0078
     2        0.9209             nan     0.2603   -0.0580
     3        0.8941             nan     0.2603   -0.0141
     4        0.8614             nan     0.2603   -0.0285
     5        0.8325             nan     0.2603   -0.0341
     6        0.7991             nan     0.2603   -0.0137
     7        0.7727             nan     0.2603   -0.0221
     8        0.7512             nan     0.2603   -0.0229
     9        0.7266             nan     0.2603   -0.0101
    10        0.7163             nan     0.2603   -0.0260
    20        0.5531             nan     0.2603   -0.0128
    40        0.3454             nan     0.2603   -0.0116
    60        0.2337             nan     0.2603   -0.0099
    80        0.1488             nan     0.2603   -0.0059
   100        0.1023             nan     0.2603   -0.0025
   120        0.0692             nan     0.2603   -0.0028
   140        0.0459             nan     0.2603   -0.0011
   160        0.0323             nan     0.2603   -0.0012
   180        0.0228             nan     0.2603   -0.0012
   200        0.0153             nan     0.2603   -0.0003
   220        0.0107             nan     0.2603   -0.0003
   240        0.0078             nan     0.2603   -0.0004
   260        0.0053             nan     0.2603   -0.0002
   280        0.0037             nan     0.2603   -0.0002
   300        0.0027             nan     0.2603   -0.0001
   320        0.0018             nan     0.2603   -0.0001
   340        0.0014             nan     0.2603   -0.0001
   360        0.0009             nan     0.2603   -0.0000
   380        0.0007             nan     0.2603   -0.0000
   400        0.0005             nan     0.2603   -0.0000
   420        0.0003             nan     0.2603   -0.0000
   440        0.0002             nan     0.2603   -0.0000
   460        0.0002             nan     0.2603   -0.0000
   480        0.0001             nan     0.2603   -0.0000
   500        0.0001             nan     0.2603   -0.0000
   520        0.0001             nan     0.2603   -0.0000
   540        0.0000             nan     0.2603   -0.0000
   560        0.0000             nan     0.2603   -0.0000
   580        0.0000             nan     0.2603   -0.0000
   600        0.0000             nan     0.2603   -0.0000
   620        0.0000             nan     0.2603   -0.0000
   640        0.0000             nan     0.2603   -0.0000
   660        0.0000             nan     0.2603   -0.0000
   680        0.0000             nan     0.2603   -0.0000
   700        0.0000             nan     0.2603   -0.0000
   720        0.0000             nan     0.2603   -0.0000
   740        0.0000             nan     0.2603   -0.0000
   760        0.0000             nan     0.2603   -0.0000
   780        0.0000             nan     0.2603   -0.0000
   800        0.0000             nan     0.2603   -0.0000
   820        0.0000             nan     0.2603   -0.0000
   840        0.0000             nan     0.2603   -0.0000
   860        0.0000             nan     0.2603   -0.0000
   880        0.0000             nan     0.2603   -0.0000
   900        0.0000             nan     0.2603   -0.0000
   920        0.0000             nan     0.2603   -0.0000
   940        0.0000             nan     0.2603   -0.0000
   960        0.0000             nan     0.2603   -0.0000
   980        0.0000             nan     0.2603   -0.0000
  1000        0.0000             nan     0.2603   -0.0000
  1020        0.0000             nan     0.2603   -0.0000
  1040        0.0000             nan     0.2603   -0.0000
  1060        0.0000             nan     0.2603   -0.0000
  1080        0.0000             nan     0.2603   -0.0000
  1100        0.0000             nan     0.2603   -0.0000
  1120        0.0000             nan     0.2603   -0.0000
  1140        0.0000             nan     0.2603   -0.0000
  1160        0.0000             nan     0.2603   -0.0000
  1180        0.0000             nan     0.2603   -0.0000
  1200        0.0000             nan     0.2603   -0.0000
  1220        0.0000             nan     0.2603   -0.0000
  1240        0.0000             nan     0.2603   -0.0000
  1260        0.0000             nan     0.2603   -0.0000
  1280        0.0000             nan     0.2603   -0.0000
  1300        0.0000             nan     0.2603   -0.0000
  1320        0.0000             nan     0.2603   -0.0000
  1340        0.0000             nan     0.2603   -0.0000
  1360        0.0000             nan     0.2603   -0.0000
  1380        0.0000             nan     0.2603   -0.0000
  1400        0.0000             nan     0.2603   -0.0000
  1420        0.0000             nan     0.2603   -0.0000
  1440        0.0000             nan     0.2603   -0.0000
  1460        0.0000             nan     0.2603   -0.0000
  1480        0.0000             nan     0.2603   -0.0000
  1500        0.0000             nan     0.2603   -0.0000
  1520        0.0000             nan     0.2603   -0.0000
  1540        0.0000             nan     0.2603   -0.0000
  1560        0.0000             nan     0.2603   -0.0000
  1580        0.0000             nan     0.2603   -0.0000
  1600        0.0000             nan     0.2603   -0.0000
  1620        0.0000             nan     0.2603   -0.0000
  1640        0.0000             nan     0.2603   -0.0000
  1660        0.0000             nan     0.2603   -0.0000
  1680        0.0000             nan     0.2603   -0.0000
  1700        0.0000             nan     0.2603   -0.0000
  1720        0.0000             nan     0.2603   -0.0000
  1740        0.0000             nan     0.2603   -0.0000
  1760        0.0000             nan     0.2603   -0.0000
  1780        0.0000             nan     0.2603   -0.0000
  1800        0.0000             nan     0.2603   -0.0000
  1820        0.0000             nan     0.2603   -0.0000
  1840        0.0000             nan     0.2603   -0.0000
  1860        0.0000             nan     0.2603   -0.0000
  1880        0.0000             nan     0.2603   -0.0000
  1900        0.0000             nan     0.2603   -0.0000
  1920        0.0000             nan     0.2603   -0.0000
  1940        0.0000             nan     0.2603   -0.0000
  1960        0.0000             nan     0.2603   -0.0000
  1980        0.0000             nan     0.2603   -0.0000
  2000        0.0000             nan     0.2603   -0.0000
  2020        0.0000             nan     0.2603   -0.0000
  2040        0.0000             nan     0.2603   -0.0000
  2060        0.0000             nan     0.2603   -0.0000
  2080        0.0000             nan     0.2603   -0.0000
  2100        0.0000             nan     0.2603   -0.0000
  2120        0.0000             nan     0.2603   -0.0000
  2140        0.0000             nan     0.2603   -0.0000
  2160        0.0000             nan     0.2603   -0.0000
  2180        0.0000             nan     0.2603   -0.0000
  2200        0.0000             nan     0.2603   -0.0000
  2220        0.0000             nan     0.2603   -0.0000
  2240        0.0000             nan     0.2603   -0.0000
  2260        0.0000             nan     0.2603   -0.0000
  2280        0.0000             nan     0.2603   -0.0000
  2300        0.0000             nan     0.2603   -0.0000
  2320        0.0000             nan     0.2603   -0.0000
  2340        0.0000             nan     0.2603   -0.0000
  2360        0.0000             nan     0.2603   -0.0000
  2380        0.0000             nan     0.2603   -0.0000
  2400        0.0000             nan     0.2603   -0.0000
  2420        0.0000             nan     0.2603   -0.0000
  2440        0.0000             nan     0.2603   -0.0000
  2460        0.0000             nan     0.2603   -0.0000
  2480        0.0000             nan     0.2603   -0.0000
  2500        0.0000             nan     0.2603   -0.0000
  2520        0.0000             nan     0.2603   -0.0000
  2540        0.0000             nan     0.2603   -0.0000
  2560        0.0000             nan     0.2603   -0.0000
  2580        0.0000             nan     0.2603   -0.0000
  2600        0.0000             nan     0.2603   -0.0000
  2620        0.0000             nan     0.2603   -0.0000
  2640        0.0000             nan     0.2603   -0.0000
  2660        0.0000             nan     0.2603   -0.0000
  2680        0.0000             nan     0.2603   -0.0000
  2700        0.0000             nan     0.2603   -0.0000
  2720        0.0000             nan     0.2603   -0.0000
  2740        0.0000             nan     0.2603   -0.0000
  2760        0.0000             nan     0.2603   -0.0000
  2780        0.0000             nan     0.2603   -0.0000
  2800        0.0000             nan     0.2603   -0.0000
  2820        0.0000             nan     0.2603   -0.0000
  2840        0.0000             nan     0.2603   -0.0000
  2860        0.0000             nan     0.2603   -0.0000
  2880        0.0000             nan     0.2603   -0.0000
  2900        0.0000             nan     0.2603   -0.0000
  2920        0.0000             nan     0.2603   -0.0000
  2940        0.0000             nan     0.2603   -0.0000
  2960        0.0000             nan     0.2603   -0.0000
  2980        0.0000             nan     0.2603   -0.0000
  3000        0.0000             nan     0.2603   -0.0000
  3020        0.0000             nan     0.2603   -0.0000
  3040        0.0000             nan     0.2603   -0.0000
  3060        0.0000             nan     0.2603   -0.0000
  3080        0.0000             nan     0.2603   -0.0000
  3100        0.0000             nan     0.2603   -0.0000
  3120        0.0000             nan     0.2603   -0.0000
  3140        0.0000             nan     0.2603   -0.0000
  3160        0.0000             nan     0.2603    0.0000
  3180        0.0000             nan     0.2603   -0.0000
  3200        0.0000             nan     0.2603   -0.0000
  3220        0.0000             nan     0.2603   -0.0000
  3240        0.0000             nan     0.2603   -0.0000
  3260        0.0000             nan     0.2603   -0.0000
  3280        0.0000             nan     0.2603   -0.0000
  3300        0.0000             nan     0.2603   -0.0000
  3320        0.0000             nan     0.2603   -0.0000
  3340        0.0000             nan     0.2603   -0.0000
  3360        0.0000             nan     0.2603   -0.0000
  3380        0.0000             nan     0.2603   -0.0000
  3400        0.0000             nan     0.2603   -0.0000
  3420        0.0000             nan     0.2603   -0.0000
  3440        0.0000             nan     0.2603   -0.0000
  3460        0.0000             nan     0.2603   -0.0000
  3480        0.0000             nan     0.2603   -0.0000
  3500        0.0000             nan     0.2603   -0.0000
  3520        0.0000             nan     0.2603   -0.0000
  3540        0.0000             nan     0.2603   -0.0000
  3560        0.0000             nan     0.2603   -0.0000
  3580        0.0000             nan     0.2603   -0.0000
  3600        0.0000             nan     0.2603   -0.0000
  3620        0.0000             nan     0.2603   -0.0000
  3640        0.0000             nan     0.2603   -0.0000
  3660        0.0000             nan     0.2603   -0.0000
  3680        0.0000             nan     0.2603   -0.0000
  3700        0.0000             nan     0.2603   -0.0000
  3720        0.0000             nan     0.2603   -0.0000
  3740        0.0000             nan     0.2603   -0.0000
  3760        0.0000             nan     0.2603   -0.0000
  3780        0.0000             nan     0.2603   -0.0000
  3800        0.0000             nan     0.2603   -0.0000
  3820        0.0000             nan     0.2603   -0.0000
  3840        0.0000             nan     0.2603   -0.0000
  3860        0.0000             nan     0.2603   -0.0000
  3880        0.0000             nan     0.2603   -0.0000
  3900        0.0000             nan     0.2603   -0.0000
  3920        0.0000             nan     0.2603   -0.0000
  3940        0.0000             nan     0.2603   -0.0000
  3960        0.0000             nan     0.2603   -0.0000
  3980        0.0000             nan     0.2603   -0.0000
  4000        0.0000             nan     0.2603   -0.0000
  4020        0.0000             nan     0.2603   -0.0000
  4040        0.0000             nan     0.2603   -0.0000
  4060        0.0000             nan     0.2603   -0.0000
  4080        0.0000             nan     0.2603   -0.0000
  4100        0.0000             nan     0.2603   -0.0000
  4120        0.0000             nan     0.2603   -0.0000
  4140        0.0000             nan     0.2603   -0.0000
  4160        0.0000             nan     0.2603   -0.0000
  4180        0.0000             nan     0.2603   -0.0000
  4200        0.0000             nan     0.2603   -0.0000
  4213        0.0000             nan     0.2603   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9413             nan     0.2885   -0.0175
     2        0.9086             nan     0.2885   -0.0360
     3        0.8824             nan     0.2885   -0.0583
     4        0.8435             nan     0.2885   -0.0329
     5        0.8101             nan     0.2885   -0.0030
     6        0.7798             nan     0.2885   -0.0198
     7        0.7539             nan     0.2885   -0.0223
     8        0.7222             nan     0.2885   -0.0163
     9        0.7011             nan     0.2885   -0.0229
    10        0.6764             nan     0.2885   -0.0182
    20        0.4783             nan     0.2885   -0.0057
    40        0.2701             nan     0.2885   -0.0185
    60        0.1585             nan     0.2885   -0.0100
    80        0.1023             nan     0.2885   -0.0069
   100        0.0632             nan     0.2885   -0.0035
   120        0.0377             nan     0.2885   -0.0011
   140        0.0238             nan     0.2885   -0.0009
   160        0.0151             nan     0.2885   -0.0013
   180        0.0099             nan     0.2885   -0.0004
   200        0.0063             nan     0.2885   -0.0002
   220        0.0041             nan     0.2885   -0.0003
   240        0.0028             nan     0.2885   -0.0002
   260        0.0018             nan     0.2885   -0.0000
   280        0.0012             nan     0.2885   -0.0001
   300        0.0008             nan     0.2885   -0.0001
   320        0.0005             nan     0.2885   -0.0000
   340        0.0003             nan     0.2885   -0.0000
   360        0.0002             nan     0.2885   -0.0000
   380        0.0001             nan     0.2885   -0.0000
   400        0.0001             nan     0.2885   -0.0000
   420        0.0001             nan     0.2885   -0.0000
   440        0.0000             nan     0.2885   -0.0000
   460        0.0000             nan     0.2885   -0.0000
   480        0.0000             nan     0.2885   -0.0000
   500        0.0000             nan     0.2885   -0.0000
   520        0.0000             nan     0.2885   -0.0000
   540        0.0000             nan     0.2885   -0.0000
   560        0.0000             nan     0.2885   -0.0000
   580        0.0000             nan     0.2885   -0.0000
   600        0.0000             nan     0.2885   -0.0000
   620        0.0000             nan     0.2885   -0.0000
   640        0.0000             nan     0.2885   -0.0000
   660        0.0000             nan     0.2885   -0.0000
   680        0.0000             nan     0.2885   -0.0000
   700        0.0000             nan     0.2885   -0.0000
   720        0.0000             nan     0.2885   -0.0000
   740        0.0000             nan     0.2885   -0.0000
   760        0.0000             nan     0.2885   -0.0000
   780        0.0000             nan     0.2885   -0.0000
   800        0.0000             nan     0.2885   -0.0000
   820        0.0000             nan     0.2885   -0.0000
   840        0.0000             nan     0.2885   -0.0000
   860        0.0000             nan     0.2885   -0.0000
   880        0.0000             nan     0.2885   -0.0000
   900        0.0000             nan     0.2885   -0.0000
   920        0.0000             nan     0.2885   -0.0000
   940        0.0000             nan     0.2885   -0.0000
   960        0.0000             nan     0.2885   -0.0000
   980        0.0000             nan     0.2885   -0.0000
  1000        0.0000             nan     0.2885   -0.0000
  1020        0.0000             nan     0.2885   -0.0000
  1040        0.0000             nan     0.2885   -0.0000
  1060        0.0000             nan     0.2885   -0.0000
  1080        0.0000             nan     0.2885   -0.0000
  1100        0.0000             nan     0.2885   -0.0000
  1120        0.0000             nan     0.2885   -0.0000
  1140        0.0000             nan     0.2885   -0.0000
  1160        0.0000             nan     0.2885   -0.0000
  1180        0.0000             nan     0.2885   -0.0000
  1200        0.0000             nan     0.2885   -0.0000
  1220        0.0000             nan     0.2885   -0.0000
  1240        0.0000             nan     0.2885   -0.0000
  1260        0.0000             nan     0.2885   -0.0000
  1280        0.0000             nan     0.2885   -0.0000
  1300        0.0000             nan     0.2885   -0.0000
  1320        0.0000             nan     0.2885   -0.0000
  1340        0.0000             nan     0.2885   -0.0000
  1360        0.0000             nan     0.2885   -0.0000
  1380        0.0000             nan     0.2885   -0.0000
  1400        0.0000             nan     0.2885   -0.0000
  1420        0.0000             nan     0.2885   -0.0000
  1440        0.0000             nan     0.2885   -0.0000
  1460        0.0000             nan     0.2885   -0.0000
  1480        0.0000             nan     0.2885   -0.0000
  1500        0.0000             nan     0.2885   -0.0000
  1520        0.0000             nan     0.2885   -0.0000
  1540        0.0000             nan     0.2885   -0.0000
  1560        0.0000             nan     0.2885   -0.0000
  1580        0.0000             nan     0.2885   -0.0000
  1600        0.0000             nan     0.2885   -0.0000
  1620        0.0000             nan     0.2885   -0.0000
  1640        0.0000             nan     0.2885   -0.0000
  1660        0.0000             nan     0.2885   -0.0000
  1680        0.0000             nan     0.2885   -0.0000
  1700        0.0000             nan     0.2885   -0.0000
  1720        0.0000             nan     0.2885   -0.0000
  1740        0.0000             nan     0.2885   -0.0000
  1760        0.0000             nan     0.2885   -0.0000
  1780        0.0000             nan     0.2885   -0.0000
  1800        0.0000             nan     0.2885   -0.0000
  1820        0.0000             nan     0.2885   -0.0000
  1840        0.0000             nan     0.2885   -0.0000
  1860        0.0000             nan     0.2885   -0.0000
  1880        0.0000             nan     0.2885   -0.0000
  1900        0.0000             nan     0.2885   -0.0000
  1920        0.0000             nan     0.2885   -0.0000
  1940        0.0000             nan     0.2885   -0.0000
  1960        0.0000             nan     0.2885   -0.0000
  1980        0.0000             nan     0.2885   -0.0000
  2000        0.0000             nan     0.2885   -0.0000
  2020        0.0000             nan     0.2885   -0.0000
  2040        0.0000             nan     0.2885   -0.0000
  2060        0.0000             nan     0.2885   -0.0000
  2080        0.0000             nan     0.2885   -0.0000
  2100        0.0000             nan     0.2885   -0.0000
  2120        0.0000             nan     0.2885   -0.0000
  2140        0.0000             nan     0.2885   -0.0000
  2160        0.0000             nan     0.2885   -0.0000
  2180        0.0000             nan     0.2885   -0.0000
  2200        0.0000             nan     0.2885   -0.0000
  2220        0.0000             nan     0.2885   -0.0000
  2240        0.0000             nan     0.2885   -0.0000
  2260        0.0000             nan     0.2885   -0.0000
  2280        0.0000             nan     0.2885   -0.0000
  2300        0.0000             nan     0.2885   -0.0000
  2320        0.0000             nan     0.2885   -0.0000
  2340        0.0000             nan     0.2885   -0.0000
  2360        0.0000             nan     0.2885   -0.0000
  2380        0.0000             nan     0.2885   -0.0000
  2400        0.0000             nan     0.2885   -0.0000
  2420        0.0000             nan     0.2885   -0.0000
  2440        0.0000             nan     0.2885   -0.0000
  2460        0.0000             nan     0.2885   -0.0000
  2480        0.0000             nan     0.2885   -0.0000
  2500        0.0000             nan     0.2885   -0.0000
  2520        0.0000             nan     0.2885   -0.0000
  2540        0.0000             nan     0.2885   -0.0000
  2560        0.0000             nan     0.2885   -0.0000
  2580        0.0000             nan     0.2885   -0.0000
  2600        0.0000             nan     0.2885   -0.0000
  2620        0.0000             nan     0.2885   -0.0000
  2640        0.0000             nan     0.2885   -0.0000
  2660        0.0000             nan     0.2885   -0.0000
  2680        0.0000             nan     0.2885   -0.0000
  2700        0.0000             nan     0.2885   -0.0000
  2720        0.0000             nan     0.2885   -0.0000
  2740        0.0000             nan     0.2885   -0.0000
  2760        0.0000             nan     0.2885   -0.0000
  2780        0.0000             nan     0.2885   -0.0000
  2800        0.0000             nan     0.2885   -0.0000
  2820        0.0000             nan     0.2885   -0.0000
  2840        0.0000             nan     0.2885   -0.0000
  2860        0.0000             nan     0.2885   -0.0000
  2880        0.0000             nan     0.2885   -0.0000
  2900        0.0000             nan     0.2885   -0.0000
  2920        0.0000             nan     0.2885   -0.0000
  2940        0.0000             nan     0.2885   -0.0000
  2960        0.0000             nan     0.2885   -0.0000
  2980        0.0000             nan     0.2885   -0.0000
  3000        0.0000             nan     0.2885   -0.0000
  3020        0.0000             nan     0.2885   -0.0000
  3040        0.0000             nan     0.2885   -0.0000
  3060        0.0000             nan     0.2885   -0.0000
  3080        0.0000             nan     0.2885   -0.0000
  3100        0.0000             nan     0.2885   -0.0000
  3120        0.0000             nan     0.2885   -0.0000
  3140        0.0000             nan     0.2885   -0.0000
  3160        0.0000             nan     0.2885   -0.0000
  3180        0.0000             nan     0.2885   -0.0000
  3200        0.0000             nan     0.2885   -0.0000
  3220        0.0000             nan     0.2885   -0.0000
  3240        0.0000             nan     0.2885   -0.0000
  3260        0.0000             nan     0.2885   -0.0000
  3280        0.0000             nan     0.2885   -0.0000
  3300        0.0000             nan     0.2885   -0.0000
  3320        0.0000             nan     0.2885   -0.0000
  3340        0.0000             nan     0.2885   -0.0000
  3360        0.0000             nan     0.2885   -0.0000
  3380        0.0000             nan     0.2885   -0.0000
  3400        0.0000             nan     0.2885   -0.0000
  3420        0.0000             nan     0.2885   -0.0000
  3440        0.0000             nan     0.2885   -0.0000
  3460        0.0000             nan     0.2885   -0.0000
  3480        0.0000             nan     0.2885   -0.0000
  3500        0.0000             nan     0.2885   -0.0000
  3520        0.0000             nan     0.2885   -0.0000
  3540        0.0000             nan     0.2885   -0.0000
  3560        0.0000             nan     0.2885   -0.0000
  3580        0.0000             nan     0.2885   -0.0000
  3600        0.0000             nan     0.2885   -0.0000
  3620        0.0000             nan     0.2885   -0.0000
  3640        0.0000             nan     0.2885   -0.0000
  3660        0.0000             nan     0.2885   -0.0000
  3680        0.0000             nan     0.2885   -0.0000
  3700        0.0000             nan     0.2885   -0.0000
  3720        0.0000             nan     0.2885   -0.0000
  3740        0.0000             nan     0.2885   -0.0000
  3760        0.0000             nan     0.2885   -0.0000
  3780        0.0000             nan     0.2885   -0.0000
  3800        0.0000             nan     0.2885   -0.0000
  3820        0.0000             nan     0.2885   -0.0000
  3840        0.0000             nan     0.2885   -0.0000
  3860        0.0000             nan     0.2885   -0.0000
  3880        0.0000             nan     0.2885   -0.0000
  3900        0.0000             nan     0.2885   -0.0000
  3920        0.0000             nan     0.2885   -0.0000
  3940        0.0000             nan     0.2885   -0.0000
  3960        0.0000             nan     0.2885   -0.0000
  3980        0.0000             nan     0.2885   -0.0000
  4000        0.0000             nan     0.2885   -0.0000
  4020        0.0000             nan     0.2885   -0.0000
  4040        0.0000             nan     0.2885   -0.0000
  4060        0.0000             nan     0.2885   -0.0000
  4080        0.0000             nan     0.2885   -0.0000
  4100        0.0000             nan     0.2885   -0.0000
  4120        0.0000             nan     0.2885   -0.0000
  4140        0.0000             nan     0.2885   -0.0000
  4160        0.0000             nan     0.2885   -0.0000
  4180        0.0000             nan     0.2885   -0.0000
  4200        0.0000             nan     0.2885   -0.0000
  4220        0.0000             nan     0.2885   -0.0000
  4240        0.0000             nan     0.2885   -0.0000
  4260        0.0000             nan     0.2885   -0.0000
  4280        0.0000             nan     0.2885   -0.0000
  4300        0.0000             nan     0.2885   -0.0000
  4320        0.0000             nan     0.2885   -0.0000
  4340        0.0000             nan     0.2885   -0.0000
  4360        0.0000             nan     0.2885   -0.0000
  4380        0.0000             nan     0.2885   -0.0000
  4400        0.0000             nan     0.2885   -0.0000
  4420        0.0000             nan     0.2885   -0.0000
  4440        0.0000             nan     0.2885   -0.0000
  4460        0.0000             nan     0.2885   -0.0000
  4480        0.0000             nan     0.2885   -0.0000
  4500        0.0000             nan     0.2885   -0.0000
  4520        0.0000             nan     0.2885   -0.0000
  4540        0.0000             nan     0.2885   -0.0000
  4560        0.0000             nan     0.2885   -0.0000
  4580        0.0000             nan     0.2885   -0.0000
  4600        0.0000             nan     0.2885   -0.0000
  4620        0.0000             nan     0.2885   -0.0000
  4640        0.0000             nan     0.2885   -0.0000
  4660        0.0000             nan     0.2885   -0.0000
  4680        0.0000             nan     0.2885   -0.0000
  4700        0.0000             nan     0.2885   -0.0000
  4720        0.0000             nan     0.2885   -0.0000
  4740        0.0000             nan     0.2885   -0.0000
  4760        0.0000             nan     0.2885   -0.0000
  4780        0.0000             nan     0.2885   -0.0000
  4800        0.0000             nan     0.2885   -0.0000
  4820        0.0000             nan     0.2885   -0.0000
  4837        0.0000             nan     0.2885   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9666             nan     0.2888   -0.0165
     2        0.9542             nan     0.2888    0.0015
     3        0.9362             nan     0.2888    0.0065
     4        0.9288             nan     0.2888   -0.0102
     5        0.9229             nan     0.2888   -0.0144
     6        0.9132             nan     0.2888   -0.0036
     7        0.8990             nan     0.2888   -0.0087
     8        0.8991             nan     0.2888   -0.0232
     9        0.8889             nan     0.2888   -0.0052
    10        0.8828             nan     0.2888   -0.0112
    20        0.8245             nan     0.2888   -0.0159
    40        0.7339             nan     0.2888   -0.0126
    60        0.6647             nan     0.2888   -0.0148
    80        0.5977             nan     0.2888   -0.0110
   100        0.5497             nan     0.2888   -0.0085
   120        0.4947             nan     0.2888   -0.0060
   140        0.4495             nan     0.2888   -0.0074
   160        0.4164             nan     0.2888   -0.0039
   180        0.3876             nan     0.2888   -0.0062
   200        0.3612             nan     0.2888   -0.0044
   220        0.3362             nan     0.2888   -0.0029
   240        0.3144             nan     0.2888   -0.0082
   260        0.2980             nan     0.2888   -0.0100
   280        0.2769             nan     0.2888   -0.0041
   300        0.2608             nan     0.2888   -0.0042
   320        0.2477             nan     0.2888   -0.0037
   340        0.2293             nan     0.2888   -0.0022
   360        0.2134             nan     0.2888   -0.0032
   380        0.2039             nan     0.2888   -0.0018
   400        0.1917             nan     0.2888   -0.0019
   420        0.1825             nan     0.2888   -0.0039
   440        0.1723             nan     0.2888   -0.0041
   460        0.1614             nan     0.2888   -0.0023
   480        0.1517             nan     0.2888   -0.0019
   500        0.1442             nan     0.2888   -0.0014
   520        0.1356             nan     0.2888   -0.0013
   540        0.1267             nan     0.2888   -0.0017
   560        0.1215             nan     0.2888   -0.0061
   580        0.1145             nan     0.2888   -0.0016
   600        0.1082             nan     0.2888   -0.0009
   620        0.1027             nan     0.2888   -0.0010
   640        0.0990             nan     0.2888   -0.0025
   660        0.0938             nan     0.2888   -0.0025
   680        0.0876             nan     0.2888   -0.0010
   700        0.0813             nan     0.2888   -0.0014
   720        0.0776             nan     0.2888   -0.0012
   740        0.0725             nan     0.2888   -0.0007
   760        0.0685             nan     0.2888   -0.0011
   780        0.0641             nan     0.2888   -0.0008
   800        0.0612             nan     0.2888   -0.0009
   820        0.0591             nan     0.2888   -0.0011
   840        0.0549             nan     0.2888   -0.0014
   860        0.0509             nan     0.2888   -0.0011
   880        0.0477             nan     0.2888   -0.0004
   900        0.0452             nan     0.2888   -0.0004
   920        0.0424             nan     0.2888   -0.0007
   940        0.0402             nan     0.2888   -0.0006
   960        0.0378             nan     0.2888   -0.0003
   980        0.0356             nan     0.2888   -0.0004
  1000        0.0340             nan     0.2888   -0.0006
  1020        0.0319             nan     0.2888   -0.0005
  1040        0.0301             nan     0.2888   -0.0005
  1060        0.0285             nan     0.2888   -0.0005
  1080        0.0272             nan     0.2888   -0.0002
  1100        0.0256             nan     0.2888   -0.0003
  1120        0.0244             nan     0.2888   -0.0007
  1140        0.0234             nan     0.2888   -0.0007
  1160        0.0223             nan     0.2888   -0.0005
  1180        0.0211             nan     0.2888   -0.0004
  1200        0.0199             nan     0.2888   -0.0006
  1220        0.0187             nan     0.2888   -0.0004
  1240        0.0179             nan     0.2888   -0.0004
  1260        0.0169             nan     0.2888   -0.0001
  1264        0.0168             nan     0.2888   -0.0003

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9583             nan     0.3308   -0.0335
     2        0.9213             nan     0.3308   -0.0051
     3        0.9012             nan     0.3308   -0.0195
     4        0.8873             nan     0.3308   -0.0215
     5        0.8562             nan     0.3308   -0.0266
     6        0.8418             nan     0.3308   -0.0219
     7        0.8214             nan     0.3308   -0.0183
     8        0.8094             nan     0.3308   -0.0407
     9        0.7907             nan     0.3308   -0.0158
    10        0.7700             nan     0.3308   -0.0200
    20        0.6317             nan     0.3308   -0.0267
    40        0.4375             nan     0.3308   -0.0169
    60        0.3175             nan     0.3308   -0.0149
    80        0.2359             nan     0.3308   -0.0070
   100        0.1808             nan     0.3308   -0.0136
   120        0.1326             nan     0.3308   -0.0054
   140        0.0975             nan     0.3308   -0.0040
   160        0.0721             nan     0.3308   -0.0016
   180        0.0522             nan     0.3308   -0.0020
   200        0.0414             nan     0.3308   -0.0009
   220        0.0304             nan     0.3308   -0.0013
   240        0.0242             nan     0.3308   -0.0013
   260        0.0191             nan     0.3308   -0.0010
   280        0.0149             nan     0.3308   -0.0002
   300        0.0121             nan     0.3308   -0.0005
   320        0.0092             nan     0.3308   -0.0004
   340        0.0069             nan     0.3308   -0.0002
   360        0.0055             nan     0.3308   -0.0002
   380        0.0043             nan     0.3308   -0.0002
   400        0.0033             nan     0.3308   -0.0001
   420        0.0025             nan     0.3308   -0.0001
   440        0.0020             nan     0.3308   -0.0000
   460        0.0016             nan     0.3308   -0.0001
   480        0.0013             nan     0.3308   -0.0000
   500        0.0010             nan     0.3308   -0.0000
   520        0.0008             nan     0.3308   -0.0001
   540        0.0006             nan     0.3308   -0.0000
   560        0.0005             nan     0.3308   -0.0000
   580        0.0004             nan     0.3308   -0.0000
   600        0.0003             nan     0.3308   -0.0000
   620        0.0002             nan     0.3308   -0.0000
   640        0.0002             nan     0.3308   -0.0000
   660        0.0001             nan     0.3308   -0.0000
   680        0.0001             nan     0.3308   -0.0000
   700        0.0001             nan     0.3308   -0.0000
   720        0.0001             nan     0.3308   -0.0000
   740        0.0001             nan     0.3308   -0.0000
   760        0.0000             nan     0.3308   -0.0000
   780        0.0000             nan     0.3308   -0.0000
   800        0.0000             nan     0.3308   -0.0000
   820        0.0000             nan     0.3308   -0.0000
   840        0.0000             nan     0.3308   -0.0000
   860        0.0000             nan     0.3308   -0.0000
   880        0.0000             nan     0.3308   -0.0000
   900        0.0000             nan     0.3308   -0.0000
   920        0.0000             nan     0.3308   -0.0000
   940        0.0000             nan     0.3308   -0.0000
   960        0.0000             nan     0.3308   -0.0000
   980        0.0000             nan     0.3308   -0.0000
  1000        0.0000             nan     0.3308   -0.0000
  1020        0.0000             nan     0.3308   -0.0000
  1040        0.0000             nan     0.3308   -0.0000
  1060        0.0000             nan     0.3308   -0.0000
  1080        0.0000             nan     0.3308   -0.0000
  1100        0.0000             nan     0.3308   -0.0000
  1120        0.0000             nan     0.3308   -0.0000
  1140        0.0000             nan     0.3308   -0.0000
  1160        0.0000             nan     0.3308   -0.0000
  1180        0.0000             nan     0.3308   -0.0000
  1200        0.0000             nan     0.3308   -0.0000
  1220        0.0000             nan     0.3308   -0.0000
  1240        0.0000             nan     0.3308   -0.0000
  1260        0.0000             nan     0.3308   -0.0000
  1280        0.0000             nan     0.3308   -0.0000
  1300        0.0000             nan     0.3308   -0.0000
  1320        0.0000             nan     0.3308   -0.0000
  1340        0.0000             nan     0.3308   -0.0000
  1360        0.0000             nan     0.3308   -0.0000
  1380        0.0000             nan     0.3308   -0.0000
  1400        0.0000             nan     0.3308   -0.0000
  1420        0.0000             nan     0.3308   -0.0000
  1440        0.0000             nan     0.3308   -0.0000
  1460        0.0000             nan     0.3308   -0.0000
  1480        0.0000             nan     0.3308   -0.0000
  1500        0.0000             nan     0.3308   -0.0000
  1520        0.0000             nan     0.3308   -0.0000
  1540        0.0000             nan     0.3308   -0.0000
  1560        0.0000             nan     0.3308   -0.0000
  1580        0.0000             nan     0.3308   -0.0000
  1600        0.0000             nan     0.3308   -0.0000
  1620        0.0000             nan     0.3308   -0.0000
  1640        0.0000             nan     0.3308   -0.0000
  1660        0.0000             nan     0.3308   -0.0000
  1680        0.0000             nan     0.3308   -0.0000
  1700        0.0000             nan     0.3308   -0.0000
  1720        0.0000             nan     0.3308   -0.0000
  1740        0.0000             nan     0.3308   -0.0000
  1760        0.0000             nan     0.3308   -0.0000
  1780        0.0000             nan     0.3308   -0.0000
  1800        0.0000             nan     0.3308   -0.0000
  1820        0.0000             nan     0.3308   -0.0000
  1825        0.0000             nan     0.3308   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9488             nan     0.3353   -0.0597
     2        0.9063             nan     0.3353   -0.0442
     3        0.8496             nan     0.3353   -0.0126
     4        0.8195             nan     0.3353   -0.0390
     5        0.7913             nan     0.3353   -0.0388
     6        0.7669             nan     0.3353   -0.0397
     7        0.7432             nan     0.3353   -0.0414
     8        0.7121             nan     0.3353   -0.0082
     9        0.6868             nan     0.3353   -0.0258
    10        0.6538             nan     0.3353   -0.0034
    20        0.4846             nan     0.3353   -0.0278
    40        0.2614             nan     0.3353   -0.0137
    60        0.1573             nan     0.3353   -0.0023
    80        0.0946             nan     0.3353   -0.0107
   100        0.0577             nan     0.3353   -0.0041
   120        0.0328             nan     0.3353   -0.0022
   140        0.0189             nan     0.3353   -0.0011
   160        0.0113             nan     0.3353   -0.0004
   180        0.0069             nan     0.3353   -0.0003
   200        0.0043             nan     0.3353   -0.0002
   220        0.0026             nan     0.3353   -0.0001
   240        0.0016             nan     0.3353   -0.0001
   260        0.0010             nan     0.3353   -0.0000
   280        0.0006             nan     0.3353   -0.0000
   300        0.0004             nan     0.3353   -0.0000
   320        0.0002             nan     0.3353   -0.0000
   340        0.0001             nan     0.3353   -0.0000
   360        0.0001             nan     0.3353   -0.0000
   380        0.0001             nan     0.3353   -0.0000
   400        0.0000             nan     0.3353   -0.0000
   420        0.0000             nan     0.3353   -0.0000
   440        0.0000             nan     0.3353   -0.0000
   460        0.0000             nan     0.3353   -0.0000
   480        0.0000             nan     0.3353   -0.0000
   500        0.0000             nan     0.3353   -0.0000
   520        0.0000             nan     0.3353   -0.0000
   540        0.0000             nan     0.3353   -0.0000
   560        0.0000             nan     0.3353   -0.0000
   580        0.0000             nan     0.3353   -0.0000
   600        0.0000             nan     0.3353   -0.0000
   620        0.0000             nan     0.3353   -0.0000
   640        0.0000             nan     0.3353   -0.0000
   660        0.0000             nan     0.3353   -0.0000
   680        0.0000             nan     0.3353   -0.0000
   700        0.0000             nan     0.3353   -0.0000
   720        0.0000             nan     0.3353   -0.0000
   740        0.0000             nan     0.3353   -0.0000
   760        0.0000             nan     0.3353   -0.0000
   780        0.0000             nan     0.3353   -0.0000
   800        0.0000             nan     0.3353   -0.0000
   820        0.0000             nan     0.3353   -0.0000
   840        0.0000             nan     0.3353   -0.0000
   860        0.0000             nan     0.3353   -0.0000
   880        0.0000             nan     0.3353   -0.0000
   900        0.0000             nan     0.3353   -0.0000
   920        0.0000             nan     0.3353   -0.0000
   940        0.0000             nan     0.3353   -0.0000
   960        0.0000             nan     0.3353   -0.0000
   980        0.0000             nan     0.3353   -0.0000
  1000        0.0000             nan     0.3353   -0.0000
  1020        0.0000             nan     0.3353   -0.0000
  1040        0.0000             nan     0.3353   -0.0000
  1060        0.0000             nan     0.3353   -0.0000
  1080        0.0000             nan     0.3353   -0.0000
  1100        0.0000             nan     0.3353   -0.0000
  1120        0.0000             nan     0.3353   -0.0000
  1140        0.0000             nan     0.3353   -0.0000
  1160        0.0000             nan     0.3353   -0.0000
  1180        0.0000             nan     0.3353   -0.0000
  1200        0.0000             nan     0.3353   -0.0000
  1220        0.0000             nan     0.3353   -0.0000
  1240        0.0000             nan     0.3353   -0.0000
  1260        0.0000             nan     0.3353   -0.0000
  1280        0.0000             nan     0.3353   -0.0000
  1300        0.0000             nan     0.3353   -0.0000
  1320        0.0000             nan     0.3353   -0.0000
  1340        0.0000             nan     0.3353   -0.0000
  1360        0.0000             nan     0.3353   -0.0000
  1380        0.0000             nan     0.3353   -0.0000
  1400        0.0000             nan     0.3353   -0.0000
  1420        0.0000             nan     0.3353   -0.0000
  1440        0.0000             nan     0.3353   -0.0000
  1460        0.0000             nan     0.3353   -0.0000
  1480        0.0000             nan     0.3353   -0.0000
  1500        0.0000             nan     0.3353   -0.0000
  1520        0.0000             nan     0.3353   -0.0000
  1540        0.0000             nan     0.3353   -0.0000
  1560        0.0000             nan     0.3353   -0.0000
  1580        0.0000             nan     0.3353   -0.0000
  1600        0.0000             nan     0.3353   -0.0000
  1620        0.0000             nan     0.3353   -0.0000
  1640        0.0000             nan     0.3353   -0.0000
  1660        0.0000             nan     0.3353   -0.0000
  1680        0.0000             nan     0.3353   -0.0000
  1700        0.0000             nan     0.3353   -0.0000
  1720        0.0000             nan     0.3353   -0.0000
  1740        0.0000             nan     0.3353   -0.0000
  1760        0.0000             nan     0.3353   -0.0000
  1780        0.0000             nan     0.3353   -0.0000
  1800        0.0000             nan     0.3353   -0.0000
  1820        0.0000             nan     0.3353   -0.0000
  1840        0.0000             nan     0.3353   -0.0000
  1860        0.0000             nan     0.3353   -0.0000
  1880        0.0000             nan     0.3353   -0.0000
  1900        0.0000             nan     0.3353   -0.0000
  1920        0.0000             nan     0.3353   -0.0000
  1940        0.0000             nan     0.3353   -0.0000
  1960        0.0000             nan     0.3353   -0.0000
  1980        0.0000             nan     0.3353   -0.0000
  2000        0.0000             nan     0.3353   -0.0000
  2020        0.0000             nan     0.3353   -0.0000
  2040        0.0000             nan     0.3353   -0.0000
  2060        0.0000             nan     0.3353   -0.0000
  2080        0.0000             nan     0.3353   -0.0000
  2100        0.0000             nan     0.3353   -0.0000
  2120        0.0000             nan     0.3353   -0.0000
  2140        0.0000             nan     0.3353   -0.0000
  2160        0.0000             nan     0.3353   -0.0000
  2180        0.0000             nan     0.3353   -0.0000
  2200        0.0000             nan     0.3353   -0.0000
  2220        0.0000             nan     0.3353   -0.0000
  2240        0.0000             nan     0.3353   -0.0000
  2260        0.0000             nan     0.3353   -0.0000
  2280        0.0000             nan     0.3353   -0.0000
  2300        0.0000             nan     0.3353   -0.0000
  2320        0.0000             nan     0.3353   -0.0000
  2340        0.0000             nan     0.3353   -0.0000
  2360        0.0000             nan     0.3353   -0.0000
  2380        0.0000             nan     0.3353   -0.0000
  2400        0.0000             nan     0.3353   -0.0000
  2420        0.0000             nan     0.3353   -0.0000
  2440        0.0000             nan     0.3353   -0.0000
  2460        0.0000             nan     0.3353   -0.0000
  2480        0.0000             nan     0.3353   -0.0000
  2500        0.0000             nan     0.3353   -0.0000
  2520        0.0000             nan     0.3353   -0.0000
  2540        0.0000             nan     0.3353   -0.0000
  2560        0.0000             nan     0.3353   -0.0000
  2580        0.0000             nan     0.3353   -0.0000
  2600        0.0000             nan     0.3353   -0.0000
  2620        0.0000             nan     0.3353   -0.0000
  2640        0.0000             nan     0.3353   -0.0000
  2660        0.0000             nan     0.3353   -0.0000
  2680        0.0000             nan     0.3353   -0.0000
  2700        0.0000             nan     0.3353   -0.0000
  2720        0.0000             nan     0.3353   -0.0000
  2740        0.0000             nan     0.3353   -0.0000
  2760        0.0000             nan     0.3353   -0.0000
  2780        0.0000             nan     0.3353   -0.0000
  2800        0.0000             nan     0.3353   -0.0000
  2820        0.0000             nan     0.3353   -0.0000
  2840        0.0000             nan     0.3353   -0.0000
  2860        0.0000             nan     0.3353   -0.0000
  2880        0.0000             nan     0.3353   -0.0000
  2900        0.0000             nan     0.3353   -0.0000
  2920        0.0000             nan     0.3353   -0.0000
  2940        0.0000             nan     0.3353   -0.0000
  2960        0.0000             nan     0.3353   -0.0000
  2980        0.0000             nan     0.3353   -0.0000
  3000        0.0000             nan     0.3353   -0.0000
  3020        0.0000             nan     0.3353   -0.0000
  3040        0.0000             nan     0.3353   -0.0000
  3060        0.0000             nan     0.3353   -0.0000
  3080        0.0000             nan     0.3353   -0.0000
  3100        0.0000             nan     0.3353   -0.0000
  3120        0.0000             nan     0.3353   -0.0000
  3140        0.0000             nan     0.3353   -0.0000
  3160        0.0000             nan     0.3353   -0.0000
  3180        0.0000             nan     0.3353   -0.0000
  3200        0.0000             nan     0.3353   -0.0000
  3220        0.0000             nan     0.3353   -0.0000
  3240        0.0000             nan     0.3353   -0.0000
  3260        0.0000             nan     0.3353   -0.0000
  3280        0.0000             nan     0.3353   -0.0000
  3300        0.0000             nan     0.3353   -0.0000
  3320        0.0000             nan     0.3353   -0.0000
  3340        0.0000             nan     0.3353   -0.0000
  3360        0.0000             nan     0.3353   -0.0000
  3380        0.0000             nan     0.3353   -0.0000
  3400        0.0000             nan     0.3353   -0.0000
  3420        0.0000             nan     0.3353   -0.0000
  3440        0.0000             nan     0.3353   -0.0000
  3460        0.0000             nan     0.3353   -0.0000
  3480        0.0000             nan     0.3353   -0.0000
  3500        0.0000             nan     0.3353   -0.0000
  3520        0.0000             nan     0.3353   -0.0000
  3540        0.0000             nan     0.3353   -0.0000
  3560        0.0000             nan     0.3353   -0.0000
  3580        0.0000             nan     0.3353   -0.0000
  3585        0.0000             nan     0.3353   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9612             nan     0.4136   -0.0163
     2        0.9492             nan     0.4136   -0.0248
     3        0.9191             nan     0.4136    0.0077
     4        0.9085             nan     0.4136   -0.0162
     5        0.8961             nan     0.4136   -0.0124
     6        0.8840             nan     0.4136   -0.0272
     7        0.8765             nan     0.4136   -0.0298
     8        0.8783             nan     0.4136   -0.0453
     9        0.8633             nan     0.4136   -0.0090
    10        0.8512             nan     0.4136   -0.0174
    20        0.7461             nan     0.4136   -0.0233
    40        0.6027             nan     0.4136   -0.0319
    60        0.5058             nan     0.4136   -0.0179
    80        0.4155             nan     0.4136   -0.0175
   100        0.3566             nan     0.4136   -0.0158
   120        0.3007             nan     0.4136   -0.0094
   140        0.2553             nan     0.4136   -0.0079
   160        0.2190             nan     0.4136   -0.0097
   180        0.1887             nan     0.4136   -0.0062
   200        0.1643             nan     0.4136   -0.0038
   220        0.1402             nan     0.4136   -0.0063
   240        0.1202             nan     0.4136   -0.0044
   260        0.1032             nan     0.4136   -0.0024
   280        0.0879             nan     0.4136   -0.0041
   300        0.0732             nan     0.4136   -0.0018
   320        0.0644             nan     0.4136   -0.0025
   340        0.0582             nan     0.4136   -0.0030
   360        0.0493             nan     0.4136   -0.0026
   380        0.0422             nan     0.4136   -0.0007
   400        0.0370             nan     0.4136   -0.0013
   420        0.0330             nan     0.4136   -0.0014
   440        0.0301             nan     0.4136   -0.0018
   460        0.0259             nan     0.4136   -0.0009
   480        0.0219             nan     0.4136   -0.0006
   500        0.0195             nan     0.4136   -0.0005
   520        0.0169             nan     0.4136   -0.0002
   540        0.0151             nan     0.4136   -0.0006
   560        0.0132             nan     0.4136   -0.0006
   580        0.0115             nan     0.4136   -0.0001
   600        0.0103             nan     0.4136   -0.0002
   620        0.0091             nan     0.4136   -0.0003
   640        0.0082             nan     0.4136   -0.0002
   660        0.0074             nan     0.4136   -0.0002
   680        0.0065             nan     0.4136   -0.0003
   700        0.0057             nan     0.4136   -0.0002
   720        0.0050             nan     0.4136   -0.0002
   740        0.0045             nan     0.4136   -0.0002
   760        0.0040             nan     0.4136   -0.0000
   780        0.0035             nan     0.4136   -0.0001
   800        0.0032             nan     0.4136   -0.0001
   820        0.0028             nan     0.4136   -0.0001
   840        0.0025             nan     0.4136   -0.0001
   860        0.0022             nan     0.4136   -0.0001
   880        0.0020             nan     0.4136   -0.0001
   900        0.0018             nan     0.4136   -0.0001
   920        0.0016             nan     0.4136   -0.0001
   940        0.0014             nan     0.4136   -0.0000
   960        0.0013             nan     0.4136   -0.0001
   980        0.0011             nan     0.4136   -0.0000
  1000        0.0009             nan     0.4136   -0.0000
  1020        0.0009             nan     0.4136   -0.0000
  1024        0.0008             nan     0.4136   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9503             nan     0.4240   -0.0121
     2        0.9336             nan     0.4240   -0.0428
     3        0.9336             nan     0.4240   -0.0791
     4        0.8933             nan     0.4240   -0.0216
     5        0.8662             nan     0.4240   -0.0309
     6        0.8388             nan     0.4240   -0.0303
     7        0.8256             nan     0.4240   -0.0243
     8        0.8102             nan     0.4240   -0.0292
     9        0.7896             nan     0.4240   -0.0436
    10        0.7913             nan     0.4240   -0.0668
    20        0.6537             nan     0.4240   -0.0237
    40        0.4157             nan     0.4240   -0.0296
    60        0.2841             nan     0.4240   -0.0198
    80        0.2040             nan     0.4240   -0.0074
   100        0.1508             nan     0.4240   -0.0086
   120        0.1127             nan     0.4240   -0.0050
   140        0.0798             nan     0.4240   -0.0037
   160        0.0620             nan     0.4240   -0.0033
   180        0.0493             nan     0.4240   -0.0010
   200        0.0380             nan     0.4240   -0.0019
   220        0.0273             nan     0.4240   -0.0007
   240        0.0215             nan     0.4240   -0.0009
   260        0.0163             nan     0.4240   -0.0012
   280        0.0121             nan     0.4240   -0.0011
   300        0.0090             nan     0.4240   -0.0002
   320        0.0071             nan     0.4240   -0.0004
   340        0.0055             nan     0.4240   -0.0003
   360        0.0046             nan     0.4240   -0.0003
   380        0.0034             nan     0.4240   -0.0001
   400        0.0027             nan     0.4240   -0.0002
   420        0.0021             nan     0.4240   -0.0001
   440        0.0017             nan     0.4240   -0.0001
   460        0.0013             nan     0.4240   -0.0001
   480        0.0010             nan     0.4240   -0.0000
   500        0.0008             nan     0.4240   -0.0000
   520        0.0006             nan     0.4240   -0.0000
   540        0.0004             nan     0.4240   -0.0000
   560        0.0003             nan     0.4240   -0.0000
   580        0.0002             nan     0.4240   -0.0000
   600        0.0002             nan     0.4240   -0.0000
   620        0.0001             nan     0.4240   -0.0000
   640        0.0001             nan     0.4240   -0.0000
   660        0.0001             nan     0.4240   -0.0000
   680        0.0001             nan     0.4240   -0.0000
   700        0.0000             nan     0.4240   -0.0000
   720        0.0000             nan     0.4240   -0.0000
   740        0.0000             nan     0.4240   -0.0000
   760        0.0000             nan     0.4240   -0.0000
   780        0.0000             nan     0.4240   -0.0000
   800        0.0000             nan     0.4240   -0.0000
   820        0.0000             nan     0.4240   -0.0000
   840        0.0000             nan     0.4240   -0.0000
   860        0.0000             nan     0.4240   -0.0000
   880        0.0000             nan     0.4240   -0.0000
   900        0.0000             nan     0.4240   -0.0000
   920        0.0000             nan     0.4240   -0.0000
   940        0.0000             nan     0.4240   -0.0000
   960        0.0000             nan     0.4240   -0.0000
   980        0.0000             nan     0.4240   -0.0000
  1000        0.0000             nan     0.4240   -0.0000
  1020        0.0000             nan     0.4240   -0.0000
  1040        0.0000             nan     0.4240   -0.0000
  1060        0.0000             nan     0.4240   -0.0000
  1080        0.0000             nan     0.4240   -0.0000
  1100        0.0000             nan     0.4240   -0.0000
  1120        0.0000             nan     0.4240   -0.0000
  1140        0.0000             nan     0.4240   -0.0000
  1160        0.0000             nan     0.4240   -0.0000
  1180        0.0000             nan     0.4240   -0.0000
  1200        0.0000             nan     0.4240   -0.0000
  1220        0.0000             nan     0.4240   -0.0000
  1240        0.0000             nan     0.4240   -0.0000
  1260        0.0000             nan     0.4240   -0.0000
  1280        0.0000             nan     0.4240   -0.0000
  1300        0.0000             nan     0.4240   -0.0000
  1320        0.0000             nan     0.4240   -0.0000
  1340        0.0000             nan     0.4240   -0.0000
  1360        0.0000             nan     0.4240   -0.0000
  1380        0.0000             nan     0.4240   -0.0000
  1400        0.0000             nan     0.4240   -0.0000
  1420        0.0000             nan     0.4240   -0.0000
  1440        0.0000             nan     0.4240   -0.0000
  1460        0.0000             nan     0.4240   -0.0000
  1480        0.0000             nan     0.4240   -0.0000
  1500        0.0000             nan     0.4240   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9636             nan     0.4738   -0.0492
     2        0.9497             nan     0.4738   -0.0463
     3        0.9376             nan     0.4738   -0.0516
     4        0.9202             nan     0.4738   -0.0608
     5        0.8978             nan     0.4738   -0.0462
     6        0.8878             nan     0.4738   -0.0497
     7        0.8641             nan     0.4738   -0.0259
     8        0.8485             nan     0.4738   -0.0266
     9        0.8345             nan     0.4738   -0.0502
    10        0.8236             nan     0.4738   -0.0423
    20        0.6681             nan     0.4738   -0.0591
    40        0.4312             nan     0.4738   -0.0222
    60        0.3255             nan     0.4738   -0.0290
    80        0.2350             nan     0.4738   -0.0132
   100        0.1726             nan     0.4738   -0.0105
   120        0.1310             nan     0.4738   -0.0107
   140        0.0959             nan     0.4738   -0.0018
   160        0.0727             nan     0.4738   -0.0039
   180        0.0492             nan     0.4738   -0.0022
   200        0.0369             nan     0.4738   -0.0017
   220        0.0285             nan     0.4738   -0.0018
   240        0.0215             nan     0.4738   -0.0011
   260        0.0165             nan     0.4738   -0.0013
   280        0.0120             nan     0.4738   -0.0000
   300        0.0099             nan     0.4738   -0.0008
   320        0.0074             nan     0.4738   -0.0007
   340        0.0057             nan     0.4738   -0.0002
   360        0.0042             nan     0.4738   -0.0002
   380        0.0033             nan     0.4738   -0.0004
   400        0.0027             nan     0.4738   -0.0003
   420        0.0020             nan     0.4738   -0.0001
   440        0.0015             nan     0.4738   -0.0001
   460        0.0012             nan     0.4738   -0.0001
   480        0.0010             nan     0.4738   -0.0001
   500        0.0007             nan     0.4738   -0.0001
   520        0.0006             nan     0.4738   -0.0000
   540        0.0004             nan     0.4738   -0.0000
   560        0.0003             nan     0.4738   -0.0000
   580        0.0003             nan     0.4738   -0.0000
   600        0.0002             nan     0.4738   -0.0000
   620        0.0001             nan     0.4738   -0.0000
   640        0.0001             nan     0.4738   -0.0000
   660        0.0001             nan     0.4738    0.0000
   680        0.0001             nan     0.4738   -0.0000
   700        0.0001             nan     0.4738   -0.0000
   720        0.0000             nan     0.4738   -0.0000
   740        0.0000             nan     0.4738   -0.0000
   760        0.0000             nan     0.4738   -0.0000
   780        0.0000             nan     0.4738   -0.0000
   800        0.0000             nan     0.4738   -0.0000
   820        0.0000             nan     0.4738   -0.0000
   840        0.0000             nan     0.4738   -0.0000
   860        0.0000             nan     0.4738   -0.0000
   880        0.0000             nan     0.4738   -0.0000
   900        0.0000             nan     0.4738   -0.0000
   920        0.0000             nan     0.4738   -0.0000
   940        0.0000             nan     0.4738   -0.0000
   960        0.0000             nan     0.4738   -0.0000
   980        0.0000             nan     0.4738   -0.0000
  1000        0.0000             nan     0.4738   -0.0000
  1020        0.0000             nan     0.4738   -0.0000
  1040        0.0000             nan     0.4738   -0.0000
  1060        0.0000             nan     0.4738   -0.0000
  1080        0.0000             nan     0.4738   -0.0000
  1100        0.0000             nan     0.4738   -0.0000
  1120        0.0000             nan     0.4738   -0.0000
  1140        0.0000             nan     0.4738   -0.0000
  1160        0.0000             nan     0.4738   -0.0000
  1180        0.0000             nan     0.4738   -0.0000
  1200        0.0000             nan     0.4738   -0.0000
  1220        0.0000             nan     0.4738   -0.0000
  1240        0.0000             nan     0.4738   -0.0000
  1260        0.0000             nan     0.4738   -0.0000
  1280        0.0000             nan     0.4738   -0.0000
  1300        0.0000             nan     0.4738   -0.0000
  1320        0.0000             nan     0.4738   -0.0000
  1340        0.0000             nan     0.4738   -0.0000
  1360        0.0000             nan     0.4738   -0.0000
  1380        0.0000             nan     0.4738   -0.0000
  1400        0.0000             nan     0.4738   -0.0000
  1420        0.0000             nan     0.4738   -0.0000
  1440        0.0000             nan     0.4738   -0.0000
  1460        0.0000             nan     0.4738   -0.0000
  1480        0.0000             nan     0.4738   -0.0000
  1500        0.0000             nan     0.4738   -0.0000
  1520        0.0000             nan     0.4738   -0.0000
  1540        0.0000             nan     0.4738   -0.0000
  1560        0.0000             nan     0.4738   -0.0000
  1580        0.0000             nan     0.4738   -0.0000
  1600        0.0000             nan     0.4738   -0.0000
  1620        0.0000             nan     0.4738   -0.0000
  1640        0.0000             nan     0.4738   -0.0000
  1660        0.0000             nan     0.4738   -0.0000
  1680        0.0000             nan     0.4738   -0.0000
  1700        0.0000             nan     0.4738   -0.0000
  1720        0.0000             nan     0.4738   -0.0000
  1740        0.0000             nan     0.4738   -0.0000
  1760        0.0000             nan     0.4738   -0.0000
  1780        0.0000             nan     0.4738   -0.0000
  1800        0.0000             nan     0.4738   -0.0000
  1820        0.0000             nan     0.4738   -0.0000
  1840        0.0000             nan     0.4738   -0.0000
  1860        0.0000             nan     0.4738   -0.0000
  1880        0.0000             nan     0.4738   -0.0000
  1900        0.0000             nan     0.4738   -0.0000
  1920        0.0000             nan     0.4738   -0.0000
  1940        0.0000             nan     0.4738   -0.0000
  1960        0.0000             nan     0.4738   -0.0000
  1980        0.0000             nan     0.4738   -0.0000
  2000        0.0000             nan     0.4738   -0.0000
  2020        0.0000             nan     0.4738   -0.0000
  2040        0.0000             nan     0.4738   -0.0000
  2060        0.0000             nan     0.4738   -0.0000
  2080        0.0000             nan     0.4738   -0.0000
  2100        0.0000             nan     0.4738   -0.0000
  2120        0.0000             nan     0.4738   -0.0000
  2140        0.0000             nan     0.4738   -0.0000
  2160        0.0000             nan     0.4738   -0.0000
  2180        0.0000             nan     0.4738   -0.0000
  2200        0.0000             nan     0.4738   -0.0000
  2220        0.0000             nan     0.4738   -0.0000
  2240        0.0000             nan     0.4738   -0.0000
  2260        0.0000             nan     0.4738   -0.0000
  2280        0.0000             nan     0.4738   -0.0000
  2300        0.0000             nan     0.4738   -0.0000
  2320        0.0000             nan     0.4738   -0.0000
  2340        0.0000             nan     0.4738   -0.0000
  2360        0.0000             nan     0.4738   -0.0000
  2380        0.0000             nan     0.4738   -0.0000
  2400        0.0000             nan     0.4738   -0.0000
  2420        0.0000             nan     0.4738   -0.0000
  2440        0.0000             nan     0.4738   -0.0000
  2460        0.0000             nan     0.4738   -0.0000
  2480        0.0000             nan     0.4738   -0.0000
  2500        0.0000             nan     0.4738   -0.0000
  2520        0.0000             nan     0.4738   -0.0000
  2540        0.0000             nan     0.4738   -0.0000
  2560        0.0000             nan     0.4738   -0.0000
  2580        0.0000             nan     0.4738   -0.0000
  2600        0.0000             nan     0.4738   -0.0000
  2620        0.0000             nan     0.4738   -0.0000
  2640        0.0000             nan     0.4738   -0.0000
  2660        0.0000             nan     0.4738   -0.0000
  2680        0.0000             nan     0.4738   -0.0000
  2700        0.0000             nan     0.4738   -0.0000
  2720        0.0000             nan     0.4738   -0.0000
  2740        0.0000             nan     0.4738   -0.0000
  2760        0.0000             nan     0.4738   -0.0000
  2780        0.0000             nan     0.4738   -0.0000
  2800        0.0000             nan     0.4738   -0.0000
  2820        0.0000             nan     0.4738   -0.0000
  2840        0.0000             nan     0.4738   -0.0000
  2860        0.0000             nan     0.4738   -0.0000
  2880        0.0000             nan     0.4738   -0.0000
  2900        0.0000             nan     0.4738   -0.0000
  2920        0.0000             nan     0.4738   -0.0000
  2940        0.0000             nan     0.4738   -0.0000
  2960        0.0000             nan     0.4738   -0.0000
  2980        0.0000             nan     0.4738   -0.0000
  3000        0.0000             nan     0.4738   -0.0000
  3020        0.0000             nan     0.4738   -0.0000
  3040        0.0000             nan     0.4738   -0.0000
  3060        0.0000             nan     0.4738   -0.0000
  3080        0.0000             nan     0.4738   -0.0000
  3100        0.0000             nan     0.4738   -0.0000
  3120        0.0000             nan     0.4738   -0.0000
  3140        0.0000             nan     0.4738   -0.0000
  3160        0.0000             nan     0.4738   -0.0000
  3180        0.0000             nan     0.4738   -0.0000
  3200        0.0000             nan     0.4738   -0.0000
  3220        0.0000             nan     0.4738   -0.0000
  3240        0.0000             nan     0.4738   -0.0000
  3260        0.0000             nan     0.4738   -0.0000
  3280        0.0000             nan     0.4738   -0.0000
  3300        0.0000             nan     0.4738   -0.0000
  3320        0.0000             nan     0.4738   -0.0000
  3340        0.0000             nan     0.4738   -0.0000
  3360        0.0000             nan     0.4738   -0.0000
  3380        0.0000             nan     0.4738   -0.0000
  3400        0.0000             nan     0.4738   -0.0000
  3420        0.0000             nan     0.4738   -0.0000
  3440        0.0000             nan     0.4738   -0.0000
  3460        0.0000             nan     0.4738   -0.0000
  3480        0.0000             nan     0.4738   -0.0000
  3500        0.0000             nan     0.4738   -0.0000
  3520        0.0000             nan     0.4738   -0.0000
  3540        0.0000             nan     0.4738   -0.0000
  3560        0.0000             nan     0.4738   -0.0000
  3580        0.0000             nan     0.4738   -0.0000
  3600        0.0000             nan     0.4738   -0.0000
  3620        0.0000             nan     0.4738   -0.0000
  3640        0.0000             nan     0.4738   -0.0000
  3660        0.0000             nan     0.4738   -0.0000
  3680        0.0000             nan     0.4738   -0.0000
  3700        0.0000             nan     0.4738   -0.0000
  3720        0.0000             nan     0.4738   -0.0000
  3740        0.0000             nan     0.4738   -0.0000
  3760        0.0000             nan     0.4738   -0.0000
  3780        0.0000             nan     0.4738   -0.0000
  3800        0.0000             nan     0.4738   -0.0000
  3820        0.0000             nan     0.4738   -0.0000
  3840        0.0000             nan     0.4738   -0.0000
  3860        0.0000             nan     0.4738   -0.0000
  3880        0.0000             nan     0.4738   -0.0000
  3900        0.0000             nan     0.4738   -0.0000
  3920        0.0000             nan     0.4738   -0.0000
  3940        0.0000             nan     0.4738   -0.0000
  3960        0.0000             nan     0.4738   -0.0000
  3980        0.0000             nan     0.4738   -0.0000
  4000        0.0000             nan     0.4738   -0.0000
  4020        0.0000             nan     0.4738   -0.0000
  4040        0.0000             nan     0.4738   -0.0000
  4060        0.0000             nan     0.4738   -0.0000
  4080        0.0000             nan     0.4738   -0.0000
  4100        0.0000             nan     0.4738   -0.0000
  4120        0.0000             nan     0.4738   -0.0000
  4129        0.0000             nan     0.4738   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9524             nan     0.5391   -0.1233
     2        0.9012             nan     0.5391   -0.0583
     3        0.8761             nan     0.5391   -0.0835
     4        0.8608             nan     0.5391   -0.1028
     5        0.8109             nan     0.5391   -0.0513
     6        0.7562             nan     0.5391   -0.0405
     7        0.7337             nan     0.5391   -0.0703
     8        0.7070             nan     0.5391   -0.0527
     9        0.6789             nan     0.5391   -0.0574
    10        0.6496             nan     0.5391   -0.0422
    20        0.4356             nan     0.5391   -0.0276
    40        0.2059             nan     0.5391   -0.0056
    60        0.1071             nan     0.5391   -0.0100
    80        0.0474             nan     0.5391   -0.0060
   100        0.0264             nan     0.5391   -0.0023
   120        0.0141             nan     0.5391   -0.0011
   140        0.0074             nan     0.5391   -0.0011
   160        0.0034             nan     0.5391   -0.0004
   180        0.0016             nan     0.5391   -0.0001
   200        0.0009             nan     0.5391   -0.0001
   220        0.0004             nan     0.5391   -0.0000
   240        0.0002             nan     0.5391   -0.0000
   260        0.0001             nan     0.5391   -0.0000
   280        0.0001             nan     0.5391   -0.0000
   300        0.0000             nan     0.5391   -0.0000
   320        0.0000             nan     0.5391   -0.0000
   340        0.0000             nan     0.5391   -0.0000
   360        0.0000             nan     0.5391   -0.0000
   380        0.0000             nan     0.5391   -0.0000
   400        0.0000             nan     0.5391   -0.0000
   420        0.0000             nan     0.5391   -0.0000
   440        0.0000             nan     0.5391   -0.0000
   460        0.0000             nan     0.5391   -0.0000
   480        0.0000             nan     0.5391   -0.0000
   500        0.0000             nan     0.5391   -0.0000
   520        0.0000             nan     0.5391   -0.0000
   540        0.0000             nan     0.5391   -0.0000
   560        0.0000             nan     0.5391   -0.0000
   580        0.0000             nan     0.5391   -0.0000
   600        0.0000             nan     0.5391   -0.0000
   620        0.0000             nan     0.5391   -0.0000
   640        0.0000             nan     0.5391   -0.0000
   660        0.0000             nan     0.5391   -0.0000
   680        0.0000             nan     0.5391   -0.0000
   700        0.0000             nan     0.5391   -0.0000
   720        0.0000             nan     0.5391   -0.0000
   740        0.0000             nan     0.5391   -0.0000
   760        0.0000             nan     0.5391   -0.0000
   780        0.0000             nan     0.5391   -0.0000
   800        0.0000             nan     0.5391   -0.0000
   820        0.0000             nan     0.5391   -0.0000
   840        0.0000             nan     0.5391   -0.0000
   860        0.0000             nan     0.5391   -0.0000
   880        0.0000             nan     0.5391   -0.0000
   900        0.0000             nan     0.5391   -0.0000
   920        0.0000             nan     0.5391   -0.0000
   940        0.0000             nan     0.5391   -0.0000
   960        0.0000             nan     0.5391   -0.0000
   980        0.0000             nan     0.5391   -0.0000
  1000        0.0000             nan     0.5391   -0.0000
  1020        0.0000             nan     0.5391   -0.0000
  1040        0.0000             nan     0.5391   -0.0000
  1060        0.0000             nan     0.5391   -0.0000
  1080        0.0000             nan     0.5391   -0.0000
  1100        0.0000             nan     0.5391   -0.0000
  1120        0.0000             nan     0.5391   -0.0000
  1140        0.0000             nan     0.5391   -0.0000
  1160        0.0000             nan     0.5391   -0.0000
  1180        0.0000             nan     0.5391   -0.0000
  1200        0.0000             nan     0.5391   -0.0000
  1220        0.0000             nan     0.5391   -0.0000
  1240        0.0000             nan     0.5391   -0.0000
  1260        0.0000             nan     0.5391   -0.0000
  1280        0.0000             nan     0.5391   -0.0000
  1300        0.0000             nan     0.5391   -0.0000
  1320        0.0000             nan     0.5391   -0.0000
  1340        0.0000             nan     0.5391   -0.0000
  1360        0.0000             nan     0.5391   -0.0000
  1380        0.0000             nan     0.5391   -0.0000
  1400        0.0000             nan     0.5391   -0.0000
  1420        0.0000             nan     0.5391   -0.0000
  1440        0.0000             nan     0.5391   -0.0000
  1460        0.0000             nan     0.5391   -0.0000
  1480        0.0000             nan     0.5391   -0.0000
  1500        0.0000             nan     0.5391   -0.0000
  1520        0.0000             nan     0.5391   -0.0000
  1540        0.0000             nan     0.5391   -0.0000
  1560        0.0000             nan     0.5391   -0.0000
  1580        0.0000             nan     0.5391   -0.0000
  1600        0.0000             nan     0.5391   -0.0000
  1620        0.0000             nan     0.5391   -0.0000
  1640        0.0000             nan     0.5391   -0.0000
  1660        0.0000             nan     0.5391   -0.0000
  1680        0.0000             nan     0.5391   -0.0000
  1700        0.0000             nan     0.5391   -0.0000
  1720        0.0000             nan     0.5391   -0.0000
  1740        0.0000             nan     0.5391   -0.0000
  1760        0.0000             nan     0.5391   -0.0000
  1780        0.0000             nan     0.5391   -0.0000
  1784        0.0000             nan     0.5391   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9601             nan     0.5600   -0.0291
     2        0.9435             nan     0.5600   -0.0282
     3        0.9290             nan     0.5600   -0.0332
     4        0.9162             nan     0.5600   -0.0385
     5        0.9120             nan     0.5600   -0.0431
     6        0.9033             nan     0.5600   -0.0427
     7        0.8992             nan     0.5600   -0.0596
     8        0.8845             nan     0.5600   -0.0341
     9        0.8641             nan     0.5600   -0.0448
    10        0.8588             nan     0.5600   -0.0515
    20        0.7204             nan     0.5600   -0.0510
    40        0.5558             nan     0.5600   -0.0382
    60        0.4465             nan     0.5600   -0.0276
    80        0.3801             nan     0.5600   -0.0039
   100        0.3255             nan     0.5600   -0.0069
   120        0.2591             nan     0.5600   -0.0158
   140        0.2178             nan     0.5600   -0.0159
   160        0.1736             nan     0.5600   -0.0068
   180        0.1396             nan     0.5600   -0.0071
   200        0.1162             nan     0.5600   -0.0045
   220        0.1025             nan     0.5600   -0.0051
   240        0.0855             nan     0.5600   -0.0037
   260        0.0674             nan     0.5600   -0.0021
   280        0.0552             nan     0.5600   -0.0020
   300        0.0452             nan     0.5600   -0.0024
   320        0.0378             nan     0.5600   -0.0012
   340        0.0305             nan     0.5600   -0.0033
   360        0.0240             nan     0.5600   -0.0014
   380        0.0199             nan     0.5600   -0.0010
   400        0.0174             nan     0.5600   -0.0004
   420        0.0143             nan     0.5600   -0.0005
   440        0.0119             nan     0.5600   -0.0007
   460        0.0102             nan     0.5600   -0.0004
   480        0.0079             nan     0.5600   -0.0002
   500        0.0068             nan     0.5600   -0.0003
   520        0.0057             nan     0.5600   -0.0003
   540        0.0048             nan     0.5600   -0.0001
   560        0.0038             nan     0.5600   -0.0001
   580        0.0031             nan     0.5600   -0.0001
   600        0.0027             nan     0.5600   -0.0003
   620        0.0022             nan     0.5600   -0.0001
   640        0.0018             nan     0.5600   -0.0001
   660        0.0015             nan     0.5600   -0.0001
   680        0.0012             nan     0.5600   -0.0001
   700        0.0010             nan     0.5600   -0.0001
   720        0.0008             nan     0.5600   -0.0000
   740        0.0007             nan     0.5600   -0.0000
   760        0.0006             nan     0.5600   -0.0000
   780        0.0005             nan     0.5600   -0.0000
   800        0.0004             nan     0.5600   -0.0000
   820        0.0003             nan     0.5600   -0.0000
   840        0.0003             nan     0.5600   -0.0000
   860        0.0003             nan     0.5600   -0.0000
   880        0.0002             nan     0.5600   -0.0000
   900        0.0002             nan     0.5600   -0.0000
   920        0.0002             nan     0.5600   -0.0000
   940        0.0001             nan     0.5600   -0.0000
   960        0.0001             nan     0.5600   -0.0000
   980        0.0001             nan     0.5600   -0.0000
  1000        0.0001             nan     0.5600   -0.0000
  1020        0.0001             nan     0.5600   -0.0000
  1040        0.0001             nan     0.5600   -0.0000
  1060        0.0001             nan     0.5600   -0.0000
  1080        0.0000             nan     0.5600   -0.0000
  1100        0.0000             nan     0.5600   -0.0000
  1120        0.0000             nan     0.5600   -0.0000
  1140        0.0000             nan     0.5600   -0.0000
  1160        0.0000             nan     0.5600   -0.0000
  1180        0.0000             nan     0.5600   -0.0000
  1200        0.0000             nan     0.5600   -0.0000
  1220        0.0000             nan     0.5600   -0.0000
  1240        0.0000             nan     0.5600   -0.0000
  1260        0.0000             nan     0.5600   -0.0000
  1280        0.0000             nan     0.5600   -0.0000
  1300        0.0000             nan     0.5600   -0.0000
  1320        0.0000             nan     0.5600   -0.0000
  1340        0.0000             nan     0.5600   -0.0000
  1360        0.0000             nan     0.5600   -0.0000
  1380        0.0000             nan     0.5600   -0.0000
  1400        0.0000             nan     0.5600   -0.0000
  1420        0.0000             nan     0.5600   -0.0000
  1440        0.0000             nan     0.5600   -0.0000
  1460        0.0000             nan     0.5600   -0.0000
  1480        0.0000             nan     0.5600   -0.0000
  1500        0.0000             nan     0.5600   -0.0000
  1520        0.0000             nan     0.5600   -0.0000
  1540        0.0000             nan     0.5600   -0.0000
  1560        0.0000             nan     0.5600   -0.0000
  1580        0.0000             nan     0.5600   -0.0000
  1600        0.0000             nan     0.5600   -0.0000
  1620        0.0000             nan     0.5600   -0.0000
  1640        0.0000             nan     0.5600   -0.0000
  1660        0.0000             nan     0.5600   -0.0000
  1680        0.0000             nan     0.5600   -0.0000
  1700        0.0000             nan     0.5600   -0.0000
  1720        0.0000             nan     0.5600   -0.0000
  1740        0.0000             nan     0.5600   -0.0000
  1760        0.0000             nan     0.5600   -0.0000
  1780        0.0000             nan     0.5600   -0.0000
  1800        0.0000             nan     0.5600   -0.0000
  1820        0.0000             nan     0.5600   -0.0000
  1840        0.0000             nan     0.5600   -0.0000
  1860        0.0000             nan     0.5600   -0.0000
  1880        0.0000             nan     0.5600   -0.0000
  1900        0.0000             nan     0.5600   -0.0000
  1920        0.0000             nan     0.5600   -0.0000
  1940        0.0000             nan     0.5600   -0.0000
  1960        0.0000             nan     0.5600   -0.0000
  1980        0.0000             nan     0.5600   -0.0000
  2000        0.0000             nan     0.5600   -0.0000
  2020        0.0000             nan     0.5600   -0.0000
  2040        0.0000             nan     0.5600   -0.0000
  2060        0.0000             nan     0.5600   -0.0000
  2080        0.0000             nan     0.5600   -0.0000
  2100        0.0000             nan     0.5600   -0.0000
  2120        0.0000             nan     0.5600   -0.0000
  2140        0.0000             nan     0.5600   -0.0000
  2160        0.0000             nan     0.5600   -0.0000
  2180        0.0000             nan     0.5600   -0.0000
  2200        0.0000             nan     0.5600   -0.0000
  2220        0.0000             nan     0.5600   -0.0000
  2240        0.0000             nan     0.5600   -0.0000
  2260        0.0000             nan     0.5600   -0.0000
  2280        0.0000             nan     0.5600   -0.0000
  2300        0.0000             nan     0.5600   -0.0000
  2320        0.0000             nan     0.5600   -0.0000
  2340        0.0000             nan     0.5600   -0.0000
  2360        0.0000             nan     0.5600   -0.0000
  2380        0.0000             nan     0.5600   -0.0000
  2400        0.0000             nan     0.5600   -0.0000
  2420        0.0000             nan     0.5600   -0.0000
  2440        0.0000             nan     0.5600   -0.0000
  2460        0.0000             nan     0.5600   -0.0000
  2480        0.0000             nan     0.5600   -0.0000
  2500        0.0000             nan     0.5600   -0.0000
  2510        0.0000             nan     0.5600   -0.0000

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9696             nan     0.5758   -0.0149
     2        0.9583             nan     0.5758   -0.0165
     3        0.9475             nan     0.5758   -0.0014
     4        0.9425             nan     0.5758   -0.0167
     5        0.9407             nan     0.5758   -0.0152
     6        0.9408             nan     0.5758   -0.0283
     7        0.9341             nan     0.5758   -0.0035
     8        0.9378             nan     0.5758   -0.0356
     9        0.9324             nan     0.5758   -0.0272
    10        0.9277             nan     0.5758   -0.0059
    20        0.9052             nan     0.5758   -0.0121
    40        0.8489             nan     0.5758   -0.0177
    60        0.7880             nan     0.5758   -0.0090
    80        0.7549             nan     0.5758   -0.0272
   100        0.7109             nan     0.5758   -0.0070
   120        0.6742             nan     0.5758   -0.0101
   140        0.6409             nan     0.5758   -0.0072
   160        0.6357             nan     0.5758   -0.0115
   180        0.5913             nan     0.5758   -0.0085
   200        0.5813             nan     0.5758   -0.0063
   220        0.5671             nan     0.5758   -0.0139
   240        0.5435             nan     0.5758   -0.0040
   260        0.5360             nan     0.5758   -0.0138
   280        0.5148             nan     0.5758   -0.0216
   300        0.5010             nan     0.5758   -0.0083
   320        0.4793             nan     0.5758   -0.0053
   340        0.4751             nan     0.5758   -0.0065
   360        0.4595             nan     0.5758   -0.0202
   380        0.4358             nan     0.5758   -0.0060
   400        0.4302             nan     0.5758   -0.0127
   420        0.4094             nan     0.5758   -0.0106
   440        0.3957             nan     0.5758   -0.0072
   460        0.3821             nan     0.5758   -0.0095
   480        0.3746             nan     0.5758   -0.0085
   500        0.3628             nan     0.5758   -0.0012
   520        0.3547             nan     0.5758   -0.0067
   540        0.3438             nan     0.5758   -0.0036
   560        0.3424             nan     0.5758   -0.0059
   580        0.3326             nan     0.5758   -0.0036
   600        0.3272             nan     0.5758   -0.0069
   620        0.3112             nan     0.5758   -0.0020
   640        0.3039             nan     0.5758   -0.0033
   660        0.2987             nan     0.5758   -0.0028
   680        0.2899             nan     0.5758   -0.0058
   700        0.2819             nan     0.5758   -0.0083
   720        0.2698             nan     0.5758   -0.0013
   740        0.2664             nan     0.5758   -0.0109
   760        0.2561             nan     0.5758   -0.0029
   780        0.2498             nan     0.5758   -0.0066
   800        0.2427             nan     0.5758   -0.0016
   820        0.2386             nan     0.5758   -0.0077
   840        0.2294             nan     0.5758   -0.0053
   860        0.2303             nan     0.5758   -0.0060
   880        0.2192             nan     0.5758   -0.0020
   900        0.2146             nan     0.5758   -0.0047
   920        0.2106             nan     0.5758   -0.0023
   940        0.2048             nan     0.5758   -0.0033
   960        0.2015             nan     0.5758   -0.0029
   980        0.1982             nan     0.5758   -0.0033
  1000        0.1929             nan     0.5758   -0.0044
  1020        0.1891             nan     0.5758   -0.0047
  1040        0.1843             nan     0.5758   -0.0070
  1060        0.1791             nan     0.5758   -0.0005
  1080        0.1737             nan     0.5758   -0.0067
  1100        0.1665             nan     0.5758   -0.0039
  1120        0.1664             nan     0.5758   -0.0028
  1140        0.1620             nan     0.5758   -0.0010
  1160        0.1578             nan     0.5758   -0.0037
  1180        0.1544             nan     0.5758   -0.0006
  1200        0.1520             nan     0.5758   -0.0031
  1220        0.1506             nan     0.5758   -0.0030
  1240        0.1466             nan     0.5758   -0.0012
  1260        0.1422             nan     0.5758   -0.0004
  1280        0.1392             nan     0.5758   -0.0052
  1300        0.1342             nan     0.5758   -0.0018
  1320        0.1327             nan     0.5758   -0.0037
  1340        0.1325             nan     0.5758   -0.0042
  1360        0.1258             nan     0.5758   -0.0016
  1380        0.1259             nan     0.5758   -0.0012
  1400        0.1212             nan     0.5758   -0.0003
  1420        0.1183             nan     0.5758   -0.0043
  1440        0.1148             nan     0.5758   -0.0024
  1460        0.1140             nan     0.5758   -0.0028
  1480        0.1115             nan     0.5758   -0.0043
  1500        0.1086             nan     0.5758   -0.0012
  1520        0.1056             nan     0.5758   -0.0007
  1540        0.1045             nan     0.5758   -0.0026
  1560        0.1037             nan     0.5758   -0.0052
  1580        0.1022             nan     0.5758   -0.0017
  1600        0.0981             nan     0.5758   -0.0023
  1620        0.0973             nan     0.5758   -0.0042
  1640        0.0949             nan     0.5758   -0.0014
  1660        0.0911             nan     0.5758   -0.0024
  1680        0.0898             nan     0.5758   -0.0025
  1700        0.0872             nan     0.5758   -0.0022
  1720        0.0859             nan     0.5758   -0.0018
  1740        0.0829             nan     0.5758   -0.0002
  1760        0.0818             nan     0.5758   -0.0023
  1780        0.0798             nan     0.5758   -0.0026
  1800        0.0788             nan     0.5758   -0.0029
  1820        0.0776             nan     0.5758   -0.0018
  1840        0.0743             nan     0.5758   -0.0017
  1860        0.0722             nan     0.5758   -0.0019
  1880        0.0699             nan     0.5758   -0.0013
  1900        0.0683             nan     0.5758   -0.0008
  1920        0.0685             nan     0.5758   -0.0030
  1940        0.0665             nan     0.5758   -0.0022
  1960        0.0644             nan     0.5758   -0.0006
  1980        0.0620             nan     0.5758   -0.0014
  2000        0.0616             nan     0.5758   -0.0020
  2020        0.0611             nan     0.5758   -0.0024
  2040        0.0596             nan     0.5758   -0.0015
  2060        0.0577             nan     0.5758   -0.0010
  2080        0.0560             nan     0.5758   -0.0010
  2100        0.0547             nan     0.5758    0.0005
  2120        0.0540             nan     0.5758   -0.0011
  2140        0.0537             nan     0.5758   -0.0009
  2160        0.0535             nan     0.5758   -0.0011
  2180        0.0513             nan     0.5758   -0.0021
  2200        0.0498             nan     0.5758   -0.0007
  2220        0.0503             nan     0.5758   -0.0010
  2240        0.0477             nan     0.5758   -0.0010
  2260        0.0470             nan     0.5758   -0.0015
  2280        0.0463             nan     0.5758   -0.0020
  2300        0.0457             nan     0.5758   -0.0010
  2320        0.0440             nan     0.5758   -0.0013
  2340        0.0426             nan     0.5758   -0.0020
  2360        0.0414             nan     0.5758   -0.0013
  2380        0.0407             nan     0.5758   -0.0011
  2400        0.0396             nan     0.5758   -0.0005
  2420        0.0389             nan     0.5758   -0.0011
  2440        0.0373             nan     0.5758   -0.0008
  2460        0.0366             nan     0.5758   -0.0012
  2480        0.0357             nan     0.5758   -0.0015
  2500        0.0346             nan     0.5758   -0.0004
  2520        0.0340             nan     0.5758   -0.0004
  2540        0.0335             nan     0.5758   -0.0005
  2560        0.0332             nan     0.5758   -0.0007
  2580        0.0323             nan     0.5758   -0.0005
  2600        0.0324             nan     0.5758   -0.0013
  2620        0.0310             nan     0.5758   -0.0005
  2640        0.0303             nan     0.5758   -0.0004
  2660        0.0297             nan     0.5758   -0.0002
  2680        0.0296             nan     0.5758   -0.0009
  2700        0.0289             nan     0.5758   -0.0008
  2720        0.0282             nan     0.5758   -0.0011
  2740        0.0277             nan     0.5758   -0.0004
  2760        0.0273             nan     0.5758   -0.0004
  2780        0.0266             nan     0.5758   -0.0004
  2800        0.0260             nan     0.5758   -0.0001
  2820        0.0250             nan     0.5758   -0.0002
  2840        0.0245             nan     0.5758   -0.0004
  2860        0.0243             nan     0.5758   -0.0008
  2880        0.0239             nan     0.5758   -0.0009
  2900        0.0233             nan     0.5758   -0.0006
  2920        0.0233             nan     0.5758   -0.0005
  2940        0.0227             nan     0.5758   -0.0005
  2960        0.0222             nan     0.5758   -0.0010
  2980        0.0217             nan     0.5758   -0.0008
  3000        0.0210             nan     0.5758   -0.0008
  3020        0.0209             nan     0.5758   -0.0005
  3040        0.0206             nan     0.5758   -0.0003
  3060        0.0202             nan     0.5758   -0.0003
  3080        0.0194             nan     0.5758   -0.0005
  3100        0.0193             nan     0.5758   -0.0005
  3120        0.0185             nan     0.5758   -0.0001
  3140        0.0184             nan     0.5758   -0.0010
  3160        0.0177             nan     0.5758   -0.0001
  3180        0.0173             nan     0.5758   -0.0004
  3200        0.0170             nan     0.5758   -0.0003
  3220        0.0166             nan     0.5758   -0.0003
  3240        0.0163             nan     0.5758   -0.0003
  3260        0.0161             nan     0.5758   -0.0006
  3280        0.0159             nan     0.5758   -0.0004
  3300        0.0157             nan     0.5758   -0.0005
  3320        0.0152             nan     0.5758   -0.0009
  3340        0.0149             nan     0.5758   -0.0004
  3360        0.0145             nan     0.5758   -0.0002
  3380        0.0145             nan     0.5758   -0.0004
  3400        0.0144             nan     0.5758   -0.0005
  3420        0.0137             nan     0.5758   -0.0006
  3440        0.0134             nan     0.5758   -0.0003
  3460        0.0131             nan     0.5758   -0.0001
  3480        0.0129             nan     0.5758   -0.0001
  3500        0.0127             nan     0.5758   -0.0002
  3520        0.0126             nan     0.5758   -0.0001
  3540        0.0123             nan     0.5758   -0.0003
  3560        0.0121             nan     0.5758   -0.0002
  3580        0.0118             nan     0.5758   -0.0006
  3600        0.0115             nan     0.5758   -0.0003
  3620        0.0112             nan     0.5758   -0.0001
  3640        0.0112             nan     0.5758   -0.0003
  3660        0.0108             nan     0.5758   -0.0001
  3680        0.0106             nan     0.5758   -0.0002
  3700        0.0104             nan     0.5758   -0.0004
  3720        0.0102             nan     0.5758   -0.0002
  3740        0.0101             nan     0.5758   -0.0003
  3760        0.0098             nan     0.5758   -0.0001
  3780        0.0096             nan     0.5758   -0.0003
  3800        0.0095             nan     0.5758   -0.0001
  3820        0.0093             nan     0.5758   -0.0002
  3840        0.0091             nan     0.5758   -0.0002
  3860        0.0090             nan     0.5758   -0.0001
  3880        0.0087             nan     0.5758   -0.0003
  3900        0.0086             nan     0.5758   -0.0002
  3920        0.0086             nan     0.5758   -0.0003
  3940        0.0082             nan     0.5758   -0.0002
  3960        0.0082             nan     0.5758   -0.0002
  3980        0.0081             nan     0.5758   -0.0005
  4000        0.0080             nan     0.5758   -0.0000
  4020        0.0079             nan     0.5758   -0.0003
  4040        0.0077             nan     0.5758   -0.0001
  4060        0.0076             nan     0.5758   -0.0002
  4080        0.0075             nan     0.5758   -0.0002
  4100        0.0073             nan     0.5758   -0.0000
  4120        0.0072             nan     0.5758   -0.0003
  4135        0.0070             nan     0.5758   -0.0002

Iter   TrainDeviance   ValidDeviance   StepSize   Improve
     1        0.9934             nan     0.0829   -0.0028
     2        0.9913             nan     0.0829    0.0001
     3        0.9893             nan     0.0829   -0.0002
     4        0.9884             nan     0.0829   -0.0012
     5        0.9872             nan     0.0829   -0.0008
     6        0.9867             nan     0.0829   -0.0018
     7        0.9863             nan     0.0829   -0.0029
     8        0.9854             nan     0.0829   -0.0010
     9        0.9833             nan     0.0829   -0.0009
    10        0.9823             nan     0.0829   -0.0013
    20        0.9727             nan     0.0829   -0.0015
    40        0.9560             nan     0.0829   -0.0012
    60        0.9439             nan     0.0829   -0.0004
    80        0.9346             nan     0.0829   -0.0024
   100        0.9252             nan     0.0829   -0.0015
   120        0.9157             nan     0.0829   -0.0009
   140        0.9076             nan     0.0829   -0.0016
   160        0.9001             nan     0.0829   -0.0026
   180        0.8936             nan     0.0829   -0.0018
   200        0.8880             nan     0.0829   -0.0025
   220        0.8815             nan     0.0829   -0.0016
   240        0.8765             nan     0.0829   -0.0010
   260        0.8703             nan     0.0829   -0.0014
   280        0.8653             nan     0.0829   -0.0021
   300        0.8601             nan     0.0829   -0.0011
   320        0.8536             nan     0.0829   -0.0017
   340        0.8480             nan     0.0829   -0.0016
   360        0.8437             nan     0.0829   -0.0014
   380        0.8397             nan     0.0829   -0.0016
   400        0.8356             nan     0.0829   -0.0014
   420        0.8317             nan     0.0829   -0.0014
   440        0.8272             nan     0.0829   -0.0019
   460        0.8245             nan     0.0829   -0.0016
   480        0.8208             nan     0.0829   -0.0013
   500        0.8159             nan     0.0829   -0.0043
   520        0.8121             nan     0.0829   -0.0006
   540        0.8075             nan     0.0829   -0.0016
   560        0.8020             nan     0.0829   -0.0015
   580        0.7985             nan     0.0829   -0.0020
   600        0.7953             nan     0.0829   -0.0013
   620        0.7927             nan     0.0829   -0.0009
   640        0.7890             nan     0.0829   -0.0012
   660        0.7847             nan     0.0829   -0.0009
   680        0.7818             nan     0.0829   -0.0029
   700        0.7782             nan     0.0829   -0.0014
   720        0.7755             nan     0.0829   -0.0011
   740        0.7711             nan     0.0829   -0.0013
   760        0.7680             nan     0.0829   -0.0023
   780        0.7641             nan     0.0829   -0.0015
   800        0.7609             nan     0.0829   -0.0011
   820        0.7576             nan     0.0829   -0.0011
   840        0.7551             nan     0.0829   -0.0011
   860        0.7507             nan     0.0829   -0.0010
   880        0.7478             nan     0.0829   -0.0016
   900        0.7446             nan     0.0829   -0.0012
   920        0.7415             nan     0.0829   -0.0014
   940        0.7380             nan     0.0829   -0.0013
   960        0.7339             nan     0.0829   -0.0015
   980        0.7311             nan     0.0829   -0.0014
  1000        0.7291             nan     0.0829   -0.0008
  1020        0.7253             nan     0.0829   -0.0020
  1040        0.7224             nan     0.0829   -0.0011
  1060        0.7197             nan     0.0829   -0.0023
  1080        0.7175             nan     0.0829   -0.0018
  1100        0.7144             nan     0.0829   -0.0017
  1120        0.7110             nan     0.0829   -0.0016
  1140        0.7090             nan     0.0829   -0.0018
  1160        0.7065             nan     0.0829   -0.0012
  1180        0.7050             nan     0.0829   -0.0019
  1200        0.7014             nan     0.0829   -0.0016
  1220        0.6983             nan     0.0829   -0.0020
  1240        0.6965             nan     0.0829   -0.0012
  1260        0.6934             nan     0.0829   -0.0007
  1280        0.6917             nan     0.0829   -0.0018
  1300        0.6891             nan     0.0829   -0.0013
  1320        0.6862             nan     0.0829   -0.0020
  1340        0.6847             nan     0.0829   -0.0013
  1360        0.6820             nan     0.0829   -0.0015
  1380        0.6798             nan     0.0829   -0.0018
  1400        0.6774             nan     0.0829   -0.0016
  1420        0.6741             nan     0.0829   -0.0003
  1440        0.6721             nan     0.0829   -0.0011
  1460        0.6701             nan     0.0829   -0.0013
  1480        0.6661             nan     0.0829   -0.0013
  1500        0.6632             nan     0.0829   -0.0007
  1520        0.6605             nan     0.0829   -0.0014
  1540        0.6584             nan     0.0829   -0.0010
  1560        0.6567             nan     0.0829   -0.0024
  1580        0.6541             nan     0.0829   -0.0013
  1600        0.6517             nan     0.0829   -0.0014
  1620        0.6481             nan     0.0829   -0.0013
  1640        0.6461             nan     0.0829   -0.0010
  1660        0.6436             nan     0.0829   -0.0012
  1680        0.6424             nan     0.0829   -0.0010
  1700        0.6402             nan     0.0829   -0.0013
  1720        0.6389             nan     0.0829   -0.0013
  1740        0.6361             nan     0.0829   -0.0008
  1760        0.6343             nan     0.0829   -0.0012
  1765        0.6334             nan     0.0829   -0.0008

Stochastic Gradient Boosting 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  shrinkage   interaction.depth  n.minobsinnode  n.trees  RMSE      Rsquared   
  0.01825578   5                 14              2501     1.163080  0.006199736
  0.06262002   9                 13              3895     1.199277  0.008650039
  0.07859767   2                 10              1753     1.197910  0.009179719
  0.08285497   1                  7              1765     1.150838  0.015565195
  0.11761534   7                  5              2186     1.224265  0.008440466
  0.13520014   9                  6               703     1.230292  0.011443829
  0.17300592   5                 15               426     1.228500  0.007708468
  0.20453318   5                 21              3999     1.258806  0.007104012
  0.24126209   7                  7               846     1.246076  0.005312720
  0.26030753   7                  7              4213     1.289330  0.016951712
  0.28848962   9                 12              4837     1.270384  0.005783430
  0.28876497   2                 13              1264     1.317913  0.010383319
  0.33082635  10                 24              1825     1.280879  0.002603360
  0.33527563   8                  7              3585     1.321629  0.008854126
  0.41357597   3                 19              1024     1.312166  0.002090974
  0.42402126   5                 16              1500     1.299412  0.001274710
  0.47378616   5                 18              4129     1.399712  0.005698972
  0.53909033   9                 14              1784     1.397680  0.001076856
  0.56004139   3                 12              2510     1.459283  0.007126016
  0.57580713   1                 14              4135     1.407335  0.004674170
  MAE        Selected
  0.9214042          
  0.9474269          
  0.9374280          
  0.9044113  *       
  0.9702796          
  0.9694137          
  0.9725905          
  0.9937588          
  0.9864471          
  1.0135193          
  0.9969190          
  1.0405381          
  1.0266653          
  1.0464623          
  1.0407543          
  1.0273098          
  1.1057042          
  1.1192097          
  1.1658440          
  1.1056375          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were n.trees = 1765, interaction.depth =
 1, shrinkage = 0.08285497 and n.minobsinnode = 7.
[1] "Mon Mar 05 15:58:44 2018"
Error in relative.influence(object, n.trees = numTrees) : 
  could not find function "relative.influence"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: There were 25 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9     NA's   :9    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:02:29 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "gbm_h2o"                 
Multivariate Adaptive Regression Splines 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.028503  0.002993608  0.8212403

Tuning parameter 'degree' was held constant at a value of 1
[1] "Mon Mar 05 16:02:42 2018"
Generalized Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.001965  0.002762589  0.7967089

[1] "Mon Mar 05 16:02:55 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3     NA's   :3    
Error : Stopping
In addition: Warning messages:
1: model fit failed for Fold1: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
2: model fit failed for Fold1: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
3: model fit failed for Fold1: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
4: model fit failed for Fold2: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
5: model fit failed for Fold2: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
6: model fit failed for Fold2: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
7: model fit failed for Fold3: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
8: model fit failed for Fold3: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
9: model fit failed for Fold3: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
10: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3     NA's   :3    
Error : Stopping
In addition: Warning messages:
1: model fit failed for Fold1: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
2: model fit failed for Fold1: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
3: model fit failed for Fold1: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
4: model fit failed for Fold2: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
5: model fit failed for Fold2: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
6: model fit failed for Fold2: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
7: model fit failed for Fold3: link=log Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
8: model fit failed for Fold3: link=sqrt Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
9: model fit failed for Fold3: link=identity Error in eval(family$initialize) : 
  negative values not allowed for the 'Poisson' family
 
10: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :3     NA's   :3     NA's   :3    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:03:11 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "glm.nb"                  
Boosted Generalized Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  mstop  prune  RMSE       Rsquared      MAE        Selected
   86    yes    0.9981926  0.0004702028  0.7934176  *       
  141    no     1.0013660  0.0025489734  0.7962244          
  170    no     1.0015748  0.0026285208  0.7963692          
  205    yes    0.9981926  0.0004702028  0.7934176          
  253    yes    0.9981926  0.0004702028  0.7934176          
  301    yes    0.9981926  0.0004702028  0.7934176          
  351    yes    0.9981926  0.0004702028  0.7934176          
  354    yes    0.9981926  0.0004702028  0.7934176          
  357    no     1.0019272  0.0027520322  0.7966726          
  366    no     1.0019302  0.0027523133  0.7966752          
  438    no     1.0019509  0.0027584067  0.7966948          
  501    yes    0.9981926  0.0004702028  0.7934176          
  502    yes    0.9981926  0.0004702028  0.7934176          
  717    no     1.0019645  0.0027624544  0.7967084          
  780    no     1.0019647  0.0027625292  0.7967087          
  800    yes    0.9981926  0.0004702028  0.7934176          
  826    yes    0.9981926  0.0004702028  0.7934176          
  828    yes    0.9981926  0.0004702028  0.7934176          
  843    no     1.0019649  0.0027625611  0.7967088          
  968    no     1.0019650  0.0027625826  0.7967089          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mstop = 86 and prune = yes.
[1] "Mon Mar 05 16:03:33 2018"
glmnet 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  alpha       lambda       RMSE       Rsquared      MAE        Selected
  0.08509428  0.073922973  1.0008305  0.0020471355  0.7958744          
  0.14056540  2.157147010  0.9968173           NaN  0.7920966          
  0.16908356  0.439483707  0.9968961  0.0008655571  0.7921833          
  0.20472461  0.006318147  1.0017978  0.0026262729  0.7965880          
  0.25284510  0.004091859  1.0018428  0.0026512976  0.7966254          
  0.30001649  0.073646506  0.9992710  0.0004387429  0.7946858          
  0.35048447  0.002764482  1.0018621  0.0026577326  0.7966413          
  0.35304203  0.002304384  1.0018782  0.0026746218  0.7966526          
  0.35682166  1.407486127  0.9968173           NaN  0.7920966          
  0.36504880  5.485239613  0.9968173           NaN  0.7920966  *       
  0.43719640  0.239101864  0.9968173           NaN  0.7920966          
  0.50026452  0.041169686  0.9995784  0.0005209523  0.7950111          
  0.50198995  0.012496276  1.0013569  0.0020464050  0.7963234          
  0.71699918  0.620530396  0.9968173           NaN  0.7920966          
  0.77909068  1.371767938  0.9968173           NaN  0.7920966          
  0.79994739  0.050733998  0.9976657  0.0005825300  0.7930553          
  0.82582888  0.052179143  0.9975283  0.0006457115  0.7929740          
  0.82702510  0.001058726  1.0018875  0.0026678940  0.7966612          
  0.84267825  0.296487512  0.9968173           NaN  0.7920966          
  0.96740112  2.807292313  0.9968173           NaN  0.7920966          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were alpha = 0.3650488 and lambda = 5.48524.
[1] "Mon Mar 05 16:03:48 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: There were 25 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9     NA's   :9    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:07:31 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "glmnet_h2o"              
Start:  AIC=1453.54
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V10   1   510.86 1451.5
- V9    1   510.86 1451.5
- V6    1   510.89 1451.6
- V5    1   510.97 1451.6
- V2    1   511.01 1451.7
- V3    1   511.04 1451.7
- V4    1   511.24 1451.9
- V7    1   511.45 1452.1
- V8    1   512.05 1452.7
<none>      510.86 1453.5

Step:  AIC=1451.54
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9

       Df Deviance    AIC
- V9    1   510.86 1449.5
- V6    1   510.89 1449.6
- V5    1   510.97 1449.6
- V2    1   511.01 1449.7
- V3    1   511.04 1449.7
- V4    1   511.24 1449.9
- V7    1   511.45 1450.1
- V8    1   512.06 1450.7
<none>      510.86 1451.5

Step:  AIC=1449.54
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8

       Df Deviance    AIC
- V6    1   510.89 1447.6
- V5    1   510.97 1447.6
- V2    1   511.01 1447.7
- V3    1   511.05 1447.7
- V4    1   511.24 1447.9
- V7    1   511.45 1448.1
- V8    1   512.06 1448.7
<none>      510.86 1449.5

Step:  AIC=1447.57
.outcome ~ V2 + V3 + V4 + V5 + V7 + V8

       Df Deviance    AIC
- V5    1   510.99 1445.7
- V2    1   511.03 1445.7
- V3    1   511.07 1445.8
- V4    1   511.26 1445.9
- V7    1   511.48 1446.2
- V8    1   512.08 1446.7
<none>      510.89 1447.6

Step:  AIC=1445.67
.outcome ~ V2 + V3 + V4 + V7 + V8

       Df Deviance    AIC
- V2    1   511.15 1443.8
- V3    1   511.17 1443.8
- V4    1   511.36 1444.0
- V7    1   511.57 1444.2
- V8    1   512.15 1444.8
<none>      510.99 1445.7

Step:  AIC=1443.82
.outcome ~ V3 + V4 + V7 + V8

       Df Deviance    AIC
- V3    1   511.31 1442.0
- V4    1   511.51 1442.2
- V7    1   511.69 1442.4
- V8    1   512.34 1443.0
<none>      511.15 1443.8

Step:  AIC=1441.98
.outcome ~ V4 + V7 + V8

       Df Deviance    AIC
- V4    1   511.65 1440.3
- V7    1   511.88 1440.5
- V8    1   512.53 1441.2
<none>      511.31 1442.0

Step:  AIC=1440.31
.outcome ~ V7 + V8

       Df Deviance    AIC
- V7    1   512.17 1438.8
- V8    1   512.96 1439.6
<none>      511.65 1440.3

Step:  AIC=1438.83
.outcome ~ V8

       Df Deviance    AIC
- V8    1   513.51 1438.1
<none>      512.17 1438.8

Step:  AIC=1438.13
.outcome ~ 1

Start:  AIC=1426.54
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V2    1   480.61 1424.5
- V8    1   480.62 1424.6
- V7    1   480.63 1424.6
- V5    1   480.65 1424.6
- V10   1   481.00 1425.0
- V9    1   481.15 1425.1
<none>      480.60 1426.5
- V3    1   482.61 1426.6
- V6    1   483.90 1428.0
- V4    1   484.17 1428.3

Step:  AIC=1424.55
.outcome ~ V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V8    1   480.63 1422.6
- V7    1   480.64 1422.6
- V5    1   480.65 1422.6
- V10   1   481.00 1423.0
- V9    1   481.16 1423.1
<none>      480.61 1424.5
- V3    1   482.62 1424.6
- V6    1   483.91 1426.0
- V4    1   484.17 1426.3

Step:  AIC=1422.57
.outcome ~ V3 + V4 + V5 + V6 + V7 + V9 + V10

       Df Deviance    AIC
- V7    1   480.66 1420.6
- V5    1   480.67 1420.6
- V10   1   481.01 1421.0
- V9    1   481.18 1421.2
<none>      480.63 1422.6
- V3    1   482.64 1422.7
- V6    1   483.94 1424.0
- V4    1   484.22 1424.3

Step:  AIC=1420.6
.outcome ~ V3 + V4 + V5 + V6 + V9 + V10

       Df Deviance    AIC
- V5    1   480.70 1418.6
- V10   1   481.03 1419.0
- V9    1   481.22 1419.2
<none>      480.66 1420.6
- V3    1   482.66 1420.7
- V6    1   483.96 1422.0
- V4    1   484.23 1422.3

Step:  AIC=1418.64
.outcome ~ V3 + V4 + V6 + V9 + V10

       Df Deviance    AIC
- V10   1   481.07 1417.0
- V9    1   481.26 1417.2
<none>      480.70 1418.6
- V3    1   482.70 1418.7
- V6    1   484.06 1420.2
- V4    1   484.24 1420.3

Step:  AIC=1417.03
.outcome ~ V3 + V4 + V6 + V9

       Df Deviance    AIC
- V9    1   481.65 1415.6
<none>      481.07 1417.0
- V3    1   483.05 1417.1
- V4    1   484.57 1418.7
- V6    1   484.58 1418.7

Step:  AIC=1415.64
.outcome ~ V3 + V4 + V6

       Df Deviance    AIC
<none>      481.65 1415.6
- V3    1   483.94 1416.0
- V4    1   485.06 1417.2
- V6    1   485.20 1417.3
Start:  AIC=1422.23
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V9    1   481.64 1420.2
- V6    1   482.06 1420.7
- V8    1   482.07 1420.7
- V2    1   482.07 1420.7
- V5    1   482.16 1420.8
- V10   1   482.34 1421.0
- V7    1   482.75 1421.4
- V3    1   482.88 1421.5
<none>      481.64 1422.2
- V4    1   484.92 1423.6

Step:  AIC=1420.23
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V10

       Df Deviance    AIC
- V6    1   482.06 1418.7
- V8    1   482.07 1418.7
- V2    1   482.08 1418.7
- V5    1   482.16 1418.8
- V10   1   482.34 1419.0
- V7    1   482.75 1419.4
- V3    1   482.89 1419.5
<none>      481.64 1420.2
- V4    1   484.92 1421.6

Step:  AIC=1418.67
.outcome ~ V2 + V3 + V4 + V5 + V7 + V8 + V10

       Df Deviance    AIC
- V8    1   482.47 1417.1
- V2    1   482.54 1417.2
- V5    1   482.64 1417.3
- V10   1   482.72 1417.3
- V7    1   483.21 1417.9
- V3    1   483.39 1418.0
<none>      482.06 1418.7
- V4    1   485.34 1420.1

Step:  AIC=1417.09
.outcome ~ V2 + V3 + V4 + V5 + V7 + V10

       Df Deviance    AIC
- V2    1   482.93 1415.6
- V5    1   483.13 1415.8
- V10   1   483.14 1415.8
- V7    1   483.64 1416.3
- V3    1   483.88 1416.6
<none>      482.47 1417.1
- V4    1   485.87 1418.6

Step:  AIC=1415.57
.outcome ~ V3 + V4 + V5 + V7 + V10

       Df Deviance    AIC
- V5    1   483.55 1414.2
- V10   1   483.69 1414.4
- V7    1   484.12 1414.8
- V3    1   484.38 1415.1
<none>      482.93 1415.6
- V4    1   486.22 1417.0

Step:  AIC=1414.21
.outcome ~ V3 + V4 + V7 + V10

       Df Deviance    AIC
- V10   1   484.41 1413.1
- V7    1   484.65 1413.3
- V3    1   485.14 1413.8
<none>      483.55 1414.2
- V4    1   486.80 1415.6

Step:  AIC=1413.1
.outcome ~ V3 + V4 + V7

       Df Deviance    AIC
- V7    1   485.53 1412.3
- V3    1   486.00 1412.7
<none>      484.41 1413.1
- V4    1   487.63 1414.4

Step:  AIC=1412.26
.outcome ~ V3 + V4

       Df Deviance    AIC
- V3    1   487.04 1411.8
<none>      485.53 1412.3
- V4    1   488.67 1413.5

Step:  AIC=1411.81
.outcome ~ V4

       Df Deviance    AIC
<none>      487.04 1411.8
- V4    1   490.30 1413.1
Start:  AIC=2143.67
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Deviance    AIC
- V10   1   739.70 2141.7
- V5    1   739.77 2141.8
- V9    1   739.78 2141.8
- V2    1   739.92 2141.9
- V8    1   740.28 2142.3
- V7    1   740.33 2142.3
- V6    1   740.88 2142.9
- V3    1   741.24 2143.2
<none>      739.69 2143.7
- V4    1   742.94 2145.0

Step:  AIC=2141.68
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9

       Df Deviance    AIC
- V5    1   739.78 2139.8
- V9    1   739.79 2139.8
- V2    1   739.93 2139.9
- V8    1   740.28 2140.3
- V7    1   740.34 2140.3
- V6    1   740.88 2140.9
- V3    1   741.26 2141.3
<none>      739.70 2141.7
- V4    1   742.95 2143.0

Step:  AIC=2139.76
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V9

       Df Deviance    AIC
- V9    1   739.87 2137.8
- V2    1   739.99 2138.0
- V8    1   740.39 2138.4
- V7    1   740.40 2138.4
- V6    1   741.00 2139.0
- V3    1   741.36 2139.4
<none>      739.78 2139.8
- V4    1   743.01 2141.0

Step:  AIC=2137.85
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8

       Df Deviance    AIC
- V2    1   740.09 2136.1
- V8    1   740.50 2136.5
- V7    1   740.50 2136.5
- V6    1   741.08 2137.1
- V3    1   741.55 2137.6
<none>      739.87 2137.8
- V4    1   743.09 2139.1

Step:  AIC=2136.08
.outcome ~ V3 + V4 + V6 + V7 + V8

       Df Deviance    AIC
- V7    1   740.70 2134.7
- V8    1   740.72 2134.7
- V6    1   741.33 2135.3
- V3    1   741.76 2135.8
<none>      740.09 2136.1
- V4    1   743.26 2137.3

Step:  AIC=2134.7
.outcome ~ V3 + V4 + V6 + V8

       Df Deviance    AIC
- V8    1   741.33 2133.3
- V6    1   741.94 2134.0
- V3    1   742.36 2134.4
<none>      740.70 2134.7
- V4    1   743.76 2135.8

Step:  AIC=2133.33
.outcome ~ V3 + V4 + V6

       Df Deviance    AIC
- V6    1   742.55 2132.6
- V3    1   743.05 2133.1
<none>      741.33 2133.3
- V4    1   744.55 2134.6

Step:  AIC=2132.58
.outcome ~ V3 + V4

       Df Deviance    AIC
- V3    1   744.33 2132.4
<none>      742.55 2132.6
- V4    1   745.78 2133.8

Step:  AIC=2132.38
.outcome ~ V4

       Df Deviance    AIC
<none>      744.33 2132.4
- V4    1   747.47 2133.5
Generalized Linear Model with Stepwise Feature Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE      Rsquared      MAE      
  1.000651  0.0006404777  0.7968362

[1] "Mon Mar 05 16:07:45 2018"
Independent Component Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  n.comp  RMSE       Rsquared     MAE        Selected
  1       0.9971670  0.004327104  0.7918180  *       
  2       0.9995170  0.004139583  0.7925363          
  3       0.9988739  0.003099927  0.7917714          
  4       1.0005862  0.003189411  0.7940552          
  5       1.0019318  0.003034803  0.7962640          
  7       1.0022177  0.003019800  0.7960435          
  8       1.0024239  0.002718307  0.7965343          
  9       1.0019650  0.002762589  0.7967089          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was n.comp = 1.
[1] "Mon Mar 05 16:08:03 2018"
Partial Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  ncomp  RMSE      Rsquared     MAE        Selected
  1      1.001843  0.002884918  0.7962518  *       
  2      1.002040  0.002721692  0.7967116          
  3      1.001964  0.002762790  0.7967060          
  4      1.001965  0.002762084  0.7967087          
  5      1.001965  0.002762569  0.7967090          
  7      1.001965  0.002762588  0.7967089          
  8      1.001965  0.002762589  0.7967089          
  9      1.001965  0.002762589  0.7967089          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 1.
[1] "Mon Mar 05 16:08:16 2018"
Error in MSEP(object) : could not find function "MSEP"
In addition: Warning message:
In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
k-Nearest Neighbors 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  kmax  distance    kernel        RMSE       Rsquared      MAE        Selected
   22   1.44049998  epanechnikov  1.0293157  0.0008159342  0.8165749          
   36   2.56364412  triangular    1.0141611  0.0007514885  0.8049212          
   43   2.03397267  biweight      1.0229758  0.0003960525  0.8131214          
   52   0.62162704  cos           1.0210698  0.0069912540  0.8094664          
   64   0.47699355  biweight      1.0270778  0.0068577709  0.8151674          
   76   1.43925251  cos           1.0094602  0.0019662383  0.8013721          
   88   0.34643654  triangular    1.0139354  0.0084376576  0.8048280          
   89   0.28583004  triangular    1.0135683  0.0080360431  0.8047606          
   90   2.42148939  gaussian      1.0040142  0.0009288266  0.7982416          
   92   2.87435876  triweight     1.0134179  0.0007363587  0.8053566          
  110   1.83131476  triangular    1.0042692  0.0012344536  0.7979542          
  126   0.84868662  gaussian      1.0078080  0.0041721235  0.8001026          
  126   1.24562914  rectangular   1.0040117  0.0013292024  0.7984052          
  180   2.14882472  triweight     1.0057100  0.0008554775  0.7986911          
  195   2.41293149  rectangular   1.0008085  0.0007247478  0.7968874          
  200   1.31517616  epanechnikov  1.0043414  0.0015956596  0.7983404          
  207   0.02689498  gaussian      1.0084629  0.0044294817  0.8001518          
  207   1.32452701  inv           1.0029875  0.0012605813  0.7980193          
  211   1.90293306  biweight      1.0028296  0.0008269460  0.7971070          
  242   2.65134907  biweight      0.9995975  0.0007559097  0.7951915  *       

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were kmax = 242, distance = 2.651349
 and kernel = biweight.
[1] "Mon Mar 05 16:13:34 2018"
k-Nearest Neighbors 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  k    RMSE       Rsquared      MAE        Selected
   22  1.0160927  0.0010255997  0.8049625          
   36  1.0128375  0.0012847849  0.8024101          
   43  1.0091604  0.0008958639  0.8014451          
   52  1.0078920  0.0011711927  0.8013439          
   64  1.0046147  0.0010302529  0.7990094          
   76  1.0034995  0.0025534487  0.7987693          
   88  1.0031397  0.0017187921  0.7983155          
   89  1.0022146  0.0012105081  0.7976735          
   90  1.0017095  0.0012463981  0.7972141          
   92  1.0014195  0.0004784972  0.7973126          
  110  0.9993342  0.0003045243  0.7963333          
  126  0.9979872  0.0009533327  0.7947675          
  180  0.9959175  0.0031831761  0.7928437  *       
  195  0.9964820  0.0019374131  0.7940042          
  200  0.9971016  0.0006779305  0.7944896          
  207  0.9970845  0.0005118034  0.7944703          
  211  0.9972076  0.0004893728  0.7944030          
  242  0.9962965  0.0012493564  0.7933653          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was k = 180.
[1] "Mon Mar 05 16:13:51 2018"
Polynomial Kernel Regularized Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  lambda        degree  RMSE          Rsquared     MAE           Selected
  2.663615e-05  2       34917.217425  0.003099465  2.785783e+04          
  5.044603e-05  3        5301.790830  0.003652072  4.278439e+03          
  7.005156e-05  3        3817.957644  0.003652071  3.081007e+03          
  1.055901e-04  1       16887.450980  0.003254793  1.380938e+04          
  1.837492e-04  1        9704.243877  0.003254792  7.935449e+03          
  3.162878e-04  2        2940.540930  0.003099462  2.346064e+03          
  5.654866e-04  1        3153.298751  0.003254790  2.578539e+03          
  5.823849e-04  1        3061.803625  0.003254789  2.503720e+03          
  6.082867e-04  3         439.665613  0.003652064  3.547787e+02          
  6.687195e-04  3         399.930825  0.003652063  3.227144e+02          
  1.534553e-03  2         606.069634  0.003099447  4.835660e+02          
  3.171923e-03  2         293.208283  0.003099427  2.339581e+02          
  3.235562e-03  1         551.112165  0.003254771  4.506492e+02          
  3.845881e-02  3           7.004517  0.003651508  5.652227e+00          
  7.860559e-02  3           3.526065  0.003650847  2.844295e+00          
  9.993945e-02  2           9.354447  0.003098260  7.490953e+00          
  1.346308e-01  2           6.976556  0.003097847  5.591853e+00          
  1.364977e-01  1          13.106506  0.003253827  1.070714e+01          
  1.634524e-01  2           5.775009  0.003097505  4.635061e+00          
  6.870773e-01  3           1.063195  0.003632485  8.545667e-01  *       

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 0.6870773 and degree = 3.
[1] "Mon Mar 05 16:16:26 2018"

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.023600788 -0.007323513 -0.025691770 -0.084110098 -0.015415656 -0.070894219 
          V8           V9          V10 
 0.030143306 -0.005685901  0.017382280 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.33655414 -0.33992831 -0.37318820 -0.34072784 -0.27677083 -0.32644149
50% -0.01843143 -0.04829314 -0.02201441 -0.09276925 -0.02674789 -0.08987056
75%  0.29880154  0.31381716  0.31125616  0.18259365  0.22941060  0.19286679
             V8          V9         V10
25% -0.23429956 -0.29199407 -0.26341506
50%  0.03131125 -0.03014005  0.01345347
75%  0.33703530  0.29655942  0.31817537

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
 0.06541876  0.04900721 -0.14967163 -0.01107516 -0.07841090 -0.11064138 
         V8          V9         V10 
 0.16694014  0.09105970  0.14327102 

 Quartiles of Marginal Effects:
 
             V2          V3         V4          V5          V6         V7
25% -0.69658222 -0.80844325 -0.9483482 -0.72589806 -0.66490488 -0.7680543
50%  0.06054549  0.05433182 -0.1120721 -0.05271443 -0.06147275 -0.1084751
75%  0.82697470  0.83520097  0.7060404  0.73335158  0.61922156  0.5471624
            V8         V9        V10
25% -0.5769088 -0.6979886 -0.6507723
50%  0.1733281  0.1092224  0.1309229
75%  0.8513873  0.8140115  0.9669721

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.024923395  0.003661449 -0.027348571 -0.049423058 -0.014059675 -0.060682840 
          V8           V9          V10 
 0.018354678  0.010132321  0.018040280 

 Quartiles of Marginal Effects:
 
            V2           V3         V4          V5           V6          V7
25% -0.1769200 -0.132522703 -0.1442667 -0.16627493 -0.110638433 -0.20100849
50% -0.0249055  0.006140771 -0.0302184 -0.06383510  0.004110426 -0.06282342
75%  0.1256474  0.135045985  0.0635170  0.04704571  0.098236323  0.06036916
            V8          V9         V10
25% -0.1013728 -0.13887855 -0.12652239
50%  0.0134053 -0.01253269  0.01963378
75%  0.1469816  0.13937881  0.16420402

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.026351482 -0.009442455 -0.028929984 -0.020511842 -0.009114558 -0.041521244 
          V8           V9          V10 
 0.043036781  0.004579293  0.006059833 

 Quartiles of Marginal Effects:
 
             V2           V3           V4          V5           V6
25% -0.06806408 -0.051059720 -0.065283578 -0.05211189 -0.040529775
50% -0.02445934 -0.009535901 -0.031190579 -0.02097680 -0.008530415
75%  0.01474821  0.030784091  0.006134843  0.01018977  0.025769667
               V7           V8           V9          V10
25% -8.273492e-02 -0.000190622 -0.038331753 -0.045104583
50% -4.248610e-02  0.041626787  0.001743445  0.008814207
75%  8.226497e-06  0.087532973  0.046327605  0.051902678

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
-0.0179070028 -0.0041182710 -0.0225603091 -0.0747953528  0.0003243159 
           V7            V8            V9           V10 
-0.0606419002  0.0110776814 -0.0048457014 -0.0072573344 

 Quartiles of Marginal Effects:
 
              V2           V3          V4          V5         V6          V7
25% -0.149422035 -0.131155104 -0.15042788 -0.18500706 -0.1095555 -0.17205311
50%  0.001364306 -0.009873378 -0.01794632 -0.05490514 -0.0113189 -0.04463371
75%  0.115581381  0.118408781  0.11099729  0.05902385  0.1089613  0.06364295
              V8           V9          V10
25% -0.110183339 -0.122338645 -0.113092686
50%  0.004846588 -0.007172891 -0.005247276
75%  0.133098169  0.115411613  0.129256295

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.024870371 -0.010667174 -0.028976431 -0.019931831 -0.008526754 -0.040483775 
          V8           V9          V10 
 0.043967638  0.004052237  0.005139283 

 Quartiles of Marginal Effects:
 
              V2          V3            V4           V5           V6
25% -0.060311651 -0.04552350 -0.0599198246 -0.046441221 -0.034545271
50% -0.023137980 -0.01068353 -0.0309308905 -0.020677873 -0.008134467
75%  0.009730562  0.02310803  0.0001193128  0.005801183  0.020776037
              V7          V8           V9          V10
25% -0.075767182 0.007563672 -0.032288598 -0.038375887
50% -0.041603372 0.043511280  0.001530023  0.007271817
75% -0.005082012 0.082210443  0.039677977  0.044596152

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
-0.0224424649  0.0002782855 -0.0509025231 -0.0977562688 -0.0013583944 
           V7            V8            V9           V10 
-0.0635558136  0.0314859934 -0.0131258626  0.0123665098 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.35378596 -0.34639457 -0.39425535 -0.37137487 -0.28442792 -0.33960677
50% -0.01866979 -0.03158428 -0.03572725 -0.06496946 -0.03124668 -0.06117221
75%  0.29000659  0.34328237  0.33664660  0.18881647  0.23017045  0.19838196
             V8           V9          V10
25% -0.28462149 -0.283229505 -0.270246814
50%  0.06426915 -0.001018293  0.003619535
75%  0.35658768  0.299847762  0.336192661

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.035089552  0.005860383 -0.025368639 -0.028775653 -0.014758544 -0.052587153 
          V8           V9          V10 
 0.021940703  0.016000972  0.019325032 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.16578667 -0.13127881 -0.13668384 -0.12337526 -0.10589890 -0.17357215
50% -0.03531011  0.01374231 -0.03069716 -0.03126350 -0.00926269 -0.05667373
75%  0.09120940  0.13634510  0.07083959  0.05061857  0.08914140  0.06299276
             V8           V9         V10
25% -0.09467454 -0.100238103 -0.12486824
50%  0.01434729  0.002177064  0.02736087
75%  0.14536126  0.127732658  0.14808050

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
-0.0077069801 -0.0083261445 -0.0126725059 -0.0054922513 -0.0024195887 
           V7            V8            V9           V10 
-0.0146134929  0.0233174645  0.0015660133  0.0005163869 

 Quartiles of Marginal Effects:
 
              V2           V3          V4           V5           V6          V7
25% -0.007726436 -0.008345510 -0.01268966 -0.005509374 -0.002432942 -0.01463639
50% -0.007708016 -0.008326454 -0.01267381 -0.005491497 -0.002418956 -0.01461526
75% -0.007687508 -0.008308773 -0.01265426 -0.005475839 -0.002402305 -0.01459245
            V8          V9          V10
25% 0.02329799 0.001544198 0.0004942154
50% 0.02331803 0.001565620 0.0005181786
75% 0.02334195 0.001586339 0.0005383412

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.007887877  0.009910654 -0.066009797 -0.086896845 -0.015116359 -0.067258723 
          V8           V9          V10 
 0.064041216  0.003817833  0.038098488 

 Quartiles of Marginal Effects:
 
            V2          V3          V4         V5          V6         V7
25% -0.4845179 -0.49299974 -0.56971341 -0.4740766 -0.38813611 -0.4449337
50% -0.0160088 -0.02270024 -0.05112353 -0.0740192 -0.01588597 -0.1002661
75%  0.4634809  0.52022284  0.45745794  0.3209752  0.36240310  0.2959000
            V8          V9         V10
25% -0.3615022 -0.39919691 -0.39991509
50%  0.1068819  0.03844408  0.03777748
75%  0.5068540  0.46398618  0.46759206

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.010412211 -0.002776862 -0.026814899 -0.052670927  0.010649854 -0.038105057 
          V8           V9          V10 
-0.003676249 -0.008787918 -0.009097055 

 Quartiles of Marginal Effects:
 
               V2           V3           V4          V5           V6
25% -0.0960350044 -0.091427208 -0.114598069 -0.13792059 -0.094239237
50%  0.0001825253 -0.001798726 -0.004949967 -0.02016862 -0.004258238
75%  0.0834326124  0.089961546  0.088903778  0.04131719  0.079579599
             V7           V8           V9           V10
25% -0.12258675 -0.099607131 -0.081628505 -0.0897969212
50% -0.00970244  0.004843335 -0.004321426 -0.0007902223
75%  0.05946103  0.103618080  0.082194480  0.0930844239

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.024280529 -0.013251677 -0.028493602 -0.016005236 -0.009079840 -0.037397818 
          V8           V9          V10 
 0.047873191  0.002516339  0.003569519 

 Quartiles of Marginal Effects:
 
              V2          V3           V4           V5           V6          V7
25% -0.049522250 -0.03789454 -0.050330005 -0.035460257 -0.027988250 -0.06223987
50% -0.022517689 -0.01335497 -0.030825895 -0.016352909 -0.009023058 -0.03865608
75%  0.001309707  0.01145658 -0.006913802  0.003048153  0.012756589 -0.01162498
            V8            V9          V10
25% 0.02111368 -0.0241126281 -0.027937080
50% 0.04760132  0.0008567747  0.005337565
75% 0.07610616  0.0296692379  0.032549353

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.038954106  0.004528865 -0.025453993 -0.022186375 -0.014333056 -0.048793856 
          V8           V9          V10 
 0.025683980  0.015099769  0.017679594 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5          V6          V7
25% -0.15724721 -0.128040517 -0.12998066 -0.10317786 -0.10941209 -0.15701404
50% -0.03293702  0.004182059 -0.03332371 -0.02000083 -0.01032581 -0.05079577
75%  0.07613340  0.129772180  0.07233937  0.05705151  0.08754111  0.06351508
             V8           V9         V10
25% -0.09171340 -0.085935953 -0.11654464
50%  0.01280434  0.008522624  0.02633861
75%  0.14299189  0.125911764  0.14609552

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.031318670 -0.005636051 -0.027700835 -0.019329252 -0.011547576 -0.042490040 
          V8           V9          V10 
 0.040470434  0.006400763  0.008862944 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5          V6          V7
25% -0.09267344 -0.069909081 -0.08187581 -0.06439995 -0.06001020 -0.10075030
50% -0.02873468 -0.004816502 -0.03246883 -0.01801920 -0.01115640 -0.04383688
75%  0.02969271  0.054972681  0.02429479  0.02335117  0.04207822  0.01837011
             V8           V9         V10
25% -0.02278297 -0.053004741 -0.06312573
50%  0.03695192  0.002341698  0.01530563
75%  0.10611317  0.066844066  0.07544666

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.026552117  0.011131811 -0.004341773  0.039755622 -0.014382277  0.006327280 
          V8           V9          V10 
-0.019968314  0.010665893  0.101466541 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5            V6         V7
25% -0.41324571 -0.36752641 -0.43336630 -0.38312574 -0.3335871283 -0.3652903
50%  0.06213254 -0.01545611 -0.02530115 -0.01619873 -0.0002197221 -0.0312560
75%  0.45965885  0.34632785  0.41589026  0.37138992  0.3399539180  0.3650211
             V8          V9         V10
25% -0.34822788 -0.43461548 -0.29355865
50% -0.01387315 -0.07296704  0.05731781
75%  0.32504052  0.41897440  0.45205056

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.013744044  0.023245540 -0.002433003 -0.010574077 -0.021817379 -0.012691303 
          V8           V9          V10 
-0.015521996  0.020748482  0.037330235 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5           V6         V7
25% -0.27806215 -0.239727955 -0.25860948 -0.27218421 -0.239947196 -0.2587612
50%  0.01739631  0.005732673 -0.03084999 -0.05865179 -0.007578574 -0.0538717
75%  0.32592368  0.264323670  0.23925194  0.21857642  0.223199988  0.2183846
              V8          V9         V10
25% -0.233462898 -0.28933066 -0.23549458
50%  0.002044026 -0.02128469  0.02760135
75%  0.223540437  0.28690107  0.28604486

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.034779405 -0.001799240 -0.026774590 -0.019843317 -0.012915561 -0.044364428 
          V8           V9          V10 
 0.035936420  0.009091555  0.011858351 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5          V6          V7
25% -0.11497046 -0.089902905 -0.09852655 -0.07890544 -0.07813977 -0.11952768
50% -0.02972145 -0.001552267 -0.03174989 -0.01845542 -0.01104550 -0.04673667
75%  0.04544062  0.082103586  0.04091412  0.03758562  0.05663850  0.03498103
             V8           V9         V10
25% -0.04738123 -0.065425655 -0.08248517
50%  0.02729966  0.004748965  0.02021079
75%  0.11806651  0.086498519  0.09991956

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0161640675  0.0027902432 -0.0081786949 -0.0006724548 -0.0240411140 
           V7            V8            V9           V10 
-0.0292941916  0.0044994764  0.0019233697  0.0782684574 

 Quartiles of Marginal Effects:
 
             V2         V3          V4          V5         V6          V7
25% -0.42857293 -0.3433666 -0.41445908 -0.38305892 -0.3158521 -0.37498303
50%  0.04846861 -0.0376929 -0.02380694 -0.04177419 -0.0119727 -0.05387931
75%  0.43352234  0.3523521  0.41258982  0.30931629  0.2835361  0.28987442
             V8          V9         V10
25% -0.31984995 -0.41441258 -0.27082503
50%  0.01936336 -0.06245554  0.03534559
75%  0.33303167  0.37009952  0.41559160

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.022605244 -0.014825450 -0.028574832 -0.015426249 -0.008494052 -0.036410406 
          V8           V9          V10 
 0.048958957  0.001952744  0.002577041 

 Quartiles of Marginal Effects:
 
              V2           V3          V4           V5           V6          V7
25% -0.040901420 -0.032178245 -0.04432979 -0.029203172 -0.021986307 -0.05441328
50% -0.021626891 -0.015043411 -0.03009585 -0.016045531 -0.007996961 -0.03737718
75% -0.004262678  0.002784603 -0.01333882 -0.001257719  0.006702165 -0.01739964
            V8            V9          V10
25% 0.02941057 -0.0182126961 -0.020266527
50% 0.04852869  0.0005362953  0.003424039
75% 0.06915631  0.0214474952  0.023421798

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.007903975 -0.002121576 -0.013545288 -0.050259047 -0.023824452 -0.057778896 
          V8           V9          V10 
 0.017981039 -0.004747314  0.037454404 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.36481443 -0.33114475 -0.34549956 -0.32150878 -0.26520074 -0.33841801
50%  0.02511128 -0.04683207 -0.03320002 -0.06694876 -0.01458818 -0.06108186
75%  0.33246927  0.28418497  0.32991309  0.19443169  0.21150704  0.19591075
             V8         V9         V10
25% -0.24574182 -0.3507603 -0.24464288
50%  0.01134708 -0.0484563  0.03323621
75%  0.27650028  0.3016384  0.31116065

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.037569513 -0.050227529 -0.190091947 -0.007618137 -0.103935755 -0.027303585 
          V8           V9          V10 
 0.019231307 -0.006831752  0.037123473 

 Quartiles of Marginal Effects:
 
             V2          V3         V4         V5          V6          V7
25% -0.27124920 -0.32228135 -0.4838140 -0.3180901 -0.41132721 -0.29580775
50%  0.05816113 -0.07273435 -0.1845113 -0.0115367 -0.08551098 -0.02483586
75%  0.37852560  0.20251362  0.1412309  0.2658439  0.19708842  0.23192279
             V8           V9         V10
25% -0.24092860 -0.276401543 -0.28991946
50%  0.02594932 -0.002997227  0.03856334
75%  0.30694634  0.273604580  0.33026107

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
 0.05501559  0.02117639 -0.41244859  0.01899399 -0.21715015 -0.12420712 
         V8          V9         V10 
 0.06043720  0.03349592  0.10346507 

 Quartiles of Marginal Effects:
 
             V2          V3         V4          V5         V6          V7
25% -0.72677276 -0.64917114 -1.2068974 -0.84158940 -0.9641875 -0.93933555
50%  0.02658514 -0.02109992 -0.3172758 -0.07687384 -0.1722448 -0.06907308
75%  0.83589207  0.66914858  0.4562921  0.77140745  0.5890855  0.58863557
             V8          V9         V10
25% -0.59467235 -0.62099110 -0.75303895
50%  0.03059547  0.05473647  0.02288037
75%  0.72195235  0.67459374  0.88232433

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.006644456 -0.062551865 -0.106644237 -0.002353976 -0.092117625 -0.022889107 
          V8           V9          V10 
 0.027118281  0.040718730  0.036185344 

 Quartiles of Marginal Effects:
 
            V2          V3          V4          V5          V6          V7
25% -0.1372259 -0.18370184 -0.19932317 -0.08719800 -0.21886971 -0.09984753
50% -0.0142845 -0.05941804 -0.10395276 -0.01154297 -0.11929606 -0.02019621
75%  0.1216749  0.05478180 -0.02365832  0.07246166  0.02805663  0.05332320
             V8          V9         V10
25% -0.06255438 -0.09216039 -0.09758047
50%  0.03783229  0.04604381  0.02990014
75%  0.13074658  0.17599952  0.15936652

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.008244070 -0.059331654 -0.086915823  0.007368147 -0.086384697 -0.014156939 
          V8           V9          V10 
 0.015334608  0.037105347  0.034118811 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5          V6          V7
25% -0.04835485 -0.09771529 -0.10803888 -0.017333267 -0.12538533 -0.04273960
50% -0.01104038 -0.06219534 -0.08629555  0.006985622 -0.08597108 -0.01498434
75%  0.03060160 -0.02435193 -0.06646096  0.031374175 -0.04921763  0.01599709
             V8           V9          V10
25% -0.01713678 -0.009753735 -0.008475681
50%  0.01621052  0.040433475  0.034906134
75%  0.04822128  0.081732187  0.079011483

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.009047467 -0.039227350 -0.085792044 -0.017790361 -0.054399063 -0.004643119 
          V8           V9          V10 
 0.020834615  0.008941942  0.008875835 

 Quartiles of Marginal Effects:
 
              V2          V3          V4           V5          V6            V7
25% -0.115918787 -0.14612337 -0.19851634 -0.127281084 -0.16773645 -0.1157611558
50%  0.009136428 -0.03028262 -0.05849928 -0.009623431 -0.04914820  0.0004066186
75%  0.139201863  0.07118804  0.04028156  0.095529247  0.08261478  0.1052276923
             V8           V9         V10
25% -0.08524751 -0.102956544 -0.10033957
50%  0.01221208  0.005408243  0.01687571
75%  0.12019058  0.113659620  0.13139222

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.007486297 -0.059264318 -0.086053713  0.007673978 -0.084934922 -0.013140579 
          V8           V9          V10 
 0.014113784  0.036314237  0.033117139 

 Quartiles of Marginal Effects:
 
              V2          V3          V4           V5          V6          V7
25% -0.041597789 -0.09244423 -0.10410873 -0.013220397 -0.11783895 -0.03779851
50% -0.009969705 -0.06236504 -0.08521020  0.007724848 -0.08490286 -0.01377959
75%  0.025580822 -0.02980881 -0.06879764  0.028573822 -0.05291738  0.01264136
             V8           V9          V10
25% -0.01336575 -0.003682874 -0.003135645
50%  0.01422968  0.037698424  0.034266665
75%  0.04246005  0.074659499  0.071158790

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.050911948 -0.033257898 -0.170613043 -0.035277791 -0.080966523 -0.008957883 
          V8           V9          V10 
 0.034536256  0.004928057  0.022150331 

 Quartiles of Marginal Effects:
 
             V2          V3         V4         V5          V6         V7
25% -0.25693851 -0.28700408 -0.4983318 -0.3589839 -0.38632456 -0.3109498
50%  0.04679119 -0.01175715 -0.1445021 -0.0252717 -0.05762095 -0.0113550
75%  0.39188271  0.23953845  0.1881528  0.2715653  0.22882535  0.2556472
             V8           V9         V10
25% -0.26310470 -0.264636692 -0.33187337
50%  0.01512751 -0.009082553  0.05210017
75%  0.32613898  0.280492215  0.35164138

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
-0.0143412700 -0.0599553216 -0.0953930476  0.0007730066 -0.0977631255 
           V7            V8            V9           V10 
-0.0222674890  0.0274575745  0.0452539685  0.0418629275 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5          V6          V7
25% -0.12685854 -0.16228261 -0.15954996 -0.069779841 -0.20741063 -0.09540562
50% -0.02174082 -0.05831188 -0.09256393 -0.004140828 -0.10379145 -0.02335698
75%  0.09430589  0.03696563 -0.02905886  0.060118598  0.01079753  0.05218585
             V8          V9         V10
25% -0.06481829 -0.06751749 -0.09204430
50%  0.03575599  0.04697422  0.02707995
75%  0.12193467  0.15740676  0.17623638

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
-0.0008141412 -0.0277832520 -0.0379353375  0.0043918157 -0.0379728981 
           V7            V8            V9           V10 
-0.0012822779  0.0039626796  0.0162473407  0.0137453825 

 Quartiles of Marginal Effects:
 
               V2          V3          V4          V5          V6           V7
25% -0.0008361665 -0.02780885 -0.03795574 0.004379522 -0.03800005 -0.001299205
50% -0.0008156280 -0.02779089 -0.03794035 0.004392722 -0.03797679 -0.001284237
75% -0.0007945045 -0.02776706 -0.03791902 0.004406918 -0.03795335 -0.001267101
             V8         V9        V10
25% 0.003946059 0.01622710 0.01372849
50% 0.003963290 0.01625008 0.01375167
75% 0.003980611 0.01627077 0.01376768

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.052717490 -0.014107241 -0.243643472 -0.030772124 -0.113214547 -0.029648376 
          V8           V9          V10 
 0.034487499  0.004330274  0.042236690 

 Quartiles of Marginal Effects:
 
             V2          V3         V4          V5          V6          V7
25% -0.38124396 -0.39808718 -0.7136777 -0.48643553 -0.54622746 -0.46076651
50%  0.04344561 -0.01041339 -0.1889752 -0.04857934 -0.06769966 -0.01304061
75%  0.54861068  0.36377943  0.2605813  0.41376178  0.36521934  0.38364755
             V8           V9         V10
25% -0.39764653 -0.400975791 -0.48414826
50%  0.03873081  0.008603503  0.03872373
75%  0.46513033  0.381537514  0.53138364

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.017414704 -0.027777641 -0.047043155 -0.008584884 -0.027659783  0.008898449 
          V8           V9          V10 
 0.020220863  0.006557705 -0.001039323 

 Quartiles of Marginal Effects:
 
              V2           V3          V4           V5          V6
25% -0.079580466 -0.096691448 -0.14827229 -0.098173545 -0.10985427
50%  0.005241502 -0.004977267 -0.01702962  0.001569822 -0.00769851
75%  0.092886893  0.060306225  0.05113540  0.077940284  0.05762393
               V7           V8            V9          V10
25% -0.0775378855 -0.064828943 -0.0695258480 -0.071159650
50% -0.0001210316  0.003854705 -0.0005006893  0.005816251
75%  0.0964433357  0.100179620  0.0866744426  0.097916307

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.006635171 -0.060222601 -0.087019601  0.008982320 -0.086056620 -0.012170200 
          V8           V9          V10 
 0.011646759  0.035975987  0.033675618 

 Quartiles of Marginal Effects:
 
              V2          V3          V4           V5          V6           V7
25% -0.031833968 -0.08413834 -0.09936386 -0.006126680 -0.10953140 -0.030018032
50% -0.008261054 -0.06235995 -0.08719837  0.008313559 -0.08556965 -0.012263982
75%  0.018073593 -0.03681652 -0.07446549  0.024369021 -0.06250131  0.008177558
             V8          V9        V10
25% -0.00933090 0.006481219 0.00679341
50%  0.01101702 0.037210004 0.03421551
75%  0.03222458 0.064147562 0.06106495

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.016763569 -0.059188577 -0.090961450  0.002623683 -0.098394457 -0.021996362 
          V8           V9          V10 
 0.026279865  0.044296930  0.041721710 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5          V6          V7
25% -0.12638917 -0.15500658 -0.15104433 -0.062278535 -0.20075693 -0.08888110
50% -0.01740236 -0.06654759 -0.08893885  0.003152841 -0.09726171 -0.02581327
75%  0.08147278  0.03124176 -0.03014963  0.062339952  0.00334786  0.04508620
             V8          V9         V10
25% -0.06434958 -0.07552632 -0.08827755
50%  0.03155842  0.04639571  0.02950853
75%  0.10835623  0.14855436  0.17637749

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.010964660 -0.059140775 -0.088762812  0.006994769 -0.091298645 -0.016827609 
          V8           V9          V10 
 0.018460506  0.039566759  0.037653281 

 Quartiles of Marginal Effects:
 
             V2           V3          V4           V5          V6          V7
25% -0.06985832 -0.114267320 -0.11943169 -0.028611404 -0.14471471 -0.05739271
50% -0.01404920 -0.063777716 -0.08762407  0.006537927 -0.08887343 -0.01835530
75%  0.04432477 -0.008561594 -0.05706849  0.041799735 -0.03654575  0.02570566
             V8          V9         V10
25% -0.02893636 -0.02833733 -0.02731423
50%  0.02081770  0.04427209  0.03616907
75%  0.06445313  0.10196176  0.10709159

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
 0.04977593 -0.09363180 -0.26493576  0.08339852 -0.13598725 -0.01600092 
         V8          V9         V10 
-0.00806860 -0.05730765  0.08211172 

 Quartiles of Marginal Effects:
 
             V2          V3         V4          V5         V6         V7
25% -0.40746022 -0.48813054 -0.6293857 -0.30091672 -0.4984766 -0.3534987
50%  0.02858726 -0.09207031 -0.2348696  0.04200493 -0.1546778 -0.0293600
75%  0.46266681  0.25076099  0.1465024  0.40994864  0.1486604  0.3255897
             V8          V9         V10
25% -0.38691626 -0.52317630 -0.37156416
50%  0.05721299 -0.04624555  0.01503811
75%  0.42331408  0.34748626  0.46660896

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.010452837 -0.073828447 -0.160584585  0.031810665 -0.101822315 -0.009884238 
          V8           V9          V10 
 0.017186743  0.027006357  0.058043336 

 Quartiles of Marginal Effects:
 
             V2          V3          V4           V5         V6          V7
25% -0.24694468 -0.30573817 -0.37930225 -0.183330427 -0.3525104 -0.19667288
50%  0.01612967 -0.08907394 -0.15832381  0.004583155 -0.1478820 -0.01501475
75%  0.24895910  0.17158693  0.09179723  0.230872902  0.1152655  0.16605611
             V8         V9         V10
25% -0.17624506 -0.2841371 -0.21774758
50%  0.03200043  0.0293284  0.01243164
75%  0.26788569  0.2979318  0.25705719

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.01335414 -0.05892527 -0.08945007  0.00583610 -0.09430363 -0.01887263 
         V8          V9         V10 
 0.02147529  0.04137960  0.03955257 

 Quartiles of Marginal Effects:
 
             V2           V3          V4           V5          V6          V7
25% -0.08989126 -0.126562668 -0.13020446 -0.039609815 -0.16158875 -0.06984807
50% -0.01681581 -0.062902330 -0.08832207  0.006450803 -0.09158398 -0.02106829
75%  0.05756375  0.007660993 -0.04705142  0.049182625 -0.02219367  0.03290564
             V8          V9         V10
25% -0.03787905 -0.04673136 -0.04827897
50%  0.02527825  0.04633149  0.03375749
75%  0.07970923  0.11885730  0.13307333

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.049782367 -0.085182635 -0.249884431  0.061142087 -0.132217024 -0.027028539 
          V8           V9          V10 
-0.001003879 -0.037009067  0.066488725 

 Quartiles of Marginal Effects:
 
             V2         V3         V4          V5         V6          V7
25% -0.37535641 -0.4318915 -0.6020293 -0.28194444 -0.4584537 -0.34592061
50%  0.03900601 -0.1021803 -0.2114871  0.02891576 -0.1139726 -0.02882244
75%  0.45482744  0.2491819  0.1412850  0.35562278  0.1793542  0.29071343
             V8          V9         V10
25% -0.34754302 -0.46524844 -0.34279889
50%  0.04053269 -0.02944156  0.01249623
75%  0.38874283  0.32077471  0.42090359

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.005702843 -0.060601212 -0.086564297  0.009212220 -0.084883271 -0.011091112 
          V8           V9          V10 
 0.010141454  0.035149256  0.032616696 

 Quartiles of Marginal Effects:
 
              V2          V3          V4           V5          V6           V7
25% -0.024085719 -0.07826160 -0.09548571 -0.001757476 -0.10186282 -0.023986580
50% -0.006729051 -0.06167407 -0.08698220  0.008903516 -0.08467900 -0.011247918
75%  0.012537811 -0.04333462 -0.07768058  0.020561760 -0.06749145  0.003603044
              V8         V9        V10
25% -0.005177082 0.01361513 0.01312125
50%  0.009753269 0.03617878 0.03302808
75%  0.025186358 0.05580566 0.05165516

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.031682097 -0.071015521 -0.199421641  0.021672286 -0.115322828 -0.030775693 
          V8           V9          V10 
 0.011886476 -0.005616152  0.046359751 

 Quartiles of Marginal Effects:
 
             V2          V3         V4           V5         V6          V7
25% -0.31938744 -0.34238980 -0.4836128 -0.264020381 -0.4156972 -0.29346972
50%  0.03636996 -0.08942489 -0.1897520  0.005047976 -0.1084699 -0.02269542
75%  0.36774693  0.20755745  0.1336806  0.272840762  0.1688112  0.23071612
             V8           V9         V10
25% -0.26413015 -0.310662700 -0.27027716
50%  0.03077115 -0.005686866  0.02434843
75%  0.29315167  0.294924907  0.32594162

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.023280165 -0.007416277 -0.080594370 -0.035604841  0.025876539 -0.025298675 
          V8           V9          V10 
-0.012681255 -0.021474892 -0.038708822 

 Quartiles of Marginal Effects:
 
             V2           V3         V4          V5          V6          V7
25% -0.30919581 -0.291930971 -0.3640060 -0.32503869 -0.23502259 -0.30657331
50% -0.02556717 -0.005496543 -0.0850037 -0.03284418  0.01397607 -0.04712767
75%  0.29200843  0.300567845  0.2213596  0.26930078  0.28884571  0.24159699
             V8           V9        V10
25% -0.28260450 -0.266749802 -0.3614332
50% -0.02027045 -0.007154813 -0.0193475
75%  0.25889641  0.202534186  0.2874429

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.010635232  0.174968205 -0.234897685 -0.114385982  0.002564236  0.075881478 
          V8           V9          V10 
-0.048067647  0.048499677 -0.054042353 

 Quartiles of Marginal Effects:
 
            V2         V3         V4         V5          V6          V7
25% -0.8860605 -0.7194779 -1.0640994 -1.0240409 -0.67513931 -0.90475392
50% -0.0844311  0.2107554 -0.1804724 -0.1089351  0.01619468 -0.01154865
75%  0.8746662  1.0623882  0.5862189  0.7396636  0.80320062  1.01861936
             V8          V9         V10
25% -0.82676941 -0.74712200 -0.92010865
50% -0.07433536  0.07671816 -0.02266219
75%  0.65068977  0.79490600  0.76242442

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.042575816 -0.054268125 -0.100583208  0.004203592 -0.015679135 -0.038362075 
          V8           V9          V10 
 0.017670030  0.004626526 -0.032884434 

 Quartiles of Marginal Effects:
 
            V2          V3          V4           V5          V6          V7
25% -0.1846290 -0.20412872 -0.17604240 -0.082538466 -0.10908864 -0.14737973
50% -0.0539852 -0.06211419 -0.10244332 -0.005050409 -0.02623842 -0.04672463
75%  0.1040508  0.07868654 -0.02036165  0.089318910  0.07789301  0.06931659
             V8         V9        V10
25% -0.08934924 -0.1116813 -0.1823751
50%  0.02429793 -0.0146595 -0.0447618
75%  0.13246198  0.1238452  0.1060274

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.038783423 -0.047578803 -0.088631607  0.025319133 -0.025349375 -0.044428523 
          V8           V9          V10 
 0.024430791  0.002312806 -0.035823765 

 Quartiles of Marginal Effects:
 
             V2           V3          V4           V5           V6           V7
25% -0.08725526 -0.091263370 -0.11725570 -0.004480175 -0.057602927 -0.077094769
50% -0.03680976 -0.053178474 -0.09006880  0.023707411 -0.026444692 -0.045785429
75%  0.01486196 -0.002912366 -0.05895242  0.055880961  0.005713565 -0.009926039
             V8            V9          V10
25% -0.00845012 -0.0297654962 -0.083723876
50%  0.02641021 -0.0003750261 -0.033979513
75%  0.05677611  0.0353610086  0.006880133

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.020920205 -0.008774213 -0.031373209 -0.021999520  0.008266242 -0.015851322 
          V8           V9          V10 
 0.007405391 -0.018964982 -0.017466460 

 Quartiles of Marginal Effects:
 
             V2           V3          V4          V5           V6          V7
25% -0.12437517 -0.121682299 -0.13674443 -0.12013999 -0.091453758 -0.12055836
50% -0.01575932 -0.006432793 -0.03297034 -0.01275965 -0.002061765 -0.01799712
75%  0.10253389  0.104187440  0.09023351  0.09321813  0.104035195  0.08054503
              V8          V9          V10
25% -0.109298376 -0.11290064 -0.120169698
50%  0.001148509 -0.01264221 -0.002792866
75%  0.113579773  0.07875536  0.104654967

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.037355340 -0.047202846 -0.087620490  0.025654445 -0.025569388 -0.044364097 
          V8           V9          V10 
 0.025107966  0.002044058 -0.035951507 

 Quartiles of Marginal Effects:
 
              V2           V3          V4           V5            V6
25% -0.078493343 -0.084602600 -0.11239083 0.0003588672 -0.0527498680
50% -0.035548335 -0.051793516 -0.08890048 0.0247203009 -0.0261081630
75%  0.007286918 -0.008972895 -0.06266671 0.0517295911  0.0009879685
             V7           V8          V9           V10
25% -0.07241374 -0.002916185 -0.02477343 -0.0767068079
50% -0.04541451  0.027269544  0.00012716 -0.0343795488
75% -0.01496407  0.052877369  0.03022205  0.0002422663

 Average Marginal Effects:
 
         V2          V3          V4          V5          V6          V7 
-0.02709608  0.02952542 -0.05163950 -0.06734780  0.02981751 -0.01525279 
         V8          V9         V10 
-0.01417369 -0.01443689 -0.02467450 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.35272872 -0.30818035 -0.37327176 -0.38728792 -0.26006084 -0.32660429
50% -0.02936903  0.02379529 -0.05022586 -0.03726603  0.02470584 -0.01292537
75%  0.30578989  0.36615641  0.28485447  0.27004806  0.31027933  0.28617516
             V8         V9           V10
25% -0.30480074 -0.2794870 -0.3684494123
50% -0.01239821 -0.0014404 -0.0001135277
75%  0.29725473  0.2508471  0.3337348944

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.052669042 -0.055077562 -0.097779357  0.017218446 -0.020154249 -0.039427060 
          V8           V9          V10 
 0.017797973  0.008116318 -0.031256333 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.18912763 -0.17519778 -0.16756895 -0.06969664 -0.10654734 -0.13439311
50% -0.05156890 -0.06927729 -0.09500832  0.01184427 -0.02462995 -0.03930846
75%  0.09155112  0.06893897 -0.03343368  0.10192526  0.06128569  0.05898636
             V8           V9         V10
25% -0.07456615 -0.091859881 -0.17401859
50%  0.01857908 -0.002053127 -0.02975436
75%  0.12248579  0.101884517  0.10035028

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.013715146 -0.023147727 -0.037447051  0.015347861 -0.013476237 -0.019828599 
          V8           V9          V10 
 0.014957676  0.001156392 -0.017976909 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5          V6          V7
25% -0.01374294 -0.02317436 -0.03747152 0.01533311 -0.01349371 -0.01984972
50% -0.01371885 -0.02315150 -0.03745181 0.01535019 -0.01347773 -0.01983240
75% -0.01369089 -0.02312585 -0.03743080 0.01536529 -0.01346037 -0.01981068
            V8          V9         V10
25% 0.01494086 0.001139158 -0.01800173
50% 0.01496005 0.001155814 -0.01797889
75% 0.01497695 0.001174581 -0.01795720

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.022241542  0.059935913 -0.097999777 -0.088377200  0.020108094 -0.001135554 
          V8           V9          V10 
-0.023498005 -0.001329667 -0.033291331 

 Quartiles of Marginal Effects:
 
             V2         V3         V4          V5          V6            V7
25% -0.51096443 -0.4046986 -0.5571954 -0.61507912 -0.39545857 -0.4842225378
50% -0.05288517  0.0421902 -0.1026856 -0.07740875  0.02540241 -0.0006246488
75%  0.49385404  0.5663749  0.3911382  0.41489557  0.44426910  0.4955453783
             V8          V9          V10
25% -0.44536797 -0.40414205 -0.549410009
50% -0.04439267  0.01745241 -0.005488819
75%  0.42353771  0.40325619  0.477790401

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
-0.0227891259  0.0098789976 -0.0003201997 -0.0230931087  0.0223608669 
           V7            V8            V9           V10 
-0.0099558542  0.0058127923 -0.0096143275 -0.0086380330 

 Quartiles of Marginal Effects:
 
             V2           V3           V4          V5           V6           V7
25% -0.11506128 -0.081953547 -0.102358574 -0.09702112 -0.065800825 -0.087778115
50% -0.00752826  0.005320754 -0.005713212 -0.00196171  0.003109169 -0.003433982
75%  0.07308644  0.094396340  0.075776083  0.07008312  0.093676952  0.076449677
              V8           V9          V10
25% -0.076642734 -0.095766270 -0.085537016
50%  0.002702374 -0.002731712 -0.000959421
75%  0.091951383  0.064156217  0.090693909

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.036766769 -0.048651279 -0.087722482  0.029349599 -0.026668896 -0.045881729 
          V8           V9          V10 
 0.025586331  0.001934904 -0.037449314 

 Quartiles of Marginal Effects:
 
              V2          V3          V4         V5           V6          V7
25% -0.066918426 -0.07642090 -0.10578120 0.01012695 -0.046382887 -0.06588272
50% -0.035473666 -0.05085913 -0.08800237 0.02940344 -0.026906995 -0.04665847
75% -0.003573403 -0.02060633 -0.06826989 0.04830981 -0.006888683 -0.02518513
             V8            V9         V10
25% 0.004896747 -0.0182729104 -0.06611181
50% 0.026858267 -0.0004596307 -0.03614839
75% 0.044580467  0.0229064601 -0.01121909

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.052631117 -0.052187414 -0.094366903  0.022582159 -0.021411147 -0.040750934 
          V8           V9          V10 
 0.017520417  0.007010495 -0.031112676 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.17830256 -0.15991631 -0.15715518 -0.05902902 -0.10749283 -0.12897795
50% -0.04502324 -0.06611911 -0.09582796  0.02138654 -0.02008340 -0.04282133
75%  0.08061643  0.06275415 -0.02553894  0.10486778  0.06441613  0.05384043
             V8           V9         V10
25% -0.06875520 -0.089301430 -0.16749697
50%  0.01727435 -0.003655841 -0.03217028
75%  0.10706396  0.104494250  0.09074472

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.043509373 -0.049262183 -0.090800701  0.026024012 -0.024749372 -0.044371380 
          V8           V9          V10 
 0.021685992  0.003530576 -0.035356866 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6           V7
25% -0.11278887 -0.11042082 -0.13000605 -0.02060190 -0.07064679 -0.092102491
50% -0.03977162 -0.05681781 -0.09145296  0.02408898 -0.02515649 -0.047141689
75%  0.03288319  0.01490387 -0.04826280  0.06977829  0.02183093  0.005595157
             V8           V9         V10
25% -0.02541611 -0.042554296 -0.10611479
50%  0.02274540  0.001138654 -0.03250217
75%  0.06837964  0.051829677  0.03186584

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
 0.019789743 -0.067058258 -0.191492566  0.035301305  0.024787184  0.017034840 
          V8           V9          V10 
-0.048794602  0.004294941 -0.069214504 

 Quartiles of Marginal Effects:
 
              V2          V3         V4           V5         V6          V7
25% -0.333454799 -0.48192328 -0.4989738 -0.314458105 -0.2917664 -0.34632398
50%  0.008153227 -0.05410714 -0.1499942  0.006196887  0.0019372 -0.04396013
75%  0.362869236  0.32726459  0.1377822  0.380358579  0.3066161  0.35112302
             V8          V9         V10
25% -0.37883151 -0.36025780 -0.48373285
50% -0.02655478 -0.04595656 -0.07996961
75%  0.26744008  0.31842708  0.37771926

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.030520495 -0.075584406 -0.139944720  0.011798706 -0.008894846 -0.016000225 
          V8           V9          V10 
-0.015368912  0.011260080 -0.047964142 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.26793439 -0.35317080 -0.33210592 -0.21874020 -0.22288311 -0.23932952
50% -0.05644246 -0.06738564 -0.13280313  0.01707886 -0.02972128 -0.04078259
75%  0.21234928  0.18194926  0.07522743  0.21441464  0.16923530  0.19063912
              V8          V9         V10
25% -0.235402997 -0.25692339 -0.35054072
50%  0.008872936 -0.04806135 -0.05993092
75%  0.215885362  0.26475812  0.23805339

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.047096682 -0.050182394 -0.092054813  0.025181138 -0.023686000 -0.043348192 
          V8           V9          V10 
 0.019744632  0.004687858 -0.034060687 

 Quartiles of Marginal Effects:
 
             V2          V3          V4          V5          V6          V7
25% -0.13679532 -0.12920932 -0.14022184 -0.03452642 -0.08404167 -0.10472428
50% -0.04206420 -0.06025254 -0.09163538  0.02391463 -0.02340855 -0.04496634
75%  0.04993764  0.03174707 -0.03895795  0.08293028  0.03887647  0.02267499
             V8           V9         V10
25% -0.04132929 -0.058860108 -0.13004747
50%  0.02103814 -0.001320354 -0.03232931
75%  0.07879132  0.069706288  0.05288191

 Average Marginal Effects:
 
           V2            V3            V4            V5            V6 
 0.0099524483 -0.0545653088 -0.1700933961  0.0199099637  0.0324592702 
           V7            V8            V9           V10 
-0.0017673225 -0.0351948366  0.0007914159 -0.0620120854 

 Quartiles of Marginal Effects:
 
              V2          V3         V4           V5          V6          V7
25% -0.325285647 -0.44885566 -0.4378124 -0.311452407 -0.25602832 -0.34995281
50%  0.004973139 -0.06285732 -0.1350299  0.008840309  0.01653817 -0.05154578
75%  0.355253626  0.32380113  0.1623383  0.310080409  0.32954122  0.30552605
             V8          V9         V10
25% -0.31953285 -0.34654982 -0.44309801
50% -0.02984406 -0.04405687 -0.07066695
75%  0.26543435  0.33602959  0.37240940

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.035293225 -0.048640588 -0.086982407  0.029999426 -0.026970628 -0.046082344 
          V8           V9          V10 
 0.026509914  0.001662791 -0.037777231 

 Quartiles of Marginal Effects:
 
             V2          V3          V4         V5          V6          V7
25% -0.05706707 -0.06862905 -0.10044798 0.01604604 -0.04094673 -0.06062601
50% -0.03422837 -0.05022610 -0.08707770 0.03035765 -0.02676106 -0.04645282
75% -0.01128000 -0.02848051 -0.07264136 0.04410500 -0.01237716 -0.03097548
            V8           V9         V10
25% 0.01151445 -0.013135081 -0.05854663
50% 0.02732267 -0.000107851 -0.03703321
75% 0.04000719  0.016680891 -0.01895419

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.013448022 -0.043806002 -0.122936431 -0.001687898  0.023819497 -0.025999615 
          V8           V9          V10 
-0.015620989 -0.009775173 -0.048683729 

 Quartiles of Marginal Effects:
 
             V2          V3         V4           V5         V6          V7
25% -0.29803559 -0.35248960 -0.3708694 -0.264307917 -0.2185572 -0.30802977
50% -0.01515115 -0.05988059 -0.1077769  0.006463119  0.0148464 -0.07334379
75%  0.27490282  0.27145688  0.1276711  0.239669358  0.2753351  0.22865245
            V8          V9         V10
25% -0.2649453 -0.28166046 -0.37839912
50% -0.0256135 -0.04408175 -0.05639629
75%  0.2416764  0.26643918  0.29320131

 Average Marginal Effects:
 
          V2           V3           V4           V5           V6           V7 
-0.009181844 -0.024649386 -0.036623110  0.005902227 -0.021312032 -0.014942847 
          V8           V9          V10 
 0.016624681  0.007491001 -0.001621079 

 Quartiles of Marginal Effects:
 
              V2          V3          V4          V5          V6          V7
25% -0.009209886 -0.02467899 -0.03664513 0.005889145 -0.02133605 -0.01496802
50% -0.009185753 -0.02465395 -0.03662769 0.005902731 -0.02131447 -0.01494592
75% -0.009158289 -0.02462485 -0.03660663 0.005917207 -0.02129116 -0.01492266
            V8          V9          V10
25% 0.01660645 0.007467567 -0.001647107
50% 0.01662690 0.007491883 -0.001618283
75% 0.01664521 0.007514097 -0.001594970
Radial Basis Function Kernel Regularized Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  lambda        sigma        RMSE       Rsquared      MAE        Selected
  2.663615e-05   120.042038  1.6271877  0.0048059153  1.2237538          
  5.044603e-05     3.817753  1.1771114  0.0015179010  0.9451342          
  7.005156e-05    19.410487  2.4877869  0.0018338272  1.8332051          
  1.055901e-04  1483.077845  1.0569338  0.0006520345  0.8388133          
  1.837492e-04  2312.110564  1.0303140  0.0006231640  0.8202036          
  3.162878e-04   120.502665  1.3273522  0.0063612070  1.0286923          
  5.654866e-04  3452.109899  1.0056269  0.0013257807  0.8000162          
  5.823849e-04  4158.084212  1.0040675  0.0017357989  0.7986449          
  6.082867e-04     5.906735  1.3718366  0.0016096664  1.0937818          
  6.687195e-04     1.470692  1.0165831  0.0010765269  0.8096557          
  1.534553e-03    36.161546  1.4965750  0.0038002197  1.1424794          
  3.171923e-03   218.353998  1.0660427  0.0007900591  0.8449408          
  3.235562e-03   738.614525  1.0190928  0.0006468472  0.8114009          
  3.845881e-02    13.642701  1.2694266  0.0023852252  0.9978489          
  7.860559e-02     6.063984  1.1883410  0.0010267600  0.9481501          
  9.993945e-02   176.372874  1.0100490  0.0007592300  0.8037154          
  1.346308e-01   171.381516  1.0078117  0.0008865841  0.8019781          
  1.364977e-01  9207.463825  0.9975401  0.0027982442  0.7927136  *       
  1.634524e-01    29.023910  1.0714505  0.0012412080  0.8473379          
  6.870773e-01     2.916540  1.0286534  0.0014207914  0.8173006          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 0.1364977 and sigma
 = 9207.464.
[1] "Mon Mar 05 16:26:59 2018"
Least Angle Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  fraction    RMSE       Rsquared      MAE        Selected
  0.08509428  0.9968671  0.0006230935  0.7928226  *       
  0.14056540  0.9969873  0.0007238382  0.7929652          
  0.16908356  0.9970653  0.0007040320  0.7930373          
  0.20472461  0.9972097  0.0005727679  0.7931112          
  0.25284510  0.9973915  0.0005155286  0.7932132          
  0.30001649  0.9975710  0.0005858393  0.7933723          
  0.35048447  0.9977326  0.0007757681  0.7934939          
  0.35304203  0.9977402  0.0007889161  0.7934973          
  0.35682166  0.9977517  0.0008085113  0.7935040          
  0.36504880  0.9977775  0.0008517800  0.7935221          
  0.43719640  0.9980609  0.0012150351  0.7937252          
  0.50026452  0.9984189  0.0014260408  0.7939966          
  0.50198995  0.9984304  0.0014312574  0.7940057          
  0.71699918  1.0001630  0.0020059183  0.7953189          
  0.77909068  1.0007259  0.0022463595  0.7957351          
  0.79994739  1.0008926  0.0023179299  0.7958593          
  0.82582888  1.0011063  0.0024041076  0.7960152          
  0.82702510  1.0011163  0.0024080213  0.7960224          
  0.84267825  1.0012031  0.0024461360  0.7960893          
  0.96740112  1.0018206  0.0026984311  0.7965849          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was fraction = 0.08509428.
[1] "Mon Mar 05 16:27:12 2018"
Least Angle Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  step  RMSE       Rsquared      MAE        Selected
  1     0.9968173           NaN  0.7920966          
  2     0.9967483  0.0009373926  0.7929556  *       
  3     0.9969833  0.0007386465  0.7930695          
  4     0.9975838  0.0010146749  0.7933348          
  5     0.9980709  0.0011295883  0.7935627          
  7     1.0000647  0.0021448624  0.7948258          
  8     0.9997648  0.0029167973  0.7943862          
  9     1.0017028  0.0028084019  0.7963753          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was step = 2.
[1] "Mon Mar 05 16:27:25 2018"
The lasso 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  fraction    RMSE       Rsquared      MAE        Selected
  0.08509428  0.9968671  0.0006230935  0.7928226  *       
  0.14056540  0.9969873  0.0007238382  0.7929652          
  0.16908356  0.9970653  0.0007040320  0.7930373          
  0.20472461  0.9972097  0.0005727679  0.7931112          
  0.25284510  0.9973915  0.0005155286  0.7932132          
  0.30001649  0.9975710  0.0005858393  0.7933723          
  0.35048447  0.9977326  0.0007757681  0.7934939          
  0.35304203  0.9977402  0.0007889161  0.7934973          
  0.35682166  0.9977517  0.0008085113  0.7935040          
  0.36504880  0.9977775  0.0008517800  0.7935221          
  0.43719640  0.9980609  0.0012150351  0.7937252          
  0.50026452  0.9984189  0.0014260408  0.7939966          
  0.50198995  0.9984304  0.0014312574  0.7940057          
  0.71699918  1.0001630  0.0020059183  0.7953189          
  0.77909068  1.0007259  0.0022463595  0.7957351          
  0.79994739  1.0008926  0.0023179299  0.7958593          
  0.82582888  1.0011063  0.0024041076  0.7960152          
  0.82702510  1.0011163  0.0024080213  0.7960224          
  0.84267825  1.0012031  0.0024461360  0.7960893          
  0.96740112  1.0018206  0.0026984311  0.7965849          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was fraction = 0.08509428.
[1] "Mon Mar 05 16:27:39 2018"
Linear Regression with Backwards Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  nvmax  RMSE      Rsquared      MAE        Selected
  2      1.000403  0.0008335876  0.7960907          
  3      1.000362  0.0017010643  0.7958972  *       
  4      1.001545  0.0027224795  0.7949919          
  5      1.002709  0.0030837357  0.7963237          
  7      1.002640  0.0027615775  0.7967167          
  8      1.002022  0.0027748637  0.7966852          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was nvmax = 3.
[1] "Mon Mar 05 16:27:52 2018"
Linear Regression with Forward Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  nvmax  RMSE      Rsquared      MAE        Selected
  2      1.000403  0.0008335876  0.7960907          
  3      1.000362  0.0017010643  0.7958972  *       
  4      1.001545  0.0027224795  0.7949919          
  5      1.002709  0.0030837357  0.7963237          
  7      1.002640  0.0027615775  0.7967167          
  8      1.002022  0.0027748637  0.7966852          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was nvmax = 3.
[1] "Mon Mar 05 16:28:05 2018"
Linear Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.001965  0.002762589  0.7967089

Tuning parameter 'intercept' was held constant at a value of TRUE
[1] "Mon Mar 05 16:28:18 2018"
Start:  AIC=29.77
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS    AIC
- V10   1   0.00000 510.86 27.766
- V9    1   0.00028 510.86 27.767
- V6    1   0.02712 510.89 27.793
- V5    1   0.10398 510.97 27.868
- V2    1   0.14374 511.01 27.907
- V3    1   0.17819 511.04 27.941
- V4    1   0.37477 511.24 28.134
- V7    1   0.59111 511.45 28.346
- V8    1   1.19151 512.05 28.933
<none>              510.86 29.766

Step:  AIC=27.77
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9

       Df Sum of Sq    RSS    AIC
- V9    1   0.00028 510.86 25.767
- V6    1   0.02729 510.89 25.793
- V5    1   0.10405 510.97 25.868
- V2    1   0.14396 511.01 25.907
- V3    1   0.17893 511.04 25.942
- V4    1   0.37488 511.24 26.134
- V7    1   0.59111 511.45 26.346
- V8    1   1.19494 512.06 26.937
<none>              510.86 27.766

Step:  AIC=25.77
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8

       Df Sum of Sq    RSS    AIC
- V6    1   0.02735 510.89 23.793
- V5    1   0.10387 510.97 23.868
- V2    1   0.14435 511.01 23.908
- V3    1   0.18406 511.05 23.947
- V4    1   0.37552 511.24 24.135
- V7    1   0.59087 511.45 24.346
- V8    1   1.19957 512.06 24.942
<none>              510.86 25.767

Step:  AIC=23.79
.outcome ~ V2 + V3 + V4 + V5 + V7 + V8

       Df Sum of Sq    RSS    AIC
- V5    1   0.09954 510.99 21.891
- V2    1   0.14492 511.03 21.935
- V3    1   0.18395 511.07 21.974
- V4    1   0.36813 511.26 22.154
- V7    1   0.59179 511.48 22.373
- V8    1   1.19111 512.08 22.960
<none>              510.89 23.793

Step:  AIC=21.89
.outcome ~ V2 + V3 + V4 + V7 + V8

       Df Sum of Sq    RSS    AIC
- V2    1   0.15679 511.15 20.045
- V3    1   0.17618 511.17 20.064
- V4    1   0.37359 511.36 20.257
- V7    1   0.58007 511.57 20.459
- V8    1   1.16307 512.15 21.030
<none>              510.99 21.891

Step:  AIC=20.04
.outcome ~ V3 + V4 + V7 + V8

       Df Sum of Sq    RSS    AIC
- V3    1   0.16539 511.31 18.207
- V4    1   0.36291 511.51 18.400
- V7    1   0.54621 511.69 18.580
- V8    1   1.19175 512.34 19.211
<none>              511.15 20.045

Step:  AIC=18.21
.outcome ~ V4 + V7 + V8

       Df Sum of Sq    RSS    AIC
- V4    1   0.33449 511.65 16.534
- V7    1   0.56920 511.88 16.764
- V8    1   1.21942 512.53 17.400
<none>              511.31 18.207

Step:  AIC=16.53
.outcome ~ V7 + V8

       Df Sum of Sq    RSS    AIC
- V7    1   0.52749 512.17 15.051
- V8    1   1.31815 512.96 15.823
<none>              511.65 16.534

Step:  AIC=15.05
.outcome ~ V8

       Df Sum of Sq    RSS    AIC
- V8    1    1.3347 513.51 14.354
<none>              512.17 15.051

Step:  AIC=14.35
.outcome ~ 1

Start:  AIC=-2.91
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V2    1    0.0052 480.61 -4.9048
- V8    1    0.0185 480.62 -4.8908
- V7    1    0.0306 480.63 -4.8782
- V5    1    0.0463 480.65 -4.8618
- V10   1    0.3965 481.00 -4.4954
- V9    1    0.5428 481.15 -4.3424
<none>              480.60 -2.9102
- V3    1    2.0109 482.61 -2.8100
- V6    1    3.2948 483.90 -1.4736
- V4    1    3.5684 484.17 -1.1893

Step:  AIC=-4.9
.outcome ~ V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V8    1    0.0186 480.63 -6.8853
- V7    1    0.0296 480.64 -6.8738
- V5    1    0.0440 480.65 -6.8588
- V10   1    0.3926 481.00 -6.4941
- V9    1    0.5506 481.16 -6.3289
<none>              480.61 -4.9048
- V3    1    2.0081 482.62 -4.8075
- V6    1    3.3025 483.91 -3.4603
- V4    1    3.5633 484.17 -3.1892

Step:  AIC=-6.89
.outcome ~ V3 + V4 + V5 + V6 + V7 + V9 + V10

       Df Sum of Sq    RSS     AIC
- V7    1    0.0279 480.66 -8.8561
- V5    1    0.0461 480.67 -8.8371
- V10   1    0.3856 481.01 -8.4819
- V9    1    0.5529 481.18 -8.3071
<none>              480.63 -6.8853
- V3    1    2.0118 482.64 -6.7843
- V6    1    3.3135 483.94 -5.4295
- V4    1    3.5936 484.22 -5.1385

Step:  AIC=-8.86
.outcome ~ V3 + V4 + V5 + V6 + V9 + V10

       Df Sum of Sq    RSS      AIC
- V5    1    0.0411 480.70 -10.8132
- V10   1    0.3744 481.03 -10.4645
- V9    1    0.5626 481.22 -10.2677
<none>              480.66  -8.8561
- V3    1    2.0001 482.66  -8.7674
- V6    1    3.3054 483.96  -7.4089
- V4    1    3.5704 484.23  -7.1335

Step:  AIC=-10.81
.outcome ~ V3 + V4 + V6 + V9 + V10

       Df Sum of Sq    RSS      AIC
- V10   1    0.3719 481.07 -12.4242
- V9    1    0.5624 481.26 -12.2250
<none>              480.70 -10.8132
- V3    1    2.0013 482.70 -10.7234
- V6    1    3.3636 484.06  -9.3058
- V4    1    3.5457 484.24  -9.1165

Step:  AIC=-12.42
.outcome ~ V3 + V4 + V6 + V9

       Df Sum of Sq    RSS     AIC
- V9    1    0.5865 481.65 -13.811
<none>              481.07 -12.424
- V3    1    1.9800 483.05 -12.358
- V4    1    3.5062 484.57 -10.771
- V6    1    3.5109 484.58 -10.767

Step:  AIC=-13.81
.outcome ~ V3 + V4 + V6

       Df Sum of Sq    RSS     AIC
<none>              481.65 -13.811
- V3    1    2.2818 483.94 -13.434
- V4    1    3.4096 485.06 -12.263
- V6    1    3.5466 485.20 -12.121
Start:  AIC=1.29
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS      AIC
- V9    1    0.0005 481.64 -0.70626
- V6    1    0.4188 482.06 -0.27228
- V8    1    0.4287 482.07 -0.26200
- V2    1    0.4356 482.07 -0.25477
- V5    1    0.5206 482.16 -0.16661
- V10   1    0.6977 482.34  0.01700
- V7    1    1.1116 482.75  0.44580
- V3    1    1.2447 482.88  0.58366
<none>              481.64  1.29319
- V4    1    3.2810 484.92  2.68775

Step:  AIC=-0.71
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V10

       Df Sum of Sq    RSS      AIC
- V6    1    0.4183 482.06 -2.27224
- V8    1    0.4318 482.07 -2.25818
- V2    1    0.4368 482.08 -2.25305
- V5    1    0.5214 482.16 -2.16527
- V10   1    0.6977 482.34 -1.98252
- V7    1    1.1126 482.75 -1.55259
- V3    1    1.2531 482.89 -1.40707
<none>              481.64 -0.70626
- V4    1    3.2805 484.92  0.68776

Step:  AIC=-2.27
.outcome ~ V2 + V3 + V4 + V5 + V7 + V8 + V10

       Df Sum of Sq    RSS     AIC
- V8    1    0.4126 482.47 -3.8445
- V2    1    0.4829 482.54 -3.7716
- V5    1    0.5865 482.64 -3.6643
- V10   1    0.6597 482.72 -3.5884
- V7    1    1.1522 483.21 -3.0786
- V3    1    1.3284 483.39 -2.8963
<none>              482.06 -2.2722
- V4    1    3.2819 485.34 -0.8797

Step:  AIC=-3.84
.outcome ~ V2 + V3 + V4 + V5 + V7 + V10

       Df Sum of Sq    RSS     AIC
- V2    1    0.4640 482.93 -5.3638
- V5    1    0.6634 483.13 -5.1575
- V10   1    0.6670 483.14 -5.1537
- V7    1    1.1688 483.64 -4.6347
- V3    1    1.4141 483.88 -4.3812
<none>              482.47 -3.8445
- V4    1    3.4024 485.87 -2.3309

Step:  AIC=-5.36
.outcome ~ V3 + V4 + V5 + V7 + V10

       Df Sum of Sq    RSS     AIC
- V5    1    0.6126 483.55 -6.7300
- V10   1    0.7566 483.69 -6.5811
- V7    1    1.1848 484.12 -6.1386
- V3    1    1.4449 484.38 -5.8701
<none>              482.93 -5.3638
- V4    1    3.2858 486.22 -3.9735

Step:  AIC=-6.73
.outcome ~ V3 + V4 + V7 + V10

       Df Sum of Sq    RSS     AIC
- V10   1    0.8624 484.41 -7.8391
- V7    1    1.1041 484.65 -7.5896
- V3    1    1.5892 485.14 -7.0895
<none>              483.55 -6.7300
- V4    1    3.2540 486.80 -5.3766

Step:  AIC=-7.84
.outcome ~ V3 + V4 + V7

       Df Sum of Sq    RSS     AIC
- V7    1    1.1250 485.53 -8.6792
- V3    1    1.5874 486.00 -8.2032
<none>              484.41 -7.8391
- V4    1    3.2214 487.63 -6.5251

Step:  AIC=-8.68
.outcome ~ V3 + V4

       Df Sum of Sq    RSS     AIC
- V3    1    1.5071 487.04 -9.1296
<none>              485.53 -8.6792
- V4    1    3.1396 488.67 -7.4565

Step:  AIC=-9.13
.outcome ~ V4

       Df Sum of Sq    RSS     AIC
<none>              487.04 -9.1296
- V4    1     3.257 490.30 -7.7971
Start:  AIC=7.59
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10

       Df Sum of Sq    RSS    AIC
- V10   1    0.0054 739.70 5.5963
- V5    1    0.0782 739.77 5.6703
- V9    1    0.0902 739.78 5.6824
- V2    1    0.2250 739.92 5.8195
- V8    1    0.5842 740.28 6.1844
- V7    1    0.6354 740.33 6.2365
- V6    1    1.1874 740.88 6.7969
- V3    1    1.5511 741.24 7.1661
<none>              739.69 7.5908
- V4    1    3.2520 742.94 8.8896

Step:  AIC=5.6
.outcome ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9

       Df Sum of Sq    RSS    AIC
- V5    1    0.0798 739.78 3.6775
- V9    1    0.0881 739.79 3.6859
- V2    1    0.2300 739.93 3.8301
- V8    1    0.5842 740.28 4.1900
- V7    1    0.6391 740.34 4.2458
- V6    1    1.1821 740.88 4.7971
- V3    1    1.5575 741.26 5.1781
<none>              739.70 5.5963
- V4    1    3.2515 742.95 6.8947

Step:  AIC=3.68
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8 + V9

       Df Sum of Sq    RSS    AIC
- V9    1    0.0902 739.87 1.7691
- V2    1    0.2148 739.99 1.8958
- V8    1    0.6095 740.39 2.2968
- V7    1    0.6252 740.40 2.3127
- V6    1    1.2196 741.00 2.9162
- V3    1    1.5815 741.36 3.2834
<none>              739.78 3.6775
- V4    1    3.2277 743.01 4.9514

Step:  AIC=1.77
.outcome ~ V2 + V3 + V4 + V6 + V7 + V8

       Df Sum of Sq    RSS      AIC
- V2    1    0.2242 740.09 -0.00301
- V8    1    0.6283 740.50  0.40748
- V7    1    0.6289 740.50  0.40810
- V6    1    1.2136 741.08  1.00166
- V3    1    1.6814 741.55  1.47619
<none>              739.87  1.76914
- V4    1    3.2173 743.09  3.03211

Step:  AIC=0
.outcome ~ V3 + V4 + V6 + V7 + V8

       Df Sum of Sq    RSS      AIC
- V7    1    0.6098 740.70 -1.38366
- V8    1    0.6313 740.72 -1.36182
- V6    1    1.2364 741.33 -0.74772
- V3    1    1.6676 741.76 -0.31048
<none>              740.09 -0.00301
- V4    1    3.1663 743.26  1.20742

Step:  AIC=-1.38
.outcome ~ V3 + V4 + V6 + V8

       Df Sum of Sq    RSS      AIC
- V8    1   0.62381 741.33 -2.75060
- V6    1   1.24107 741.94 -2.12472
- V3    1   1.65794 742.36 -1.70231
<none>              740.70 -1.38366
- V4    1   3.06038 743.76 -0.28301

Step:  AIC=-2.75
.outcome ~ V3 + V4 + V6

       Df Sum of Sq    RSS     AIC
- V6    1    1.2266 742.55 -3.5074
- V3    1    1.7291 743.05 -2.9987
<none>              741.33 -2.7506
- V4    1    3.2253 744.55 -1.4860

Step:  AIC=-3.51
.outcome ~ V3 + V4

       Df Sum of Sq    RSS     AIC
- V3    1    1.7803 744.33 -3.7066
<none>              742.55 -3.5074
- V4    1    3.2317 745.78 -2.2416

Step:  AIC=-3.71
.outcome ~ V4

       Df Sum of Sq    RSS     AIC
<none>              744.33 -3.7066
- V4    1    3.1395 747.47 -2.5414
Linear Regression with Stepwise Selection 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE      Rsquared      MAE      
  1.000651  0.0006404777  0.7968362

[1] "Mon Mar 05 16:28:33 2018"
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :20    NA's   :20    NA's   :20   
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :8     NA's   :8     NA's   :8    
Error : Stopping
In addition: There were 25 warnings (use warnings() to see them)
Something is wrong; all the RMSE metric values are missing:
      RMSE        Rsquared        MAE     
 Min.   : NA   Min.   : NA   Min.   : NA  
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA  
 Median : NA   Median : NA   Median : NA  
 Mean   :NaN   Mean   :NaN   Mean   :NaN  
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA  
 Max.   : NA   Max.   : NA   Max.   : NA  
 NA's   :9     NA's   :9     NA's   :9    
Error : Stopping
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:29:10 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "logreg"                  
Error : package RWeka is required
Error : package RWeka is required
Error : package RWeka is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:29:23 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "M5"                      
Error : package RWeka is required
Error : package RWeka is required
Error : package RWeka is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:29:36 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "M5Rules"                 
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:29:49 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "mlpKerasDecay"           
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
Error : Could not start a sequential model. `tensorflow` might not be installed. See `?install_tensorflow`.
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:30:02 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "mlpKerasDropout"         
Timing stopped at: 0.05 0 0.04
Error in (function (x, y, family = c("gaussian", "binomial", "poisson",  : 
  Null model produced by the full fit (all coefficients are zero).
           Please try a different parameter setting.
In addition: There were 27 warnings (use warnings() to see them)
Timing stopped at: 0.04 0 0.04
Error in (function (x, y, family = c("gaussian", "binomial", "poisson",  : 
  Null model produced by the full fit (all coefficients are zero).
           Please try a different parameter setting.
In addition: There were 17 warnings (use warnings() to see them)
Timing stopped at: 0.06 0 0.06
Error in (function (x, y, family = c("gaussian", "binomial", "poisson",  : 
  Null model produced by the full fit (all coefficients are zero).
           Please try a different parameter setting.
In addition: There were 50 or more warnings (use warnings() to see the first 50)
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:32:26 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "msaenet"                 
# weights:  177
initial  value 691.788302 
iter  10 value 515.428888
iter  20 value 514.513086
final  value 514.512974 
converged
# weights:  45
initial  value 648.491127 
iter  10 value 511.515153
iter  20 value 494.360780
iter  30 value 488.166608
iter  40 value 487.293593
iter  50 value 487.109168
iter  60 value 487.029699
iter  70 value 487.025298
iter  70 value 487.025295
iter  70 value 487.025295
final  value 487.025295 
converged
# weights:  188
initial  value 624.207468 
iter  10 value 513.856934
iter  20 value 491.659163
iter  30 value 479.029086
iter  40 value 467.687701
iter  50 value 454.096656
iter  60 value 442.327040
iter  70 value 431.174413
iter  80 value 423.615785
iter  90 value 419.345324
iter 100 value 416.521189
final  value 416.521189 
stopped after 100 iterations
# weights:  177
initial  value 560.307258 
iter  10 value 513.843502
iter  20 value 510.367681
iter  30 value 476.654539
iter  40 value 453.989103
iter  50 value 430.790682
iter  60 value 412.673531
iter  70 value 401.110513
iter  80 value 393.953717
iter  90 value 388.056313
iter 100 value 383.343567
final  value 383.343567 
stopped after 100 iterations
# weights:  221
initial  value 817.552955 
iter  10 value 517.057073
iter  20 value 516.623735
final  value 516.622984 
converged
# weights:  188
initial  value 641.417694 
iter  10 value 512.640180
iter  20 value 472.155425
iter  30 value 441.145849
iter  40 value 413.275269
iter  50 value 399.861315
iter  60 value 389.394091
iter  70 value 384.818126
iter  80 value 372.516926
iter  90 value 368.493253
iter 100 value 366.132334
final  value 366.132334 
stopped after 100 iterations
# weights:  34
initial  value 688.538936 
iter  10 value 519.477587
iter  20 value 519.061499
final  value 519.059898 
converged
# weights:  122
initial  value 595.360017 
iter  10 value 513.801457
iter  20 value 497.754033
iter  30 value 477.489555
iter  40 value 466.957826
iter  50 value 458.152425
iter  60 value 449.714024
iter  70 value 445.408865
iter  80 value 442.328148
iter  90 value 440.478808
iter 100 value 435.870859
final  value 435.870859 
stopped after 100 iterations
# weights:  188
initial  value 775.565795 
iter  10 value 513.784851
iter  20 value 513.739833
final  value 513.739256 
converged
# weights:  89
initial  value 650.387169 
iter  10 value 514.914446
iter  20 value 514.726369
final  value 514.725913 
converged
# weights:  89
initial  value 642.543474 
iter  10 value 525.348382
iter  20 value 525.292781
final  value 525.292607 
converged
# weights:  89
initial  value 589.070086 
iter  10 value 513.787460
iter  20 value 513.740725
iter  30 value 513.740659
iter  40 value 513.740585
iter  50 value 513.740498
iter  60 value 513.740394
iter  70 value 513.740269
iter  80 value 513.740112
iter  90 value 513.739910
iter 100 value 513.739637
final  value 513.739637 
stopped after 100 iterations
# weights:  56
initial  value 660.102612 
iter  10 value 514.051517
iter  20 value 513.746872
iter  30 value 513.746620
iter  40 value 513.746306
iter  50 value 513.745896
iter  60 value 513.745316
iter  70 value 513.744400
iter  80 value 513.742686
iter  90 value 513.738311
iter 100 value 513.714176
final  value 513.714176 
stopped after 100 iterations
# weights:  122
initial  value 784.706842 
iter  10 value 515.060205
iter  20 value 513.752806
iter  30 value 513.752016
iter  40 value 513.750986
iter  50 value 513.749473
iter  60 value 513.746722
iter  70 value 513.738950
iter  80 value 513.629107
iter  90 value 496.020528
iter 100 value 473.981368
final  value 473.981368 
stopped after 100 iterations
# weights:  23
initial  value 735.226343 
iter  10 value 514.663687
iter  20 value 499.770882
iter  30 value 483.989592
iter  40 value 480.317687
iter  50 value 479.328282
iter  60 value 479.180114
iter  70 value 479.174768
final  value 479.174278 
converged
# weights:  78
initial  value 800.300918 
iter  10 value 511.629700
iter  20 value 483.148441
iter  30 value 471.361158
iter  40 value 464.739009
iter  50 value 461.723008
iter  60 value 456.287137
iter  70 value 454.581749
iter  80 value 450.438066
iter  90 value 448.507552
iter 100 value 447.233819
final  value 447.233819 
stopped after 100 iterations
# weights:  67
initial  value 643.192695 
iter  10 value 513.890118
iter  20 value 513.742137
iter  30 value 513.741792
iter  40 value 513.741327
iter  50 value 513.740635
iter  60 value 513.739440
iter  70 value 513.736859
iter  80 value 513.728252
iter  90 value 513.613259
iter 100 value 491.136524
final  value 491.136524 
stopped after 100 iterations
# weights:  100
initial  value 541.744496 
iter  10 value 513.964500
iter  20 value 498.842565
iter  30 value 482.064759
iter  40 value 478.258668
iter  50 value 473.787297
iter  60 value 471.275480
iter  70 value 462.743529
iter  80 value 457.146949
iter  90 value 454.666340
iter 100 value 453.025448
final  value 453.025448 
stopped after 100 iterations
# weights:  89
initial  value 689.293190 
iter  10 value 513.845571
final  value 513.741121 
converged
# weights:  166
initial  value 788.431395 
iter  10 value 515.244861
iter  20 value 503.878012
iter  30 value 499.000126
iter  40 value 496.145347
iter  50 value 495.475319
iter  60 value 494.921111
iter  70 value 493.751416
iter  80 value 492.079890
iter  90 value 490.238544
iter 100 value 487.631634
final  value 487.631634 
stopped after 100 iterations
# weights:  177
initial  value 617.155687 
iter  10 value 489.085648
iter  20 value 486.510608
iter  30 value 486.451129
iter  40 value 486.448844
final  value 486.448835 
converged
# weights:  45
initial  value 601.418719 
iter  10 value 481.946905
iter  20 value 468.064910
iter  30 value 463.436888
iter  40 value 459.641212
iter  50 value 459.612644
final  value 459.612160 
converged
# weights:  188
initial  value 697.023041 
iter  10 value 486.392824
iter  20 value 465.174565
iter  30 value 451.550820
iter  40 value 441.101946
iter  50 value 433.307624
iter  60 value 426.458793
iter  70 value 419.281343
iter  80 value 414.514425
iter  90 value 408.440217
iter 100 value 405.041482
final  value 405.041482 
stopped after 100 iterations
# weights:  177
initial  value 585.800672 
iter  10 value 492.432463
iter  20 value 474.048114
iter  30 value 455.788828
iter  40 value 451.708043
iter  50 value 445.452087
iter  60 value 441.501748
iter  70 value 435.825567
iter  80 value 432.175423
iter  90 value 421.765047
iter 100 value 416.686068
final  value 416.686068 
stopped after 100 iterations
# weights:  221
initial  value 672.209562 
iter  10 value 494.080527
iter  20 value 493.371089
final  value 493.366227 
converged
# weights:  188
initial  value 622.660271 
iter  10 value 491.576519
iter  20 value 459.770009
iter  30 value 430.492058
iter  40 value 418.682474
iter  50 value 413.420530
iter  60 value 409.549679
iter  70 value 406.957056
iter  80 value 405.655812
iter  90 value 400.689476
iter 100 value 396.124073
final  value 396.124073 
stopped after 100 iterations
# weights:  34
initial  value 563.738289 
iter  10 value 494.391603
iter  20 value 493.608926
final  value 493.608026 
converged
# weights:  122
initial  value 518.076581 
iter  10 value 492.574987
iter  20 value 491.633430
iter  30 value 480.803816
iter  40 value 451.050896
iter  50 value 443.907914
iter  60 value 440.885929
iter  70 value 433.662878
iter  80 value 422.833375
iter  90 value 416.371688
iter 100 value 409.798191
final  value 409.798191 
stopped after 100 iterations
# weights:  188
initial  value 514.461635 
final  value 491.710580 
converged
# weights:  89
initial  value 717.727474 
iter  10 value 488.950728
iter  20 value 487.652627
iter  30 value 487.646861
final  value 487.646435 
converged
# weights:  89
initial  value 683.827656 
iter  10 value 502.565907
iter  20 value 501.650408
final  value 501.649270 
converged
# weights:  89
initial  value 632.486622 
iter  10 value 491.727608
iter  20 value 491.605806
iter  30 value 491.605704
iter  40 value 491.605594
iter  50 value 491.605475
iter  60 value 491.605341
iter  70 value 491.605184
iter  80 value 491.604995
iter  90 value 491.604759
iter 100 value 491.604450
final  value 491.604450 
stopped after 100 iterations
# weights:  56
initial  value 600.154863 
iter  10 value 491.806138
iter  20 value 491.610138
iter  30 value 491.609110
iter  40 value 491.607430
iter  50 value 491.604054
iter  60 value 491.593749
iter  70 value 491.473185
iter  80 value 475.660764
iter  90 value 443.040190
iter 100 value 436.791662
final  value 436.791662 
stopped after 100 iterations
# weights:  122
initial  value 567.413717 
iter  10 value 492.342183
iter  20 value 491.609650
iter  30 value 491.597104
iter  40 value 489.741982
iter  50 value 459.070476
iter  60 value 445.981860
iter  70 value 436.577061
iter  80 value 428.504535
iter  90 value 425.560834
iter 100 value 420.465734
final  value 420.465734 
stopped after 100 iterations
# weights:  23
initial  value 529.985320 
iter  10 value 493.159050
iter  20 value 483.515522
iter  30 value 461.799817
iter  40 value 460.717507
iter  50 value 460.397587
iter  60 value 460.311349
iter  70 value 460.305205
final  value 460.305156 
converged
# weights:  78
initial  value 746.598624 
iter  10 value 481.089617
iter  20 value 458.367215
iter  30 value 442.661065
iter  40 value 431.144231
iter  50 value 426.369912
iter  60 value 423.994456
iter  70 value 423.053457
iter  80 value 422.581083
iter  90 value 421.576518
iter 100 value 417.958365
final  value 417.958365 
stopped after 100 iterations
# weights:  67
initial  value 562.180657 
iter  10 value 491.680596
final  value 491.608566 
converged
# weights:  100
initial  value 518.564326 
iter  10 value 488.750269
iter  20 value 468.130023
iter  30 value 450.373785
iter  40 value 437.622357
iter  50 value 426.202818
iter  60 value 415.608453
iter  70 value 405.431866
iter  80 value 403.668341
iter  90 value 403.308865
iter 100 value 403.045737
final  value 403.045737 
stopped after 100 iterations
# weights:  89
initial  value 740.069751 
iter  10 value 491.702174
iter  20 value 491.421928
iter  30 value 455.241133
iter  40 value 440.934471
iter  50 value 439.512753
iter  60 value 439.316622
iter  70 value 439.117726
iter  80 value 438.663637
iter  90 value 438.281037
iter 100 value 437.845750
final  value 437.845750 
stopped after 100 iterations
# weights:  166
initial  value 677.537241 
iter  10 value 493.468909
iter  20 value 478.960546
iter  30 value 474.137878
iter  40 value 470.971195
iter  50 value 468.037656
iter  60 value 465.733897
iter  70 value 463.952042
iter  80 value 461.980211
iter  90 value 460.686738
iter 100 value 459.234025
final  value 459.234025 
stopped after 100 iterations
# weights:  177
initial  value 659.771597 
iter  10 value 492.062949
iter  20 value 487.377717
iter  30 value 487.194727
iter  40 value 487.161499
final  value 487.161157 
converged
# weights:  45
initial  value 593.196407 
iter  10 value 483.325332
iter  20 value 467.959685
iter  30 value 464.034667
iter  40 value 463.743633
iter  50 value 463.734276
final  value 463.734179 
converged
# weights:  188
initial  value 506.462720 
iter  10 value 490.485235
iter  20 value 471.621358
iter  30 value 458.253280
iter  40 value 448.559139
iter  50 value 441.686136
iter  60 value 431.729614
iter  70 value 426.457169
iter  80 value 423.901015
iter  90 value 421.994568
iter 100 value 419.490598
final  value 419.490598 
stopped after 100 iterations
# weights:  177
initial  value 703.980319 
iter  10 value 490.270439
iter  20 value 447.956041
iter  30 value 428.126420
iter  40 value 410.159244
iter  50 value 400.874729
iter  60 value 391.479552
iter  70 value 388.938435
iter  80 value 386.754924
iter  90 value 385.007977
iter 100 value 382.807869
final  value 382.807869 
stopped after 100 iterations
# weights:  221
initial  value 885.488030 
iter  10 value 493.114620
iter  20 value 492.721206
final  value 492.719969 
converged
# weights:  188
initial  value 628.312134 
iter  10 value 484.381195
iter  20 value 454.181900
iter  30 value 447.506862
iter  40 value 444.216471
iter  50 value 441.270064
iter  60 value 438.957610
iter  70 value 437.222383
iter  80 value 434.923247
iter  90 value 430.560018
iter 100 value 424.167636
final  value 424.167636 
stopped after 100 iterations
# weights:  34
initial  value 580.986857 
iter  10 value 493.913576
iter  20 value 493.618308
final  value 493.618075 
converged
# weights:  122
initial  value 571.746925 
iter  10 value 475.335092
iter  20 value 438.696601
iter  30 value 423.471528
iter  40 value 409.349986
iter  50 value 401.042691
iter  60 value 394.052279
iter  70 value 389.022438
iter  80 value 385.438174
iter  90 value 383.067980
iter 100 value 379.680382
final  value 379.680382 
stopped after 100 iterations
# weights:  188
initial  value 593.660096 
iter  10 value 490.790493
iter  20 value 490.760965
iter  20 value 490.760965
final  value 490.760965 
converged
# weights:  89
initial  value 523.205768 
iter  10 value 488.398821
iter  20 value 488.085953
iter  30 value 488.066763
iter  40 value 488.066006
final  value 488.065891 
converged
# weights:  89
initial  value 673.918964 
iter  10 value 501.366762
iter  20 value 501.025571
final  value 501.024733 
converged
# weights:  89
initial  value 517.859118 
iter  10 value 490.774447
iter  20 value 490.759636
iter  30 value 490.758239
iter  40 value 490.755167
iter  50 value 490.744005
iter  60 value 490.157193
iter  70 value 458.034611
iter  80 value 442.212215
iter  90 value 439.436210
iter 100 value 439.093606
final  value 439.093606 
stopped after 100 iterations
# weights:  56
initial  value 552.480682 
iter  10 value 490.895118
iter  20 value 490.768587
iter  30 value 490.768278
iter  40 value 490.767883
iter  50 value 490.767350
iter  60 value 490.766570
iter  70 value 490.765286
iter  80 value 490.762714
iter  90 value 490.755063
iter 100 value 490.673874
final  value 490.673874 
stopped after 100 iterations
# weights:  122
initial  value 629.295687 
iter  10 value 492.113281
iter  20 value 490.774358
iter  30 value 490.773280
iter  40 value 490.771661
iter  50 value 490.768698
iter  60 value 490.760574
iter  70 value 490.657817
iter  80 value 466.727980
iter  90 value 453.421212
iter 100 value 451.577403
final  value 451.577403 
stopped after 100 iterations
# weights:  23
initial  value 682.545605 
iter  10 value 491.520879
iter  20 value 489.224808
iter  30 value 468.082552
iter  40 value 460.730992
iter  50 value 453.964648
iter  60 value 452.724518
iter  70 value 452.567244
iter  80 value 452.513464
iter  90 value 452.446332
iter 100 value 452.426731
final  value 452.426731 
stopped after 100 iterations
# weights:  78
initial  value 565.035002 
iter  10 value 477.535911
iter  20 value 438.767490
iter  30 value 428.715627
iter  40 value 424.329679
iter  50 value 411.013644
iter  60 value 404.063572
iter  70 value 399.294124
iter  80 value 397.744570
iter  90 value 396.951909
iter 100 value 396.704030
final  value 396.704030 
stopped after 100 iterations
# weights:  67
initial  value 702.697442 
iter  10 value 490.950819
iter  20 value 490.762066
iter  30 value 490.760037
iter  40 value 490.755206
iter  50 value 490.730119
iter  60 value 479.592044
iter  70 value 455.367466
iter  80 value 454.089198
iter  90 value 452.090299
iter 100 value 444.421709
final  value 444.421709 
stopped after 100 iterations
# weights:  100
initial  value 536.188805 
iter  10 value 488.900606
iter  20 value 458.564010
iter  30 value 449.328832
iter  40 value 443.836271
iter  50 value 435.580849
iter  60 value 432.364785
iter  70 value 430.082555
iter  80 value 429.033606
iter  90 value 427.403675
iter 100 value 425.301828
final  value 425.301828 
stopped after 100 iterations
# weights:  89
initial  value 551.513989 
iter  10 value 490.792509
iter  20 value 484.421649
iter  30 value 450.813040
iter  40 value 447.586474
iter  50 value 445.365752
iter  60 value 442.946482
iter  70 value 442.479758
iter  80 value 442.343138
iter  90 value 442.018668
iter 100 value 439.104253
final  value 439.104253 
stopped after 100 iterations
# weights:  166
initial  value 610.335918 
iter  10 value 490.213845
iter  20 value 475.629275
iter  30 value 471.260104
iter  40 value 470.212129
iter  50 value 468.980345
iter  60 value 467.163334
iter  70 value 466.818233
iter  80 value 465.961826
iter  90 value 465.712875
iter 100 value 465.500612
final  value 465.500612 
stopped after 100 iterations
# weights:  89
initial  value 840.268236 
iter  10 value 748.152259
iter  20 value 748.052166
iter  30 value 748.051714
iter  40 value 748.051021
iter  50 value 748.049820
iter  60 value 748.047240
iter  70 value 748.038333
iter  80 value 747.695460
iter  90 value 711.401838
iter 100 value 696.570567
final  value 696.570567 
stopped after 100 iterations
Neural Network 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  size  decay         RMSE       Rsquared      MAE        Selected
   2    7.603262e-03  1.0238627  0.0032887958  0.8115816          
   3    1.340566e+00  0.9988640  0.0054112690  0.7904711          
   4    1.169352e-01  1.0129548  0.0033340676  0.8035712          
   5    1.750871e-04  1.0229837  0.0076756176  0.8135546          
   6    8.994709e-05  0.9983897  0.0094024537  0.7925131          
   7    7.559708e-03  1.0538968  0.0004337405  0.8371525          
   8    3.729581e-05  1.0240163  0.0055559424  0.8097952          
   8    4.930297e-05  0.9917179  0.0147224963  0.7901474  *       
   8    6.965925e-01  0.9981227  0.0060412875  0.7908901          
   8    5.606832e+00  0.9999749  0.0041198084  0.7902732          
   9    4.598641e-02  1.0508801  0.0023674599  0.8211122          
  11    4.981650e-04  1.0200211  0.0191043228  0.8104302          
  11    3.099262e-03  1.0548437  0.0032026337  0.8340927          
  15    1.984492e-01  1.0190956  0.0037977582  0.8021569          
  16    4.269257e-03  1.0507414  0.0048914210  0.8249904          
  16    6.696733e-01  0.9993309  0.0066674734  0.7923557          
  17    1.131853e-05  0.9971584  0.0003062985  0.7938169          
  17    4.457117e-03  1.0398386  0.0080209590  0.8278612          
  17    6.395376e-02  1.0583319  0.0021205665  0.8348743          
  20    2.007697e+00  0.9974131  0.0038389629  0.7905582          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 8 and decay = 4.930297e-05.
[1] "Mon Mar 05 16:33:28 2018"
Non-Negative Least Squares 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE     Rsquared     MAE     
  0.99942  0.000546762  0.796478

[1] "Mon Mar 05 16:33:41 2018"
Non-Informative Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE       Rsquared  MAE      
  0.9968173  NaN       0.7920966

[1] "Mon Mar 05 16:33:54 2018"
Parallel Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  mtry  RMSE      Rsquared     MAE        Selected
  1     1.027315  0.011580002  0.8164830  *       
  2     1.035747  0.013564190  0.8206332          
  3     1.038397  0.010670717  0.8237187          
  4     1.039475  0.009867178  0.8239006          
  5     1.041421  0.009141219  0.8266293          
  7     1.042538  0.008592320  0.8278966          
  8     1.042484  0.008035431  0.8270311          
  9     1.043032  0.008400468  0.8287291          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 1.
[1] "Mon Mar 05 16:35:17 2018"
Error in varImp[, "%IncMSE"] : subscript out of bounds
In addition: Warning messages:
1: package 'mxnet' is not available (for R version 3.4.3) 
2: package 'mxnet' is not available (for R version 3.4.3) 
3: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
4: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
# weights:  177
initial  value 682.291651 
iter  10 value 515.310983
iter  20 value 514.497671
final  value 514.497650 
converged
# weights:  45
initial  value 650.160176 
iter  10 value 513.340730
iter  20 value 496.547733
iter  30 value 489.883757
iter  40 value 487.604378
iter  50 value 487.313313
iter  60 value 487.296302
final  value 487.295491 
converged
# weights:  188
initial  value 625.365196 
iter  10 value 513.803130
iter  20 value 501.301656
iter  30 value 484.816353
iter  40 value 474.084176
iter  50 value 463.970446
iter  60 value 454.723757
iter  70 value 449.504248
iter  80 value 443.154588
iter  90 value 440.509962
iter 100 value 435.846126
final  value 435.846126 
stopped after 100 iterations
# weights:  177
initial  value 557.098623 
iter  10 value 513.809321
iter  20 value 500.845382
iter  30 value 452.764148
iter  40 value 436.682993
iter  50 value 424.353720
iter  60 value 417.217769
iter  70 value 410.966175
iter  80 value 405.789294
iter  90 value 400.635935
iter 100 value 397.697874
final  value 397.697874 
stopped after 100 iterations
# weights:  221
initial  value 813.825375 
iter  10 value 516.686047
iter  20 value 516.617053
final  value 516.616796 
converged
# weights:  188
initial  value 644.531988 
iter  10 value 513.940817
iter  20 value 501.410323
iter  30 value 465.075360
iter  40 value 457.210222
iter  50 value 451.267782
iter  60 value 440.678292
iter  70 value 430.818707
iter  80 value 419.212726
iter  90 value 408.917140
iter 100 value 400.820130
final  value 400.820130 
stopped after 100 iterations
# weights:  34
initial  value 686.084452 
iter  10 value 520.038733
iter  20 value 519.045478
final  value 519.041652 
converged
# weights:  122
initial  value 595.640865 
iter  10 value 513.915685
iter  20 value 497.716422
iter  30 value 478.825840
iter  40 value 475.640452
iter  50 value 470.746391
iter  60 value 464.128454
iter  70 value 462.300371
iter  80 value 461.389888
iter  90 value 456.388332
iter 100 value 452.920907
final  value 452.920907 
stopped after 100 iterations
# weights:  188
initial  value 771.364348 
iter  10 value 513.785722
iter  20 value 513.739845
final  value 513.739465 
converged
# weights:  89
initial  value 648.386121 
iter  10 value 515.076349
iter  20 value 514.704403
final  value 514.703911 
converged
# weights:  89
initial  value 644.002168 
iter  10 value 525.340977
final  value 525.286044 
converged
# weights:  89
initial  value 585.394827 
iter  10 value 513.789095
final  value 513.740929 
converged
# weights:  56
initial  value 651.190931 
iter  10 value 514.057942
iter  20 value 513.747444
iter  30 value 513.747263
iter  40 value 513.747055
iter  50 value 513.746809
iter  60 value 513.746505
iter  70 value 513.746111
iter  80 value 513.745560
iter  90 value 513.744708
iter 100 value 513.743166
final  value 513.743166 
stopped after 100 iterations
# weights:  122
initial  value 787.602817 
iter  10 value 515.055797
iter  20 value 513.752616
iter  30 value 513.751795
iter  40 value 513.750711
iter  50 value 513.749087
iter  60 value 513.746027
iter  70 value 513.736629
iter  80 value 513.487032
iter  90 value 484.284002
iter 100 value 475.706892
final  value 475.706892 
stopped after 100 iterations
# weights:  23
initial  value 735.697564 
iter  10 value 514.577689
iter  20 value 508.149547
iter  30 value 489.066408
iter  40 value 482.134602
iter  50 value 480.451383
iter  60 value 480.061394
iter  70 value 480.059034
iter  80 value 480.058779
final  value 480.058729 
converged
# weights:  78
initial  value 798.798237 
iter  10 value 499.760918
iter  20 value 481.353547
iter  30 value 466.352696
iter  40 value 460.137163
iter  50 value 455.872770
iter  60 value 451.708352
iter  70 value 450.417877
iter  80 value 449.756482
iter  90 value 448.788045
iter 100 value 446.959471
final  value 446.959471 
stopped after 100 iterations
# weights:  67
initial  value 644.749142 
iter  10 value 513.896511
iter  20 value 513.742175
iter  30 value 513.741829
iter  40 value 513.741349
iter  50 value 513.740609
iter  60 value 513.739287
iter  70 value 513.736287
iter  80 value 513.725162
iter  90 value 513.475825
iter 100 value 487.350507
final  value 487.350507 
stopped after 100 iterations
# weights:  100
initial  value 540.757115 
iter  10 value 513.910830
iter  20 value 498.392413
iter  30 value 486.420847
iter  40 value 474.592072
iter  50 value 464.457685
iter  60 value 449.024665
iter  70 value 443.679984
iter  80 value 440.203957
iter  90 value 436.839500
iter 100 value 435.423105
final  value 435.423105 
stopped after 100 iterations
# weights:  89
initial  value 693.126750 
iter  10 value 513.843963
final  value 513.741059 
converged
# weights:  166
initial  value 797.505932 
iter  10 value 514.202100
iter  20 value 500.568967
iter  30 value 495.093159
iter  40 value 493.621929
iter  50 value 492.771577
iter  60 value 492.323100
iter  70 value 492.057758
iter  80 value 491.942507
iter  90 value 489.564104
iter 100 value 481.793259
final  value 481.793259 
stopped after 100 iterations
# weights:  177
initial  value 614.251876 
iter  10 value 492.680876
iter  20 value 486.800824
iter  30 value 486.527541
iter  40 value 486.520407
final  value 486.519803 
converged
# weights:  45
initial  value 604.903225 
iter  10 value 484.936365
iter  20 value 467.269426
iter  30 value 465.299068
iter  40 value 463.039803
iter  50 value 462.563310
iter  60 value 462.549703
final  value 462.549678 
converged
# weights:  188
initial  value 689.344538 
iter  10 value 490.245992
iter  20 value 470.131032
iter  30 value 457.723898
iter  40 value 448.808119
iter  50 value 440.438402
iter  60 value 434.174221
iter  70 value 428.248275
iter  80 value 426.271693
iter  90 value 424.157298
iter 100 value 417.602707
final  value 417.602707 
stopped after 100 iterations
# weights:  177
initial  value 588.577485 
iter  10 value 492.744992
iter  20 value 481.105791
iter  30 value 453.348146
iter  40 value 433.938422
iter  50 value 423.433744
iter  60 value 393.097318
iter  70 value 379.229845
iter  80 value 377.270182
iter  90 value 375.816354
iter 100 value 374.468316
final  value 374.468316 
stopped after 100 iterations
# weights:  221
initial  value 670.240456 
iter  10 value 494.306172
iter  20 value 493.383696
iter  30 value 493.379679
iter  30 value 493.379677
iter  30 value 493.379677
final  value 493.379677 
converged
# weights:  188
initial  value 613.225976 
iter  10 value 491.826962
iter  20 value 454.571924
iter  30 value 419.273618
iter  40 value 409.749557
iter  50 value 405.536002
iter  60 value 401.428418
iter  70 value 396.217410
iter  80 value 394.881484
iter  90 value 392.667390
iter 100 value 387.117848
final  value 387.117848 
stopped after 100 iterations
# weights:  34
initial  value 569.540045 
iter  10 value 493.948075
iter  20 value 493.725936
final  value 493.725869 
converged
# weights:  122
initial  value 513.850420 
iter  10 value 491.509224
iter  20 value 459.064396
iter  30 value 437.987442
iter  40 value 428.530135
iter  50 value 416.593889
iter  60 value 413.203857
iter  70 value 409.118330
iter  80 value 402.032292
iter  90 value 394.473557
iter 100 value 388.487207
final  value 388.487207 
stopped after 100 iterations
# weights:  188
initial  value 523.932863 
iter  10 value 491.609239
final  value 491.603870 
converged
# weights:  89
initial  value 717.242660 
iter  10 value 489.195139
iter  20 value 487.748370
iter  30 value 487.713555
final  value 487.712320 
converged
# weights:  89
initial  value 680.426828 
iter  10 value 502.619108
iter  20 value 501.682244
final  value 501.681092 
converged
# weights:  89
initial  value 624.184462 
iter  10 value 491.719203
iter  20 value 491.605425
iter  30 value 491.605195
iter  40 value 491.604934
iter  50 value 491.604616
iter  60 value 491.604201
iter  70 value 491.603617
iter  80 value 491.602705
iter  90 value 491.601050
iter 100 value 491.597108
final  value 491.597108 
stopped after 100 iterations
# weights:  56
initial  value 599.983293 
iter  10 value 491.798645
iter  20 value 491.608818
iter  30 value 491.606717
iter  40 value 491.602186
iter  50 value 491.585148
iter  60 value 490.833706
iter  70 value 451.672352
iter  80 value 441.937462
iter  90 value 437.987071
iter 100 value 437.683316
final  value 437.683316 
stopped after 100 iterations
# weights:  122
initial  value 562.109440 
iter  10 value 492.313662
iter  20 value 491.605597
iter  30 value 491.556731
iter  40 value 471.817496
iter  50 value 436.171453
iter  60 value 426.913168
iter  70 value 423.655011
iter  80 value 421.668824
iter  90 value 418.151738
iter 100 value 416.409004
final  value 416.409004 
stopped after 100 iterations
# weights:  23
initial  value 528.521880 
iter  10 value 485.190484
iter  20 value 462.924721
iter  30 value 455.473989
iter  40 value 454.816967
iter  50 value 454.774323
iter  60 value 454.772844
final  value 454.772377 
converged
# weights:  78
initial  value 754.077476 
iter  10 value 492.447008
iter  20 value 479.600038
iter  30 value 448.050330
iter  40 value 436.079534
iter  50 value 427.812066
iter  60 value 422.484539
iter  70 value 419.248483
iter  80 value 417.751142
iter  90 value 415.196444
iter 100 value 414.550650
final  value 414.550650 
stopped after 100 iterations
# weights:  67
initial  value 559.575620 
iter  10 value 491.680233
final  value 491.608618 
converged
# weights:  100
initial  value 515.399162 
iter  10 value 489.456602
iter  20 value 463.004319
iter  30 value 444.628274
iter  40 value 434.463054
iter  50 value 429.024047
iter  60 value 427.758730
iter  70 value 425.267392
iter  80 value 422.756566
iter  90 value 421.465700
iter 100 value 421.122677
final  value 421.122677 
stopped after 100 iterations
# weights:  89
initial  value 741.698041 
iter  10 value 491.700232
iter  20 value 491.605198
iter  30 value 491.605045
iter  40 value 491.604880
iter  50 value 491.604692
iter  60 value 491.604470
iter  70 value 491.604194
iter  80 value 491.603833
iter  90 value 491.603327
iter 100 value 491.602556
final  value 491.602556 
stopped after 100 iterations
# weights:  166
initial  value 673.980984 
iter  10 value 492.303933
iter  20 value 477.996185
iter  30 value 471.860891
iter  40 value 467.560434
iter  50 value 465.357948
iter  60 value 462.365284
iter  70 value 460.406882
iter  80 value 458.116853
iter  90 value 455.631387
iter 100 value 451.839651
final  value 451.839651 
stopped after 100 iterations
# weights:  177
initial  value 666.892695 
iter  10 value 494.970621
iter  20 value 488.394720
iter  30 value 487.814697
iter  40 value 487.133209
iter  50 value 487.085322
final  value 487.084010 
converged
# weights:  45
initial  value 593.276628 
iter  10 value 491.326462
iter  20 value 473.178822
iter  30 value 466.488498
iter  40 value 463.609515
iter  50 value 463.386551
iter  60 value 463.027807
iter  70 value 462.957356
final  value 462.956398 
converged
# weights:  188
initial  value 505.162061 
iter  10 value 490.682659
iter  20 value 470.735888
iter  30 value 458.560176
iter  40 value 450.192180
iter  50 value 447.206260
iter  60 value 443.879821
iter  70 value 440.072226
iter  80 value 436.706329
iter  90 value 433.577286
iter 100 value 427.160307
final  value 427.160307 
stopped after 100 iterations
# weights:  177
initial  value 705.302426 
iter  10 value 491.345309
iter  20 value 452.834701
iter  30 value 433.234658
iter  40 value 420.920213
iter  50 value 409.577855
iter  60 value 404.345736
iter  70 value 399.574265
iter  80 value 397.119375
iter  90 value 393.781150
iter 100 value 390.770824
final  value 390.770824 
stopped after 100 iterations
# weights:  221
initial  value 887.128951 
iter  10 value 493.136430
iter  20 value 492.713540
final  value 492.712061 
converged
# weights:  188
initial  value 621.662346 
iter  10 value 486.244438
iter  20 value 452.288978
iter  30 value 426.732801
iter  40 value 411.054529
iter  50 value 397.609249
iter  60 value 389.558383
iter  70 value 379.953694
iter  80 value 377.161359
iter  90 value 376.122365
iter 100 value 375.281966
final  value 375.281966 
stopped after 100 iterations
# weights:  34
initial  value 582.253463 
iter  10 value 493.908356
iter  20 value 493.592487
final  value 493.592370 
converged
# weights:  122
initial  value 566.666568 
iter  10 value 482.482013
iter  20 value 445.006066
iter  30 value 431.421309
iter  40 value 427.354529
iter  50 value 424.833820
iter  60 value 421.704441
iter  70 value 418.201658
iter  80 value 415.681931
iter  90 value 413.444795
iter 100 value 410.200674
final  value 410.200674 
stopped after 100 iterations
# weights:  188
initial  value 592.747100 
iter  10 value 490.790941
iter  20 value 490.760913
iter  20 value 490.760913
final  value 490.760913 
converged
# weights:  89
initial  value 523.692668 
iter  10 value 489.270161
iter  20 value 488.022476
iter  30 value 488.003867
iter  40 value 488.003510
iter  50 value 488.003242
iter  50 value 488.003241
iter  50 value 488.003241
final  value 488.003241 
converged
# weights:  89
initial  value 670.349570 
iter  10 value 501.393750
iter  20 value 501.024462
final  value 501.021570 
converged
# weights:  89
initial  value 518.741704 
iter  10 value 490.774178
iter  20 value 490.761027
iter  30 value 490.760596
iter  40 value 490.759948
iter  50 value 490.758869
iter  60 value 490.756741
iter  70 value 490.750920
iter  80 value 490.708981
iter  90 value 473.002809
iter 100 value 448.603407
final  value 448.603407 
stopped after 100 iterations
# weights:  56
initial  value 550.247942 
iter  10 value 490.901407
iter  20 value 490.769358
iter  30 value 490.769163
iter  40 value 490.768938
iter  50 value 490.768670
iter  60 value 490.768342
iter  70 value 490.767919
iter  80 value 490.767341
iter  90 value 490.766482
iter 100 value 490.765027
final  value 490.765027 
stopped after 100 iterations
# weights:  122
initial  value 637.135935 
iter  10 value 492.037654
iter  20 value 490.773104
iter  30 value 490.771437
iter  40 value 490.768289
iter  50 value 490.759057
iter  60 value 490.580963
iter  70 value 455.684077
iter  80 value 442.543411
iter  90 value 441.185498
iter 100 value 440.918346
final  value 440.918346 
stopped after 100 iterations
# weights:  23
initial  value 682.099394 
iter  10 value 491.485790
iter  20 value 484.648894
iter  30 value 464.525646
iter  40 value 459.580094
iter  50 value 458.287393
iter  60 value 458.182294
iter  70 value 458.163860
final  value 458.163728 
converged
# weights:  78
initial  value 566.200107 
iter  10 value 474.205385
iter  20 value 444.791167
iter  30 value 434.710443
iter  40 value 421.072187
iter  50 value 417.296604
iter  60 value 416.017247
iter  70 value 414.615956
iter  80 value 413.914752
iter  90 value 413.029473
iter 100 value 411.624831
final  value 411.624831 
stopped after 100 iterations
# weights:  67
initial  value 703.696243 
iter  10 value 490.948540
iter  20 value 490.765543
iter  30 value 490.765477
iter  40 value 490.765403
iter  50 value 490.765322
iter  60 value 490.765230
iter  70 value 490.765125
iter  80 value 490.765004
iter  90 value 490.764861
iter 100 value 490.764688
final  value 490.764688 
stopped after 100 iterations
# weights:  100
initial  value 537.183775 
iter  10 value 491.042387
iter  20 value 461.485099
iter  30 value 450.691004
iter  40 value 441.039478
iter  50 value 437.206135
iter  60 value 432.602519
iter  70 value 428.064488
iter  80 value 425.964987
iter  90 value 424.819089
iter 100 value 423.580182
final  value 423.580182 
stopped after 100 iterations
# weights:  89
initial  value 553.574135 
iter  10 value 490.793385
iter  20 value 487.488518
iter  30 value 456.884115
iter  40 value 433.145180
iter  50 value 421.254277
iter  60 value 419.246061
iter  70 value 418.740428
iter  80 value 418.651423
iter  90 value 418.605999
iter 100 value 418.569698
final  value 418.569698 
stopped after 100 iterations
# weights:  166
initial  value 612.270355 
iter  10 value 490.527755
iter  20 value 476.897304
iter  30 value 472.671175
iter  40 value 469.615429
iter  50 value 467.012208
iter  60 value 465.735003
iter  70 value 464.897817
iter  80 value 463.924320
iter  90 value 462.894271
iter 100 value 462.488605
final  value 462.488605 
stopped after 100 iterations
# weights:  67
initial  value 1050.567840 
iter  10 value 748.494578
iter  20 value 748.056266
iter  30 value 748.056144
iter  40 value 748.056001
iter  50 value 748.055829
iter  60 value 748.055615
iter  70 value 748.055340
iter  80 value 748.054966
iter  90 value 748.054425
iter 100 value 748.053561
final  value 748.053561 
stopped after 100 iterations
Neural Networks with Feature Extraction 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  size  decay         RMSE       Rsquared      MAE        Selected
   2    7.603262e-03  1.0330289  0.0004572682  0.8182607          
   3    1.340566e+00  0.9988898  0.0047792490  0.7904540          
   4    1.169352e-01  1.0205880  0.0039993509  0.8112748          
   5    1.750871e-04  1.0179100  0.0036569749  0.8110146          
   6    8.994709e-05  0.9939669  0.0091010534  0.7895437  *       
   7    7.559708e-03  1.0537392  0.0012644860  0.8406356          
   8    3.729581e-05  1.0033268  0.0039930546  0.7968099          
   8    4.930297e-05  0.9973618  0.0042149571  0.7930921          
   8    6.965925e-01  0.9982317  0.0057768979  0.7910009          
   8    5.606832e+00  0.9999854  0.0032597792  0.7902729          
   9    4.598641e-02  1.0573820  0.0043725337  0.8290766          
  11    4.981650e-04  1.0126633  0.0102272839  0.8040217          
  11    3.099262e-03  1.0383152  0.0036322370  0.8230123          
  15    1.984492e-01  1.0386727  0.0020330674  0.8228424          
  16    4.269257e-03  1.0664472  0.0015203031  0.8437773          
  16    6.696733e-01  0.9994099  0.0064497636  0.7924768          
  17    1.131853e-05  0.9971585  0.0050565812  0.7938170          
  17    4.457117e-03  1.0522722  0.0009684162  0.8328510          
  17    6.395376e-02  1.0397344  0.0004781081  0.8223127          
  20    2.007697e+00  0.9974229  0.0033630681  0.7905643          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 6 and decay = 8.994709e-05.
[1] "Mon Mar 05 16:35:46 2018"
Principal Component Analysis 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  ncomp  RMSE       Rsquared     MAE        Selected
  1      0.9966437  0.005549363  0.7925321  *       
  2      0.9983827  0.001230239  0.7927063          
  3      0.9969878  0.003283586  0.7912787          
  4      1.0016364  0.003365460  0.7949672          
  5      1.0025799  0.001681096  0.7961525          
  6      1.0032021  0.001270919  0.7961100          
  7      1.0017888  0.003183780  0.7949411          
  8      1.0024578  0.002598906  0.7963094          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was ncomp = 1.
[1] "Mon Mar 05 16:35:59 2018"
____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.160862099099904) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.13559817825444) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.126862203748897) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0876784103922546) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.176756604528055) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0883018009364605) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.170909607689828) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0830419426318258) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.00179299893788993) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.161432626191527) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.191623917594552) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0230957693420351) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0414418026339263) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0565791077911854) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0960333320312202) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.095950167439878) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0317995700985193) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.122087650513276) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0190553359687328) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.143254981329665) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.160862099099904) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Component____ 2 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Component____ 2 ____
No more significant predictors (<0.126862203748897) found
Warning only 2 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0876784103922546) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.176756604528055) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0883018009364605) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.170909607689828) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0830419426318258) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.00179299893788993) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.161432626191527) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.191623917594552) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0230957693420351) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0414418026339263) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0565791077911854) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.095950167439878) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0317995700985193) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.122087650513276) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0190553359687328) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.143254981329665) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.160862099099904) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.13559817825444) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.126862203748897) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0876784103922546) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.176756604528055) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0883018009364605) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.170909607689828) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.0830419426318258) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.00179299893788993) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.161432626191527) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.191623917594552) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0230957693420351) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0414418026339263) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0565791077911854) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.095950167439878) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0317995700985193) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.122087650513276) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

No significant predictors (<0.0190553359687328) found
Warning only one standard component (without sparse option) was thus extracted
____Component____ 1 ____
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.143254981329665) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

____************************************************____

Family: gaussian 
Link function: identity 

____Component____ 1 ____
No more significant predictors (<0.122087650513276) found
Warning only 1 components were thus extracted
____Predicting X without NA neither in X nor in Y____
****________________________________________________****

Partial Least Squares Generalized Linear Models  

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  nt  alpha.pvals.expli  RMSE      Rsquared     MAE        Selected
  1   0.096033332        1.000352  0.002740589  0.7952256          
  2   0.041441803        1.002077  0.002853727  0.7965743          
  2   0.135598178        1.002011  0.002820213  0.7965926          
  2   0.170909608        1.000995  0.002659483  0.7959837          
  3   0.031799570        1.002077  0.002853727  0.7965743          
  3   0.095950167        1.000352  0.002740589  0.7952256          
  4   0.019055336        1.002077  0.002853727  0.7965743          
  4   0.023095769        1.002077  0.002853727  0.7965743          
  4   0.122087651        1.000352  0.002740589  0.7952256  *       
  4   0.161432626        1.000995  0.002659483  0.7959837          
  4   0.191623918        1.000995  0.002659483  0.7959837          
  5   0.056579108        1.000352  0.002740589  0.7952256          
  5   0.083041943        1.000352  0.002740589  0.7952256          
  7   0.143254981        1.000995  0.002659483  0.7959837          
  8   0.001792999        1.002077  0.002853727  0.7965743          
  8   0.087678410        1.000352  0.002740589  0.7952256          
  8   0.088301801        1.000352  0.002740589  0.7952256          
  8   0.126862204        1.002011  0.002820213  0.7965926          
  8   0.160862099        1.000995  0.002659483  0.7959837          
  9   0.176756605        1.000995  0.002659483  0.7959837          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were nt = 4 and alpha.pvals.expli
 = 0.1220877.
[1] "Mon Mar 05 16:36:42 2018"
Projection Pursuit Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  nterms  RMSE      Rsquared      MAE        Selected
   1      1.022283  0.0009508389  0.8162183  *       
   2      1.052998  0.0002926671  0.8388387          
   3      1.111854  0.0022837265  0.8803131          
   4      1.148827  0.0028618322  0.9173091          
   5      1.162742  0.0010582747  0.9213862          
   6      1.179819  0.0038515078  0.9368236          
   7      1.213924  0.0042387570  0.9667177          
   8      1.225067  0.0031868883  0.9654448          
   9      1.229283  0.0009542314  0.9661611          
  10      1.200480  0.0030963621  0.9427708          
  11      1.222777  0.0058071002  0.9726602          
  12      1.285317  0.0037914815  1.0196688          
  13      1.282885  0.0016821083  1.0200874          
  14      1.289184  0.0010366057  1.0311375          
  15      1.336310  0.0033629755  1.0544649          
  16      1.340315  0.0070278406  1.0584134          
  17      1.322009  0.0010325634  1.0381641          
  18      1.318767  0.0016653771  1.0493979          
  19      1.325481  0.0028712559  1.0560026          
  20      1.352906  0.0044339524  1.0615007          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was nterms = 1.
[1] "Mon Mar 05 16:37:07 2018"
Quantile Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  mtry  RMSE      Rsquared     MAE       Selected
  1     1.635639  0.006856659  1.379187  *       
  2     1.639131  0.006651749  1.379172          
  3     1.641120  0.006087079  1.379998          
  4     1.654284  0.006881399  1.390123          
  5     1.650796  0.008980213  1.385170          
  7     1.652995  0.009691336  1.388087          
  8     1.651376  0.008087243  1.386213          
  9     1.652487  0.006837657  1.386889          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 1.
[1] "Mon Mar 05 16:39:00 2018"
Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  min.node.size  mtry  splitrule   RMSE      Rsquared     MAE        Selected
   2             5     variance    1.040755  0.008845860  0.8272638          
   3             8     variance    1.042900  0.008487012  0.8298214          
   4             7     extratrees  1.027497  0.006392138  0.8159782          
   5             2     maxstat     1.009429  0.005732425  0.8025037          
   6             2     extratrees  1.014485  0.007167263  0.8052526          
   7             5     maxstat     1.018366  0.007583863  0.8098849          
   8             1     variance    1.026645  0.014960938  0.8150805          
   8             2     variance    1.032733  0.012009927  0.8213982          
   8             8     maxstat     1.021226  0.005695658  0.8113212          
   8             9     extratrees  1.025687  0.005014736  0.8142718          
   9             6     variance    1.041242  0.009839192  0.8248110          
  11             3     maxstat     1.012605  0.006711532  0.8047581          
  11             4     variance    1.039124  0.009871495  0.8255228          
  15             7     extratrees  1.018847  0.004168392  0.8078634          
  16             4     extratrees  1.015099  0.004807262  0.8068136          
  16             8     variance    1.040822  0.009458867  0.8250882          
  17             1     maxstat     1.003347  0.005150030  0.7971037  *       
  17             4     maxstat     1.014849  0.007201080  0.8075435          
  17             6     extratrees  1.017265  0.004736813  0.8061131          
  20             8     extratrees  1.017871  0.004804680  0.8086190          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were mtry = 1, splitrule = maxstat
 and min.node.size = 17.
[1] "Mon Mar 05 16:39:45 2018"
Error in code$varImp(object$finalModel, ...) : 
  No importance values available
In addition: Warning messages:
1: package 'gpls' is not available (for R version 3.4.3) 
2: package 'rPython' is not available (for R version 3.4.3) 
Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  predFixed  minNode  RMSE      Rsquared     MAE        Selected
  1          10       1.027679  0.013279465  0.8150604  *       
  2           5       1.037630  0.013515821  0.8255535          
  2          14       1.032259  0.010342880  0.8196092          
  2          18       1.030639  0.008847866  0.8196918          
  3           4       1.040500  0.009477474  0.8256981          
  3          10       1.040948  0.012309958  0.8272847          
  4           2       1.044073  0.009335688  0.8313199          
  4           3       1.046872  0.011242887  0.8312000          
  4          13       1.038820  0.010205539  0.8243991          
  4          17       1.037761  0.009480319  0.8243290          
  4          20       1.036536  0.010322567  0.8240457          
  5           6       1.046003  0.008830118  0.8321405          
  5           9       1.043470  0.011159834  0.8295110          
  7          15       1.044188  0.008886876  0.8315037          
  8           1       1.051771  0.010595674  0.8375732          
  8           9       1.045258  0.009303644  0.8320205          
  8          13       1.044483  0.009839959  0.8313602          
  8          17       1.041588  0.008599525  0.8285676          
  9          18       1.043718  0.009129540  0.8304583          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were predFixed = 1 and minNode = 10.
[1] "Mon Mar 05 16:52:25 2018"
Relaxed Lasso 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  phi          lambda     RMSE       Rsquared      MAE        Selected
  0.008964995  26.044739  1.0008837  0.0007716347  0.7983215          
  0.095276680   5.081085  1.0023136  0.0030848650  0.7983573          
  0.115478847   5.036475  1.0023050  0.0030577162  0.7983545          
  0.158997850   3.596807  1.0025924  0.0022886176  0.7984954          
  0.207209013   3.046908  1.0026079  0.0022550413  0.7984917          
  0.282895539   8.491761  1.0021937  0.0013832309  0.7987683          
  0.415209713   8.441391  1.0018340  0.0012919996  0.7984389          
  0.438392052  23.723165  0.9995718  0.0011099950  0.7964180          
  0.441509005  25.937538  0.9987772  0.0007786321  0.7961478          
  0.479750837   4.232078  1.0022914  0.0021789234  0.7983030          
  0.480166660   2.017063  1.0023957  0.0021441417  0.7983912          
  0.610438253   6.791614  1.0021595  0.0022417580  0.7983637          
  0.634311019  27.489051  0.9981090  0.0007848656  0.7955530          
  0.677990891   2.694566  1.0023076  0.0020842823  0.7983573          
  0.716274907  17.822239  0.9995314  0.0001142166  0.7960980          
  0.804310495  22.077041  0.9984673  0.0009087901  0.7952888          
  0.807163131   5.147736  1.0021359  0.0018282926  0.7984320          
  0.854548038   2.442218  1.0022347  0.0020244921  0.7983269          
  0.883783023  42.259601  0.9971587           NaN  0.7938173  *       
  0.958119588   5.295853  1.0021309  0.0014801786  0.7984906          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 42.2596 and phi = 0.883783.
[1] "Mon Mar 05 16:52:40 2018"
Random Forest 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  mtry  RMSE      Rsquared     MAE        Selected
  1     1.025206  0.009972604  0.8146528  *       
  2     1.033739  0.010731828  0.8201131          
  3     1.038052  0.010613740  0.8234267          
  4     1.042843  0.012366504  0.8282231          
  5     1.043117  0.010927399  0.8294714          
  7     1.044267  0.010811271  0.8294033          
  8     1.044384  0.009965360  0.8293783          
  9     1.042047  0.007913587  0.8287056          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 1.
[1] "Mon Mar 05 16:54:02 2018"
Error in varImp[, "%IncMSE"] : subscript out of bounds
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Ridge Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  lambda        RMSE      Rsquared     MAE        Selected
  3.240154e-05  1.001965  0.002762590  0.7967090  *       
  6.972563e-05  1.001965  0.002762591  0.7967090          
  1.033954e-04  1.001965  0.002762592  0.7967090          
  1.691795e-04  1.001965  0.002762594  0.7967090          
  3.289051e-04  1.001965  0.002762600  0.7967091          
  6.311011e-04  1.001965  0.002762610  0.7967092          
  1.267380e-03  1.001966  0.002762631  0.7967095          
  1.312962e-03  1.001966  0.002762633  0.7967095          
  1.383343e-03  1.001966  0.002762635  0.7967095          
  1.549861e-03  1.001966  0.002762641  0.7967096          
  4.199314e-03  1.001968  0.002762730  0.7967106          
  1.003661e-02  1.001973  0.002762928  0.7967130          
  1.027874e-02  1.001973  0.002762936  0.7967130          
  2.004449e-01  1.002097  0.002769858  0.7967841          
  4.726548e-01  1.002227  0.002779463  0.7968584          
  6.304989e-01  1.002284  0.002784395  0.7968912          
  9.015156e-01  1.002363  0.002791713  0.7969361          
  9.165382e-01  1.002366  0.002792080  0.7969384          
  1.137809e+00  1.002416  0.002797057  0.7969678          
  6.373922e+00  1.002749  0.002834809  0.7971951          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was lambda = 3.240154e-05.
[1] "Mon Mar 05 16:54:16 2018"
Robust Linear Model 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  intercept  psi           RMSE      Rsquared     MAE        Selected
  FALSE      psi.huber     1.002814  0.002164155  0.7990239          
  FALSE      psi.hampel    1.002458  0.001930083  0.7983952          
  FALSE      psi.bisquare  1.003119  0.001451683  0.7992331          
   TRUE      psi.huber     1.002663  0.002223368  0.7972225          
   TRUE      psi.hampel    1.002181  0.002193333  0.7966918  *       
   TRUE      psi.bisquare  1.002892  0.001609193  0.7973021          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were intercept = TRUE and psi = psi.hampel.
[1] "Mon Mar 05 16:54:30 2018"
CART 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  cp           RMSE      Rsquared     MAE        Selected
  0.000000000  1.199005  0.002525220  0.9638745          
  0.002801683  1.199416  0.002801055  0.9621949          
  0.003120606  1.199416  0.002801055  0.9621949          
  0.003178982  1.199416  0.002801055  0.9621949          
  0.003342376  1.199416  0.002801055  0.9621949          
  0.003427889  1.199416  0.002801055  0.9621949          
  0.003643033  1.199877  0.002837092  0.9634213          
  0.003828668  1.194863  0.002279444  0.9601001          
  0.004593504  1.191503  0.002606804  0.9562129          
  0.005003148  1.192928  0.002625534  0.9563210          
  0.005689594  1.189468  0.003114265  0.9518013          
  0.005871446  1.185166  0.003076911  0.9463610          
  0.007154497  1.171750  0.004405160  0.9368687          
  0.009082259  1.141617  0.002780684  0.9122460          
  0.009253984  1.139690  0.002616349  0.9096475          
  0.011517410  1.107934  0.005043524  0.8844973  *       

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.01151741.
[1] "Mon Mar 05 16:54:43 2018"
CART 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results:

  RMSE      Rsquared     MAE      
  1.141397  0.004841357  0.9122759

[1] "Mon Mar 05 16:54:57 2018"
CART 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  maxdepth  RMSE      Rsquared     MAE        Selected
   1        1.031953  0.002732330  0.8193276  *       
   9        1.103341  0.004673879  0.8817552          
  12        1.112113  0.005836337  0.8884296          
  13        1.115706  0.005903472  0.8937390          
  14        1.122376  0.005877460  0.8981333          
  16        1.125865  0.004876692  0.8997033          
  17        1.138946  0.005786883  0.9112562          
  18        1.142847  0.006741772  0.9128380          
  19        1.142847  0.006741772  0.9128380          
  20        1.141397  0.004841357  0.9122759          
  29        1.141397  0.004841357  0.9122759          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was maxdepth = 1.
[1] "Mon Mar 05 16:55:10 2018"
Quantile Regression with LASSO penalty 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  lambda        RMSE       Rsquared      MAE        Selected
  3.240154e-05  1.0067868  0.0006970658  0.8005457          
  6.972563e-05  1.0067868  0.0006970658  0.8005457          
  1.033954e-04  1.0067868  0.0006970658  0.8005457          
  1.691795e-04  1.0065882  0.0006813712  0.8003007          
  3.289051e-04  1.0064090  0.0006874068  0.8001606          
  6.311011e-04  1.0056912  0.0008204166  0.7993514          
  1.267380e-03  1.0043181  0.0008594470  0.7976833          
  1.312962e-03  1.0043181  0.0008594471  0.7976833          
  1.383343e-03  1.0043181  0.0008594471  0.7976833          
  1.549861e-03  1.0040058  0.0009414258  0.7973118          
  4.199314e-03  1.0033840  0.0010780978  0.7968281          
  1.003661e-02  0.9996824  0.0021091492  0.7936145          
  1.027874e-02  0.9996824  0.0021091492  0.7936145          
  2.004449e-01  0.9988191           NaN  0.7903704          
  4.726548e-01  0.9988316           NaN  0.7903704          
  6.304989e-01  0.9989478           NaN  0.7903704          
  9.015156e-01  0.9988321           NaN  0.7903704          
  9.165382e-01  0.9988328           NaN  0.7903704          
  1.137809e+00  0.9988102           NaN  0.7903704  *       
  6.373922e+00  0.9988335           NaN  0.7903704          

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was lambda = 1.137809.
[1] "Mon Mar 05 16:55:24 2018"
Non-Convex Penalized Quantile Regression 

752 samples
  9 predictor

No pre-processing
Resampling: Cross-Validated (3 fold) 
Summary of sample sizes: 501, 503, 500 
Resampling results across tuning parameters:

  lambda        penalty  RMSE       Rsquared      MAE        Selected
  3.240154e-05  MCP      1.0068525  0.0007225506  0.8007142          
  6.972563e-05  SCAD     1.0068525  0.0007225506  0.8007142          
  1.033954e-04  SCAD     1.0068525  0.0007225506  0.8007142          
  1.691795e-04  MCP      1.0068525  0.0007225506  0.8007142          
  3.289051e-04  MCP      1.0068525  0.0007225506  0.8007142          
  6.311011e-04  MCP      1.0068525  0.0007225506  0.8007142          
  1.267380e-03  MCP      1.0068525  0.0007225506  0.8007142          
  1.312962e-03  MCP      1.0068525  0.0007225506  0.8007142          
  1.383343e-03  SCAD     1.0068525  0.0007225506  0.8007142          
  1.549861e-03  SCAD     1.0068525  0.0007225506  0.8007142          
  4.199314e-03  SCAD     1.0055830  0.0009499623  0.7987036          
  1.003661e-02  MCP      1.0043756  0.0018444612  0.7972897          
  1.027874e-02  MCP      1.0037189  0.0017376309  0.7967751          
  2.004449e-01  SCAD     0.9988191           NaN  0.7903704          
  4.726548e-01  SCAD     0.9988316           NaN  0.7903704          
  6.304989e-01  MCP      0.9989478           NaN  0.7903704          
  9.015156e-01  MCP      0.9988321           NaN  0.7903704          
  9.165382e-01  MCP      0.9988328           NaN  0.7903704          
  1.137809e+00  SCAD     0.9988102           NaN  0.7903704  *       
  6.373922e+00  SCAD     0.9988335           NaN  0.7903704          

RMSE was used to select the optimal model using the smallest value.
The final values used for the model were lambda = 1.137809 and penalty = SCAD.
[1] "Mon Mar 05 16:55:40 2018"
Error : package RRF is required
In addition: Warning messages:
1: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
2: In nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo,  :
  There were missing values in resampled performance measures.
Error : package RRF is required
Error : package RRF is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:55:53 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "RRF"                     
Error : package RRF is required
Error : package RRF is required
Error : package RRF is required
 [1] "failed"                   "failed"                  
 [3] "Mon Mar 05 16:56:06 2018" "just random"             
 [5] "ignore"                   "none"                    
 [7] "expoTrans"                "HOPPER"                  
 [9] "14th20hp3cv"              "RRFglobal"               
Error in .local(object, ...) : test vector does not match model !
Error in .local(object, ...) : test vector does not match model !
