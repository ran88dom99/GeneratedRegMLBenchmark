
R version 3.4.3 (2017-11-30) -- "Kite-Eating Tree"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> options(repos=structure(c(CRAN="https://rweb.crmda.ku.edu/cran/")))
> ## capture messages and errors to a file.https://rweb.crmda.ku.edu/cran/
> #zz <- file("all.Rout", open="wt")https://cran.cnr.berkeley.edu
> #sink(zz, type="message") edit for rebaseless
> #chek for R package updates
> #try(log("a")) ## test --no-edit
> #devtools::install_github("berndbischl/ParamHelpers") # version >= 1.11 needed.
> #devtools::install_github("jakob-r/mlrHyperopt", dependencies = TRUE)
> 
> which.computer<-Sys.info()[['nodename']]
> task.subject<-"14th20hp3cv"
> out.file<-paste("out",task.subject,which.computer,.Platform$OS.type,.Platform$r_arch,".csv",sep="")
> importance.file<-paste("importance",task.subject,which.computer,.Platform$OS.type,.Platform$r_arch,sep="")
> 
> base.folder<-getwd()
> cpout.folder<-paste(base.folder,"/",which.computer,sep = "")
> setwd(cpout.folder)
> 
> if(length(which(list.files() == out.file))<1) write.table( "0.01,0.01,100,100,100,Wed Aug 02 16:37:25 2017,dummy,8,1,basic latent features,ignore,none,asis,1.12784979099243,random,333,53,adaptive_cv,16,5,2,2,19,0.0107744822639878,FALSE,,,,,,,,,," ,file =,out.file,  quote = F, sep = ",", row.names = F,col.names = F)
> if(length(which(list.files() == paste(importance.file,".csv",sep="")))<1) write.table( ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,," ,file = paste(importance.file,".csv",sep=""),  quote = F, sep = ",", row.names = F,col.names = F)
> if(length(which(list.files() == paste(importance.file,"mlr.csv",sep="")))<1) write.table( ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,," ,file = paste(importance.file,"mlr.csv",sep=""),  quote = F, sep = ",", row.names = F,col.names = F)
> 
> cv.iters=3
> tuneLength=20
> tuneLength2=8
> normings=c("YeoJohnson","ICA", "centernscale","expoTrans","range01","asis","quantile")#,"centernscale"
> 
> gensTTesto<-c(56,53,4,12,13,14,15,20,45,54,55, 44,52,1,3)#,  51,c(4)#c(1:40)#c(5,10,11,13,14,15,16,17,18,19,20,21,24,28,38,39,40)
> write.table( t(gensTTesto),file = "initial tasks to test.csv",  quote = F, sep = ",", row.names = F,col.names = F)
> try({
+   gensTTest<-(read.csv("tasks to test.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+ })
> if(length(gensTTest)<1) gensTTest<-gensTTesto#inversion[length(inversion):1]
> 
> ########packages install check######
> 
> #list.of.packages <- c("caret","caretEnsemble","mlr","MLmetrics","tgp")
> #list.of.packages <- c("gower","dimRed","DEoptimR","caretEnsemble","logicFS"," RWeka","ordinalNet","xgboost","mlr","caret","MLmetrics","bartMachine","spikeslab","party","rqPen","monomvn","foba","logicFS","rPython","qrnn","randomGLM","msaenet","Rborist","relaxo","ordinalNet","rrf","frbs","extraTrees","ipred","elasticnet","bst","brnn","Boruta","arm","elmNN","evtree","extraTrees","deepnet","kknn","KRLS","RSNNS","partDSA","plsRglm","quantregForest","ranger","inTrees")
> #new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
> #if(length(new.packages)) install.packages(new.packages, dep = TRUE)
> 
> 
> #install.packages("mlr", dependencies = c("Depends", "Suggests"))
> #install.packages("caret", dependencies = c("Depends", "Suggests"))
> #install.packages("caret",repos = "http://cran.r-project.org",dependencies = c("Depends", "Imports", "Suggests"))
> #install.packages("SuperLearner", dependencies = c("Depends", "Suggests"))
> #install.packages("rattle", dependencies = c("Depends", "Suggests"))
> 
> # Load libraries
> #library(mlbench)
> 
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
> #library(caretEnsemble)
> library(MLmetrics)

Attaching package: 'MLmetrics'

The following objects are masked from 'package:caret':

    MAE, RMSE

The following object is masked from 'package:base':

    Recall

> 
> ########error no repeat#########
> 
> 
> try({
+   before.last.alg<-as.matrix(read.csv("beforelast algorithm.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   last.alg<-as.matrix(read.csv("last algorithm tried.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   #write.table(paste(date(), last.alg,.Platform$OS.type,.Platform$r_arch,which.computer,sep=" "),file = "algos after which reset.csv",  quote = F, row.names = F,col.names = F,append = T)
+   if(last.alg==before.last.alg){print("algorithm may be broken")}
+   write.table(last.alg,file = "beforelast algorithm.csv",  quote = F, row.names = F,col.names = F)
+ })
> try({
+   before.last.tsk<-as.matrix(read.csv("beforelast task.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   last.tsk<-as.matrix(read.csv("last task tried.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   write.table(paste(date(),last.alg, last.tsk,cv.iters,tuneLength,.Platform$OS.type,.Platform$r_arch,which.computer,sep=","),file = "test after which reset.csv",  quote = F, row.names = F,col.names = F,append = T)
+   if(last.tsk==before.last.tsk){print("task may be broken")}
+   write.table(last.tsk,file = "beforelast task.csv",  quote = F, row.names = F,col.names = F)
+ })
> bad.models=c("spaccceeee")
> previous.fails<-(read.csv("test after which reset.csv", sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
> previous.fails<-previous.fails[previous.fails[,8]==which.computer,]
> lgf<-length(previous.fails[,2])
> for(lt in 2:lgf)  {
+   if(previous.fails[lt,2]==previous.fails[lt-1,2])  {
+     bad.models=union(bad.models,c(paste(previous.fails[lt,2])))  }}
> 
> #######not to redo a test function#####
> check.redundant<-function(df=df.previous.calcs,norming="asis",trans.y=1,withextra="missing",missingdata="leaveempty",datasource="mean" ,column.to.predict=200,allmodel="ctree")
+ {
+   for(intern in 1:length(df[,1])){
+     if((any(df[intern,] == norming, na.rm=T))&&
+        (any(df[intern,] == withextra, na.rm=T))&&
+        (any(df[intern,] == missingdata, na.rm=T))&&
+        (any(df[intern,] == datasource, na.rm=T))&&
+        (any(df[intern,] == column.to.predict, na.rm=T))&&
+        (any(df[intern,] == allmodel, na.rm=T))&&
+        (  (df[intern,9] == trans.y)))
+     {return(TRUE)}
+   }
+   return(FALSE)
+ }
> #####caret init#####
> best.ranged <- c("avNNet", "nnet", "pcaNNet", "glm.nb")
> best.asis <- c("svmLinear3", "relaxo", "superpc", "xgbTree")
> best.cns <- c("gam", "bam", "svmLinear2", "msaenet", "BstLm", "gbm") 
> 
> cv6hp5 <- c( "BstLm", "qrnn")#earth
> cv3hp32 <- c("Rborist", "pcaNNet", "SBC")
> cv7x5hp32 <- c("gbm", "krlsPoly", "kknn", "xgbLinear","RRF", "cubist", "rlm" )
> cv6hp5.avoid <- c("pcaNNet")
> cv3hp32.avoid <- c("glm.nb", "gamboost", "ctree2","glmboost", "leapSeq","ctree","svmLinear2")
> cv7x5hp32.avoid <- c("SBC","bagearthgcv","gcvearth","lmStepAIC","glmStepAIC","bridge","lm","glm","bayesglm","blassoAveraged","treebag","rpart1SE")
> 
> allmodels <- c("avNNet", "bagEarth", "bagEarthGCV",
+                "bayesglm", "bdk", "blackboost", "Boruta", "brnn", "BstLm" ,
+                "bstTree", "cforest", "ctree", "ctree2", "cubist", "DENFIS",
+                "dnn", "earth", "elm", "enet",   "evtree",
+                "extraTrees",  "gamLoess",  "gaussprLinear", "gaussprPoly", "gaussprRadial",
+                "gcvEarth","glm", "glmboost",  "icr", "kernelpls",
+                "kknn", "knn",  "krlsRadial", "lars" , "lasso",
+                "leapBackward", "leapForward", "leapSeq", "lm", "M5", "M5Rules",
+                "mlpWeightDecay", "neuralnet" , "partDSA",
+                "pcaNNet", "pcr", "penalized", "pls", "plsRglm", "ppr",
+                "qrf" , "ranger",  "rf")
> allmodels <- c("rlm", "rpart", "rpart2",
+                "RRF", "RRFglobal",  "simpls",
+                "svmLinear", "svmPoly", "svmRadial", "svmRadialCost",
+                "widekernelpls",  "xgbLinear",
+                "xgbTree")
> allmodels <- c("avNNet","BstLm","bstTree","cforest","ctree","ctree2",
+                "cubist","earth","enet","evtree","glmboost",
+                "icr","kernelpls","kknn","lasso","pcaNNet",
+                "pcr","pls","qrf","ranger","rf")
> 
> allmodels <- c("kknn", "cubist", "avNNet", "xgbLinear", "RRF", "pcaNNet","earth","nnet","gbm","enet","lasso","BstLm",
+                "foba", "leapBackward", "gcvEarth", "SBC","glm.nb","gamboost","ctree2","relaxo", 
+                "bartMachine","extraTrees","bam","gam","randomGLM")
> #allmodels <- c("bam")
> #allmodels <- c("rf")"rqlasso",, "xyf" "rvmPoly", "rvmRadial",    "spls", "superpc" ,   "treebag",  "svmLinear2",  "SBC",
> #allmodels <- c("bartMachine", "xgbLinear", "pcaNNet","svmLinear","glmnet","cforest","cubist","rf","ranger")"glmnet",
> #wow rfRules is really slow "rfRules","WM", takes 50min
> # brak everythig "rbfDDA","ridge","rqnc",
> # use "rf" to test all
> library(caret)
> allmodels <- unique(modelLookup()[modelLookup()$forReg,c(1)])
> #allmodels <-c("avNNet", "nnet", "pcaNNet",  "glm.nb", "gam" ,
> #              "bam","msaenet", "svmLinear2","svmLinear3",
> #              "relaxo",  "superpc", "xgbTree", "BstLm")
> #allmodels<- c("svmLinear","svmPoly","svmRadial")
> #library(doParallel); cl <- makeCluster(detectCores()); registerDoParallel(cl)
> #allmodels<-c("bartMachine","extraTrees")#,"randomGLM"
> 
> 
> adaptControl <- trainControl(method = "adaptive_cv",
+                              number = 7, repeats = 5,
+                              adaptive = list(min = 4, alpha = 0.05,
+                                              method = "gls", complete = FALSE),
+                              search = "random")
> adaptControl <-trainControl(method = "cv", number = cv.iters,  search = "random")
> simpleControl <- trainControl(method = "cv",
+                               number = cv.iters,
+                               search = "random")
> 
> 
> #########MLR init######
> #R.utils::gcDLLs()
> #list.of.packages <- c("ParamHelpers","devtools","mlrMBO","RJSONIO","plot3D","plotly")
> #install.packages("mlrMBO", dependencies = c("Depends", "Suggests"))
> list.of.packages <- c("caretEnsemble","logicFS"," RWeka","ordinalNet","xgboost","mlr","caret","MLmetrics","bartMachine","spikeslab","party","rqPen","monomvn","foba","logicFS","rPython","qrnn","randomGLM","msaenet","Rborist","relaxo","ordinalNet","rrf","frbs","extraTrees","ipred","elasticnet","bst","brnn","Boruta","arm","elmNN","evtree","extraTrees","deepnet","kknn","KRLS","RSNNS","partDSA","plsRglm","quantregForest","ranger","inTrees")
> new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
> if(length(new.packages)) install.packages(new.packages, dep = TRUE)
Warning message:
packages 'logicFS', ' RWeka', 'rPython', 'rrf' are not available (for R version 3.4.3) 
> 
> #devtools::install_github("berndbischl/ParamHelpers") # version >= 1.11 needed.
> #devtools::install_github("jakob-r/mlrHyperopt", dependencies = TRUE)
> 
> tuneLengthMLR<-tuneLength
> mlr.iters<-cv.iters
> #######data read process start#####
> seed.var =222+round(runif(1,min=0,max=100))
> column.to.predict=1
> print(date());
[1] "Fri Feb 09 17:08:52 2018"
> 
> setwd(base.folder)
> if(!exists("gen.count")){gen.count=56}
> gens.names<-as.matrix(read.table("gens names.csv", sep = ",",header = FALSE,row.names=1,fill=TRUE, quote="",dec="."))
> for(gend.data in gensTTest){
+   setwd(base.folder)
+   data.source<-as.matrix(read.csv(paste("Generats/",gens.names[gend.data],".csv", sep = ""), sep = ",",fill=TRUE, header = FALSE,quote="",dec="."))
+   datasource<-gens.names[gend.data,1]
+   setwd(cpout.folder)
+   missingdatas=c("ignore")
+   for(missingdata in missingdatas){
+     withextras=c("none")
+     for(withextra in withextras){
+       ################data wrestling###############
+       
+       dependant.selection=complete.cases(data.source[,column.to.predict])
+       df.previous.calcs=as.data.frame(read.csv(file=out.file, header = FALSE, sep = ",", quote = "",
+                                                dec = ".", fill = TRUE, comment.char = ""))
+       unimportant.computations<-vector(mode = "logical",length=length(df.previous.calcs[,1])  )
+       for(intern in 1:length(df.previous.calcs[,1])){
+         if((any(df.previous.calcs[intern,] == withextra, na.rm=T))&&
+            (any(df.previous.calcs[intern,] == missingdata, na.rm=T))&&
+            (any(df.previous.calcs[intern,] == datasource, na.rm=T))&&
+            (any(df.previous.calcs[intern,] == column.to.predict, na.rm=T)))
+         {unimportant.computations[intern]<-T}}
+       
+       df.previous.calcs<-df.previous.calcs[unimportant.computations,]
+       
+       
+       
+       #data.source=data.frame( data.source[,column.to.predict],data.source[,1:2], data.source[,4:(column.to.predict-1)], data.source[,(column.to.predict+1):length( data.source[1,])])
+       
+       
+         for(norming in normings) {
+         for(trans.y in 1:2) {
+           df.toprocess=data.source
+           y.untransformed<-df.toprocess[,1]
+           
+           if(norming=="centernscale"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("center", "scale"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           if(norming=="range01"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("range"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           if(norming=="expoTrans"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("expoTrans"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           if(norming=="YeoJohnson"){
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("YeoJohnson"))#"center", "scale",
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           
+           if((norming=="asis")&&(trans.y==2)){next}
+           
+           
+           ################preprocess###########
+           df.toprocess=data.frame(df.toprocess[dependant.selection,])
+           y.untransformed=y.untransformed[dependant.selection]
+           if(norming=="quantile"){
+             for(Clol in trans.y:length(data.source[1,])){
+               df.toprocess[,Clol]<- (rank(df.toprocess[,Clol],na.last = "keep",ties.method = "average")-1) }
+             preProcValues= preProcess(df.toprocess[,trans.y:length(df.toprocess[1,])],method = c("range"))
+             df.toprocess[,trans.y:length(df.toprocess[1,])]<- predict(preProcValues, df.toprocess[,trans.y:length(df.toprocess[1,])])}
+           
+           
+           loess.model<-loess(y.untransformed~ df.toprocess[,1],span = 0.21, degree = 1)
+           
+           
+           #df.toprocess = data.frame(df.toprocess,)
+           nzv <- nearZeroVar(df.toprocess[,])#, saveMetrics= TRUE
+           #nzv[nzv$nzv,][1:10,]
+           if(length(nzv)>1){
+             df.toprocess = (df.toprocess[, -nzv])}
+           
+           seed.var =222+round(runif(1,min=0,max=100))
+           set.seed(seed.var)
+           inTrain <- createDataPartition(y = df.toprocess[,1],
+                                          p = .75,
+                                          list = FALSE)
+           training <- df.toprocess[ inTrain,]
+           testing  <- df.toprocess[-inTrain,]
+           write.table(df.toprocess,file = "sanity check 1.csv",  quote = F, row.names = F,col.names = F)
+           
+           
+           
+           ###########for all models#################
+           setwd(base.folder)
+           if(max(which.computer==c("ALTA","HOPPER"))>0)
+             source("MLR part.R")
+           else
+             source("Caret part.R")
+           
+          setwd(cpout.folder)
+           if(norming == normings[length(normings)]){
+             write.table( gensTTest[-1],file = "tasks to test.csv",  quote = F, sep = ",", row.names = F,col.names = F)}
+           
+         }
+       }
+     }
+   }
+   
+ }

Attaching package: 'mlr'

The following object is masked from 'package:caret':

    train

Warning in preProcess.default(df.toprocess[, trans.y:length(df.toprocess[1,  :
  These variables have zero variances: V11, V12
Warning in preProcess.default(df.toprocess[, trans.y:length(df.toprocess[1,  :
  These variables have zero variances: V11, V12
Warning in preProcess.default(df.toprocess[, trans.y:length(df.toprocess[1,  :
  No variation for for: V11, V12
Warning in preProcess.default(df.toprocess[, trans.y:length(df.toprocess[1,  :
  No variation for for: V11, V12
Warning in preProcess.default(df.toprocess[, trans.y:length(df.toprocess[1,  :
  No variation for for: V11, V12
Error in getDefaultParConfig(learner) : 
  For the learner regr.laGP no default is available.
In addition: Warning message:
replacing previous import 'BBmisc::isFALSE' by 'backports::isFALSE' when loading 'mlr' 
i = 1 (of 248), d = 4.03081, its = 10
i = 2 (of 248), d = 8.3371, its = 20
i = 3 (of 248), d = 8.3371, its = 56
i = 4 (of 248), d = 4.12673, its = 11
i = 5 (of 248), d = 4.55152, its = 11
i = 6 (of 248), d = 4.65797, its = 12
i = 7 (of 248), d = 7.16367, its = 12
i = 8 (of 248), d = 2.93379, its = 10
i = 9 (of 248), d = 5.3511, its = 12
i = 10 (of 248), d = 5.98557, its = 12
i = 11 (of 248), d = 2.55262, its = 10
i = 12 (of 248), d = 6.37047, its = 12
i = 13 (of 248), d = 0.910576, its = 7
i = 14 (of 248), d = 3.36569, its = 9
i = 15 (of 248), d = 7.66243, its = 24
i = 16 (of 248), d = 2.41212, its = 8
i = 17 (of 248), d = 4.03068, its = 11
i = 18 (of 248), d = 3.74002, its = 11
i = 19 (of 248), d = 8.07489, its = 12
i = 20 (of 248), d = 2.81922, its = 10
i = 21 (of 248), d = 7.56688, its = 11
i = 22 (of 248), d = 5.13961, its = 11
i = 23 (of 248), d = 3.43849, its = 10
i = 24 (of 248), d = 7.70638, its = 12
i = 25 (of 248), d = 3.66894, its = 11
i = 26 (of 248), d = 3.42935, its = 11
i = 27 (of 248), d = 1.54886, its = 7
i = 28 (of 248), d = 7.7869, its = 11
i = 29 (of 248), d = 8.07187, its = 12
i = 30 (of 248), d = 4.43991, its = 10
i = 31 (of 248), d = 6.08024, its = 12
i = 32 (of 248), d = 5.96585, its = 11
i = 33 (of 248), d = 3.59262, its = 11
i = 34 (of 248), d = 7.48817, its = 10
i = 35 (of 248), d = 6.88067, its = 11
i = 36 (of 248), d = 5.82253, its = 11
i = 37 (of 248), d = 5.34255, its = 12
i = 38 (of 248), d = 6.48937, its = 12
i = 39 (of 248), d = 7.59276, its = 11
i = 40 (of 248), d = 5.13467, its = 11
i = 41 (of 248), d = 5.65935, its = 11
i = 42 (of 248), d = 2.52877, its = 9
i = 43 (of 248), d = 8.3371, its = 26
i = 44 (of 248), d = 1.93317, its = 8
i = 45 (of 248), d = 3.83435, its = 10
i = 46 (of 248), d = 6.53351, its = 11
i = 47 (of 248), d = 6.972, its = 11
i = 48 (of 248), d = 3.86272, its = 11
i = 49 (of 248), d = 4.4297, its = 11
i = 50 (of 248), d = 7.62165, its = 12
i = 51 (of 248), d = 4.2604, its = 11
i = 52 (of 248), d = 4.94765, its = 11
i = 53 (of 248), d = 5.93451, its = 11
i = 54 (of 248), d = 6.86295, its = 12
i = 55 (of 248), d = 0.689794, its = 7
i = 56 (of 248), d = 2.69295, its = 10
i = 57 (of 248), d = 8.3371, its = 40
i = 58 (of 248), d = 6.98304, its = 11
i = 59 (of 248), d = 6.87534, its = 11
i = 60 (of 248), d = 6.50667, its = 11
i = 61 (of 248), d = 7.86378, its = 11
i = 62 (of 248), d = 4.88297, its = 11
i = 63 (of 248), d = 4.40283, its = 11
i = 64 (of 248), d = 6.98213, its = 12
i = 65 (of 248), d = 6.23307, its = 11
i = 66 (of 248), d = 2.23432, its = 9
i = 67 (of 248), d = 3.18961, its = 10
i = 68 (of 248), d = 3.39619, its = 10
i = 69 (of 248), d = 3.64458, its = 11
i = 70 (of 248), d = 5.97932, its = 11
i = 71 (of 248), d = 4.63432, its = 10
i = 72 (of 248), d = 5.02815, its = 11
i = 73 (of 248), d = 4.18585, its = 11
i = 74 (of 248), d = 6.02572, its = 12
i = 75 (of 248), d = 6.08606, its = 12
i = 76 (of 248), d = 8.3371, its = 56
i = 77 (of 248), d = 5.08245, its = 11
i = 78 (of 248), d = 7.91133, its = 11
i = 79 (of 248), d = 7.66635, its = 11
i = 80 (of 248), d = 5.04026, its = 11
i = 81 (of 248), d = 1.12143, its = 7
i = 82 (of 248), d = 7.37428, its = 11
i = 83 (of 248), d = 5.01704, its = 11
i = 84 (of 248), d = 4.07383, its = 11
i = 85 (of 248), d = 6.14693, its = 12
i = 86 (of 248), d = 7.02133, its = 11
i = 87 (of 248), d = 4.52326, its = 11
i = 88 (of 248), d = 3.34277, its = 12
i = 89 (of 248), d = 1.99306, its = 10
i = 90 (of 248), d = 7.96942, its = 11
i = 91 (of 248), d = 3.99984, its = 11
i = 92 (of 248), d = 2.98038, its = 10
i = 93 (of 248), d = 6.69921, its = 12
i = 94 (of 248), d = 5.37417, its = 12
i = 95 (of 248), d = 5.56599, its = 11
i = 96 (of 248), d = 3.40647, its = 11
i = 97 (of 248), d = 2.65592, its = 10
i = 98 (of 248), d = 7.61494, its = 12
i = 99 (of 248), d = 8.3371, its = 57
i = 100 (of 248), d = 4.76934, its = 10
i = 101 (of 248), d = 5.39863, its = 11
i = 102 (of 248), d = 2.98004, its = 10
i = 103 (of 248), d = 8.3371, its = 45
i = 104 (of 248), d = 8.05812, its = 12
i = 105 (of 248), d = 6.09774, its = 11
i = 106 (of 248), d = 5.12185, its = 11
i = 107 (of 248), d = 8.3371, its = 57
i = 108 (of 248), d = 1.60019, its = 10
i = 109 (of 248), d = 8.2978, its = 11
i = 110 (of 248), d = 6.96993, its = 11
i = 111 (of 248), d = 4.34157, its = 11
i = 112 (of 248), d = 3.52071, its = 12
i = 113 (of 248), d = 7.75678, its = 11
i = 114 (of 248), d = 7.04647, its = 11
i = 115 (of 248), d = 5.42307, its = 11
i = 116 (of 248), d = 4.26513, its = 11
i = 117 (of 248), d = 8.3371, its = 20
i = 118 (of 248), d = 4.65948, its = 11
i = 119 (of 248), d = 6.55545, its = 11
i = 120 (of 248), d = 5.52769, its = 12
i = 121 (of 248), d = 6.56103, its = 12
i = 122 (of 248), d = 8.3371, its = 57
i = 123 (of 248), d = 5.05602, its = 11
i = 124 (of 248), d = 5.01193, its = 11
i = 125 (of 248), d = 3.0183, its = 10
i = 126 (of 248), d = 8.3371, its = 19
i = 127 (of 248), d = 7.30957, its = 12
i = 128 (of 248), d = 4.26798, its = 11
i = 129 (of 248), d = 5.2473, its = 12
i = 130 (of 248), d = 2.89382, its = 11
i = 131 (of 248), d = 1.17593, its = 8
i = 132 (of 248), d = 4.88452, its = 11
i = 133 (of 248), d = 4.9905, its = 11
i = 134 (of 248), d = 5.24647, its = 11
i = 135 (of 248), d = 4.42708, its = 10
i = 136 (of 248), d = 7.30042, its = 12
i = 137 (of 248), d = 8.3371, its = 23
i = 138 (of 248), d = 5.74195, its = 10
i = 139 (of 248), d = 5.2751, its = 25
i = 140 (of 248), d = 4.50044, its = 11
i = 141 (of 248), d = 3.11443, its = 10
i = 142 (of 248), d = 4.95713, its = 11
i = 143 (of 248), d = 6.16488, its = 12
i = 144 (of 248), d = 2.92963, its = 10
i = 145 (of 248), d = 4.57773, its = 12
i = 146 (of 248), d = 7.86838, its = 11
i = 147 (of 248), d = 6.79529, its = 11
i = 148 (of 248), d = 4.18654, its = 11
i = 149 (of 248), d = 4.61612, its = 12
i = 150 (of 248), d = 7.15301, its = 11
i = 151 (of 248), d = 6.43855, its = 11
i = 152 (of 248), d = 6.64187, its = 11
i = 153 (of 248), d = 4.73539, its = 11
i = 154 (of 248), d = 3.26561, its = 10
i = 155 (of 248), d = 8.3371, its = 58
i = 156 (of 248), d = 5.03572, its = 11
i = 157 (of 248), d = 7.67747, its = 12
i = 158 (of 248), d = 2.12209, its = 8
i = 159 (of 248), d = 6.34419, its = 12
i = 160 (of 248), d = 4.46615, its = 11
i = 161 (of 248), d = 2.7426, its = 10
i = 162 (of 248), d = 4.13503, its = 12
i = 163 (of 248), d = 1.73122, its = 10
i = 164 (of 248), d = 6.53785, its = 11
i = 165 (of 248), d = 5.11375, its = 12
i = 166 (of 248), d = 5.12029, its = 11
i = 167 (of 248), d = 3.64238, its = 10
i = 168 (of 248), d = 5.15999, its = 11
i = 169 (of 248), d = 5.51281, its = 11
i = 170 (of 248), d = 7.73514, its = 11
i = 171 (of 248), d = 5.99444, its = 11
i = 172 (of 248), d = 8.3371, its = 21
i = 173 (of 248), d = 6.69657, its = 11
i = 174 (of 248), d = 1.58729, its = 8
i = 175 (of 248), d = 6.07356, its = 12
i = 176 (of 248), d = 7.95467, its = 11
i = 177 (of 248), d = 5.4913, its = 10
i = 178 (of 248), d = 8.05126, its = 12
i = 179 (of 248), d = 6.25314, its = 11
i = 180 (of 248), d = 6.6544, its = 12
i = 181 (of 248), d = 8.3371, its = 22
i = 182 (of 248), d = 5.71014, its = 11
i = 183 (of 248), d = 0.583049, its = 7
i = 184 (of 248), d = 6.52362, its = 11
i = 185 (of 248), d = 8.3371, its = 22
i = 186 (of 248), d = 6.87598, its = 11
i = 187 (of 248), d = 8.29448, its = 12
i = 188 (of 248), d = 6.13798, its = 11
i = 189 (of 248), d = 6.18371, its = 12
i = 190 (of 248), d = 6.76291, its = 11
i = 191 (of 248), d = 3.12754, its = 10
i = 192 (of 248), d = 1.61134, its = 9
i = 193 (of 248), d = 5.93149, its = 11
i = 194 (of 248), d = 6.61071, its = 11
i = 195 (of 248), d = 8.19084, its = 12
i = 196 (of 248), d = 5.95537, its = 11
i = 197 (of 248), d = 5.40416, its = 19
i = 198 (of 248), d = 5.64317, its = 11
i = 199 (of 248), d = 5.57111, its = 11
i = 200 (of 248), d = 4.29356, its = 10
i = 201 (of 248), d = 7.20052, its = 12
i = 202 (of 248), d = 3.82713, its = 11
i = 203 (of 248), d = 7.45072, its = 11
i = 204 (of 248), d = 5.51841, its = 11
i = 205 (of 248), d = 4.58151, its = 12
i = 206 (of 248), d = 5.98354, its = 11
i = 207 (of 248), d = 4.41392, its = 11
i = 208 (of 248), d = 4.25808, its = 11
i = 209 (of 248), d = 2.44588, its = 9
i = 210 (of 248), d = 6.07259, its = 12
i = 211 (of 248), d = 6.81546, its = 11
i = 212 (of 248), d = 7.2263, its = 12
i = 213 (of 248), d = 3.64356, its = 10
i = 214 (of 248), d = 5.46068, its = 11
i = 215 (of 248), d = 8.3371, its = 24
i = 216 (of 248), d = 3.26508, its = 11
i = 217 (of 248), d = 5.74893, its = 11
i = 218 (of 248), d = 3.93042, its = 10
i = 219 (of 248), d = 5.68086, its = 11
i = 220 (of 248), d = 6.68069, its = 12
i = 221 (of 248), d = 6.55763, its = 11
i = 222 (of 248), d = 5.97653, its = 11
i = 223 (of 248), d = 7.70504, its = 11
i = 224 (of 248), d = 7.33714, its = 12
i = 225 (of 248), d = 5.98732, its = 11
i = 226 (of 248), d = 6.0927, its = 11
i = 227 (of 248), d = 5.23307, its = 12
i = 228 (of 248), d = 4.1316, its = 10
i = 229 (of 248), d = 4.13595, its = 12
i = 230 (of 248), d = 5.68819, its = 12
i = 231 (of 248), d = 7.16671, its = 12
i = 232 (of 248), d = 7.52292, its = 12
i = 233 (of 248), d = 5.09421, its = 11
i = 234 (of 248), d = 7.32584, its = 12
i = 235 (of 248), d = 6.43939, its = 12
i = 236 (of 248), d = 6.25682, its = 11
i = 237 (of 248), d = 8.3371, its = 20
i = 238 (of 248), d = 6.94211, its = 12
i = 239 (of 248), d = 5.01527, its = 12
i = 240 (of 248), d = 4.02795, its = 10
i = 241 (of 248), d = 6.89031, its = 11
i = 242 (of 248), d = 5.2654, its = 12
i = 243 (of 248), d = 4.17386, its = 11
i = 244 (of 248), d = 4.12786, its = 12
i = 245 (of 248), d = 3.34838, its = 11
i = 246 (of 248), d = 6.15476, its = 10
i = 247 (of 248), d = 5.59129, its = 12
i = 248 (of 248), d = 6.06844, its = 11
[1] "Fri Feb 09 17:56:28 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.LiblineaRL2L1SVR no default is available.
[1] "Fri Feb 09 17:56:35 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.LiblineaRL2L2SVR no default is available.
[1] "Fri Feb 09 17:56:41 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.lm no default is available.
[1] "Fri Feb 09 17:56:48 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.mars no default is available.
[1] "Fri Feb 09 17:56:54 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.mob no default is available.
[1] "Fri Feb 09 17:57:17 2018"
[Tune] Started tuning learner regr.nnet for parameter set:
         Type len   Def  Constr Req Tunable Trafo
size  integer   -     3 1 to 20   -    TRUE     -
decay numeric   - 1e-05 -5 to 1   -    TRUE     Y
With control class: TuneControlRandom
Imputation value: Inf
[Tune-x] 1: size=16; decay=0.000442
# weights:  177
initial  value 217.136915 
iter  10 value 1.017163
iter  20 value 0.106305
iter  30 value 0.059216
iter  40 value 0.049550
iter  50 value 0.045094
iter  60 value 0.042210
iter  70 value 0.039602
iter  80 value 0.037641
iter  90 value 0.035607
iter 100 value 0.034364
final  value 0.034364 
stopped after 100 iterations
# weights:  177
initial  value 74.022431 
iter  10 value 1.886258
iter  20 value 0.129395
iter  30 value 0.062671
iter  40 value 0.053804
iter  50 value 0.047818
iter  60 value 0.043747
iter  70 value 0.039967
iter  80 value 0.038141
iter  90 value 0.036864
iter 100 value 0.035424
final  value 0.035424 
stopped after 100 iterations
# weights:  177
initial  value 713.155515 
iter  10 value 2.368924
iter  20 value 0.117856
iter  30 value 0.071507
iter  40 value 0.055033
iter  50 value 0.048438
iter  60 value 0.043572
iter  70 value 0.040236
iter  80 value 0.037325
iter  90 value 0.035277
iter 100 value 0.033778
final  value 0.033778 
stopped after 100 iterations
[Tune-y] 1: rmse.test.rmse=0.00654; time: 0.0 min
[Tune-x] 2: size=3; decay=0.0815
# weights:  34
initial  value 38.020722 
iter  10 value 0.865047
iter  20 value 0.638804
iter  30 value 0.608489
iter  40 value 0.590626
iter  50 value 0.572524
iter  60 value 0.567047
iter  70 value 0.564647
iter  80 value 0.562100
iter  90 value 0.557173
iter 100 value 0.556462
final  value 0.556462 
stopped after 100 iterations
# weights:  34
initial  value 85.110539 
iter  10 value 1.378168
iter  20 value 0.732044
iter  30 value 0.618188
iter  40 value 0.603092
iter  50 value 0.592089
iter  60 value 0.579307
iter  70 value 0.577047
iter  80 value 0.569586
iter  90 value 0.567957
iter 100 value 0.567671
final  value 0.567671 
stopped after 100 iterations
# weights:  34
initial  value 337.814587 
iter  10 value 32.119962
iter  20 value 2.988903
iter  30 value 1.162218
iter  40 value 0.661829
iter  50 value 0.595206
iter  60 value 0.590759
iter  70 value 0.588020
iter  80 value 0.584203
iter  90 value 0.565754
iter 100 value 0.559513
final  value 0.559513 
stopped after 100 iterations
[Tune-y] 2: rmse.test.rmse=0.0152; time: 0.0 min
[Tune-x] 3: size=13; decay=0.0204
# weights:  144
initial  value 244.811547 
iter  10 value 1.269759
iter  20 value 0.509903
iter  30 value 0.269290
iter  40 value 0.228997
iter  50 value 0.219141
iter  60 value 0.215932
iter  70 value 0.212412
iter  80 value 0.209400
iter  90 value 0.207002
iter 100 value 0.204341
final  value 0.204341 
stopped after 100 iterations
# weights:  144
initial  value 52.063751 
iter  10 value 0.684058
iter  20 value 0.309135
iter  30 value 0.235713
iter  40 value 0.227233
iter  50 value 0.219995
iter  60 value 0.213855
iter  70 value 0.211687
iter  80 value 0.210198
iter  90 value 0.208553
iter 100 value 0.207594
final  value 0.207594 
stopped after 100 iterations
# weights:  144
initial  value 295.535327 
iter  10 value 2.994093
iter  20 value 1.294739
iter  30 value 0.631360
iter  40 value 0.366605
iter  50 value 0.285842
iter  60 value 0.251857
iter  70 value 0.234841
iter  80 value 0.226891
iter  90 value 0.220465
iter 100 value 0.216365
final  value 0.216365 
stopped after 100 iterations
[Tune-y] 3: rmse.test.rmse=0.0121; time: 0.0 min
[Tune-x] 4: size=8; decay=9.22
# weights:  89
initial  value 384.669335 
iter  10 value 41.768283
iter  20 value 29.320632
iter  30 value 28.249619
iter  40 value 28.165388
iter  50 value 28.068121
iter  60 value 28.057943
final  value 28.057235 
converged
# weights:  89
initial  value 164.955039 
iter  10 value 57.480847
iter  20 value 32.119260
iter  30 value 28.765807
iter  40 value 28.467033
iter  50 value 28.317402
iter  60 value 28.283404
iter  70 value 28.277428
iter  80 value 28.276932
final  value 28.276927 
converged
# weights:  89
initial  value 349.855426 
iter  10 value 40.889657
iter  20 value 29.012728
iter  30 value 28.496069
iter  40 value 28.381324
iter  50 value 28.299328
iter  60 value 28.116416
iter  70 value 28.056153
iter  80 value 27.997359
final  value 27.997326 
converged
[Tune-y] 4: rmse.test.rmse=0.14; time: 0.0 min
[Tune-x] 5: size=18; decay=0.109
# weights:  199
initial  value 163.247782 
iter  10 value 2.991353
iter  20 value 0.872101
iter  30 value 0.626924
iter  40 value 0.618208
iter  50 value 0.615696
iter  60 value 0.614772
iter  70 value 0.613967
iter  80 value 0.613462
iter  90 value 0.613115
iter 100 value 0.612827
final  value 0.612827 
stopped after 100 iterations
# weights:  199
initial  value 1158.663888 
iter  10 value 18.184326
iter  20 value 10.654761
iter  30 value 5.302260
iter  40 value 2.412074
iter  50 value 1.449135
iter  60 value 1.088412
iter  70 value 0.979762
iter  80 value 0.916397
iter  90 value 0.887652
iter 100 value 0.869409
final  value 0.869409 
stopped after 100 iterations
# weights:  199
initial  value 61.100313 
iter  10 value 3.702471
iter  20 value 0.891814
iter  30 value 0.718652
iter  40 value 0.658024
iter  50 value 0.635399
iter  60 value 0.627721
iter  70 value 0.622942
iter  80 value 0.620667
iter  90 value 0.619516
iter 100 value 0.619020
final  value 0.619020 
stopped after 100 iterations
[Tune-y] 5: rmse.test.rmse=0.0173; time: 0.0 min
[Tune-x] 6: size=8; decay=0.000519
# weights:  89
initial  value 206.249069 
iter  10 value 0.288453
iter  20 value 0.074909
iter  30 value 0.053280
iter  40 value 0.043782
iter  50 value 0.040328
iter  60 value 0.037569
iter  70 value 0.035669
iter  80 value 0.034590
iter  90 value 0.034064
iter 100 value 0.033644
final  value 0.033644 
stopped after 100 iterations
# weights:  89
initial  value 130.402605 
iter  10 value 0.804840
iter  20 value 0.107977
iter  30 value 0.065022
iter  40 value 0.057600
iter  50 value 0.051842
iter  60 value 0.047255
iter  70 value 0.043226
iter  80 value 0.041727
iter  90 value 0.040725
iter 100 value 0.039697
final  value 0.039697 
stopped after 100 iterations
# weights:  89
initial  value 3531.615276 
iter  10 value 0.393576
iter  20 value 0.073207
iter  30 value 0.056780
iter  40 value 0.049771
iter  50 value 0.046576
iter  60 value 0.042845
iter  70 value 0.041121
iter  80 value 0.039053
iter  90 value 0.038201
iter 100 value 0.037209
final  value 0.037209 
stopped after 100 iterations
[Tune-y] 6: rmse.test.rmse=0.00726; time: 0.0 min
[Tune-x] 7: size=10; decay=0.000293
# weights:  111
initial  value 393.287959 
iter  10 value 0.647372
iter  20 value 0.072376
iter  30 value 0.044752
iter  40 value 0.039462
iter  50 value 0.037538
iter  60 value 0.035068
iter  70 value 0.032487
iter  80 value 0.031217
iter  90 value 0.029844
iter 100 value 0.028892
final  value 0.028892 
stopped after 100 iterations
# weights:  111
initial  value 90.030854 
iter  10 value 0.159668
iter  20 value 0.064039
iter  30 value 0.046884
iter  40 value 0.042582
iter  50 value 0.039782
iter  60 value 0.036942
iter  70 value 0.035561
iter  80 value 0.034283
iter  90 value 0.033004
iter 100 value 0.032462
final  value 0.032462 
stopped after 100 iterations
# weights:  111
initial  value 1581.181511 
iter  10 value 0.254204
iter  20 value 0.064578
iter  30 value 0.044740
iter  40 value 0.039832
iter  50 value 0.036383
iter  60 value 0.033790
iter  70 value 0.032193
iter  80 value 0.029817
iter  90 value 0.028131
iter 100 value 0.027381
final  value 0.027381 
stopped after 100 iterations
[Tune-y] 7: rmse.test.rmse=0.0068; time: 0.0 min
[Tune-x] 8: size=9; decay=1.04
# weights:  100
initial  value 155.407038 
iter  10 value 6.586280
iter  20 value 4.771991
iter  30 value 4.583250
iter  40 value 4.504987
iter  50 value 4.498242
iter  60 value 4.496306
iter  70 value 4.492548
iter  80 value 4.491434
iter  90 value 4.490039
iter  90 value 4.490039
iter  90 value 4.490039
final  value 4.490039 
converged
# weights:  100
initial  value 69.516572 
iter  10 value 6.606537
iter  20 value 4.792724
iter  30 value 4.597927
iter  40 value 4.563342
iter  50 value 4.530019
iter  60 value 4.524467
iter  70 value 4.521257
iter  80 value 4.521026
iter  90 value 4.520540
final  value 4.520540 
converged
# weights:  100
initial  value 848.725588 
iter  10 value 14.289979
iter  20 value 7.068827
iter  30 value 5.238342
iter  40 value 4.781031
iter  50 value 4.599085
iter  60 value 4.543812
iter  70 value 4.529891
iter  80 value 4.522133
iter  90 value 4.517964
iter 100 value 4.511244
final  value 4.511244 
stopped after 100 iterations
[Tune-y] 8: rmse.test.rmse=0.0279; time: 0.0 min
[Tune-x] 9: size=7; decay=0.000462
# weights:  78
initial  value 100.486302 
iter  10 value 0.106674
iter  20 value 0.058832
iter  30 value 0.046322
iter  40 value 0.042025
iter  50 value 0.039367
iter  60 value 0.037655
iter  70 value 0.035622
iter  80 value 0.034367
iter  90 value 0.033628
iter 100 value 0.033151
final  value 0.033151 
stopped after 100 iterations
# weights:  78
initial  value 55.611055 
iter  10 value 0.493804
iter  20 value 0.087373
iter  30 value 0.056462
iter  40 value 0.047273
iter  50 value 0.043469
iter  60 value 0.041099
iter  70 value 0.039231
iter  80 value 0.038272
iter  90 value 0.037018
iter 100 value 0.036339
final  value 0.036339 
stopped after 100 iterations
# weights:  78
initial  value 589.921604 
iter  10 value 1.196280
iter  20 value 0.131422
iter  30 value 0.064173
iter  40 value 0.050925
iter  50 value 0.044717
iter  60 value 0.042384
iter  70 value 0.040986
iter  80 value 0.040182
iter  90 value 0.039099
iter 100 value 0.038141
final  value 0.038141 
stopped after 100 iterations
[Tune-y] 9: rmse.test.rmse=0.00726; time: 0.0 min
[Tune-x] 10: size=3; decay=0.000169
# weights:  34
initial  value 369.222226 
iter  10 value 0.875438
iter  20 value 0.089646
iter  30 value 0.048232
iter  40 value 0.042335
iter  50 value 0.039392
iter  60 value 0.036902
iter  70 value 0.035566
iter  80 value 0.034996
iter  90 value 0.033814
iter 100 value 0.030688
final  value 0.030688 
stopped after 100 iterations
# weights:  34
initial  value 175.759567 
iter  10 value 1.519713
iter  20 value 0.134948
iter  30 value 0.054289
iter  40 value 0.043041
iter  50 value 0.036446
iter  60 value 0.034422
iter  70 value 0.033321
iter  80 value 0.032713
iter  90 value 0.031357
iter 100 value 0.029958
final  value 0.029958 
stopped after 100 iterations
# weights:  34
initial  value 567.008083 
iter  10 value 0.569571
iter  20 value 0.051227
iter  30 value 0.041268
iter  40 value 0.037793
iter  50 value 0.034863
iter  60 value 0.033327
iter  70 value 0.032131
iter  80 value 0.031787
iter  90 value 0.031078
iter 100 value 0.030751
final  value 0.030751 
stopped after 100 iterations
[Tune-y] 10: rmse.test.rmse=0.00732; time: 0.0 min
[Tune-x] 11: size=11; decay=7.69e-05
# weights:  122
initial  value 1124.645294 
iter  10 value 0.926972
iter  20 value 0.101082
iter  30 value 0.051687
iter  40 value 0.034888
iter  50 value 0.031838
iter  60 value 0.029164
iter  70 value 0.026647
iter  80 value 0.024960
iter  90 value 0.023491
iter 100 value 0.022544
final  value 0.022544 
stopped after 100 iterations
# weights:  122
initial  value 826.714560 
iter  10 value 0.270367
iter  20 value 0.063250
iter  30 value 0.041377
iter  40 value 0.036407
iter  50 value 0.031610
iter  60 value 0.027630
iter  70 value 0.025876
iter  80 value 0.024524
iter  90 value 0.023203
iter 100 value 0.022286
final  value 0.022286 
stopped after 100 iterations
# weights:  122
initial  value 196.818692 
iter  10 value 0.891753
iter  20 value 0.093101
iter  30 value 0.045075
iter  40 value 0.034575
iter  50 value 0.031418
iter  60 value 0.028772
iter  70 value 0.026015
iter  80 value 0.024835
iter  90 value 0.022677
iter 100 value 0.020529
final  value 0.020529 
stopped after 100 iterations
[Tune-y] 11: rmse.test.rmse=0.00626; time: 0.0 min
[Tune-x] 12: size=7; decay=0.0818
# weights:  78
initial  value 861.645328 
iter  10 value 1.290518
iter  20 value 0.595653
iter  30 value 0.544858
iter  40 value 0.533823
iter  50 value 0.528580
iter  60 value 0.524633
iter  70 value 0.521714
iter  80 value 0.520345
iter  90 value 0.519582
iter 100 value 0.519083
final  value 0.519083 
stopped after 100 iterations
# weights:  78
initial  value 128.706641 
iter  10 value 1.293491
iter  20 value 0.602521
iter  30 value 0.585123
iter  40 value 0.562323
iter  50 value 0.548981
iter  60 value 0.545283
iter  70 value 0.543678
iter  80 value 0.543129
iter  90 value 0.542625
iter 100 value 0.542435
final  value 0.542435 
stopped after 100 iterations
# weights:  78
initial  value 1015.388559 
iter  10 value 2.015150
iter  20 value 0.680207
iter  30 value 0.563096
iter  40 value 0.545340
iter  50 value 0.535598
iter  60 value 0.533169
iter  70 value 0.529378
iter  80 value 0.526583
iter  90 value 0.524697
iter 100 value 0.524273
final  value 0.524273 
stopped after 100 iterations
[Tune-y] 12: rmse.test.rmse=0.0169; time: 0.0 min
[Tune-x] 13: size=15; decay=0.0556
# weights:  166
initial  value 190.417360 
iter  10 value 4.627664
iter  20 value 1.791673
iter  30 value 0.944883
iter  40 value 0.599828
iter  50 value 0.466724
iter  60 value 0.426405
iter  70 value 0.406467
iter  80 value 0.395354
iter  90 value 0.387978
iter 100 value 0.386074
final  value 0.386074 
stopped after 100 iterations
# weights:  166
initial  value 82.782612 
iter  10 value 3.419691
iter  20 value 1.313189
iter  30 value 0.924390
iter  40 value 0.718521
iter  50 value 0.568882
iter  60 value 0.490775
iter  70 value 0.457783
iter  80 value 0.434486
iter  90 value 0.421508
iter 100 value 0.413719
final  value 0.413719 
stopped after 100 iterations
# weights:  166
initial  value 40.676489 
iter  10 value 1.579366
iter  20 value 0.487098
iter  30 value 0.429140
iter  40 value 0.401027
iter  50 value 0.392106
iter  60 value 0.389788
iter  70 value 0.388658
iter  80 value 0.387794
iter  90 value 0.387149
iter 100 value 0.386501
final  value 0.386501 
stopped after 100 iterations
[Tune-y] 13: rmse.test.rmse=0.0163; time: 0.0 min
[Tune-x] 14: size=17; decay=8.02e-05
# weights:  188
initial  value 2748.894744 
iter  10 value 0.529396
iter  20 value 0.068790
iter  30 value 0.036282
iter  40 value 0.032285
iter  50 value 0.028636
iter  60 value 0.025919
iter  70 value 0.023253
iter  80 value 0.021490
iter  90 value 0.020096
iter 100 value 0.019303
final  value 0.019303 
stopped after 100 iterations
# weights:  188
initial  value 150.487136 
iter  10 value 0.242359
iter  20 value 0.091097
iter  30 value 0.058336
iter  40 value 0.038779
iter  50 value 0.034907
iter  60 value 0.032459
iter  70 value 0.029623
iter  80 value 0.027167
iter  90 value 0.025998
iter 100 value 0.024558
final  value 0.024558 
stopped after 100 iterations
# weights:  188
initial  value 93.470438 
iter  10 value 0.442872
iter  20 value 0.097496
iter  30 value 0.060209
iter  40 value 0.034002
iter  50 value 0.030086
iter  60 value 0.026119
iter  70 value 0.024614
iter  80 value 0.022952
iter  90 value 0.021982
iter 100 value 0.020646
final  value 0.020646 
stopped after 100 iterations
[Tune-y] 14: rmse.test.rmse=0.00614; time: 0.0 min
[Tune-x] 15: size=20; decay=0.000771
# weights:  221
initial  value 1783.263254 
iter  10 value 2.238500
iter  20 value 0.255353
iter  30 value 0.183356
iter  40 value 0.168017
iter  50 value 0.155932
iter  60 value 0.144609
iter  70 value 0.135674
iter  80 value 0.128828
iter  90 value 0.117747
iter 100 value 0.107832
final  value 0.107832 
stopped after 100 iterations
# weights:  221
initial  value 64.939159 
iter  10 value 1.255324
iter  20 value 0.205339
iter  30 value 0.098244
iter  40 value 0.073091
iter  50 value 0.061022
iter  60 value 0.053717
iter  70 value 0.047817
iter  80 value 0.044924
iter  90 value 0.042875
iter 100 value 0.041776
final  value 0.041776 
stopped after 100 iterations
# weights:  221
initial  value 85.765653 
iter  10 value 0.313259
iter  20 value 0.118938
iter  30 value 0.089278
iter  40 value 0.068166
iter  50 value 0.060182
iter  60 value 0.052624
iter  70 value 0.048117
iter  80 value 0.044683
iter  90 value 0.041886
iter 100 value 0.041011
final  value 0.041011 
stopped after 100 iterations
[Tune-y] 15: rmse.test.rmse=0.00686; time: 0.0 min
[Tune-x] 16: size=8; decay=0.00157
# weights:  89
initial  value 2054.450508 
iter  10 value 1.436085
iter  20 value 0.139860
iter  30 value 0.078945
iter  40 value 0.067041
iter  50 value 0.058963
iter  60 value 0.056572
iter  70 value 0.055212
iter  80 value 0.054497
iter  90 value 0.053245
iter 100 value 0.052307
final  value 0.052307 
stopped after 100 iterations
# weights:  89
initial  value 75.539001 
iter  10 value 0.304300
iter  20 value 0.069671
iter  30 value 0.060425
iter  40 value 0.056517
iter  50 value 0.054524
iter  60 value 0.054057
iter  70 value 0.053757
iter  80 value 0.053213
iter  90 value 0.052607
iter 100 value 0.051902
final  value 0.051902 
stopped after 100 iterations
# weights:  89
initial  value 1675.072207 
iter  10 value 0.640252
iter  20 value 0.116334
iter  30 value 0.077720
iter  40 value 0.066357
iter  50 value 0.059731
iter  60 value 0.057532
iter  70 value 0.055714
iter  80 value 0.054529
iter  90 value 0.053873
iter 100 value 0.053237
final  value 0.053237 
stopped after 100 iterations
[Tune-y] 16: rmse.test.rmse=0.00797; time: 0.0 min
[Tune-x] 17: size=15; decay=0.126
# weights:  166
initial  value 480.064900 
iter  10 value 11.314386
iter  20 value 4.217097
iter  30 value 1.716093
iter  40 value 1.159976
iter  50 value 0.952835
iter  60 value 0.848514
iter  70 value 0.785928
iter  80 value 0.761310
iter  90 value 0.748881
iter 100 value 0.739266
final  value 0.739266 
stopped after 100 iterations
# weights:  166
initial  value 102.770870 
iter  10 value 2.613593
iter  20 value 1.037729
iter  30 value 0.837902
iter  40 value 0.761682
iter  50 value 0.735837
iter  60 value 0.728341
iter  70 value 0.721155
iter  80 value 0.717631
iter  90 value 0.716928
iter 100 value 0.716436
final  value 0.716436 
stopped after 100 iterations
# weights:  166
initial  value 90.773496 
iter  10 value 11.220025
iter  20 value 3.333095
iter  30 value 2.045093
iter  40 value 1.518490
iter  50 value 0.894007
iter  60 value 0.784709
iter  70 value 0.744988
iter  80 value 0.718480
iter  90 value 0.706666
iter 100 value 0.704402
final  value 0.704402 
stopped after 100 iterations
[Tune-y] 17: rmse.test.rmse=0.0175; time: 0.0 min
[Tune-x] 18: size=16; decay=0.00035
# weights:  177
initial  value 304.780931 
iter  10 value 0.238773
iter  20 value 0.080737
iter  30 value 0.049704
iter  40 value 0.043582
iter  50 value 0.039461
iter  60 value 0.036886
iter  70 value 0.034452
iter  80 value 0.031785
iter  90 value 0.030617
iter 100 value 0.029674
final  value 0.029674 
stopped after 100 iterations
# weights:  177
initial  value 1760.636836 
iter  10 value 8.898014
iter  20 value 1.549204
iter  30 value 0.290147
iter  40 value 0.224971
iter  50 value 0.203202
iter  60 value 0.188758
iter  70 value 0.175959
iter  80 value 0.164674
iter  90 value 0.157369
iter 100 value 0.151766
final  value 0.151766 
stopped after 100 iterations
# weights:  177
initial  value 304.559630 
iter  10 value 1.278139
iter  20 value 0.115566
iter  30 value 0.086055
iter  40 value 0.078269
iter  50 value 0.067366
iter  60 value 0.058202
iter  70 value 0.052842
iter  80 value 0.047532
iter  90 value 0.044099
iter 100 value 0.041087
final  value 0.041087 
stopped after 100 iterations
[Tune-y] 18: rmse.test.rmse=0.00691; time: 0.0 min
[Tune-x] 19: size=7; decay=0.0479
# weights:  78
initial  value 481.179479 
iter  10 value 1.484213
iter  20 value 0.547279
iter  30 value 0.422875
iter  40 value 0.367001
iter  50 value 0.365150
iter  60 value 0.364559
iter  70 value 0.363577
iter  80 value 0.362427
iter  90 value 0.361054
iter 100 value 0.359816
final  value 0.359816 
stopped after 100 iterations
# weights:  78
initial  value 482.814454 
iter  10 value 0.860936
iter  20 value 0.396210
iter  30 value 0.378423
iter  40 value 0.376850
iter  50 value 0.376168
iter  60 value 0.375667
iter  70 value 0.375345
iter  80 value 0.375124
iter  90 value 0.374557
iter 100 value 0.373999
final  value 0.373999 
stopped after 100 iterations
# weights:  78
initial  value 178.508081 
iter  10 value 1.402486
iter  20 value 0.581686
iter  30 value 0.435646
iter  40 value 0.379238
iter  50 value 0.368702
iter  60 value 0.365584
iter  70 value 0.363776
iter  80 value 0.362804
iter  90 value 0.361645
iter 100 value 0.360914
final  value 0.360914 
stopped after 100 iterations
[Tune-y] 19: rmse.test.rmse=0.0153; time: 0.0 min
[Tune-x] 20: size=7; decay=0.0129
# weights:  78
initial  value 1866.265295 
iter  10 value 1.170680
iter  20 value 0.316781
iter  30 value 0.230277
iter  40 value 0.203608
iter  50 value 0.185174
iter  60 value 0.169350
iter  70 value 0.161022
iter  80 value 0.154978
iter  90 value 0.152072
iter 100 value 0.151206
final  value 0.151206 
stopped after 100 iterations
# weights:  78
initial  value 234.993530 
iter  10 value 0.567871
iter  20 value 0.240020
iter  30 value 0.182065
iter  40 value 0.171147
iter  50 value 0.165944
iter  60 value 0.160906
iter  70 value 0.159509
iter  80 value 0.158056
iter  90 value 0.156768
iter 100 value 0.156175
final  value 0.156175 
stopped after 100 iterations
# weights:  78
initial  value 753.366430 
iter  10 value 1.263172
iter  20 value 0.363642
iter  30 value 0.255348
iter  40 value 0.219551
iter  50 value 0.183339
iter  60 value 0.167742
iter  70 value 0.157889
iter  80 value 0.153673
iter  90 value 0.151168
iter 100 value 0.149803
final  value 0.149803 
stopped after 100 iterations
[Tune-y] 20: rmse.test.rmse=0.0103; time: 0.0 min
[Tune] Result: size=17; decay=8.02e-05 : rmse.test.rmse=0.00614
# weights:  188
initial  value 616.956909 
iter  10 value 0.967214
iter  20 value 0.125821
iter  30 value 0.074400
iter  40 value 0.061454
iter  50 value 0.051087
iter  60 value 0.044625
iter  70 value 0.039316
iter  80 value 0.034356
iter  90 value 0.031620
iter 100 value 0.029557
final  value 0.029557 
stopped after 100 iterations
[1] "Fri Feb 09 17:57:40 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.nodeHarvest no default is available.

 ... generating 1000 nodes ...
 total number of nodes in initial set                   : 1081
 total number of nodes after removal of identical nodes : 675 
 ... computing node means ... 
 ... computing node weights ...
 dimension of null space of I                           : 387
 number of selected nodes                               : 81 
[1] "Fri Feb 09 17:58:00 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.pcr no default is available.
[1] "Fri Feb 09 17:58:07 2018"
Loading required package: penalized
Loading required package: survival

Attaching package: 'survival'

The following object is masked from 'package:caret':

    cluster

Welcome to penalized. For extended examples, see vignette("penalized").
Error in getDefaultParConfig(learner) : 
  For the learner regr.plsr no default is available.
In addition: Warning messages:
1: package '!penalized' is not available (for R version 3.4.3) 
2: package '!penalized' is not available (for R version 3.4.3) 
3: package '!penalized' is not available (for R version 3.4.3) 
[1] "Fri Feb 09 17:58:36 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.randomForestSRC no default is available.
[1] "Fri Feb 09 17:58:45 2018"
[Tune] Started tuning learner regr.ranger for parameter set:
                 Type len Def  Constr Req Tunable Trafo
mtry          integer   -   3  1 to 9   -    TRUE     -
min.node.size integer   -   5 1 to 10   -    TRUE     -
With control class: TuneControlRandom
Imputation value: Inf
[Tune-x] 1: mtry=8; min.node.size=3
[Tune-y] 1: rmse.test.rmse=0.0164; time: 0.2 min
[Tune-x] 2: mtry=2; min.node.size=7
[Tune-y] 2: rmse.test.rmse=0.0178; time: 0.0 min
[Tune-x] 3: mtry=6; min.node.size=6
[Tune-y] 3: rmse.test.rmse=0.0159; time: 0.1 min
[Tune-x] 4: mtry=4; min.node.size=10
[Tune-y] 4: rmse.test.rmse=0.0166; time: 0.1 min
[Tune-x] 5: mtry=8; min.node.size=7
[Tune-y] 5: rmse.test.rmse=0.0173; time: 0.1 min
[Tune-x] 6: mtry=4; min.node.size=3
[Tune-y] 6: rmse.test.rmse=0.0147; time: 0.1 min
[Tune-x] 7: mtry=5; min.node.size=3
[Tune-y] 7: rmse.test.rmse=0.015; time: 0.1 min
[Tune-x] 8: mtry=4; min.node.size=9
[Tune-y] 8: rmse.test.rmse=0.0163; time: 0.1 min
[Tune-x] 9: mtry=3; min.node.size=3
[Tune-y] 9: rmse.test.rmse=0.015; time: 0.1 min
[Tune-x] 10: mtry=2; min.node.size=3
[Tune-y] 10: rmse.test.rmse=0.0164; time: 0.1 min
[Tune-x] 11: mtry=5; min.node.size=2
[Tune-y] 11: rmse.test.rmse=0.015; time: 0.1 min
[Tune-x] 12: mtry=3; min.node.size=7
[Tune-y] 12: rmse.test.rmse=0.0156; time: 0.1 min
[Tune-x] 13: mtry=7; min.node.size=7
[Tune-y] 13: rmse.test.rmse=0.0167; time: 0.1 min
[Tune-x] 14: mtry=8; min.node.size=2
[Tune-y] 14: rmse.test.rmse=0.0162; time: 0.1 min
[Tune-x] 15: mtry=9; min.node.size=4
[Tune-y] 15: rmse.test.rmse=0.0172; time: 0.1 min
[Tune-x] 16: mtry=4; min.node.size=4
[Tune-y] 16: rmse.test.rmse=0.0148; time: 0.1 min
[Tune-x] 17: mtry=7; min.node.size=7
[Tune-y] 17: rmse.test.rmse=0.0166; time: 0.1 min
[Tune-x] 18: mtry=8; min.node.size=3
[Tune-y] 18: rmse.test.rmse=0.0164; time: 0.1 min
[Tune-x] 19: mtry=3; min.node.size=7
[Tune-y] 19: rmse.test.rmse=0.0161; time: 0.1 min
[Tune-x] 20: mtry=3; min.node.size=6
[Tune-y] 20: rmse.test.rmse=0.0156; time: 0.1 min
[Tune] Result: mtry=4; min.node.size=3 : rmse.test.rmse=0.0147
[1] "Fri Feb 09 18:00:39 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.rknn no default is available.
[1] "Fri Feb 09 18:00:49 2018"
[Tune] Started tuning learner regr.rpart for parameter set:
             Type len   Def   Constr Req Tunable Trafo
cp        numeric   - -6.64 -10 to 0   -    TRUE     Y
maxdepth  integer   -    30  3 to 30   -    TRUE     -
minbucket integer   -     7  5 to 50   -    TRUE     -
minsplit  integer   -    20  5 to 50   -    TRUE     -
With control class: TuneControlRandom
Imputation value: Inf
[Tune-x] 1: cp=0.221; maxdepth=10; minbucket=10; minsplit=34
[Tune-y] 1: rmse.test.rmse=0.148; time: 0.0 min
[Tune-x] 2: cp=0.0637; maxdepth=18; minbucket=23; minsplit=50
[Tune-y] 2: rmse.test.rmse=0.0846; time: 0.0 min
[Tune-x] 3: cp=0.366; maxdepth=21; minbucket=21; minsplit=18
[Tune-y] 3: rmse.test.rmse=0.148; time: 0.0 min
[Tune-x] 4: cp=0.0242; maxdepth=9; minbucket=24; minsplit=43
[Tune-y] 4: rmse.test.rmse=0.0846; time: 0.0 min
[Tune-x] 5: cp=0.00911; maxdepth=10; minbucket=10; minsplit=14
[Tune-y] 5: rmse.test.rmse=0.066; time: 0.0 min
[Tune-x] 6: cp=0.0328; maxdepth=7; minbucket=19; minsplit=34
[Tune-y] 6: rmse.test.rmse=0.0846; time: 0.0 min
[Tune-x] 7: cp=0.129; maxdepth=20; minbucket=42; minsplit=11
[Tune-y] 7: rmse.test.rmse=0.148; time: 0.0 min
[Tune-x] 8: cp=0.847; maxdepth=11; minbucket=21; minsplit=21
[Tune-y] 8: rmse.test.rmse=0.289; time: 0.0 min
[Tune-x] 9: cp=0.168; maxdepth=22; minbucket=41; minsplit=16
[Tune-y] 9: rmse.test.rmse=0.148; time: 0.0 min
[Tune-x] 10: cp=0.00797; maxdepth=20; minbucket=18; minsplit=28
[Tune-y] 10: rmse.test.rmse=0.0632; time: 0.0 min
[Tune-x] 11: cp=0.218; maxdepth=8; minbucket=47; minsplit=24
[Tune-y] 11: rmse.test.rmse=0.148; time: 0.0 min
[Tune-x] 12: cp=0.00274; maxdepth=12; minbucket=47; minsplit=34
[Tune-y] 12: rmse.test.rmse=0.0584; time: 0.0 min
[Tune-x] 13: cp=0.00412; maxdepth=15; minbucket=27; minsplit=32
[Tune-y] 13: rmse.test.rmse=0.0563; time: 0.0 min
[Tune-x] 14: cp=0.19; maxdepth=29; minbucket=6; minsplit=19
[Tune-y] 14: rmse.test.rmse=0.148; time: 0.0 min
[Tune-x] 15: cp=0.0104; maxdepth=28; minbucket=41; minsplit=27
[Tune-y] 15: rmse.test.rmse=0.0721; time: 0.0 min
[Tune-x] 16: cp=0.013; maxdepth=14; minbucket=5; minsplit=39
[Tune-y] 16: rmse.test.rmse=0.0743; time: 0.0 min
[Tune-x] 17: cp=0.214; maxdepth=6; minbucket=44; minsplit=8
[Tune-y] 17: rmse.test.rmse=0.148; time: 0.0 min
[Tune-x] 18: cp=0.724; maxdepth=14; minbucket=6; minsplit=45
[Tune-y] 18: rmse.test.rmse=0.148; time: 0.0 min
[Tune-x] 19: cp=0.998; maxdepth=7; minbucket=16; minsplit=37
[Tune-y] 19: rmse.test.rmse=0.289; time: 0.0 min
[Tune-x] 20: cp=0.0727; maxdepth=5; minbucket=27; minsplit=26
[Tune-y] 20: rmse.test.rmse=0.0846; time: 0.0 min
[Tune] Result: cp=0.00412; maxdepth=15; minbucket=27; minsplit=32 : rmse.test.rmse=0.0563
[1] "Fri Feb 09 18:00:58 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.rsm no default is available.
[1] "Fri Feb 09 18:01:04 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.rvm no default is available.
Using automatic sigma estimation (sigest) for RBF or laplace kernel 
[1] "Fri Feb 09 18:01:28 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.slim no default is available.
Sparse Linear Regression with L1 Regularization.
Square root Lasso with screening.

slim options summary: 
5 lambdas used:
[1] 0.9840 0.4770 0.2310 0.1120 0.0541
Method = lq 
q = 2 loss, SQRT Lasso
Degree of freedom: 0 -----> 4 
Runtime: 0.5350301 secs 

 Values of predicted responses: 
   index             3 
   lambda       0.2307 
    Y 1         0.6127 
    Y 2        0.09064 
    Y 3         0.3614 
    Y 4         0.3228 
    Y 5         0.5364 
[1] "Fri Feb 09 18:01:36 2018"
[Tune] Started tuning learner regr.xgboost for parameter set:
                    Type len Def       Constr Req Tunable Trafo
nrounds          numeric   -   0    0 to 8.64   -    TRUE     Y
max_depth        integer   -   6      1 to 10   -    TRUE     -
eta              numeric   - 0.3 0.001 to 0.6   -    TRUE     -
gamma            numeric   -   0      0 to 10   -    TRUE     -
colsample_bytree numeric   - 0.5   0.3 to 0.7   -    TRUE     -
min_child_weight numeric   -   1      0 to 20   -    TRUE     -
subsample        numeric   -   1    0.25 to 1   -    TRUE     -
With control class: TuneControlRandom
Imputation value: Inf
[Tune-x] 1: nrounds=1.09e+03; max_depth=3; eta=0.0676; gamma=6.52; colsample_bytree=0.541; min_child_weight=11; subsample=0.544
[Tune-y] 1: rmse.test.rmse=0.179; time: 0.2 min
[Tune-x] 2: nrounds=3.86e+03; max_depth=9; eta=0.404; gamma=3.66; colsample_bytree=0.414; min_child_weight=9.27; subsample=0.433
[Tune-y] 2: rmse.test.rmse=0.139; time: 1.2 min
[Tune-x] 3: nrounds=134; max_depth=9; eta=0.194; gamma=2.77; colsample_bytree=0.35; min_child_weight=4.1; subsample=0.63
[Tune-y] 3: rmse.test.rmse=0.114; time: 0.1 min
[Tune-x] 4: nrounds=24; max_depth=4; eta=0.392; gamma=7.04; colsample_bytree=0.55; min_child_weight=16.3; subsample=0.363
[Tune-y] 4: rmse.test.rmse=0.218; time: 0.0 min
[Tune-x] 5: nrounds=3.46e+03; max_depth=4; eta=0.211; gamma=3.66; colsample_bytree=0.597; min_child_weight=13.7; subsample=0.85
[Tune-y] 5: rmse.test.rmse=0.114; time: 0.7 min
[Tune-x] 6: nrounds=47; max_depth=4; eta=0.368; gamma=3.02; colsample_bytree=0.507; min_child_weight=15.6; subsample=0.393
[Tune-y] 6: rmse.test.rmse=0.142; time: 0.0 min
[Tune-x] 7: nrounds=2.4e+03; max_depth=5; eta=0.09; gamma=3.51; colsample_bytree=0.673; min_child_weight=12.7; subsample=0.406
[Tune-y] 7: rmse.test.rmse=0.147; time: 0.6 min
[Tune-x] 8: nrounds=132; max_depth=5; eta=0.359; gamma=7.6; colsample_bytree=0.682; min_child_weight=0.864; subsample=0.482
[Tune-y] 8: rmse.test.rmse=0.174; time: 0.0 min
[Tune-x] 9: nrounds=77; max_depth=10; eta=0.47; gamma=4.84; colsample_bytree=0.45; min_child_weight=8.24; subsample=0.261
[Tune-y] 9: rmse.test.rmse=0.176; time: 0.0 min
[Tune-x] 10: nrounds=867; max_depth=8; eta=0.0668; gamma=8.51; colsample_bytree=0.333; min_child_weight=19.1; subsample=0.556
[Tune-y] 10: rmse.test.rmse= 0.2; time: 0.2 min
[Tune-x] 11: nrounds=12; max_depth=9; eta=0.6; gamma=1.49; colsample_bytree=0.4; min_child_weight=13.9; subsample=0.716
[Tune-y] 11: rmse.test.rmse=0.0787; time: 0.0 min
[Tune-x] 12: nrounds=17; max_depth=5; eta=0.278; gamma=1.67; colsample_bytree=0.402; min_child_weight=4.57; subsample=0.854
[Tune-y] 12: rmse.test.rmse=0.0858; time: 0.0 min
[Tune-x] 13: nrounds=1.6e+03; max_depth=5; eta=0.52; gamma=4.33; colsample_bytree=0.676; min_child_weight=19.4; subsample=0.467
[Tune-y] 13: rmse.test.rmse=0.15; time: 0.4 min
[Tune-x] 14: nrounds=2.24e+03; max_depth=8; eta=0.124; gamma=8.71; colsample_bytree=0.572; min_child_weight=6.42; subsample=0.532
[Tune-y] 14: rmse.test.rmse=0.191; time: 0.8 min
[Tune-x] 15: nrounds=2.83e+03; max_depth=8; eta=0.193; gamma=6.14; colsample_bytree=0.321; min_child_weight=11.4; subsample=0.329
[Tune-y] 15: rmse.test.rmse=0.19; time: 0.7 min
[Tune-x] 16: nrounds=16; max_depth=6; eta=0.203; gamma=1.13; colsample_bytree=0.549; min_child_weight=10.2; subsample=0.663
[Tune-y] 16: rmse.test.rmse=0.082; time: 0.0 min
[Tune-x] 17: nrounds=22; max_depth=6; eta=0.112; gamma=3.93; colsample_bytree=0.55; min_child_weight=14.9; subsample=0.722
[Tune-y] 17: rmse.test.rmse=0.137; time: 0.0 min
[Tune-x] 18: nrounds=19; max_depth=3; eta=0.226; gamma=3.32; colsample_bytree=0.674; min_child_weight=13.3; subsample=0.318
[Tune-y] 18: rmse.test.rmse=0.16; time: 0.0 min
[Tune-x] 19: nrounds=25; max_depth=8; eta=0.57; gamma=0.365; colsample_bytree=0.516; min_child_weight=13.2; subsample=0.791
[Tune-y] 19: rmse.test.rmse=0.0527; time: 0.0 min
[Tune-x] 20: nrounds=10; max_depth=6; eta=0.0826; gamma=9.11; colsample_bytree=0.478; min_child_weight=4.05; subsample=0.852
[Tune-y] 20: rmse.test.rmse=0.185; time: 0.0 min
[Tune] Result: nrounds=25; max_depth=8; eta=0.57; gamma=0.365; colsample_bytree=0.516; min_child_weight=13.2; subsample=0.791 : rmse.test.rmse=0.0527
[1] "Fri Feb 09 18:06:31 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.xyf no default is available.
Warning in train(allmodel, regr.task) :
  Could not train learner regr.xyf: Error in !toroidal : invalid argument type

[1] "Fri Feb 09 18:06:39 2018"
Warning in preProcess.default(df.toprocess[, trans.y:length(df.toprocess[1,  :
  No variation for for: V11, V12
Error in requirePackages(package, why = stri_paste("learner", id, sep = " "),  : 
  For learner regr.bartMachine please install the following packages: bartMachine
Error in getDefaultParConfig(learner) : 
  For the learner regr.bcart no default is available.

burn in:
**GROW** @depth 0: [9,0.502002], n=(382,370)
**GROW** @depth 1: [3,0.498497], n=(286,95)
**GROW** @depth 1: [3,0.446894], n=(68,303)
**GROW** @depth 2: [9,0.268268], n=(175,111)
**GROW** @depth 2: [3,0.713928], n=(121,182)
**GROW** @depth 3: [9,0.132132], n=(92,82)
**GROW** @depth 2: [3,0.745992], n=(73,23)
**GROW** @depth 3: [2,0.402806], n=(41,31)
**GROW** @depth 2: [3,0.856212], n=(75,105)
**GROW** @depth 4: [9,0.376376], n=(59,49)
**GROW** @depth 3: [3,0.933868], n=(49,52)
**GROW** @depth 4: [9,0.247748], n=(17,28)
r=1000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0]; n=(94,76,63,48,17,28,32,23,71,118,79,51,52)
**GROW** @depth 4: [9,0.747748], n=(18,35)
**GROW** @depth 4: [9,0.321822], n=(35,29)
**PRUNE** @depth 5: [9,0.321822]
**GROW** @depth 5: [6,0.867735], n=(30,12)
**PRUNE** @depth 5: [6,0.867735]
r=2000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0]; n=(94,76,65,49,17,29,32,25,54,116,64,41,42,48)

Sampling @ nn=0 pred locs:
**GROW** @depth 4: [9,0.624625], n=(27,29)
**GROW** @depth 4: [3,0.710421], n=(62,52)
r=1000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0]; mh=6 n=(93,76,65,50,19,30,34,25,27,29,62,52,60,42,39,49)
**GROW** @depth 5: [9,0.316316], n=(31,33)
**GROW** @depth 5: [9,0.032032], n=(25,68)
**GROW** @depth 5: [9,0.0810811], n=(37,31)
**GROW** @depth 5: [9,0.638639], n=(30,29)
r=2000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0]; mh=10 n=(26,38,29,74,31,36,50,19,30,34,25,28,32,30,29,51,60,40,42,48)
**GROW** @depth 5: [3,0.831162], n=(27,24)
r=3000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0]; mh=8 n=(26,39,31,69,33,36,51,19,30,34,25,27,32,30,29,27,25,58,42,42,47)
r=4000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0]; mh=8 n=(24,41,31,69,36,32,52,19,30,34,25,26,33,31,28,27,25,58,42,44,45)
r=5000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0]; mh=8 n=(26,39,30,71,35,31,52,19,30,34,25,29,33,29,28,28,25,58,42,44,44)
Grow: 6.094%, Prune: 0.5618%, Change: 68.45%, Swap: 37.12%

[1] "Fri Feb 09 18:07:00 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.bdk no default is available.
Warning in train(allmodel, regr.task) :
  Could not train learner regr.bdk: Error : 'bdk' is not an exported object from 'namespace:kohonen'

[1] "Fri Feb 09 18:07:07 2018"
Error in requirePackages(package, why = stri_paste("learner", id, sep = " "),  : 
  For learner regr.blackboost please install the following packages: mboost
Error in getDefaultParConfig(learner) : 
  For the learner regr.blm no default is available.

burn in:
r=1000 d=[0]; n=752

Sampling @ nn=0 pred locs:
r=1000 d=[0]; mh=1 n=752
r=2000 d=[0]; mh=1 n=752
r=3000 d=[0]; mh=1 n=752

[1] "Fri Feb 09 18:07:20 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.brnn no default is available.
Number of parameters (weights and biases) to estimate: 22 
Nguyen-Widrow method
Scaling factor= 0.7006455 
gamma= 21.0052 	 alpha= 0.2006 	 beta= 2168.643 
[1] "Fri Feb 09 18:07:27 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.bst no default is available.
[1] "Fri Feb 09 18:07:34 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.btlm no default is available.

burn in:
**GROW** @depth 0: [4,0.448345], n=(341,411)
**GROW** @depth 1: [9,0.510511], n=(166,245)
**GROW** @depth 2: [8,0.863363], n=(142,102)
**GROW** @depth 3: [8,0.934434], n=(48,54)
**PRUNE** @depth 3: [8,0.863363]
**GROW** @depth 1: [6,0.5], n=(283,58)
**GROW** @depth 2: [1,0.460381], n=(248,40)
**GROW** @depth 3: [4,0.740221], n=(108,78)
**GROW** @depth 3: [8,0.958959], n=(25,34)
**PRUNE** @depth 3: [4,0.741224]
**GROW** @depth 2: [3,0.48497], n=(76,90)
**PRUNE** @depth 2: [3,0.48497]
**PRUNE** @depth 3: [8,0.960961]
**GROW** @depth 2: [8,0.665165], n=(128,38)
**PRUNE** @depth 2: [8,0.665165]
**GROW** @depth 2: [9,0.251251], n=(51,113)
**GROW** @depth 3: [2,0.174349], n=(101,85)
r=1000 d=[0] [0] [0] [0] [0] [0] [0] [0]; n=(101,85,95,60,53,114,186,58)
**GROW** @depth 4: [4,0.124373], n=(45,56)
r=2000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0]; n=(44,59,86,94,61,48,117,185,58)

Sampling @ nn=0 pred locs:
**GROW** @depth 4: [1,0.367101], n=(50,37)
**PRUNE** @depth 4: [1,0.367101]
r=1000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0]; mh=6 n=(44,57,87,93,58,49,117,190,57)
**GROW** @depth 3: [8,0.95996], n=(25,33)
**PRUNE** @depth 3: [8,0.95996]
r=2000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0]; mh=6 n=(44,57,87,93,58,50,116,189,58)
**GROW** @depth 4: [3,0.175351], n=(38,48)
**PRUNE** @depth 4: [3,0.175351]
r=3000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0]; mh=6 n=(44,60,88,93,61,47,116,184,59)
r=4000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0]; mh=6 n=(45,60,84,94,61,49,120,182,57)
**GROW** @depth 5: [2,0.0521042], n=(16,48)
**GROW** @depth 4: [8,0.0780781], n=(23,17)
**GROW** @depth 4: [4,0.725176], n=(100,79)
**PRUNE** @depth 4: [4,0.725176]
r=5000 d=[0] [0] [0] [0] [0] [0] [0] [0] [0] [0] [0]; mh=7 n=(21,20,18,47,86,93,61,46,123,178,59)
Grow: 5.367%, Prune: 2.535%, Change: 72.65%, Swap: 10.78%

[1] "Fri Feb 09 18:07:47 2018"
Loading required package: crs
Error: package or namespace load failed for 'crs' in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
 there is no package called 'MatrixModels'
Error in requirePackages(package, why = stri_paste("learner", id, sep = " "),  : 
  For learner regr.crs please install the following packages: crs
Error in getDefaultParConfig(learner) : 
  For the learner regr.ctree no default is available.
[1] "Fri Feb 09 18:07:56 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.cubist no default is available.
[1] "Fri Feb 09 18:08:03 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.cvglmnet no default is available.
[1] "Fri Feb 09 18:08:10 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.earth no default is available.
[1] "Fri Feb 09 18:08:18 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.elmNN no default is available.
Loading required package: MASS
[1] "Fri Feb 09 18:08:25 2018"
Error in requirePackages(package, why = stri_paste("learner", id, sep = " "),  : 
  For learner regr.evtree please install the following packages: evtree
Error in getDefaultParConfig(learner) : 
  For the learner regr.featureless no default is available.
[1] "Fri Feb 09 18:08:34 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.fnn no default is available.
[1] "Fri Feb 09 18:08:40 2018"
Error in requirePackages(package, why = stri_paste("learner", id, sep = " "),  : 
  For learner regr.gamboost please install the following packages: mboost
Error in getDefaultParConfig(learner) : 
  For the learner regr.gausspr no default is available.
Using automatic sigma estimation (sigest) for RBF or laplace kernel 
[1] "Fri Feb 09 18:08:51 2018"
[Tune] Started tuning learner regr.gbm for parameter set:
                     Type len   Def       Constr Req Tunable Trafo
n.trees           numeric   -  5.64    0 to 6.64   -    TRUE     Y
interaction.depth integer   -     1      1 to 10   -    TRUE     -
shrinkage         numeric   - 0.001 0.001 to 0.6   -    TRUE     -
n.minobsinnode    integer   -    10      5 to 25   -    TRUE     -
With control class: TuneControlRandom
Imputation value: Inf
[Tune-x] 1: n.trees=10; interaction.depth=6; shrinkage=0.393; n.minobsinnode=13
[Tune-y] 1: rmse.test.rmse=0.0599; time: 0.0 min
[Tune-x] 2: n.trees=94; interaction.depth=6; shrinkage=0.00808; n.minobsinnode=12
[Tune-y] 2: rmse.test.rmse=0.322; time: 0.0 min
[Tune-x] 3: n.trees=283; interaction.depth=3; shrinkage=0.41; n.minobsinnode=16
[Tune-y] 3: rmse.test.rmse=0.0458; time: 0.0 min
[Tune-x] 4: n.trees=16; interaction.depth=7; shrinkage=0.518; n.minobsinnode=16
[Tune-y] 4: rmse.test.rmse=0.0625; time: 0.0 min
[Tune-x] 5: n.trees=236; interaction.depth=5; shrinkage=0.00765; n.minobsinnode=6
[Tune-y] 5: rmse.test.rmse=0.139; time: 0.0 min
[Tune-x] 6: n.trees=50; interaction.depth=5; shrinkage=0.107; n.minobsinnode=19
[Tune-y] 6: rmse.test.rmse=0.0534; time: 0.0 min
[Tune-x] 7: n.trees=16; interaction.depth=2; shrinkage=0.172; n.minobsinnode=10
[Tune-y] 7: rmse.test.rmse=0.114; time: 0.0 min
[Tune-x] 8: n.trees=37; interaction.depth=4; shrinkage=0.468; n.minobsinnode=25
[Tune-y] 8: rmse.test.rmse=0.0731; time: 0.0 min
[Tune-x] 9: n.trees=47; interaction.depth=3; shrinkage=0.135; n.minobsinnode=18
[Tune-y] 9: rmse.test.rmse=0.0559; time: 0.0 min
[Tune-x] 10: n.trees=378; interaction.depth=6; shrinkage=0.505; n.minobsinnode=9
[Tune-y] 10: rmse.test.rmse=0.0506; time: 0.0 min
[Tune-x] 11: n.trees=34; interaction.depth=5; shrinkage=0.26; n.minobsinnode=21
[Tune-y] 11: rmse.test.rmse=0.0569; time: 0.0 min
[Tune-x] 12: n.trees=17; interaction.depth=3; shrinkage=0.337; n.minobsinnode=25
[Tune-y] 12: rmse.test.rmse=0.0833; time: 0.0 min
[Tune-x] 13: n.trees=75; interaction.depth=7; shrinkage=0.0941; n.minobsinnode=21
[Tune-y] 13: rmse.test.rmse=0.0511; time: 0.0 min
[Tune-x] 14: n.trees=439; interaction.depth=5; shrinkage=0.489; n.minobsinnode=22
[Tune-y] 14: rmse.test.rmse=0.0597; time: 0.0 min
[Tune-x] 15: n.trees=129; interaction.depth=8; shrinkage=0.00596; n.minobsinnode=6
[Tune-y] 15: rmse.test.rmse=0.314; time: 0.0 min
[Tune-x] 16: n.trees=299; interaction.depth=9; shrinkage=0.551; n.minobsinnode=5
[Tune-y] 16: rmse.test.rmse=0.0552; time: 0.0 min
[Tune-x] 17: n.trees=463; interaction.depth=1; shrinkage=0.331; n.minobsinnode=10
[Tune-y] 17: rmse.test.rmse=0.051; time: 0.0 min
[Tune-x] 18: n.trees=14; interaction.depth=2; shrinkage=0.128; n.minobsinnode=23
[Tune-y] 18: rmse.test.rmse=0.179; time: 0.0 min
[Tune-x] 19: n.trees=84; interaction.depth=7; shrinkage=0.408; n.minobsinnode=12
[Tune-y] 19: rmse.test.rmse=0.0456; time: 0.0 min
[Tune-x] 20: n.trees=249; interaction.depth=7; shrinkage=0.513; n.minobsinnode=10
[Tune-y] 20: rmse.test.rmse=0.0519; time: 0.0 min
[Tune] Result: n.trees=84; interaction.depth=7; shrinkage=0.408; n.minobsinnode=12 : rmse.test.rmse=0.0456
[1] "Fri Feb 09 18:09:09 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.glm no default is available.
[1] "Fri Feb 09 18:09:16 2018"
Error in requirePackages(package, why = stri_paste("learner", id, sep = " "),  : 
  For learner regr.glmboost please install the following packages: mboost
[Tune] Started tuning learner regr.glmnet for parameter set:
          Type len Def   Constr Req Tunable Trafo
alpha  numeric   -   1   0 to 1   -    TRUE     -
lambda numeric   -   0 -10 to 3   -    TRUE     Y
With control class: TuneControlRandom
Imputation value: Inf
[Tune-x] 1: alpha=0.00236; lambda=0.174
[Tune-y] 1: rmse.test.rmse=0.0903; time: 0.0 min
[Tune-x] 2: alpha=0.654; lambda=0.0311
[Tune-y] 2: rmse.test.rmse=0.0726; time: 0.0 min
[Tune-x] 3: alpha=0.486; lambda=0.113
[Tune-y] 3: rmse.test.rmse=0.107; time: 0.0 min
[Tune-x] 4: alpha=0.0118; lambda=0.0258
[Tune-y] 4: rmse.test.rmse=0.0678; time: 0.0 min
[Tune-x] 5: alpha=0.726; lambda=0.0116
[Tune-y] 5: rmse.test.rmse=0.0586; time: 0.0 min
[Tune-x] 6: alpha=0.683; lambda=0.134
[Tune-y] 6: rmse.test.rmse=0.136; time: 0.0 min
[Tune-x] 7: alpha=0.106; lambda=0.443
[Tune-y] 7: rmse.test.rmse=0.153; time: 0.0 min
[Tune-x] 8: alpha=0.864; lambda=0.129
[Tune-y] 8: rmse.test.rmse=0.148; time: 0.0 min
[Tune-x] 9: alpha=0.686; lambda=0.0719
[Tune-y] 9: rmse.test.rmse=0.0974; time: 0.0 min
[Tune-x] 10: alpha=0.0111; lambda=0.00193
[Tune-y] 10: rmse.test.rmse=0.0526; time: 0.0 min
[Tune-x] 11: alpha=0.351; lambda=0.0469
[Tune-y] 11: rmse.test.rmse=0.0761; time: 0.0 min
[Tune-x] 12: alpha=0.176; lambda=0.514
[Tune-y] 12: rmse.test.rmse=0.191; time: 0.0 min
[Tune-x] 13: alpha=0.107; lambda=0.00353
[Tune-y] 13: rmse.test.rmse=0.0545; time: 0.0 min
[Tune-x] 14: alpha=0.285; lambda=0.012
[Tune-y] 14: rmse.test.rmse=0.0624; time: 0.0 min
[Tune-x] 15: alpha=0.282; lambda=0.0191
[Tune-y] 15: rmse.test.rmse=0.0666; time: 0.0 min
[Tune-x] 16: alpha=0.779; lambda=7.45
[Tune-y] 16: rmse.test.rmse=0.642; time: 0.0 min
[Tune-x] 17: alpha=0.337; lambda=0.0133
[Tune-y] 17: rmse.test.rmse=0.063; time: 0.0 min
[Tune-x] 18: alpha=0.224; lambda=0.27
[Tune-y] 18: rmse.test.rmse=0.135; time: 0.0 min
[Tune-x] 19: alpha=0.789; lambda=0.146
[Tune-y] 19: rmse.test.rmse=0.154; time: 0.0 min
[Tune-x] 20: alpha=0.842; lambda=0.00651
[Tune-y] 20: rmse.test.rmse=0.055; time: 0.0 min
[Tune] Result: alpha=0.0111; lambda=0.00193 : rmse.test.rmse=0.0526
[1] "Fri Feb 09 18:09:27 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.h2o.deeplearning no default is available.

H2O is not running yet, starting it now...

Note:  In case of errors look at the following log files:
    C:\Users\gvg\AppData\Local\Temp\RtmpqeFSP6/h2o_gvg_started_from_r.out
    C:\Users\gvg\AppData\Local\Temp\RtmpqeFSP6/h2o_gvg_started_from_r.err

java version "1.8.0_25"
Java(TM) SE Runtime Environment (build 1.8.0_25-b18)
Java HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode)

Starting H2O JVM and connecting: .. Connection successful!

R is connected to the H2O cluster: 
    H2O cluster uptime:         6 seconds 927 milliseconds 
    H2O cluster version:        3.16.0.2 
    H2O cluster version age:    2 months and 9 days  
    H2O cluster name:           H2O_started_from_R_gvg_csf638 
    H2O cluster total nodes:    1 
    H2O cluster total memory:   0.77 GB 
    H2O cluster total cores:    4 
    H2O cluster allowed cores:  4 
    H2O cluster healthy:        TRUE 
    H2O Connection ip:          localhost 
    H2O Connection port:        54321 
    H2O Connection proxy:       NA 
    H2O Internal Security:      FALSE 
    H2O API Extensions:         Algos, AutoML, Core V3, Core V4 
    R Version:                  R version 3.4.3 (2017-11-30) 

  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |==============                                                        |  20%  |                                                                              |===================================                                   |  50%  |                                                                              |===============================================================       |  90%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
[1] "Fri Feb 09 18:10:04 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.h2o.gbm no default is available.
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |====================================                                  |  52%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
[1] "Fri Feb 09 18:10:16 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.h2o.glm no default is available.
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |===                                                                   |   4%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
[1] "Fri Feb 09 18:10:26 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.h2o.randomForest no default is available.
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |=                                                                     |   2%  |                                                                              |=============================================                         |  64%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
  |                                                                              |                                                                      |   0%  |                                                                              |======================================================================| 100%
[1] "Fri Feb 09 18:10:38 2018"
Error in requirePackages(package, why = stri_paste("learner", id, sep = " "),  : 
  For learner regr.IBk please install the following packages: RWeka
Loading required package: kknn

Attaching package: 'kknn'

The following object is masked from 'package:caret':

    contr.dummy

Error in getDefaultParConfig(learner) : 
  For the learner regr.km no default is available.
In addition: Warning message:
package '!kknn' is not available (for R version 3.4.3) 

optimisation start
------------------
* estimation method   : MLE 
* optimisation method : BFGS 
* analytical gradient : used
* trend model : ~1
* covariance model : 
  - type :  matern5_2 
  - nugget : NO
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 
  - parameters upper bounds :  1.995996 1.997998 1.997998 1.995996 1.997998 1.997998 2 2 2 
  - best initial criterion value(s) :  1712.633 

N = 9, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -1712.6  |proj g|=       1.4596
At iterate     1  f =      -1820.5  |proj g|=        1.8642
At iterate     2  f =      -1821.3  |proj g|=        1.4484
At iterate     3  f =      -1831.5  |proj g|=        1.3348
At iterate     4  f =      -1837.4  |proj g|=        1.8464
At iterate     5  f =      -1841.7  |proj g|=        1.4414
At iterate     6  f =      -1843.7  |proj g|=        1.4535
At iterate     7  f =        -1858  |proj g|=        1.3348
At iterate     8  f =      -1868.4  |proj g|=        1.4544
At iterate     9  f =      -1872.8  |proj g|=        1.8266
At iterate    10  f =      -1873.9  |proj g|=        1.4148
At iterate    11  f =      -1874.1  |proj g|=        1.8245
At iterate    12  f =      -1874.5  |proj g|=        1.8242
At iterate    13  f =      -1875.3  |proj g|=        1.8222
At iterate    14  f =      -1875.9  |proj g|=        1.5738
At iterate    15  f =      -1875.9  |proj g|=        1.5746
At iterate    16  f =      -1876.4  |proj g|=        1.8266
At iterate    17  f =      -1876.7  |proj g|=         1.828
At iterate    18  f =      -1878.5  |proj g|=        1.8317
At iterate    19  f =      -1879.8  |proj g|=         1.459
At iterate    20  f =        -1880  |proj g|=        1.8368
At iterate    21  f =      -1880.4  |proj g|=        1.2874
At iterate    22  f =      -1880.9  |proj g|=        1.1865
At iterate    23  f =      -1881.2  |proj g|=        1.8547
At iterate    24  f =      -1881.2  |proj g|=        1.1832
At iterate    25  f =      -1881.3  |proj g|=        1.1813
At iterate    26  f =      -1881.5  |proj g|=        1.1599
At iterate    27  f =      -1881.7  |proj g|=        1.1229
At iterate    28  f =      -1882.1  |proj g|=        1.3627
At iterate    29  f =      -1882.3  |proj g|=         1.854
At iterate    30  f =      -1882.7  |proj g|=        1.8508
At iterate    31  f =      -1882.8  |proj g|=        1.4301
At iterate    32  f =      -1882.9  |proj g|=        1.4153
At iterate    33  f =      -1882.9  |proj g|=        1.8465
At iterate    34  f =      -1882.9  |proj g|=        1.3594
At iterate    35  f =      -1882.9  |proj g|=        1.3795
At iterate    36  f =      -1882.9  |proj g|=        1.3838
At iterate    37  f =      -1882.9  |proj g|=        1.3914
At iterate    38  f =      -1882.9  |proj g|=         1.421
At iterate    39  f =        -1883  |proj g|=        1.3034
At iterate    40  f =        -1883  |proj g|=        1.8482
At iterate    41  f =      -1883.1  |proj g|=        1.8484
At iterate    42  f =      -1883.1  |proj g|=        1.0194
At iterate    43  f =      -1883.1  |proj g|=       0.96451
At iterate    44  f =      -1883.1  |proj g|=        0.8279
At iterate    45  f =      -1883.1  |proj g|=       0.45917
At iterate    46  f =      -1883.1  |proj g|=       0.45738
At iterate    47  f =      -1883.1  |proj g|=        1.8467
At iterate    48  f =      -1883.1  |proj g|=       0.31364
At iterate    49  f =      -1883.1  |proj g|=       0.18786
At iterate    50  f =      -1883.1  |proj g|=        0.8725
At iterate    51  f =      -1883.1  |proj g|=      0.094489
At iterate    52  f =      -1883.1  |proj g|=     0.0043329

iterations 52
function evaluations 60
segments explored during Cauchy searches 60
BFGS updates skipped 0
active bounds at final generalized Cauchy point 4
norm of the final projected gradient 0.00433293
final function value -1883.12

F = -1883.12
final  value -1883.124951 
converged
[1] "Fri Feb 09 18:13:43 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.laGP no default is available.
i = 1 (of 248), d = 8.3371, its = 18
i = 2 (of 248), d = 1.42691, its = 9
i = 3 (of 248), d = 4.71536, its = 11
i = 4 (of 248), d = 4.93058, its = 11
i = 5 (of 248), d = 3.46719, its = 10
i = 6 (of 248), d = 8.3371, its = 20
i = 7 (of 248), d = 2.04299, its = 11
i = 8 (of 248), d = 3.20905, its = 11
i = 9 (of 248), d = 1.24555, its = 9
i = 10 (of 248), d = 2.28512, its = 10
i = 11 (of 248), d = 6.8671, its = 12
i = 12 (of 248), d = 1.78976, its = 9
i = 13 (of 248), d = 1.30417, its = 9
i = 14 (of 248), d = 0.998545, its = 7
i = 15 (of 248), d = 2.7229, its = 10
i = 16 (of 248), d = 2.71435, its = 10
i = 17 (of 248), d = 2.06801, its = 10
i = 18 (of 248), d = 6.48331, its = 12
i = 19 (of 248), d = 1.77222, its = 10
i = 20 (of 248), d = 2.36955, its = 10
i = 21 (of 248), d = 3.32401, its = 10
i = 22 (of 248), d = 1.9447, its = 10
i = 23 (of 248), d = 3.07006, its = 11
i = 24 (of 248), d = 3.68566, its = 10
i = 25 (of 248), d = 2.41099, its = 10
i = 26 (of 248), d = 1.03832, its = 8
i = 27 (of 248), d = 1.56517, its = 10
i = 28 (of 248), d = 1.84432, its = 9
i = 29 (of 248), d = 0.930518, its = 7
i = 30 (of 248), d = 3.70332, its = 12
i = 31 (of 248), d = 6.52153, its = 12
i = 32 (of 248), d = 2.77107, its = 10
i = 33 (of 248), d = 1.07803, its = 8
i = 34 (of 248), d = 6.21992, its = 12
i = 35 (of 248), d = 4.6917, its = 11
i = 36 (of 248), d = 6.81102, its = 12
i = 37 (of 248), d = 8.3371, its = 56
i = 38 (of 248), d = 2.16755, its = 9
i = 39 (of 248), d = 1.20659, its = 9
i = 40 (of 248), d = 6.15737, its = 12
i = 41 (of 248), d = 1.68637, its = 9
i = 42 (of 248), d = 2.4354, its = 10
i = 43 (of 248), d = 2.35738, its = 9
i = 44 (of 248), d = 3.0155, its = 10
i = 45 (of 248), d = 3.48654, its = 11
i = 46 (of 248), d = 8.3371, its = 21
i = 47 (of 248), d = 2.7066, its = 10
i = 48 (of 248), d = 4.55885, its = 11
i = 49 (of 248), d = 1.67376, its = 8
i = 50 (of 248), d = 1.67695, its = 9
i = 51 (of 248), d = 8.03603, its = 11
i = 52 (of 248), d = 2.40242, its = 10
i = 53 (of 248), d = 3.01428, its = 11
i = 54 (of 248), d = 3.05625, its = 10
i = 55 (of 248), d = 1.08681, its = 8
i = 56 (of 248), d = 6.11412, its = 12
i = 57 (of 248), d = 8.3371, its = 23
i = 58 (of 248), d = 8.3371, its = 18
i = 59 (of 248), d = 3.14539, its = 10
i = 60 (of 248), d = 6.82731, its = 12
i = 61 (of 248), d = 6.13346, its = 11
i = 62 (of 248), d = 3.49155, its = 11
i = 63 (of 248), d = 1.19957, its = 9
i = 64 (of 248), d = 1.75534, its = 9
i = 65 (of 248), d = 7.89147, its = 11
i = 66 (of 248), d = 2.8632, its = 10
i = 67 (of 248), d = 3.97215, its = 11
i = 68 (of 248), d = 8.05407, its = 12
i = 69 (of 248), d = 1.85991, its = 9
i = 70 (of 248), d = 4.46506, its = 10
i = 71 (of 248), d = 7.31526, its = 11
i = 72 (of 248), d = 2.45947, its = 9
i = 73 (of 248), d = 4.39281, its = 12
i = 74 (of 248), d = 1.83343, its = 9
i = 75 (of 248), d = 3.54328, its = 10
i = 76 (of 248), d = 3.5678, its = 11
i = 77 (of 248), d = 3.68169, its = 10
i = 78 (of 248), d = 1.2875, its = 9
i = 79 (of 248), d = 1.46796, its = 9
i = 80 (of 248), d = 4.19569, its = 11
i = 81 (of 248), d = 3.67243, its = 10
i = 82 (of 248), d = 8.14576, its = 12
i = 83 (of 248), d = 7.813, its = 12
i = 84 (of 248), d = 5.57462, its = 11
i = 85 (of 248), d = 1.73612, its = 9
i = 86 (of 248), d = 1.00685, its = 7
i = 87 (of 248), d = 3.84999, its = 12
i = 88 (of 248), d = 2.70313, its = 10
i = 89 (of 248), d = 7.51807, its = 12
i = 90 (of 248), d = 3.9541, its = 10
i = 91 (of 248), d = 6.96057, its = 12
i = 92 (of 248), d = 8.3371, its = 58
i = 93 (of 248), d = 1.59997, its = 10
i = 94 (of 248), d = 2.71249, its = 10
i = 95 (of 248), d = 3.22372, its = 10
i = 96 (of 248), d = 3.47543, its = 11
i = 97 (of 248), d = 8.3371, its = 56
i = 98 (of 248), d = 6.70633, its = 11
i = 99 (of 248), d = 5.27163, its = 11
i = 100 (of 248), d = 8.3371, its = 61
i = 101 (of 248), d = 2.13507, its = 10
i = 102 (of 248), d = 2.94896, its = 10
i = 103 (of 248), d = 4.18632, its = 11
i = 104 (of 248), d = 8.3371, its = 55
i = 105 (of 248), d = 1.2462, its = 8
i = 106 (of 248), d = 3.40554, its = 10
i = 107 (of 248), d = 3.13381, its = 10
i = 108 (of 248), d = 8.3371, its = 26
i = 109 (of 248), d = 1.49202, its = 9
i = 110 (of 248), d = 2.19718, its = 10
i = 111 (of 248), d = 8.3371, its = 19
i = 112 (of 248), d = 1.18137, its = 8
i = 113 (of 248), d = 2.12961, its = 10
i = 114 (of 248), d = 2.26066, its = 10
i = 115 (of 248), d = 1.80998, its = 9
i = 116 (of 248), d = 1.66163, its = 8
i = 117 (of 248), d = 6.86288, its = 12
i = 118 (of 248), d = 3.86054, its = 12
i = 119 (of 248), d = 5.47633, its = 12
i = 120 (of 248), d = 0.905252, its = 8
i = 121 (of 248), d = 1.96205, its = 10
i = 122 (of 248), d = 5.39311, its = 12
i = 123 (of 248), d = 6.14841, its = 12
i = 124 (of 248), d = 6.2447, its = 12
i = 125 (of 248), d = 1.72944, its = 8
i = 126 (of 248), d = 1.65267, its = 9
i = 127 (of 248), d = 8.3371, its = 59
i = 128 (of 248), d = 4.31937, its = 11
i = 129 (of 248), d = 4.68255, its = 11
i = 130 (of 248), d = 1.36759, its = 12
i = 131 (of 248), d = 1.15062, its = 9
i = 132 (of 248), d = 4.02933, its = 11
i = 133 (of 248), d = 2.69898, its = 10
i = 134 (of 248), d = 2.29491, its = 10
i = 135 (of 248), d = 1.73641, its = 10
i = 136 (of 248), d = 4.19476, its = 11
i = 137 (of 248), d = 8.3371, its = 21
i = 138 (of 248), d = 8.3371, its = 23
i = 139 (of 248), d = 1.81767, its = 9
i = 140 (of 248), d = 3.28588, its = 11
i = 141 (of 248), d = 5.37713, its = 11
i = 142 (of 248), d = 3.79745, its = 11
i = 143 (of 248), d = 7.59317, its = 12
i = 144 (of 248), d = 3.44022, its = 10
i = 145 (of 248), d = 5.58951, its = 12
i = 146 (of 248), d = 8.04735, its = 12
i = 147 (of 248), d = 1.90985, its = 9
i = 148 (of 248), d = 3.47642, its = 10
i = 149 (of 248), d = 1.75309, its = 9
i = 150 (of 248), d = 7.74176, its = 12
i = 151 (of 248), d = 2.28374, its = 11
i = 152 (of 248), d = 1.69838, its = 9
i = 153 (of 248), d = 7.46328, its = 11
i = 154 (of 248), d = 2.83828, its = 10
i = 155 (of 248), d = 1.14208, its = 8
i = 156 (of 248), d = 3.64872, its = 11
i = 157 (of 248), d = 2.69534, its = 10
i = 158 (of 248), d = 4.53889, its = 11
i = 159 (of 248), d = 7.67129, its = 12
i = 160 (of 248), d = 4.21727, its = 11
i = 161 (of 248), d = 0.776124, its = 9
i = 162 (of 248), d = 1.69991, its = 9
i = 163 (of 248), d = 1.65976, its = 9
i = 164 (of 248), d = 3.20392, its = 11
i = 165 (of 248), d = 6.42324, its = 11
i = 166 (of 248), d = 3.5461, its = 10
i = 167 (of 248), d = 1.2811, its = 8
i = 168 (of 248), d = 1.74389, its = 9
i = 169 (of 248), d = 5.12459, its = 13
i = 170 (of 248), d = 8.3371, its = 61
i = 171 (of 248), d = 3.68182, its = 11
i = 172 (of 248), d = 8.3371, its = 63
i = 173 (of 248), d = 3.15551, its = 10
i = 174 (of 248), d = 2.60053, its = 10
i = 175 (of 248), d = 2.78825, its = 10
i = 176 (of 248), d = 1.66666, its = 9
i = 177 (of 248), d = 6.02235, its = 12
i = 178 (of 248), d = 2.08946, its = 10
i = 179 (of 248), d = 4.9542, its = 11
i = 180 (of 248), d = 2.39917, its = 10
i = 181 (of 248), d = 3.35735, its = 10
i = 182 (of 248), d = 2.10019, its = 9
i = 183 (of 248), d = 8.3371, its = 58
i = 184 (of 248), d = 2.92669, its = 11
i = 185 (of 248), d = 4.31525, its = 10
i = 186 (of 248), d = 7.44129, its = 11
i = 187 (of 248), d = 6.69273, its = 12
i = 188 (of 248), d = 3.35484, its = 11
i = 189 (of 248), d = 1.47338, its = 9
i = 190 (of 248), d = 1.11129, its = 8
i = 191 (of 248), d = 6.53993, its = 12
i = 192 (of 248), d = 5.9191, its = 12
i = 193 (of 248), d = 2.18123, its = 11
i = 194 (of 248), d = 2.81544, its = 10
i = 195 (of 248), d = 1.36897, its = 10
i = 196 (of 248), d = 4.04875, its = 10
i = 197 (of 248), d = 2.03192, its = 11
i = 198 (of 248), d = 8.3371, its = 52
i = 199 (of 248), d = 3.08621, its = 11
i = 200 (of 248), d = 6.35128, its = 11
i = 201 (of 248), d = 4.06848, its = 11
i = 202 (of 248), d = 1.79514, its = 9
i = 203 (of 248), d = 5.96464, its = 12
i = 204 (of 248), d = 6.30975, its = 11
i = 205 (of 248), d = 4.05651, its = 11
i = 206 (of 248), d = 5.31886, its = 11
i = 207 (of 248), d = 2.78721, its = 10
i = 208 (of 248), d = 3.35431, its = 10
i = 209 (of 248), d = 4.76906, its = 11
i = 210 (of 248), d = 5.45925, its = 12
i = 211 (of 248), d = 0.906204, its = 8
i = 212 (of 248), d = 3.23391, its = 11
i = 213 (of 248), d = 1.7001, its = 9
i = 214 (of 248), d = 2.72176, its = 10
i = 215 (of 248), d = 6.42001, its = 11
i = 216 (of 248), d = 1.70233, its = 9
i = 217 (of 248), d = 2.64859, its = 10
i = 218 (of 248), d = 4.00365, its = 11
i = 219 (of 248), d = 2.20394, its = 10
i = 220 (of 248), d = 1.83758, its = 9
i = 221 (of 248), d = 2.43355, its = 10
i = 222 (of 248), d = 3.43111, its = 10
i = 223 (of 248), d = 5.42064, its = 11
i = 224 (of 248), d = 6.73868, its = 11
i = 225 (of 248), d = 8.3371, its = 55
i = 226 (of 248), d = 4.73601, its = 11
i = 227 (of 248), d = 3.89708, its = 11
i = 228 (of 248), d = 2.00223, its = 9
i = 229 (of 248), d = 1.77343, its = 10
i = 230 (of 248), d = 8.3371, its = 24
i = 231 (of 248), d = 1.07452, its = 9
i = 232 (of 248), d = 1.71142, its = 8
i = 233 (of 248), d = 3.11503, its = 10
i = 234 (of 248), d = 1.55741, its = 9
i = 235 (of 248), d = 3.21045, its = 10
i = 236 (of 248), d = 3.00769, its = 10
i = 237 (of 248), d = 1.298, its = 9
i = 238 (of 248), d = 5.75428, its = 12
i = 239 (of 248), d = 7.62172, its = 12
i = 240 (of 248), d = 7.9646, its = 12
i = 241 (of 248), d = 4.63589, its = 11
i = 242 (of 248), d = 4.08902, its = 10
i = 243 (of 248), d = 3.79308, its = 11
i = 244 (of 248), d = 7.73522, its = 12
i = 245 (of 248), d = 2.13042, its = 9
i = 246 (of 248), d = 2.37438, its = 9
i = 247 (of 248), d = 2.82079, its = 10
i = 248 (of 248), d = 8.3371, its = 58
[1] "Fri Feb 09 18:14:53 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.LiblineaRL2L1SVR no default is available.
[1] "Fri Feb 09 18:15:01 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.LiblineaRL2L2SVR no default is available.
[1] "Fri Feb 09 18:15:07 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.lm no default is available.
[1] "Fri Feb 09 18:15:13 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.mars no default is available.
[1] "Fri Feb 09 18:15:20 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.mob no default is available.
[1] "Fri Feb 09 18:15:48 2018"
[Tune] Started tuning learner regr.nnet for parameter set:
         Type len   Def  Constr Req Tunable Trafo
size  integer   -     3 1 to 20   -    TRUE     -
decay numeric   - 1e-05 -5 to 1   -    TRUE     Y
With control class: TuneControlRandom
Imputation value: Inf
[Tune-x] 1: size=1; decay=0.0282
# weights:  12
initial  value 1915.262857 
iter  10 value 58.631581
iter  20 value 11.160052
iter  30 value 4.719338
iter  40 value 2.820612
iter  50 value 2.691151
iter  60 value 2.690950
final  value 2.690929 
converged
# weights:  12
initial  value 1296.971301 
iter  10 value 189.484146
iter  20 value 12.219385
iter  30 value 3.018739
iter  40 value 2.780156
iter  50 value 2.756942
final  value 2.756679 
converged
# weights:  12
initial  value 1188.494822 
iter  10 value 205.475560
iter  20 value 129.811488
iter  30 value 13.109305
iter  40 value 3.748067
iter  50 value 2.724126
iter  60 value 2.430638
final  value 2.428220 
converged
[Tune-y] 1: rmse.test.rmse=0.0599; time: 0.0 min
[Tune-x] 2: size=14; decay=0.00201
# weights:  155
initial  value 384.283754 
iter  10 value 4.068751
iter  20 value 1.689863
iter  30 value 1.257886
iter  40 value 1.136741
iter  50 value 1.021225
iter  60 value 0.843390
iter  70 value 0.640157
iter  80 value 0.567457
iter  90 value 0.521708
iter 100 value 0.494116
final  value 0.494116 
stopped after 100 iterations
# weights:  155
initial  value 735.666912 
iter  10 value 5.630063
iter  20 value 1.886112
iter  30 value 1.415553
iter  40 value 1.285973
iter  50 value 1.068854
iter  60 value 0.803147
iter  70 value 0.606915
iter  80 value 0.545111
iter  90 value 0.512309
iter 100 value 0.492722
final  value 0.492722 
stopped after 100 iterations
# weights:  155
initial  value 4666.645723 
iter  10 value 5.770092
iter  20 value 0.921605
iter  30 value 0.591897
iter  40 value 0.535106
iter  50 value 0.498391
iter  60 value 0.476838
iter  70 value 0.461805
iter  80 value 0.447964
iter  90 value 0.438463
iter 100 value 0.429518
final  value 0.429518 
stopped after 100 iterations
[Tune-y] 2: rmse.test.rmse=0.0226; time: 0.0 min
[Tune-x] 3: size=10; decay=0.0146
# weights:  111
initial  value 2403.063569 
iter  10 value 7.321125
iter  20 value 2.395563
iter  30 value 1.759674
iter  40 value 1.515944
iter  50 value 1.378107
iter  60 value 1.299119
iter  70 value 1.256419
iter  80 value 1.227386
iter  90 value 1.210986
iter 100 value 1.197688
final  value 1.197688 
stopped after 100 iterations
# weights:  111
initial  value 2595.947056 
iter  10 value 6.938856
iter  20 value 2.374279
iter  30 value 1.873050
iter  40 value 1.735755
iter  50 value 1.575868
iter  60 value 1.448076
iter  70 value 1.406970
iter  80 value 1.367180
iter  90 value 1.342322
iter 100 value 1.325819
final  value 1.325819 
stopped after 100 iterations
# weights:  111
initial  value 1591.151758 
iter  10 value 3.495594
iter  20 value 1.785827
iter  30 value 1.337652
iter  40 value 1.128200
iter  50 value 1.062703
iter  60 value 1.047758
iter  70 value 1.040761
iter  80 value 1.037177
iter  90 value 1.033599
iter 100 value 1.029617
final  value 1.029617 
stopped after 100 iterations
[Tune-y] 3: rmse.test.rmse=0.0332; time: 0.0 min
[Tune-x] 4: size=1; decay=0.00151
# weights:  12
initial  value 1227.661203 
iter  10 value 49.653235
iter  20 value 4.954633
iter  30 value 2.064548
iter  40 value 1.764659
iter  50 value 1.551442
iter  60 value 1.516899
iter  70 value 1.493383
iter  80 value 1.484311
iter  90 value 1.483982
final  value 1.483978 
converged
# weights:  12
initial  value 2152.852817 
iter  10 value 63.835393
iter  20 value 13.652850
iter  30 value 6.139002
iter  40 value 3.488716
iter  50 value 2.194218
iter  60 value 1.871525
iter  70 value 1.640342
iter  80 value 1.578995
iter  90 value 1.571503
iter 100 value 1.567703
final  value 1.567703 
stopped after 100 iterations
# weights:  12
initial  value 435.172861 
iter  10 value 199.141582
iter  20 value 60.683610
iter  30 value 12.705117
iter  40 value 3.135176
iter  50 value 2.189626
iter  60 value 1.520542
iter  70 value 1.385366
iter  80 value 1.330680
iter  90 value 1.294379
iter 100 value 1.290785
final  value 1.290785 
stopped after 100 iterations
[Tune-y] 4: rmse.test.rmse=0.0529; time: 0.0 min
[Tune-x] 5: size=15; decay=0.000446
# weights:  166
initial  value 257.480848 
iter  10 value 4.496509
iter  20 value 1.874453
iter  30 value 1.032673
iter  40 value 0.655055
iter  50 value 0.469101
iter  60 value 0.365429
iter  70 value 0.289766
iter  80 value 0.245307
iter  90 value 0.230883
iter 100 value 0.216756
final  value 0.216756 
stopped after 100 iterations
# weights:  166
initial  value 618.816810 
iter  10 value 6.049384
iter  20 value 2.052393
iter  30 value 1.468510
iter  40 value 1.294437
iter  50 value 0.893445
iter  60 value 0.510550
iter  70 value 0.419532
iter  80 value 0.318413
iter  90 value 0.271631
iter 100 value 0.254343
final  value 0.254343 
stopped after 100 iterations
# weights:  166
initial  value 8163.454073 
iter  10 value 42.301211
iter  20 value 5.168140
iter  30 value 1.135228
iter  40 value 0.535824
iter  50 value 0.448850
iter  60 value 0.377032
iter  70 value 0.309522
iter  80 value 0.279619
iter  90 value 0.256246
iter 100 value 0.239820
final  value 0.239820 
stopped after 100 iterations
[Tune-y] 5: rmse.test.rmse=0.0185; time: 0.0 min
[Tune-x] 6: size=14; decay=0.0189
# weights:  155
initial  value 185.685762 
iter  10 value 4.356920
iter  20 value 2.343996
iter  30 value 1.905429
iter  40 value 1.751938
iter  50 value 1.515097
iter  60 value 1.436764
iter  70 value 1.405935
iter  80 value 1.393355
iter  90 value 1.387635
iter 100 value 1.384233
final  value 1.384233 
stopped after 100 iterations
# weights:  155
initial  value 1983.557836 
iter  10 value 4.558570
iter  20 value 2.499112
iter  30 value 2.077920
iter  40 value 1.916085
iter  50 value 1.860319
iter  60 value 1.829498
iter  70 value 1.817857
iter  80 value 1.802898
iter  90 value 1.795027
iter 100 value 1.788158
final  value 1.788158 
stopped after 100 iterations
# weights:  155
initial  value 805.322089 
iter  10 value 4.372242
iter  20 value 2.252463
iter  30 value 1.758921
iter  40 value 1.426100
iter  50 value 1.276032
iter  60 value 1.240793
iter  70 value 1.225283
iter  80 value 1.216931
iter  90 value 1.206025
iter 100 value 1.198466
final  value 1.198466 
stopped after 100 iterations
[Tune-y] 6: rmse.test.rmse=0.0408; time: 0.0 min
[Tune-x] 7: size=3; decay=0.118
# weights:  34
initial  value 3482.356627 
iter  10 value 54.440959
iter  20 value 7.326357
iter  30 value 4.956959
iter  40 value 4.537470
iter  50 value 4.296689
iter  60 value 4.238931
iter  70 value 4.232268
iter  80 value 4.221676
iter  90 value 4.120591
iter 100 value 4.103782
final  value 4.103782 
stopped after 100 iterations
# weights:  34
initial  value 2798.863508 
iter  10 value 18.046828
iter  20 value 8.339468
iter  30 value 6.602325
iter  40 value 5.843091
iter  50 value 5.461869
iter  60 value 5.276506
iter  70 value 5.137686
iter  80 value 4.658078
iter  90 value 4.431010
iter 100 value 4.361142
final  value 4.361142 
stopped after 100 iterations
# weights:  34
initial  value 2324.454691 
iter  10 value 57.264935
iter  20 value 7.972109
iter  30 value 4.438662
iter  40 value 4.075312
iter  50 value 3.990659
iter  60 value 3.980101
iter  70 value 3.964565
iter  80 value 3.909153
iter  90 value 3.766435
iter 100 value 3.739940
final  value 3.739940 
stopped after 100 iterations
[Tune-y] 7: rmse.test.rmse=0.0619; time: 0.0 min
[Tune-x] 8: size=18; decay=0.0178
# weights:  199
initial  value 1477.811353 
iter  10 value 5.885419
iter  20 value 2.578547
iter  30 value 1.917177
iter  40 value 1.642671
iter  50 value 1.528983
iter  60 value 1.459847
iter  70 value 1.424144
iter  80 value 1.391146
iter  90 value 1.371082
iter 100 value 1.355664
final  value 1.355664 
stopped after 100 iterations
# weights:  199
initial  value 967.500182 
iter  10 value 4.034601
iter  20 value 2.189784
iter  30 value 1.870376
iter  40 value 1.764742
iter  50 value 1.744535
iter  60 value 1.734301
iter  70 value 1.728625
iter  80 value 1.725214
iter  90 value 1.721857
iter 100 value 1.719551
final  value 1.719551 
stopped after 100 iterations
# weights:  199
initial  value 1744.758004 
iter  10 value 8.899282
iter  20 value 2.906508
iter  30 value 2.056784
iter  40 value 1.734376
iter  50 value 1.605483
iter  60 value 1.481655
iter  70 value 1.390799
iter  80 value 1.321256
iter  90 value 1.265150
iter 100 value 1.233012
final  value 1.233012 
stopped after 100 iterations
[Tune-y] 8: rmse.test.rmse=0.0396; time: 0.0 min
[Tune-x] 9: size=14; decay=0.00728
# weights:  155
initial  value 4278.350954 
iter  10 value 16.778473
iter  20 value 3.703089
iter  30 value 2.169944
iter  40 value 1.744771
iter  50 value 1.515997
iter  60 value 1.397939
iter  70 value 1.343722
iter  80 value 1.290683
iter  90 value 1.239830
iter 100 value 1.195424
final  value 1.195424 
stopped after 100 iterations
# weights:  155
initial  value 380.821973 
iter  10 value 2.918652
iter  20 value 1.856973
iter  30 value 1.595005
iter  40 value 1.429222
iter  50 value 1.233314
iter  60 value 1.073695
iter  70 value 1.004019
iter  80 value 0.959217
iter  90 value 0.934919
iter 100 value 0.919369
final  value 0.919369 
stopped after 100 iterations
# weights:  155
initial  value 2851.197707 
iter  10 value 72.551794
iter  20 value 11.299155
iter  30 value 3.154843
iter  40 value 1.682586
iter  50 value 1.238855
iter  60 value 1.107795
iter  70 value 1.016602
iter  80 value 0.962557
iter  90 value 0.928129
iter 100 value 0.913457
final  value 0.913457 
stopped after 100 iterations
[Tune-y] 9: rmse.test.rmse=0.0302; time: 0.0 min
[Tune-x] 10: size=1; decay=2.84e-05
# weights:  12
initial  value 1066.083823 
iter  10 value 33.080995
iter  20 value 7.727460
iter  30 value 3.146806
iter  40 value 1.893728
iter  50 value 1.684024
iter  60 value 1.586732
iter  70 value 1.408275
iter  80 value 1.349023
iter  90 value 1.322882
iter 100 value 1.286276
final  value 1.286276 
stopped after 100 iterations
# weights:  12
initial  value 1008.625309 
iter  10 value 52.467225
iter  20 value 6.203336
iter  30 value 4.100647
iter  40 value 2.218207
iter  50 value 1.756730
iter  60 value 1.630253
iter  70 value 1.475871
iter  80 value 1.428731
iter  90 value 1.400057
iter 100 value 1.362067
final  value 1.362067 
stopped after 100 iterations
# weights:  12
initial  value 1671.930004 
iter  10 value 59.016893
iter  20 value 11.903643
iter  30 value 4.006386
iter  40 value 2.304276
iter  50 value 1.636978
iter  60 value 1.393620
iter  70 value 1.227507
iter  80 value 1.154985
iter  90 value 1.140759
iter 100 value 1.104310
final  value 1.104310 
stopped after 100 iterations
[Tune-y] 10: rmse.test.rmse=0.0517; time: 0.0 min
[Tune-x] 11: size=8; decay=0.00379
# weights:  89
initial  value 761.193824 
iter  10 value 5.587907
iter  20 value 2.469938
iter  30 value 1.541613
iter  40 value 1.237879
iter  50 value 1.113546
iter  60 value 0.931184
iter  70 value 0.771525
iter  80 value 0.714783
iter  90 value 0.690773
iter 100 value 0.675864
final  value 0.675864 
stopped after 100 iterations
# weights:  89
initial  value 1962.428983 
iter  10 value 9.914462
iter  20 value 3.310047
iter  30 value 1.260922
iter  40 value 0.879176
iter  50 value 0.772792
iter  60 value 0.728302
iter  70 value 0.699922
iter  80 value 0.675699
iter  90 value 0.661556
iter 100 value 0.648122
final  value 0.648122 
stopped after 100 iterations
# weights:  89
initial  value 914.776892 
iter  10 value 4.489569
iter  20 value 1.634883
iter  30 value 1.209505
iter  40 value 0.919460
iter  50 value 0.680956
iter  60 value 0.602837
iter  70 value 0.564295
iter  80 value 0.547991
iter  90 value 0.537270
iter 100 value 0.529494
final  value 0.529494 
stopped after 100 iterations
[Tune-y] 11: rmse.test.rmse=0.0272; time: 0.0 min
[Tune-x] 12: size=4; decay=0.149
# weights:  45
initial  value 340.980371 
iter  10 value 10.218406
iter  20 value 5.378912
iter  30 value 4.662830
iter  40 value 4.560930
iter  50 value 4.509230
iter  60 value 4.456923
iter  70 value 4.447518
iter  80 value 4.439899
iter  90 value 4.436049
iter 100 value 4.431718
final  value 4.431718 
stopped after 100 iterations
# weights:  45
initial  value 2595.435962 
iter  10 value 23.315722
iter  20 value 8.607193
iter  30 value 6.837047
iter  40 value 5.978434
iter  50 value 5.441253
iter  60 value 5.192358
iter  70 value 5.126333
iter  80 value 5.065906
iter  90 value 4.979082
iter 100 value 4.703603
final  value 4.703603 
stopped after 100 iterations
# weights:  45
initial  value 2225.545426 
iter  10 value 10.961735
iter  20 value 6.488759
iter  30 value 5.118081
iter  40 value 4.786257
iter  50 value 4.358585
iter  60 value 4.254219
iter  70 value 4.226823
iter  80 value 4.185976
iter  90 value 4.161456
iter 100 value 4.137649
final  value 4.137649 
stopped after 100 iterations
[Tune-y] 12: rmse.test.rmse=0.0637; time: 0.0 min
[Tune-x] 13: size=3; decay=7.16e-05
# weights:  34
initial  value 733.436460 
iter  10 value 41.564615
iter  20 value 7.465100
iter  30 value 2.346155
iter  40 value 1.481769
iter  50 value 1.308176
iter  60 value 1.058200
iter  70 value 0.901897
iter  80 value 0.838311
iter  90 value 0.676067
iter 100 value 0.475011
final  value 0.475011 
stopped after 100 iterations
# weights:  34
initial  value 1512.245482 
iter  10 value 25.250956
iter  20 value 3.855385
iter  30 value 1.893727
iter  40 value 1.560915
iter  50 value 1.247750
iter  60 value 1.021334
iter  70 value 0.760884
iter  80 value 0.565348
iter  90 value 0.472368
iter 100 value 0.433588
final  value 0.433588 
stopped after 100 iterations
# weights:  34
initial  value 2066.338806 
iter  10 value 5.518208
iter  20 value 1.248575
iter  30 value 0.606267
iter  40 value 0.392676
iter  50 value 0.360973
iter  60 value 0.327803
iter  70 value 0.303124
iter  80 value 0.289427
iter  90 value 0.269211
iter 100 value 0.250044
final  value 0.250044 
stopped after 100 iterations
[Tune-y] 13: rmse.test.rmse=0.0285; time: 0.0 min
[Tune-x] 14: size=6; decay=0.000467
# weights:  67
initial  value 2108.351740 
iter  10 value 6.719155
iter  20 value 1.210597
iter  30 value 0.709075
iter  40 value 0.507161
iter  50 value 0.453055
iter  60 value 0.410459
iter  70 value 0.379941
iter  80 value 0.362919
iter  90 value 0.351978
iter 100 value 0.345852
final  value 0.345852 
stopped after 100 iterations
# weights:  67
initial  value 925.862067 
iter  10 value 6.823000
iter  20 value 1.715774
iter  30 value 0.793744
iter  40 value 0.582183
iter  50 value 0.465613
iter  60 value 0.413884
iter  70 value 0.381074
iter  80 value 0.369390
iter  90 value 0.357354
iter 100 value 0.348960
final  value 0.348960 
stopped after 100 iterations
# weights:  67
initial  value 2690.497900 
iter  10 value 4.921171
iter  20 value 1.430103
iter  30 value 0.951315
iter  40 value 0.712418
iter  50 value 0.558640
iter  60 value 0.389595
iter  70 value 0.323551
iter  80 value 0.290293
iter  90 value 0.268442
iter 100 value 0.258937
final  value 0.258937 
stopped after 100 iterations
[Tune-y] 14: rmse.test.rmse=0.0231; time: 0.0 min
[Tune-x] 15: size=6; decay=0.000951
# weights:  67
initial  value 463.788036 
iter  10 value 11.766761
iter  20 value 1.729019
iter  30 value 0.778959
iter  40 value 0.648867
iter  50 value 0.558498
iter  60 value 0.509354
iter  70 value 0.463553
iter  80 value 0.438699
iter  90 value 0.420572
iter 100 value 0.399046
final  value 0.399046 
stopped after 100 iterations
# weights:  67
initial  value 303.684508 
iter  10 value 6.551220
iter  20 value 2.019820
iter  30 value 1.022515
iter  40 value 0.694859
iter  50 value 0.558962
iter  60 value 0.489150
iter  70 value 0.443676
iter  80 value 0.419805
iter  90 value 0.408656
iter 100 value 0.390370
final  value 0.390370 
stopped after 100 iterations
# weights:  67
initial  value 2714.859322 
iter  10 value 4.415399
iter  20 value 2.112835
iter  30 value 1.515048
iter  40 value 1.080288
iter  50 value 0.753259
iter  60 value 0.545898
iter  70 value 0.408175
iter  80 value 0.353425
iter  90 value 0.332926
iter 100 value 0.317383
final  value 0.317383 
stopped after 100 iterations
[Tune-y] 15: rmse.test.rmse=0.023; time: 0.0 min
[Tune-x] 16: size=16; decay=8.97
# weights:  177
initial  value 3392.617671 
iter  10 value 485.313463
iter  20 value 251.862095
iter  30 value 131.984454
iter  40 value 106.553520
iter  50 value 94.745592
iter  60 value 87.000518
iter  70 value 84.491650
iter  80 value 83.254254
iter  90 value 80.797172
iter 100 value 78.946674
final  value 78.946674 
stopped after 100 iterations
# weights:  177
initial  value 1436.263232 
iter  10 value 157.471294
iter  20 value 98.506051
iter  30 value 83.845865
iter  40 value 81.863771
iter  50 value 80.912772
iter  60 value 79.728512
iter  70 value 77.804297
iter  80 value 76.817784
iter  90 value 76.558196
iter 100 value 76.507313
final  value 76.507313 
stopped after 100 iterations
# weights:  177
initial  value 2052.578360 
iter  10 value 318.150351
iter  20 value 104.292162
iter  30 value 84.847782
iter  40 value 79.277191
iter  50 value 77.335089
iter  60 value 76.472718
iter  70 value 76.050981
iter  80 value 75.359742
iter  90 value 75.056725
iter 100 value 74.977153
final  value 74.977153 
stopped after 100 iterations
[Tune-y] 16: rmse.test.rmse=0.177; time: 0.0 min
[Tune-x] 17: size=7; decay=0.000548
# weights:  78
initial  value 465.064733 
iter  10 value 4.085669
iter  20 value 1.806607
iter  30 value 0.835357
iter  40 value 0.499234
iter  50 value 0.376479
iter  60 value 0.322084
iter  70 value 0.294876
iter  80 value 0.280348
iter  90 value 0.266986
iter 100 value 0.254994
final  value 0.254994 
stopped after 100 iterations
# weights:  78
initial  value 2030.027421 
iter  10 value 5.610838
iter  20 value 1.711892
iter  30 value 1.342669
iter  40 value 1.085740
iter  50 value 0.844713
iter  60 value 0.604949
iter  70 value 0.527802
iter  80 value 0.450562
iter  90 value 0.408350
iter 100 value 0.378692
final  value 0.378692 
stopped after 100 iterations
# weights:  78
initial  value 3955.485920 
iter  10 value 4.431657
iter  20 value 1.261165
iter  30 value 1.052426
iter  40 value 0.854429
iter  50 value 0.670989
iter  60 value 0.421901
iter  70 value 0.296238
iter  80 value 0.252938
iter  90 value 0.232184
iter 100 value 0.224428
final  value 0.224428 
stopped after 100 iterations
[Tune-y] 17: rmse.test.rmse=0.0209; time: 0.0 min
[Tune-x] 18: size=5; decay=0.0554
# weights:  56
initial  value 1429.571239 
iter  10 value 51.466930
iter  20 value 24.208456
iter  30 value 11.506179
iter  40 value 6.900540
iter  50 value 3.875600
iter  60 value 3.058380
iter  70 value 2.845731
iter  80 value 2.763769
iter  90 value 2.730356
iter 100 value 2.708828
final  value 2.708828 
stopped after 100 iterations
# weights:  56
initial  value 1622.460360 
iter  10 value 17.846387
iter  20 value 9.860181
iter  30 value 5.113279
iter  40 value 4.298181
iter  50 value 3.830719
iter  60 value 3.573839
iter  70 value 3.354581
iter  80 value 3.192826
iter  90 value 3.081644
iter 100 value 3.051905
final  value 3.051905 
stopped after 100 iterations
# weights:  56
initial  value 693.868673 
iter  10 value 5.665757
iter  20 value 2.835112
iter  30 value 2.546487
iter  40 value 2.464012
iter  50 value 2.444309
iter  60 value 2.429244
iter  70 value 2.425417
iter  80 value 2.421856
iter  90 value 2.419460
iter 100 value 2.418804
final  value 2.418804 
stopped after 100 iterations
[Tune-y] 18: rmse.test.rmse=0.0524; time: 0.0 min
[Tune-x] 19: size=16; decay=0.0217
# weights:  177
initial  value 915.970059 
iter  10 value 6.874832
iter  20 value 2.970329
iter  30 value 2.196626
iter  40 value 1.970874
iter  50 value 1.870155
iter  60 value 1.754765
iter  70 value 1.628598
iter  80 value 1.542144
iter  90 value 1.516150
iter 100 value 1.501075
final  value 1.501075 
stopped after 100 iterations
# weights:  177
initial  value 606.212244 
iter  10 value 6.379854
iter  20 value 2.780766
iter  30 value 2.214370
iter  40 value 2.001392
iter  50 value 1.930957
iter  60 value 1.897600
iter  70 value 1.884990
iter  80 value 1.877866
iter  90 value 1.870095
iter 100 value 1.863081
final  value 1.863081 
stopped after 100 iterations
# weights:  177
initial  value 1337.402891 
iter  10 value 10.961270
iter  20 value 4.235562
iter  30 value 3.170622
iter  40 value 2.599173
iter  50 value 2.039311
iter  60 value 1.738037
iter  70 value 1.578494
iter  80 value 1.523790
iter  90 value 1.496285
iter 100 value 1.468901
final  value 1.468901 
stopped after 100 iterations
[Tune-y] 19: rmse.test.rmse=0.0411; time: 0.0 min
[Tune-x] 20: size=17; decay=0.000183
# weights:  188
initial  value 2475.164603 
iter  10 value 6.612092
iter  20 value 1.910784
iter  30 value 0.893713
iter  40 value 0.526527
iter  50 value 0.340865
iter  60 value 0.258459
iter  70 value 0.206817
iter  80 value 0.178858
iter  90 value 0.167549
iter 100 value 0.155901
final  value 0.155901 
stopped after 100 iterations
# weights:  188
initial  value 4225.943741 
iter  10 value 103.257150
iter  20 value 5.390275
iter  30 value 1.246739
iter  40 value 0.900790
iter  50 value 0.734701
iter  60 value 0.627866
iter  70 value 0.514499
iter  80 value 0.431998
iter  90 value 0.344024
iter 100 value 0.263817
final  value 0.263817 
stopped after 100 iterations
# weights:  188
initial  value 1666.168080 
iter  10 value 3.468898
iter  20 value 1.275089
iter  30 value 0.905674
iter  40 value 0.587574
iter  50 value 0.346745
iter  60 value 0.288677
iter  70 value 0.240512
iter  80 value 0.200084
iter  90 value 0.173528
iter 100 value 0.154212
final  value 0.154212 
stopped after 100 iterations
[Tune-y] 20: rmse.test.rmse=0.0172; time: 0.0 min
[Tune] Result: size=17; decay=0.000183 : rmse.test.rmse=0.0172
# weights:  188
initial  value 3433.437546 
iter  10 value 7.138835
iter  20 value 2.192180
iter  30 value 1.055316
iter  40 value 0.601317
iter  50 value 0.418393
iter  60 value 0.302126
iter  70 value 0.256397
iter  80 value 0.227053
iter  90 value 0.203451
iter 100 value 0.192605
final  value 0.192605 
stopped after 100 iterations
[1] "Fri Feb 09 18:16:11 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.nodeHarvest no default is available.

 ... generating 1000 nodes ...
 total number of nodes in initial set                   : 1081
 total number of nodes after removal of identical nodes : 657 
 ... computing node means ... 
 ... computing node weights ...
 dimension of null space of I                           : 388
 number of selected nodes                               : 94 
[1] "Fri Feb 09 18:16:31 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.pcr no default is available.
[1] "Fri Feb 09 18:16:37 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.plsr no default is available.
In addition: Warning messages:
1: package '!penalized' is not available (for R version 3.4.3) 
2: package '!penalized' is not available (for R version 3.4.3) 
3: package '!penalized' is not available (for R version 3.4.3) 
[1] "Fri Feb 09 18:17:07 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.randomForestSRC no default is available.
[1] "Fri Feb 09 18:17:18 2018"
[Tune] Started tuning learner regr.ranger for parameter set:
                 Type len Def  Constr Req Tunable Trafo
mtry          integer   -   3  1 to 9   -    TRUE     -
min.node.size integer   -   5 1 to 10   -    TRUE     -
With control class: TuneControlRandom
Imputation value: Inf
[Tune-x] 1: mtry=1; min.node.size=6
[Tune-y] 1: rmse.test.rmse=0.0508; time: 0.0 min
[Tune-x] 2: mtry=6; min.node.size=4
[Tune-y] 2: rmse.test.rmse=0.033; time: 0.1 min
[Tune-x] 3: mtry=5; min.node.size=6
[Tune-y] 3: rmse.test.rmse=0.0336; time: 0.1 min
[Tune-x] 4: mtry=1; min.node.size=4
[Tune-y] 4: rmse.test.rmse=0.0481; time: 0.1 min
[Tune-x] 5: mtry=7; min.node.size=3
[Tune-y] 5: rmse.test.rmse=0.0341; time: 0.1 min
[Tune-x] 6: mtry=7; min.node.size=6
[Tune-y] 6: rmse.test.rmse=0.0359; time: 0.1 min
[Tune-x] 7: mtry=1; min.node.size=7
[Tune-y] 7: rmse.test.rmse=0.0514; time: 0.0 min
[Tune-x] 8: mtry=8; min.node.size=6
[Tune-y] 8: rmse.test.rmse=0.0372; time: 0.1 min
[Tune-x] 9: mtry=7; min.node.size=5
[Tune-y] 9: rmse.test.rmse=0.0349; time: 0.1 min
[Tune-x] 10: mtry=1; min.node.size=1
[Tune-y] 10: rmse.test.rmse=0.0449; time: 0.1 min
[Tune-x] 11: mtry=4; min.node.size=5
[Tune-y] 11: rmse.test.rmse=0.0329; time: 0.1 min
[Tune-x] 12: mtry=2; min.node.size=7
[Tune-y] 12: rmse.test.rmse=0.0379; time: 0.0 min
[Tune-x] 13: mtry=1; min.node.size=2
[Tune-y] 13: rmse.test.rmse=0.0461; time: 0.0 min
[Tune-x] 14: mtry=3; min.node.size=3
[Tune-y] 14: rmse.test.rmse=0.0325; time: 0.1 min
[Tune-x] 15: mtry=3; min.node.size=4
[Tune-y] 15: rmse.test.rmse=0.033; time: 0.1 min
[Tune-x] 16: mtry=8; min.node.size=10
[Tune-y] 16: rmse.test.rmse=0.0408; time: 0.1 min
[Tune-x] 17: mtry=4; min.node.size=3
[Tune-y] 17: rmse.test.rmse=0.0321; time: 0.1 min
[Tune-x] 18: mtry=3; min.node.size=7
[Tune-y] 18: rmse.test.rmse=0.035; time: 0.1 min
[Tune-x] 19: mtry=8; min.node.size=6
[Tune-y] 19: rmse.test.rmse=0.0373; time: 0.1 min
[Tune-x] 20: mtry=8; min.node.size=3
[Tune-y] 20: rmse.test.rmse=0.0355; time: 0.1 min
[Tune] Result: mtry=4; min.node.size=3 : rmse.test.rmse=0.0321
[1] "Fri Feb 09 18:19:06 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.rknn no default is available.
[1] "Fri Feb 09 18:19:15 2018"
[Tune] Started tuning learner regr.rpart for parameter set:
             Type len   Def   Constr Req Tunable Trafo
cp        numeric   - -6.64 -10 to 0   -    TRUE     Y
maxdepth  integer   -    30  3 to 30   -    TRUE     -
minbucket integer   -     7  5 to 50   -    TRUE     -
minsplit  integer   -    20  5 to 50   -    TRUE     -
With control class: TuneControlRandom
Imputation value: Inf
[Tune-x] 1: cp=0.000993; maxdepth=19; minbucket=35; minsplit=22
[Tune-y] 1: rmse.test.rmse=0.143; time: 0.0 min
[Tune-x] 2: cp=0.0283; maxdepth=17; minbucket=5; minsplit=21
[Tune-y] 2: rmse.test.rmse=0.223; time: 0.0 min
[Tune-x] 3: cp=0.15; maxdepth=10; minbucket=36; minsplit=30
[Tune-y] 3: rmse.test.rmse=0.374; time: 0.0 min
[Tune-x] 4: cp=0.00204; maxdepth=22; minbucket=44; minsplit=29
[Tune-y] 4: rmse.test.rmse=0.16; time: 0.0 min
[Tune-x] 5: cp=0.114; maxdepth=16; minbucket=5; minsplit=8
[Tune-y] 5: rmse.test.rmse=0.328; time: 0.0 min
[Tune-x] 6: cp=0.0111; maxdepth=15; minbucket=13; minsplit=36
[Tune-y] 6: rmse.test.rmse=0.158; time: 0.0 min
[Tune-x] 7: cp=0.00205; maxdepth=6; minbucket=18; minsplit=17
[Tune-y] 7: rmse.test.rmse=0.126; time: 0.0 min
[Tune-x] 8: cp=0.00688; maxdepth=12; minbucket=40; minsplit=50
[Tune-y] 8: rmse.test.rmse=0.157; time: 0.0 min
[Tune-x] 9: cp=0.0101; maxdepth=11; minbucket=15; minsplit=33
[Tune-y] 9: rmse.test.rmse=0.154; time: 0.0 min
[Tune-x] 10: cp=0.232; maxdepth=18; minbucket=43; minsplit=14
[Tune-y] 10: rmse.test.rmse=0.374; time: 0.0 min
[Tune-x] 11: cp=0.00603; maxdepth=15; minbucket=24; minsplit=41
[Tune-y] 11: rmse.test.rmse=0.152; time: 0.0 min
[Tune-x] 12: cp=0.00224; maxdepth=11; minbucket=30; minsplit=49
[Tune-y] 12: rmse.test.rmse=0.142; time: 0.0 min
[Tune-x] 13: cp=0.0203; maxdepth=21; minbucket=12; minsplit=40
[Tune-y] 13: rmse.test.rmse=0.198; time: 0.0 min
[Tune-x] 14: cp=0.29; maxdepth=16; minbucket=42; minsplit=42
[Tune-y] 14: rmse.test.rmse=0.374; time: 0.0 min
[Tune-x] 15: cp=0.0461; maxdepth=23; minbucket=5; minsplit=7
[Tune-y] 15: rmse.test.rmse=0.223; time: 0.0 min
[Tune-x] 16: cp=0.162; maxdepth=27; minbucket=47; minsplit=6
[Tune-y] 16: rmse.test.rmse=0.374; time: 0.0 min
[Tune-x] 17: cp=0.314; maxdepth=4; minbucket=30; minsplit=17
[Tune-y] 17: rmse.test.rmse=0.374; time: 0.0 min
[Tune-x] 18: cp=0.00156; maxdepth=8; minbucket=14; minsplit=46
[Tune-y] 18: rmse.test.rmse=0.12; time: 0.0 min
[Tune-x] 19: cp=0.0242; maxdepth=20; minbucket=36; minsplit=20
[Tune-y] 19: rmse.test.rmse=0.223; time: 0.0 min
[Tune-x] 20: cp=0.123; maxdepth=21; minbucket=44; minsplit=17
[Tune-y] 20: rmse.test.rmse=0.328; time: 0.0 min
[Tune] Result: cp=0.00156; maxdepth=8; minbucket=14; minsplit=46 : rmse.test.rmse=0.12
[1] "Fri Feb 09 18:19:24 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.rsm no default is available.
[1] "Fri Feb 09 18:19:30 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.rvm no default is available.
Using automatic sigma estimation (sigest) for RBF or laplace kernel 
[1] "Fri Feb 09 18:20:01 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.slim no default is available.
Sparse Linear Regression with L1 Regularization.
Square root Lasso with screening.

slim options summary: 
5 lambdas used:
[1] 0.9760 0.4730 0.2300 0.1110 0.0541
Method = lq 
q = 2 loss, SQRT Lasso
Degree of freedom: 0 -----> 4 
Runtime: 3.631207 secs 

 Values of predicted responses: 
   index             3 
   lambda       0.2297 
    Y 1          1.872 
    Y 2          2.738 
    Y 3          2.069 
    Y 4          1.918 
    Y 5           1.61 
[1] "Fri Feb 09 18:20:12 2018"
[Tune] Started tuning learner regr.xgboost for parameter set:
                    Type len Def       Constr Req Tunable Trafo
nrounds          numeric   -   0    0 to 8.64   -    TRUE     Y
max_depth        integer   -   6      1 to 10   -    TRUE     -
eta              numeric   - 0.3 0.001 to 0.6   -    TRUE     -
gamma            numeric   -   0      0 to 10   -    TRUE     -
colsample_bytree numeric   - 0.5   0.3 to 0.7   -    TRUE     -
min_child_weight numeric   -   1      0 to 20   -    TRUE     -
subsample        numeric   -   1    0.25 to 1   -    TRUE     -
With control class: TuneControlRandom
Imputation value: Inf
[Tune-x] 1: nrounds=10; max_depth=6; eta=0.393; gamma=3.84; colsample_bytree=0.494; min_child_weight=10.5; subsample=0.259
[Tune-y] 1: rmse.test.rmse=0.229; time: 0.0 min
[Tune-x] 2: nrounds=88; max_depth=8; eta=0.166; gamma=6.83; colsample_bytree=0.518; min_child_weight=2.13; subsample=0.759
[Tune-y] 2: rmse.test.rmse=0.199; time: 0.0 min
[Tune-x] 3: nrounds=1.77e+03; max_depth=6; eta=0.412; gamma=4.77; colsample_bytree=0.304; min_child_weight=1.51; subsample=0.513
[Tune-y] 3: rmse.test.rmse=0.192; time: 0.5 min
[Tune-x] 4: nrounds=131; max_depth=2; eta=0.418; gamma=1.07; colsample_bytree=0.357; min_child_weight=5.7; subsample=0.459
[Tune-y] 4: rmse.test.rmse=0.119; time: 0.0 min
[Tune-x] 5: nrounds=54; max_depth=4; eta=0.468; gamma=9.92; colsample_bytree=0.435; min_child_weight=5.8; subsample=0.418
[Tune-y] 5: rmse.test.rmse=0.254; time: 0.0 min
[Tune-x] 6: nrounds=420; max_depth=8; eta=0.334; gamma=8.42; colsample_bytree=0.384; min_child_weight=5.25; subsample=0.582
[Tune-y] 6: rmse.test.rmse=0.212; time: 0.2 min
[Tune-x] 7: nrounds=133; max_depth=8; eta=0.0728; gamma=2.98; colsample_bytree=0.525; min_child_weight=19.4; subsample=0.579
[Tune-y] 7: rmse.test.rmse=0.152; time: 0.0 min
[Tune-x] 8: nrounds=583; max_depth=2; eta=0.461; gamma=8.21; colsample_bytree=0.5; min_child_weight=16.3; subsample=0.863
[Tune-y] 8: rmse.test.rmse=0.189; time: 0.1 min
[Tune-x] 9: nrounds=280; max_depth=8; eta=0.00596; gamma=0.619; colsample_bytree=0.595; min_child_weight=17.5; subsample=0.939
[Tune-y] 9: rmse.test.rmse=0.262; time: 0.1 min
[Tune-x] 10: nrounds=11; max_depth=9; eta=0.0251; gamma=5.51; colsample_bytree=0.411; min_child_weight=1.35; subsample=0.391
[Tune-y] 10: rmse.test.rmse=0.959; time: 0.0 min
[Tune-x] 11: nrounds=36; max_depth=9; eta=0.278; gamma=6.14; colsample_bytree=0.572; min_child_weight=6.95; subsample=0.773
[Tune-y] 11: rmse.test.rmse=0.187; time: 0.0 min
[Tune-x] 12: nrounds=508; max_depth=9; eta=0.16; gamma=3.71; colsample_bytree=0.597; min_child_weight=16.1; subsample=0.786
[Tune-y] 12: rmse.test.rmse=0.152; time: 0.2 min
[Tune-x] 13: nrounds=767; max_depth=7; eta=0.25; gamma=7.33; colsample_bytree=0.633; min_child_weight=14.6; subsample=0.843
[Tune-y] 13: rmse.test.rmse=0.196; time: 0.3 min
[Tune-x] 14: nrounds=175; max_depth=6; eta=0.0983; gamma=9.05; colsample_bytree=0.55; min_child_weight=19.9; subsample=0.513
[Tune-y] 14: rmse.test.rmse=0.248; time: 0.0 min
[Tune-x] 15: nrounds=189; max_depth=3; eta=0.42; gamma=4.21; colsample_bytree=0.309; min_child_weight=18.5; subsample=0.399
[Tune-y] 15: rmse.test.rmse=0.189; time: 0.0 min
[Tune-x] 16: nrounds=172; max_depth=2; eta=0.412; gamma=9.59; colsample_bytree=0.598; min_child_weight=13.6; subsample=0.58
[Tune-y] 16: rmse.test.rmse=0.233; time: 0.0 min
[Tune-x] 17: nrounds=1.79e+03; max_depth=9; eta=0.0552; gamma=3.22; colsample_bytree=0.631; min_child_weight=3.64; subsample=0.526
[Tune-y] 17: rmse.test.rmse=0.155; time: 0.8 min
[Tune-x] 18: nrounds=3.93e+03; max_depth=6; eta=0.284; gamma=9.03; colsample_bytree=0.361; min_child_weight=3.27; subsample=0.666
[Tune-y] 18: rmse.test.rmse=0.212; time: 1.1 min
[Tune-x] 19: nrounds=292; max_depth=2; eta=0.595; gamma=0.0358; colsample_bytree=0.465; min_child_weight=12.2; subsample=0.386
[Tune-y] 19: rmse.test.rmse=0.0754; time: 0.0 min
[Tune-x] 20: nrounds=32; max_depth=8; eta=0.0486; gamma=7.04; colsample_bytree=0.369; min_child_weight=13.6; subsample=0.295
[Tune-y] 20: rmse.test.rmse=0.385; time: 0.0 min
[Tune] Result: nrounds=292; max_depth=2; eta=0.595; gamma=0.0358; colsample_bytree=0.465; min_child_weight=12.2; subsample=0.386 : rmse.test.rmse=0.0754
[1] "Fri Feb 09 18:23:43 2018"
Error in getDefaultParConfig(learner) : 
  For the learner regr.xyf no default is available.
Warning in train(allmodel, regr.task) :
  Could not train learner regr.xyf: Error in !toroidal : invalid argument type

[1] "Fri Feb 09 18:23:50 2018"
> ##########end#########
> #stopCluster(cl)
> ## reset message sink and close the file connection
> sink(type="message")
> close(zz)
Error in close(zz) : object 'zz' not found
Execution halted
